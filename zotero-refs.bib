
@book{schwab_fourth_2017,
title = {The {Fourth} {Industrial} {Revolution}},
isbn = {978-1-5247-5887-5},
abstract = {World-renowned economist Klaus Schwab, Founder and Executive Chairman of the World Economic Forum, explains that we have an opportunity to shape the fourth industrial revolu­tion, which will fundamentally alter how we live and work. Schwab argues that this revolution is different in scale, scope and complexity from any that have come before. Characterized by a range of new technologies that are fusing the physical, digital and biological worlds, the developments are affecting all disciplines, economies, industries and governments, and even challenging ideas about what it means to be human. Artificial intelligence is already all around us, from supercomputers, drones and virtual assistants to 3D printing, DNA sequencing, smart thermostats, wear­able sensors and microchips smaller than a grain of sand. But this is just the beginning: nanomaterials 200 times stronger than steel and a million times thinner than a strand of hair and the first transplant of a 3D printed liver are already in development. Imagine “smart factories” in which global systems of manu­facturing are coordinated virtually, or implantable mobile phones made of biosynthetic materials. The fourth industrial revolution, says Schwab, is more significant, and its ramifications more profound, than in any prior period of human history.   He outlines the key technologies driving this revolution and discusses the major impacts expected on government, business, civil society and individu­als. Schwab also offers bold ideas on how to harness these changes and shape a better future—one in which technology empowers people rather than replaces them; progress serves society rather than disrupts it; and in which innovators respect moral and ethical boundaries rather than cross them. We all have the opportunity to contribute to developing new frame­works that advance progress.},
language = {en},
publisher = {Crown},
author = {Schwab, Klaus},
month = jan,
year = {2017},
note = {Google-Books-ID: ST\_FDAAAQBAJ},
keywords = {Business \& Economics / Development / Economic Development, Business \& Economics / Economic History, Business \& Economics / Industries / Computers \& Information Technology},
}

@misc{standley_which_2020,
title = {Which {Tasks} {Should} {Be} {Learned} {Together} in {Multi}-task {Learning}?},
url = {http://arxiv.org/abs/1905.07553},
doi = {10.48550/arXiv.1905.07553},
abstract = {Many computer vision applications require solving multiple tasks in real-time. A neural network can be trained to solve multiple tasks simultaneously using multi-task learning. This can save computation at inference time as only a single network needs to be evaluated. Unfortunately, this often leads to inferior overall performance as task objectives can compete, which consequently poses the question: which tasks should and should not be learned together in one network when employing multi-task learning? We study task cooperation and competition in several different learning settings and propose a framework for assigning tasks to a few neural networks such that cooperating tasks are computed by the same neural network, while competing tasks are computed by different networks. Our framework offers a time-accuracy trade-off and can produce better accuracy using less inference time than not only a single large multi-task neural network but also many single-task networks.},
urldate = {2022-11-21},
publisher = {arXiv},
author = {Standley, Trevor and Zamir, Amir R. and Chen, Dawn and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
month = sep,
year = {2020},
note = {arXiv:1905.07553 [cs]},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{sriram_cold_2017,
title = {Cold {Fusion}: {Training} {Seq2Seq} {Models} {Together} with {Language} {Models}},
shorttitle = {Cold {Fusion}},
url = {http://arxiv.org/abs/1708.06426},
doi = {10.48550/arXiv.1708.06426},
abstract = {Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10\% of the labeled training data.},
urldate = {2022-11-17},
publisher = {arXiv},
author = {Sriram, Anuroop and Jun, Heewoo and Satheesh, Sanjeev and Coates, Adam},
month = aug,
year = {2017},
note = {arXiv:1708.06426 [cs]},
keywords = {Computer Science - Computation and Language},
}

@misc{gulcehre_using_2015,
title = {On {Using} {Monolingual} {Corpora} in {Neural} {Machine} {Translation}},
url = {http://arxiv.org/abs/1503.03535},
doi = {10.48550/arXiv.1503.03535},
abstract = {Recent work on end-to-end neural network-based architectures for machine translation has shown promising results for En-Fr and En-De translation. Arguably, one of the major factors behind this success has been the availability of high quality parallel corpora. In this work, we investigate how to leverage abundant monolingual corpora for neural machine translation. Compared to a phrase-based and hierarchical baseline, we obtain up to \$1.96\$ BLEU improvement on the low-resource language pair Turkish-English, and \$1.59\$ BLEU on the focused domain task of Chinese-English chat messages. While our method was initially targeted toward such tasks with less parallel data, we show that it also extends to high resource languages such as Cs-En and De-En where we obtain an improvement of \$0.39\$ and \$0.47\$ BLEU scores over the neural machine translation baselines, respectively.},
urldate = {2022-11-17},
publisher = {arXiv},
author = {Gulcehre, Caglar and Firat, Orhan and Xu, Kelvin and Cho, Kyunghyun and Barrault, Loic and Lin, Huei-Chi and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
month = jun,
year = {2015},
note = {arXiv:1503.03535 [cs]},
keywords = {Computer Science - Computation and Language},
}

@inproceedings{kannan_analysis_2018,
title = {An {Analysis} of {Incorporating} an {External} {Language} {Model} into a {Sequence}-to-{Sequence} {Model}},
doi = {10.1109/ICASSP.2018.8462682},
abstract = {Attention-based sequence-to-sequence models for automatic speech recognition jointly train an acoustic model, language model, and alignment mechanism. Thus, the language model component is only trained on transcribed audio-text pairs. This leads to the use of shallow fusion with an external language model at inference time. Shallow fusion refers to log-linear interpolation with a separately trained language model at each step of the beam search. In this work, we investigate the behavior of shallow fusion across a range of conditions: different types of language models, different decoding units, and different tasks. On Google Voice Search, we demonstrate that the use of shallow fusion with an neural LM with wordpieces yields a 9.1\% relative word error rate reduction (WERR) over our competitive attention-based sequence-to-sequence model, obviating the need for second-pass rescoring.},
booktitle = {2018 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
author = {Kannan, Anjuli and Wu, Yonghui and Nguyen, Patrick and Sainath, Tara N. and Chen, ZhiJeng and Prabhavalkar, Rohit},
month = apr,
year = {2018},
note = {ISSN: 2379-190X},
keywords = {Acoustics, Data models, Decoding, Google, Interpolation, Task analysis, Training},
pages = {1--5828},
}

@article{barth_let_2022,
title = {“{Let} {Me} {Get} {Back} to {You}”: {A} {Machine} {Learning} {Approach} to {Measuring} {NonAnswers}},
issn = {0025-1909},
shorttitle = {“{Let} {Me} {Get} {Back} to {You}”},
url = {https://pubsonline.informs.org/doi/10.1287/mnsc.2022.4597},
doi = {10.1287/mnsc.2022.4597},
abstract = {Using a supervised machine learning framework on a large training set of questions and answers, we identify 1,364 trigrams that signal nonanswers in earnings call questions and answers (Q\&A). We show that this glossary has economic relevance by applying it to contemporaneous stock market reactions after earnings calls. Our findings suggest that obstructing the flow of information leads to significantly lower cumulative abnormal stock returns and higher implied volatility. As both our method and glossary are free of financial context, we believe that the measure is applicable to other fields with a Q\&A setup outside the contextual domain of financial earnings conference calls.

This paper was accepted by Kay Giesecke, finance.

Supplemental Material: The data files are available at https://doi.org/10.1287/mnsc.2022.4597.},
urldate = {2022-11-17},
journal = {Management Science},
author = {Barth, Andreas and Mansouri, Sasan and Wöbbeking, Fabian},
month = nov,
year = {2022},
note = {Publisher: INFORMS},
keywords = {econlinguistics, multinomial inverse regression, natural language processing, nonanswers, textual analysis},
}

@article{bengio_representation_2013,
title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
volume = {35},
issn = {1939-3539},
shorttitle = {Representation {Learning}},
doi = {10.1109/TPAMI.2013.50},
abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
number = {8},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
month = aug,
year = {2013},
note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Abstracts, Boltzmann machine, Deep learning, Feature extraction, Learning systems, Machine learning, Manifolds, Neural networks, Speech recognition, autoencoder, feature learning, neural nets, representation learning, unsupervised learning},
pages = {1798--1828},
}

@article{davis_thats_1971,
title = {That's {Interesting}!: {Towards} a {Phenomenology} of {Sociology} and a {Sociology} of {Phenomenology}},
volume = {1},
issn = {0048-3931},
shorttitle = {That's {Interesting}!},
url = {https://doi.org/10.1177/004839317100100211},
doi = {10.1177/004839317100100211},
language = {en},
number = {2},
urldate = {2022-11-15},
journal = {Philosophy of the Social Sciences},
author = {Davis, Murray S.},
month = jun,
year = {1971},
note = {Publisher: SAGE Publications Inc},
pages = {309--344},
}

@article{zhang_group_2011,
title = {Group {Size} and {Incentives} to {Contribute}: {A} {Natural} {Experiment} at {Chinese} {Wikipedia}},
volume = {101},
issn = {0002-8282},
shorttitle = {Group {Size} and {Incentives} to {Contribute}},
url = {https://pubs.aeaweb.org/doi/10.1257/aer.101.4.1601},
doi = {10.1257/aer.101.4.1601},
abstract = {The literature on the private provision of public goods suggests an inverse relationship between incentives to contribute and group size. We find, however, that after an exogenous reduction of group size at Chinese Wikipedia, the nonblocked contributors decrease their contributions by 42.8 percent on average. We attribute the cause to social effects: contributors receive social benefits that increase with both the amount of their contributions and group size, and the shrinking group size weakens these social benefits. Consistent with our explanation, we find that the more contributors value social benefits, the more they reduce their contributions after the block. (JEL H41, L17, L82)},
language = {en},
number = {4},
urldate = {2022-10-25},
journal = {American Economic Review},
author = {Zhang, Xiaoquan (Michael) and Zhu, Feng},
month = jun,
year = {2011},
pages = {1601--1615},
}

@article{star_layers_1999,
title = {Layers of {Silence}, {Arenas} of {Voice}: {The} {Ecology} of {Visible} and {Invisible} {Work}},
volume = {8},
issn = {0925-9724, 1573-7551},
shorttitle = {Layers of {Silence}, {Arenas} of {Voice}},
url = {http://link.springer.com/10.1023/A:1008651105359},
doi = {10.1023/A:1008651105359},
abstract = {No work is inherently either visible or invisible. We always “see” work through a selection of indicators: straining muscles, ﬁnished artifacts, a changed state of affairs. The indicators change with context, and that context becomes a negotiation about the relationship between visible and invisible work. With shifts in industrial practice these negotiations require longer chains of inference and representation, and may become solely abstract.},
language = {en},
number = {1-2},
urldate = {2022-10-25},
journal = {Computer Supported Cooperative Work (CSCW)},
author = {Star, Susan Leigh and Strauss, Anselm},
month = mar,
year = {1999},
pages = {9--30},
}

@article{benbasat_identity_2003,
title = {The {Identity} {Crisis} within the {Is} {Discipline}: {Defining} and {Communicating} the {Discipline}'s {Core} {Properties}},
volume = {27},
issn = {02767783},
shorttitle = {The {Identity} {Crisis} within the {Is} {Discipline}},
url = {https://www.jstor.org/stable/10.2307/30036527},
doi = {10.2307/30036527},
language = {en},
number = {2},
urldate = {2022-10-25},
journal = {MIS Quarterly},
author = {{Benbasat} and {Zmud}},
year = {2003},
pages = {183},
}

@article{haunschild_modes_1997,
title = {Modes of {Interorganizational} {Imitation}: {The} {Effects} of {Outcome} {Salience} and {Uncertainty}},
volume = {42},
issn = {00018392},
shorttitle = {Modes of {Interorganizational} {Imitation}},
url = {https://www.jstor.org/stable/2393735?origin=crossref},
doi = {10.2307/2393735},
language = {en},
number = {3},
urldate = {2022-10-25},
journal = {Administrative Science Quarterly},
author = {Haunschild, Pamela R. and Miner, Anne S.},
month = sep,
year = {1997},
pages = {472},
}

@article{clemson_university_new_2015,
title = {New {State} of {Play} in {Information} {Systems} {Research}: {The} {Push} to the {Edges}},
volume = {39},
issn = {02767783, 21629730},
shorttitle = {New {State} of {Play} in {Information} {Systems} {Research}},
url = {https://misq.org/new-state-of-play-in-information-systems-research-the-push-to-the-edges.html},
doi = {10.25300/MISQ/2015/39.2.01},
language = {en},
number = {2},
urldate = {2022-10-25},
journal = {MIS Quarterly},
author = {{Clemson University} and Grover, Varun and Lyytinen, Kalle and {Case Western Reserve University}},
month = feb,
year = {2015},
pages = {271--296},
}

@article{shugan_editorial_2003,
title = {Editorial: {Defining} {Interesting} {Research} {Problems}},
volume = {22},
issn = {0732-2399, 1526-548X},
shorttitle = {Editorial},
url = {http://pubsonline.informs.org/doi/10.1287/mksc.22.1.1.12848},
doi = {10.1287/mksc.22.1.1.12848},
abstract = {We argue that research problems are only interesting relative to some external audience. Interesting academic research should impact, at least, that external audience. Hence, we should target our research toward specific external audiences. Several foreboding trends that exacerbate the urgency of this targeting are discussed. To facilitate the targeting task, a partial list of fifteen possible audiences for academic research in marketing is identified. We discuss some of them, including practitioners, in detail. For example, we conclude that, for our research to be interesting to practitioners, practitioners must have the ability to improve and to make better decisions with enhanced understanding. Finally, we strongly suggest that we focus our research on fundamental problems in marketing. These are problems with the property that external audiences would first look to the marketing literature for answers.},
language = {en},
number = {1},
urldate = {2022-10-25},
journal = {Marketing Science},
author = {Shugan, Steven M.},
month = feb,
year = {2003},
pages = {1--15},
}

@article{mcknight_initial_2022,
title = {Initial {Trust} {Formation} in {New} {Organizational} {Relationships}},
language = {en},
author = {Mcknight, D Harrison},
year = {2022},
pages = {19},
}

@article{teo_predicting_2003,
title = {Predicting {Intention} to {Adopt} {Interorganizational} {Linkages}: {An} {Institutional} {Perspective}},
volume = {27},
issn = {02767783},
shorttitle = {Predicting {Intention} to {Adopt} {Interorganizational} {Linkages}},
url = {https://www.jstor.org/stable/10.2307/30036518},
doi = {10.2307/30036518},
language = {en},
number = {1},
urldate = {2022-10-25},
journal = {MIS Quarterly},
author = {{Teo} and {Wei} and {Benbasat}},
year = {2003},
pages = {19},
}

@article{follett_teacher-student_1970,
title = {The {Teacher}-{Student} {Relation}},
volume = {15},
issn = {00018392},
url = {https://www.jstor.org/stable/2391484?origin=crossref},
doi = {10.2307/2391484},
language = {en},
number = {2},
urldate = {2022-10-25},
journal = {Administrative Science Quarterly},
author = {Follett, Mary Parker},
month = jun,
year = {1970},
pages = {137},
}

@article{bass_new_2022,
title = {A {New} {Product} {Growth} for {Model} {Consumer} {Durables}},
language = {en},
author = {Bass, Frank M},
year = {2022},
pages = {14},
}

@article{van_maanen_song_2010,
title = {A {Song} for {My} {Supper}: {More} {Tales} of the {Field}},
volume = {13},
issn = {1094-4281, 1552-7425},
shorttitle = {A {Song} for {My} {Supper}},
url = {http://journals.sagepub.com/doi/10.1177/1094428109343968},
doi = {10.1177/1094428109343968},
abstract = {This essay tries to be true to a podium talk I presented at a conference in March, 2008. But, of necessity, certain consolidation liberties are taken. Beginning with a brief and broad treatment of ethnography as a paired written representation of and lengthy personal experience in a particular social world, I move to consider why the former, the text, has been so infrequently examined in lieu of the latter, the so-called method. I then move to ethnographic texts themselves and look at what I take to be some broad changes the seem apparent — particularly within the organizational ethnography domain — over the past 20 or so years. Alongside these changes comes the emergence of several distinct genres treated only lightly (or not at all) in Tales of the Field. I end by considering what seems to have stayed the course in ethnography and why.},
language = {en},
number = {2},
urldate = {2022-10-25},
journal = {Organizational Research Methods},
author = {Van Maanen, John},
month = apr,
year = {2010},
pages = {240--255},
}

@book{chalmers_what_1999,
address = {Indianapolis},
edition = {3rd ed},
title = {What is this thing called science?},
isbn = {978-0-87220-452-2 978-0-87220-453-9},
language = {en},
publisher = {Hackett Pub},
author = {Chalmers, A. F.},
year = {1999},
keywords = {Philosophy, Science},
}

@article{simon_future_nodate,
title = {The future of information systems},
language = {en},
author = {Simon, Herbert A},
pages = {12},
}

@article{orlikowski_duality_1992,
title = {The {Duality} of {Technology}: {Rethinking} the {Concept} of {Technology} in {Organizations}},
volume = {3},
issn = {1047-7039, 1526-5455},
shorttitle = {The {Duality} of {Technology}},
url = {http://pubsonline.informs.org/doi/10.1287/orsc.3.3.398},
doi = {10.1287/orsc.3.3.398},
abstract = {This paper develops a new theoretical model with which to examine the interaction between technology and organizations. Early research studies assumed technology to be an objective, external force that would have deterministic impacts on organizational properties such as structure. Later researchers focused on the human aspect of technology, seeing it as the outcome of strategic choice and social action. This paper suggests that either view is incomplete, and proposes a reconceptualization of technology that takes both perspectives into account. A theoretical model—the structurational model of technology—is built on the basis of this new conceptualization, and its workings explored through discussion of a field study of information technology. The paper suggests that the reformulation of the technology concept and the structurational model of technology allow a deeper and more dialectical understanding of the interaction between technology and organizations. This understanding provides insight into the limits and opportunities of human choice, technology development and use, and organizational design. Implications for future research of the new concept of technology and the structurational model of technology are discussed.},
language = {en},
number = {3},
urldate = {2022-10-25},
journal = {Organization Science},
author = {Orlikowski, Wanda J.},
month = aug,
year = {1992},
pages = {398--427},
}

@article{gioia_seeking_2013,
title = {Seeking {Qualitative} {Rigor} in {Inductive} {Research}: {Notes} on the {Gioia} {Methodology}},
volume = {16},
issn = {1094-4281, 1552-7425},
shorttitle = {Seeking {Qualitative} {Rigor} in {Inductive} {Research}},
url = {http://journals.sagepub.com/doi/10.1177/1094428112452151},
doi = {10.1177/1094428112452151},
abstract = {For all its richness and potential for discovery, qualitative research has been critiqued as too often lacking in scholarly rigor. The authors summarize a systematic approach to new concept development and grounded theory articulation that is designed to bring ‘‘qualitative rigor’’ to the conduct and presentation of inductive research.},
language = {en},
number = {1},
urldate = {2022-10-25},
journal = {Organizational Research Methods},
author = {Gioia, Dennis A. and Corley, Kevin G. and Hamilton, Aimee L.},
month = jan,
year = {2013},
pages = {15--31},
}

@article{siggelkow_evolution_2002,
title = {Evolution toward {Fit}},
volume = {47},
issn = {0001-8392, 1930-3815},
url = {http://journals.sagepub.com/doi/10.2307/3094893},
doi = {10.2307/3094893},
abstract = {This paper uses a longitudinal case study of the mutual fund provider, The Vanguard Group, to understand the developmental processes that lead to organizational configurations and fit. A new method for determining an organization's core elements is developed, and four processes are identified that describe the creation and subsequent elaboration of these core elements: thickening (reinforcement of an existing core element by new elaborating elements), patching (creation of a new core element and its reinforcement by new elaborating elements), coasting (no further elaboration of a new core element in a given period), and trimming (deletion of a core element and its elaborating elements). The four processes are used to describe organizations' development paths toward configurations and their transitions between configurations, including two new ideal types, termed thin-to-thick and patch-by-patch, as well as two known paths between configurations, the punctuated equilibrium path and reorientation through linear progression.},
language = {en},
number = {1},
urldate = {2022-10-25},
journal = {Administrative Science Quarterly},
author = {Siggelkow, Nicolaj},
month = mar,
year = {2002},
pages = {125--159},
}

@article{andriani_perspective_2009,
title = {\textbf{{Perspective}} —{From} {Gaussian} to {Paretian} {Thinking}: {Causes} and {Implications} of {Power} {Laws} in {Organizations}},
volume = {20},
issn = {1047-7039, 1526-5455},
shorttitle = {\textbf{{Perspective}} —{From} {Gaussian} to {Paretian} {Thinking}},
url = {http://pubsonline.informs.org/doi/10.1287/orsc.1090.0481},
doi = {10.1287/orsc.1090.0481},
abstract = {Although normal distributions and related current quantitative methods are still relevant for some organizational research, the growing ubiquity of power laws signifies that Pareto rank/frequency distributions, fractals, and underlying scale-free theories are increasingly pervasive and valid characterizations of organizational dynamics. When they apply, researchers ignoring power-law effects risk drawing false conclusions and promulgating useless advice to practitioners. This is because what is important to most managers are the extremes they face, not the averages. We show that power laws are pervasive in the organizational world and present 15 scale-free theories that apply to organizations. Next we discuss research implications embedded in Pareto rank/frequency distributions and draw statistical and methodological implications.},
language = {en},
number = {6},
urldate = {2022-10-25},
journal = {Organization Science},
author = {Andriani, Pierpaolo and McKelvey, Bill},
month = dec,
year = {2009},
pages = {1053--1071},
}

@book{latour_pandoras_1999,
address = {Cambridge, Mass},
title = {Pandora's hope: essays on the reality of science studies},
isbn = {978-0-674-65335-1 978-0-674-65336-8},
shorttitle = {Pandora's hope},
language = {en},
publisher = {Harvard University Press},
author = {Latour, Bruno},
year = {1999},
keywords = {Philosophy, Realism, Science},
}

@article{grant_publishing_2011,
title = {Publishing in \textit{{AMJ}} —{Part} 3: {Setting} the {Hook}},
volume = {54},
issn = {0001-4273, 1948-0989},
shorttitle = {Publishing in \textit{{AMJ}} —{Part} 3},
url = {http://journals.aom.org/doi/10.5465/amj.2011.4000},
doi = {10.5465/amj.2011.4000},
language = {en},
number = {5},
urldate = {2022-10-25},
journal = {Academy of Management Journal},
author = {Grant, Adam M. and Pollock, Timothy G.},
month = oct,
year = {2011},
pages = {873--879},
}

@article{vaughan_theorizing_2004,
title = {Theorizing {Disaster}: {Analogy}, historical ethnography, and the {Challenger} accident},
volume = {5},
issn = {1466-1381, 1741-2714},
shorttitle = {Theorizing {Disaster}},
url = {http://journals.sagepub.com/doi/10.1177/1466138104045659},
doi = {10.1177/1466138104045659},
abstract = {Building explanations from data is an important but usually invisible process behind all published research. Here I reconstruct my theorizing for an historical ethnography of the 1986 Space Shuttle Challenger disaster and the NASA (National Aeronautical and Space Administration) decisions that produced that accident. I show how analogical theorizing, a method that compares similar events or activities across different social settings, leads to more refined and generalizable theoretical explanations. Revealing the utility of mistakes in theorizing, I show how my mistakes uncovered mistakes in the documentary record, converting my analysis to a revisionist account that contradicted the conventional explanation accepted at the time. Retracing how I developed the concepts and theory that explained the case demonstrates the connection between historic political and economic forces, organization structure and processes, and cultural understandings and actions at NASA. Finally, these analytic reflections show how analysis, writing, and theorizing are integrated throughout the research process.},
language = {en},
number = {3},
urldate = {2022-10-25},
journal = {Ethnography},
author = {Vaughan, Diane},
month = sep,
year = {2004},
pages = {315--347},
}

@article{simon_random_1991,
title = {Random {Thoughts} {About} {Methods} of {Research}},
language = {en},
journal = {Research Methods},
author = {Simon, Herbert A},
year = {1991},
pages = {11},
}

@article{noauthor_generating_2022,
title = {{GENERATING} {RESEARCH} {QUESTIONS} {THROUGH} {PROBLEMATIZATION}},
language = {en},
year = {2022},
pages = {26},
}

@article{faulkner_theorizing_nodate,
title = {{THEORIZING} {THE} {DIGITAL} {OBJECT}},
abstract = {Prompted by perceived shortcomings of prevailing conceptualizations of digital technology in IS, we propose a theory aimed at capturing both the ontological complexity of digital objects qua objects, and how their identity and use is bound up with various social associations. We begin with what it is to be an object, the differences between material and nonmaterial objects, and various categories of nonmaterial objects including syntactic objects and bitstrings. Building on these categories we develop a conception of digital objects and a novel “bearer” theory of how material and nonmaterial objects combine. The role of computation is considered, and how the identity and system functions of digital objects flow from their social positioning in the communities in which they arise. Various implications of the theory are identified, focusing on its use as a conceptual frame through which to view digital phenomena, and its potential to inform existing perspectives with regard both to how digital technology per se and the relationship between people and digital technology should be theorized. These implications are illustrated with reference to secondary markets for software, the treatment of digital resources in the resource-based, knowledge-based, and service-dominant logic views of organizing, and recent work on sociomateriality.},
language = {en},
author = {Faulkner, Philip and Runde, Jochen},
pages = {25},
}

@incollection{mitchell_organization_2011,
title = {Organization {Science}},
isbn = {978-1-84980-763-0},
url = {http://www.elgaronline.com/view/9781849807623.00024.xml},
language = {en},
urldate = {2022-10-25},
booktitle = {In {Search} of {Research} {Excellence}},
publisher = {Edward Elgar Publishing},
author = {Sine, Wesley D.},
collaborator = {Mitchell, Ronald and Dino, Richard},
year = {2011},
doi = {10.4337/9781849807630.00024},
pages = {14204},
}

@article{ross_organizational_1993,
title = {{ORGANIZATIONAL} {ESCALATION} {AND} {EXIT}: {LESSONS} {FROM} {THE} {SHOREHAM} {NUCLEAR} {POWER} {PLANT}.},
volume = {36},
issn = {0001-4273, 1948-0989},
shorttitle = {{ORGANIZATIONAL} {ESCALATION} {AND} {EXIT}},
url = {http://amj.aom.org/cgi/doi/10.2307/256756},
doi = {10.2307/256756},
language = {en},
number = {4},
urldate = {2022-10-25},
journal = {Academy of Management Journal},
author = {Ross, J. and Staw, B. M.},
month = aug,
year = {1993},
pages = {701--732},
}

@article{gjerde_sandwiched_2020,
title = {Sandwiched: {Exploring} role and identity of middle managers in the genuine middle},
volume = {73},
issn = {0018-7267, 1741-282X},
shorttitle = {Sandwiched},
url = {http://journals.sagepub.com/doi/10.1177/0018726718823243},
doi = {10.1177/0018726718823243},
abstract = {This article explores middle managers in the professions from their position in the sandwiched middle. Based upon interviews with senior academics in management roles and their subordinates in UK business schools, we investigate this experienced middle through a metaphor that informs one particular subject position: to be an umbrella carrier. This position entails protecting subordinates from what is seen as unnecessary and/or damaging initiatives and information from top management above, in order to allow for good professional work to take place below. This form of countermanagement, which aims to weaken hierarchical pressure rather than enforce or uphold it, is informed by a stronger identification with the profession and subordinates below than with the leader role or the superiors above, and aids the middle managers in their identity work.},
language = {en},
number = {1},
urldate = {2022-10-25},
journal = {Human Relations},
author = {Gjerde, Susann and Alvesson, Mats},
month = jan,
year = {2020},
pages = {124--151},
}

@article{walsham_doing_2006,
title = {Doing interpretive research},
volume = {15},
issn = {0960-085X, 1476-9344},
url = {https://www.tandfonline.com/doi/full/10.1057/palgrave.ejis.3000589},
doi = {10.1057/palgrave.ejis.3000589},
abstract = {Interpretive research in information systems (IS) is now a well-established part of the field. However, there is a need for more material on how to carry out such work from inception to publication. I published a paper a decade ago (Walsham, 1995) which addressed the nature of interpretive IS case studies and methods for doing such research. The current paper extends this earlier contribution, with a widened scope of all interpretive research in IS, and through further material on carrying out fieldwork, using theory and analysing data. In addition, new topics are discussed on constructing and justifying a research contribution, and on ethical issues and tensions in the conduct of interpretive work. The primary target audience for the paper is lessexperienced IS researchers, but I hope that the paper will also stimulate reflection for the more-experienced IS researcher and be of relevance to interpretive researchers in other social science fields.},
language = {en},
number = {3},
urldate = {2022-10-25},
journal = {European Journal of Information Systems},
author = {Walsham, Geoff},
month = jun,
year = {2006},
pages = {320--330},
}

@article{university_of_notre_dame_beyond_2018,
title = {Beyond the {Privacy} {Paradox}: {Objective} {Versus} {Relative} {Risk} in {Privacy} {Decision} {Making}},
volume = {42},
issn = {02767783, 21629730},
shorttitle = {Beyond the {Privacy} {Paradox}},
url = {https://misq.org/beyond-the-privacy-paradox-objective-versus-relative-risk-in-privacy-decision-making.html},
doi = {10.25300/MISQ/2018/14316},
abstract = {Privacy decision making has been examined in the literature from alternative perspectives. A dominant “normative” perspective has focused on rational processes by which consumers with stable preferences for privacy weigh the expected benefits of privacy choices against their potential costs. More recently, a behavioral perspective has leveraged theories from decision research to construe privacy decision making as a process in which cognitive heuristics and biases predictably occur. In a series of experiments, we compare the predictive power of these two perspectives by evaluating the impact of changes in the objective risk of disclosure and the impact of changes in the relative perceptions of risk of disclosure on both hypothetical and actual consumer privacy choices. We find that both relative and objective risks can, in fact, influence consumer privacy decisions. However, and surprisingly, the impact of objective changes in risk diminishes between hypothetical and actual choice settings. Vice versa, the impact of relative risk becomes more pronounced going from hypothetical to actual choice settings. Our results suggest a way to integrate diverse streams of the information systems literature on privacy decision making: in hypothetical choice contexts, relative to actual choice contexts, consumers may both overestimate their response to normative factors and underestimate their response to behavioral factors.},
language = {en},
number = {2},
urldate = {2022-10-25},
journal = {MIS Quarterly},
author = {{University of Notre Dame} and Adjerid, Idris and Peer, Eyal and {Bar-Ilan University} and Acquisti, Alessandro and {Carnegie Mellon University}},
month = feb,
year = {2018},
pages = {465--488},
}

@article{noauthor_society_2022,
title = {The {Society} of {Mind}},
language = {en},
year = {2022},
pages = {15},
}

@article{varian_how_nodate,
title = {How to {Build} an {Economic} {Model} in {Your} {Spare} {Time}},
abstract = {This is an essay for Passion and Craft: Economists at Work, edited by Michael Szenberg, University of Michigan Press, 1997.},
language = {en},
author = {Varian, Hal R},
pages = {17},
}

@article{the_australian_national_university_positioning_2013,
title = {Positioning and {Presenting} {Design} {Science} {Research} for {Maximum} {Impact}},
volume = {37},
issn = {02767783, 21629730},
url = {https://misq.org/positioning-and-presenting-design-science-research-for-maximum-impact.html},
doi = {10.25300/MISQ/2013/37.2.01},
language = {en},
number = {2},
urldate = {2022-10-25},
journal = {MIS Quarterly},
author = {{The Australian National University} and Gregor, Shirley and Hevner, Alan R. and {University of South Florida}},
month = feb,
year = {2013},
pages = {337--355},
}

@article{hevner_design_nodate,
title = {{DESIGN} {SCIENCE} {IN} {INFORMATION} {SYSTEMS} {RESEARCH}},
language = {en},
author = {Hevner, Alan R and Ram, Sudha},
pages = {31},
}

@article{markus_information_1988,
title = {Information {Technology} and {Organizational} {Change}: {Causal} {Structure} in {Theory} and {Research}},
volume = {34},
issn = {0025-1909, 1526-5501},
shorttitle = {Information {Technology} and {Organizational} {Change}},
url = {http://pubsonline.informs.org/doi/10.1287/mnsc.34.5.583},
doi = {10.1287/mnsc.34.5.583},
abstract = {This article concerns theories about why and how information technology affects organizational life. Good theory guides research, which, when applied, increases the likelihood that information technology will be employed with desirable consequences for users, organizations, and other interested parties.
        But what is a good theory? Theories are often evaluated in terms of their content—the specific concepts used and the human values served. This article examines theories in terms of their structures—theorists' assumptions about the nature and direction of causal influence. Three dimensions of causal structure are considered—causal agency, logical structure, and level of analysis. Causal agency refers to beliefs about the nature of causality: whether external forces cause change, whether people act purposefully to accomplish intended objectives, or whether changes emerge unpredictably from the interaction of people and events. Logical structure refers to the temporal aspect of theory—static versus dynamic—and to the logical relationships between the “causes” and the outcomes. Level of analysis refers to the entities about which the theory poses concepts and relationships—individuals, groups, organizations, and society.
        While there are many possible structures for good theory about the role of information technology in organizational change, only a few of these structures can be seen in current theorizing. Increased awareness of the options, open discussion of their advantages and disadvantages, and explicit characterization of future theoretical statements in terms of the dimensions and categories discussed here should, we believe, promote the development of better theory.},
language = {en},
number = {5},
urldate = {2022-10-25},
journal = {Management Science},
author = {Markus, M. Lynne and Robey, Daniel},
month = may,
year = {1988},
pages = {583--598},
}

@article{locke_constructing_1997,
title = {{CONSTRUCTING} {OPPORTUNITIES} {FOR} {CONTRIBUTION}: {STRUCTURING} {INTERTEXTUAL} {COHERENCE} {AND} "{PROBLEMATIZING}" {IN} {ORGANIZATIONAL} {STUDIES}.},
volume = {40},
issn = {0001-4273, 1948-0989},
shorttitle = {{CONSTRUCTING} {OPPORTUNITIES} {FOR} {CONTRIBUTION}},
url = {http://amj.aom.org/cgi/doi/10.2307/256926},
doi = {10.2307/256926},
language = {en},
number = {5},
urldate = {2022-10-25},
journal = {Academy of Management Journal},
author = {Locke, K. and Golden-Biddle, K.},
month = oct,
year = {1997},
pages = {1023--1062},
}

@article{weick_collapse_2022,
title = {The {Collapse} of {Sensemaking} in {Organizations}: {The} {Mann} {Gulch} {Disaster}},
language = {en},
author = {Weick, Karl E},
year = {2022},
pages = {26},
}

@article{schultze_confessional_2000,
title = {A {Confessional} {Account} of an {Ethnography} about {Knowledge} {Work}},
volume = {24},
issn = {02767783},
url = {https://www.jstor.org/stable/3250978?origin=crossref},
doi = {10.2307/3250978},
abstract = {Information systems research has traditionally focused on information as an object that serves as input to decision making. Such a perspective attends mainly to the use of information. Increasingly, however, organizations are concerned about the production of information. This paper focuses on the work of producing informational objects, an activity central to knowledge work. Based on data collected during an eight-month ethnographic study of three groups of knowledge workers—computer system administrators, competitive intelligence analysts, and librarians—I explore the informing practices they relied upon. These are identified as ex-pressing, monitoring, and translating. Common to these informing practices is the knowledge workers’ endeavor to balance subjectivity and objectivity, where subjectivity is a necessary part of doing value adding work and objectivity promises workers authority and a sense of security.},
language = {en},
number = {1},
urldate = {2022-10-25},
journal = {MIS Quarterly},
author = {Schultze, Ulrike},
month = mar,
year = {2000},
pages = {3},
}

@article{fitzgerald_towards_nodate,
title = {Towards {Dissolution} of the is {Research} {Debate}: {From} {Polarization} to {Polarity}},
language = {en},
author = {Fitzgerald, Brian and Howcroft, Debra},
pages = {14},
}

@article{lin_first_2021,
title = {First, {Do} {No} {Harm}: {Predictive} {Analytics} to {Reduce} {In}-{Hospital} {Adverse} {Events}},
volume = {38},
issn = {0742-1222},
shorttitle = {First, {Do} {No} {Harm}},
url = {https://doi.org/10.1080/07421222.2021.1990619},
doi = {10.1080/07421222.2021.1990619},
abstract = {Inadequate patient safety is a serious issue in current medical practice. Medical errors cause adverse events (AEs) for patients and lead to premature deaths, unintended complications, prolonged hospital stays, and higher medical costs. Although the importance of AE prediction and prevention is well recognized in the information systems literature, there is a dearth of research on modeling and predicting AEs caused by medical errors. Following the design science research paradigm, this study describes the search, design, and evaluation of a novel in-hospital AE prediction model, called Stochastic Autoregressions for Latent Trajectories (SALT). The proposed model uniquely integrates generalized linear mixed model with multitask learning and stochastic time-series processes. Results from our empirical evaluation show that SALT outperforms prior state-of-the-art techniques in predicting AEs during patients’ hospital stays. Through a simulation, we further demonstrate significant cost savings potential when hospitals implement and integrate SALT in their inpatient care. This study contributes to the design science literature by formalizing the in-hospital AE prediction problem, on the one hand, and developing a novel graphical model to address the prediction problem, on the other. For healthcare practitioners and administrators, our predictive analytics approach unveils important insights to minimize AEs.},
number = {4},
urldate = {2022-10-24},
journal = {Journal of Management Information Systems},
author = {Lin, Yu-Kai and Fang, Xiao},
month = oct,
year = {2021},
note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/07421222.2021.1990619},
keywords = {HealthTech, adverse events, design science, healthcare predictive analytics, medical errors, patient safety},
pages = {1122--1149},
}

@incollection{chute_medical_2005,
address = {Boston, MA},
series = {Integrated {Series} in {Information} {Systems}},
title = {Medical {Concept} {Representation}},
isbn = {978-0-387-25739-6},
url = {https://doi.org/10.1007/0-387-25739-X_6},
abstract = {The description of concepts in the biomedical domain spans levels of precision, complexity, implicit knowledge, and breadth of application that makes the knowledge representation problem more challenging than that in virtually any other domain. This chapter reviews some of this breadth in the form of use-cases, and highlights some of the challenges confronted, including variability among the properties of terminologies, classifications, and ontologies. Special challenges arise at the semantic boundary between information and terminology models, which are not resolvable on one side of either boundary. The problems of aggregation are considered, together with the requirement for rule-based logic when mapping information described using detailed terminologies to high-level classifications. Finally, the challenge of semantic interoperability, arguably the goal of all standards efforts, is explored with respect to medical concept representation.},
language = {en},
urldate = {2022-10-24},
booktitle = {Medical {Informatics}: {Knowledge} {Management} and {Data} {Mining} in {Biomedicine}},
publisher = {Springer US},
author = {Chute, Christopher G.},
editor = {Chen, Hsinchun and Fuller, Sherrilynne S. and Friedman, Carol and Hersh, William},
year = {2005},
doi = {10.1007/0-387-25739-X_6},
keywords = {biomedical concepts, classification, ontology, terminology, vocabulary},
pages = {163--182},
}

@misc{chen_integration_2022,
title = {Integration of knowledge and data in machine learning},
url = {http://arxiv.org/abs/2202.10337},
doi = {10.48550/arXiv.2202.10337},
abstract = {Scientific research's mandate is to comprehend and explore the world, as well as to improve it based on experience and knowledge. Knowledge embedding and knowledge discovery are two significant methods of integrating knowledge and data. Through knowledge embedding, the barriers between knowledge and data can be eliminated, and machine learning models with physical common sense can be established. Meanwhile, humans' understanding of the world is always limited, and knowledge discovery takes advantage of machine learning to extract new knowledge from observations. Knowledge discovery can not only assist researchers to better grasp the nature of physics, but it can also support them in conducting knowledge embedding research. A closed loop of knowledge generation and usage are formed by combining knowledge embedding with knowledge discovery, which can improve the robustness and accuracy of models and uncover previously unknown scientific principles. This study summarizes and analyzes extant literature, as well as identifies research gaps and future opportunities.},
urldate = {2022-10-12},
publisher = {arXiv},
author = {Chen, Yuntian and Zhang, Dongxiao},
month = apr,
year = {2022},
note = {arXiv:2202.10337 [cs]},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@inproceedings{bai_medical_2019,
title = {Medical {Concept} {Representation} {Learning} from {Multi}-source {Data}},
url = {https://www.ijcai.org/proceedings/2019/680},
abstract = {Electronic proceedings of IJCAI 2019},
urldate = {2022-10-11},
author = {Bai, Tian and Egleston, Brian L. and Bleicher, Richard and Vucetic, Slobodan},
year = {2019},
pages = {4897--4903},
}

@article{hussain_exploring_2020,
title = {Exploring the dominant features of social media for depression detection},
volume = {46},
issn = {0165-5515},
url = {https://doi.org/10.1177/0165551519860469},
doi = {10.1177/0165551519860469},
abstract = {Recently, social media have been used by researchers to detect depressive symptoms in individuals using linguistic data from users’ posts. In this study, we propose a framework to identify social information as a significant predictor of depression. Using the proposed framework, we develop an application called the Socially Mediated Patient Portal (SMPP), which detects depression-related markers in Facebook users by applying a data-driven approach with machine learning classification techniques. We examined a data set of 4350 users who were evaluated for depression using the Center for Epidemiological Studies Depression (CES-D) scale. From this analysis, we identified a set of features that can distinguish between individuals with and without depression. Finally, we identified the dominant features that adequately assess individuals with and without depression on social media. The model trained on these features will be helpful to physicians in diagnosing mental diseases and psychiatrists in analysing patient behaviour.},
language = {en},
number = {6},
urldate = {2022-08-25},
journal = {Journal of Information Science},
author = {Hussain, Jamil and Satti, Fahad Ahmed and Afzal, Muhammad and Khan, Wajahat Ali and Bilal, Hafiz Syed Muhammad and Ansaar, Muhammad Zaki and Ahmad, Hafiz Farooq and Hur, Taeho and Bang, Jaehun and Kim, Jee-In and Park, Gwang Hoon and Seung, Hyonwoo and Lee, Sungyoung},
month = dec,
year = {2020},
note = {Publisher: SAGE Publications Ltd},
keywords = {Depression, Facebook, mental illness, value-added information},
pages = {739--759},
}

@misc{dhariwal_diffusion_2021,
title = {Diffusion {Models} {Beat} {GANs} on {Image} {Synthesis}},
url = {http://arxiv.org/abs/2105.05233},
doi = {10.48550/arXiv.2105.05233},
abstract = {We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128\${\textbackslash}times\$128, 4.59 on ImageNet 256\${\textbackslash}times\$256, and 7.72 on ImageNet 512\${\textbackslash}times\$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256\${\textbackslash}times\$256 and 3.85 on ImageNet 512\${\textbackslash}times\$512. We release our code at https://github.com/openai/guided-diffusion},
urldate = {2022-10-06},
publisher = {arXiv},
author = {Dhariwal, Prafulla and Nichol, Alex},
month = jun,
year = {2021},
note = {arXiv:2105.05233 [cs, stat]},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{cong_alphaportfolio_2021,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {{AlphaPortfolio}: {Direct} {Construction} {Through} {Deep} {Reinforcement} {Learning} and {Interpretable} {AI}},
shorttitle = {{AlphaPortfolio}},
url = {https://papers.ssrn.com/abstract=3554486},
doi = {10.2139/ssrn.3554486},
abstract = {We directly optimize the objectives of portfolio management via deep reinforcement learning---an alternative to conventional supervised-learning paradigms that routinely entail first-step estimations of return distributions or risk premia. We develop multi-sequence, attention-based neural-network models tailored for the distinguishing features of financial big data, while allowing interactions with the market states and training without labels. Such AlphaPortfolio models yield stellar out-of-sample performances (e.g., Sharpe ratio above two and over 13\% risk-adjusted alpha with monthly re-balancing) that are robust under various market conditions and economic restrictions (e.g., exclusion of small and illiquid stocks). We further demonstrate AlphaPortfolio's flexibility to incorporate transaction costs, state interactions, and alternative objectives, before applying polynomial-feature-sensitivity analysis to uncover key drivers of investment performance, including their rotation and nonlinearity. Overall, we highlight the utility of deep reinforcement learning in finance and "economic distillation" for model interpretation.},
language = {en},
urldate = {2022-09-29},
author = {Cong, Lin William and Tang, Ke and Wang, Jingyuan and Zhang, Yang},
month = aug,
year = {2021},
keywords = {Artificial Intelligence, Distillation, LSTM, Machine Learning, Portfolio Theory, Reinforcement Learning.},
}

@misc{yang_deep_2021,
title = {Deep {Reinforcement} {Learning} for {Automated} {Stock} {Trading}},
url = {https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02},
abstract = {Trade multiple stocks using DRL {\textbar} ICAIF 2020},
language = {en},
urldate = {2022-09-28},
journal = {Medium},
author = {Yang, Bruce},
month = oct,
year = {2021},
}

@misc{noauthor_9deep_nodate,
title = {9.{Deep} {Reinforcement} {Learning}},
}

@article{cao_man_nodate,
title = {From {Man} vs. {Machine} to {Man} + {Machine}: {The} {Art} and {AI} of {Stock} {Analyses}},
abstract = {We train an AI analyst that digests corporate disclosures, industry trends, and macroeconomic indicators to the extent it beats most analysts. Human wins the “Man vs. Machine” contest when a ﬁrm is complex with intangible assets, and AI wins when information is transparent but voluminous. Analysts catch up with machines over time, especially after ﬁrms are covered by alternative data and their institutions build AI capabilities. AI power and human wisdom are complementary in generating accurate forecasts and mitigating extreme errors, portraying a future of “Man + Machine” (instead of human displacement) in ﬁnancial analyses, and likely other high-skill professions.},
language = {en},
author = {Cao, Sean and Jiang, Wei and Wang, Junbo and Yang, Baozhong},
pages = {64},
}

@inproceedings{chen_knowprompt_2022,
title = {{KnowPrompt}: {Knowledge}-aware {Prompt}-tuning with {Synergistic} {Optimization} for {Relation} {Extraction}},
shorttitle = {{KnowPrompt}},
url = {http://arxiv.org/abs/2104.07650},
doi = {10.1145/3485447.3511998},
abstract = {Recently, prompt-tuning has achieved promising results for specific few-shot classification tasks. The core idea of prompt-tuning is to insert text pieces (i.e., templates) into the input and transform a classification task into a masked language modeling problem. However, for relation extraction, determining an appropriate prompt template requires domain expertise, and it is cumbersome and time-consuming to obtain a suitable label word. Furthermore, there exists abundant semantic and prior knowledge among the relation labels that cannot be ignored. To this end, we focus on incorporating knowledge among relation labels into prompt-tuning for relation extraction and propose a Knowledge-aware Prompt-tuning approach with synergistic optimization (KnowPrompt). Specifically, we inject latent knowledge contained in relation labels into prompt construction with learnable virtual type words and answer words. Then, we synergistically optimize their representation with structured constraints. Extensive experimental results on five datasets with standard and low-resource settings demonstrate the effectiveness of our approach. Our code and datasets are available in https://github.com/zjunlp/KnowPrompt for reproducibility.},
urldate = {2022-09-24},
booktitle = {Proceedings of the {ACM} {Web} {Conference} 2022},
author = {Chen, Xiang and Zhang, Ningyu and Xie, Xin and Deng, Shumin and Yao, Yunzhi and Tan, Chuanqi and Huang, Fei and Si, Luo and Chen, Huajun},
month = apr,
year = {2022},
note = {arXiv:2104.07650 [cs]},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
pages = {2778--2788},
}

@article{jiang_how_2020,
title = {How {Can} {We} {Know} {What} {Language} {Models} {Know}?},
volume = {8},
url = {https://aclanthology.org/2020.tacl-1.28},
doi = {10.1162/tacl_a_00324},
abstract = {Recent work has presented intriguing results examining the knowledge contained in language models (LMs) by having the LM fill in the blanks of prompts such as “Obama is a \_\_ by profession”. These prompts are usually manually created, and quite possibly sub-optimal; another prompt such as “Obama worked as a \_\_ ” may result in more accurately predicting the correct profession. Because of this, given an inappropriate prompt, we might fail to retrieve facts that the LM does know, and thus any given prompt only provides a lower bound estimate of the knowledge contained in an LM. In this paper, we attempt to more accurately estimate the knowledge contained in LMs by automatically discovering better prompts to use in this querying process. Specifically, we propose mining-based and paraphrasing-based methods to automatically generate high-quality and diverse prompts, as well as ensemble methods to combine answers from different prompts. Extensive experiments on the LAMA benchmark for extracting relational knowledge from LMs demonstrate that our methods can improve accuracy from 31.1\% to 39.6\%, providing a tighter lower bound on what LMs know. We have released the code and the resulting LM Prompt And Query Archive (LPAQA) at https://github.com/jzbjyb/LPAQA.},
urldate = {2022-09-24},
journal = {Transactions of the Association for Computational Linguistics},
author = {Jiang, Zhengbao and Xu, Frank F. and Araki, Jun and Neubig, Graham},
year = {2020},
note = {Place: Cambridge, MA
Publisher: MIT Press},
pages = {423--438},
}

@inproceedings{gao_making_2021,
address = {Online},
title = {Making {Pre}-trained {Language} {Models} {Better} {Few}-shot {Learners}},
url = {https://aclanthology.org/2021.acl-long.295},
doi = {10.18653/v1/2021.acl-long.295},
abstract = {The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot performance solely by leveraging a natural-language prompt and a few task demonstrations as input context. Inspired by their findings, we study few-shot learning in a more practical scenario, where we use smaller language models for which fine-tuning is computationally efficient. We present LM-BFF—better few-shot fine-tuning of language models—a suite of simple and complementary techniques for fine-tuning language models on a small number of annotated examples. Our approach includes (1) prompt-based fine-tuning together with a novel pipeline for automating prompt generation; and (2) a refined strategy for dynamically and selectively incorporating demonstrations into each context. Finally, we present a systematic evaluation for analyzing few-shot performance on a range of NLP tasks, including classification and regression. Our experiments demonstrate that our methods combine to dramatically outperform standard fine-tuning procedures in this low resource setting, achieving up to 30\% absolute improvement, and 11\% on average across all tasks. Our approach makes minimal assumptions on task resources and domain expertise, and hence constitutes a strong task-agnostic method for few-shot learning.},
urldate = {2022-09-24},
booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
publisher = {Association for Computational Linguistics},
author = {Gao, Tianyu and Fisch, Adam and Chen, Danqi},
month = aug,
year = {2021},
pages = {3816--3830},
}

@misc{shin_autoprompt_2020,
title = {{AutoPrompt}: {Eliciting} {Knowledge} from {Language} {Models} with {Automatically} {Generated} {Prompts}},
shorttitle = {{AutoPrompt}},
url = {http://arxiv.org/abs/2010.15980},
doi = {10.48550/arXiv.2010.15980},
abstract = {The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.},
urldate = {2022-09-24},
publisher = {arXiv},
author = {Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L. and Wallace, Eric and Singh, Sameer},
month = nov,
year = {2020},
note = {arXiv:2010.15980 [cs]},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@inproceedings{haviv_bertese_2021,
address = {Online},
title = {{BERTese}: {Learning} to {Speak} to {BERT}},
shorttitle = {{BERTese}},
url = {https://aclanthology.org/2021.eacl-main.316},
doi = {10.18653/v1/2021.eacl-main.316},
abstract = {Large pre-trained language models have been shown to encode large amounts of world and commonsense knowledge in their parameters, leading to substantial interest in methods for extracting that knowledge. In past work, knowledge was extracted by taking manually-authored queries and gathering paraphrases for them using a separate pipeline. In this work, we propose a method for automatically rewriting queries into “BERTese”, a paraphrase query that is directly optimized towards better knowledge extraction. To encourage meaningful rewrites, we add auxiliary loss functions that encourage the query to correspond to actual language tokens. We empirically show our approach outperforms competing baselines, obviating the need for complex pipelines. Moreover, BERTese provides some insight into the type of language that helps language models perform knowledge extraction.},
urldate = {2022-09-24},
booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
publisher = {Association for Computational Linguistics},
author = {Haviv, Adi and Berant, Jonathan and Globerson, Amir},
month = apr,
year = {2021},
pages = {3618--3623},
}

@misc{liu_pre-train_2021,
title = {Pre-train, {Prompt}, and {Predict}: {A} {Systematic} {Survey} of {Prompting} {Methods} in {Natural} {Language} {Processing}},
shorttitle = {Pre-train, {Prompt}, and {Predict}},
url = {http://arxiv.org/abs/2107.13586},
doi = {10.48550/arXiv.2107.13586},
abstract = {This paper surveys and organizes research works in a new paradigm in natural language processing, which we dub "prompt-based learning". Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y{\textbar}x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x' that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: it allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this paper we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g.the choice of pre-trained models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts, but also release other resources, e.g., a website http://pretrain.nlpedia.ai/ including constantly-updated survey, and paperlist.},
urldate = {2022-09-17},
publisher = {arXiv},
author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
month = jul,
year = {2021},
note = {arXiv:2107.13586 [cs]},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{zhao_exploiting_nodate,
title = {Exploiting {Expert} {Knowledge} for {Assigning} {Firms} to {Industries}: {A} {Novel} {Deep} {Learning} {Method}},
abstract = {Industry assignment, which assigns firms to industries according to a predefined Industry Classification System (ICS), is fundamental to a large number of critical business practices, ranging from operations and strategic decision making by firms to economic analyses by government agencies. Three types of expert knowledge are essential to effective industry assignment: definition-based knowledge (i.e., expert definitions of each industry), structure-based knowledge (i.e., structural relationships among industries as specified in an ICS), and assignment-based knowledge (i.e., prior firm-industry assignments performed by domain experts). Existing industry assignment methods utilize only assignment-based knowledge to learn a model that classifies unassigned firms to industries, and overlook definition-based and structure-based knowledge. Moreover, these methods only consider which industry a firm has been assigned to, but ignore the time-specificity of assignment-based knowledge, i.e., when the assignment occurs. To address the limitations of existing methods, we propose a novel deep learning-based method that not only seamlessly integrates the three types of knowledge for industry assignment but also takes the time-specificity of assignment-based knowledge into account. Methodologically, our method features two innovations: dynamic industry representation and hierarchical assignment. The former represents an industry as a sequence of time-specific vectors by integrating the three types of knowledge through our proposed temporal and spatial aggregation mechanisms. The latter takes industry and firm representations as inputs, computes the probability of assigning a firm to different industries, and assigns the firm to the industry with the highest probability. We conduct extensive evaluations with two widely used ICSs and demonstrate the superiority of our method over prevalent existing methods.},
language = {en},
author = {Zhao, Xiaohang and Fang, Xiao and He, Jing and Huang, Lihua},
pages = {46},
}

@article{hacker_writers_nodate,
title = {A {Writer}'s {Reference}},
language = {en},
author = {Hacker, Diana},
pages = {652},
}

@misc{baker_policy_2019,
type = {Working {Paper}},
series = {Working {Paper} {Series}},
title = {Policy {News} and {Stock} {Market} {Volatility}},
url = {https://www.nber.org/papers/w25720},
doi = {10.3386/w25720},
abstract = {We create a newspaper-based Equity Market Volatility (EMV) tracker that moves with the VIX and with the realized volatility of returns on the S\&P 500. Parsing the underlying text, we find that 72 percent of EMV articles discuss the Macroeconomic Outlook, and 44 percent discuss Commodity Markets. Policy news is another major source of volatility: 35 percent of EMV articles refer to Fiscal Policy (mostly Tax Policy), 30 percent discuss Monetary Policy, 25 percent refer to one or more forms of Regulation, and 13 percent mention National Security matters. The contribution of particular policy areas fluctuates greatly over time. Trade Policy news, for example, went from a virtual nonfactor in equity market volatility to a leading source after Donald Trump’s election and especially after the intensification of U.S-China trade tensions. The share of EMV articles with attention to government policy rises over time, reaching its peak in 2017-18. We validate our measurement approach in various ways. For example, tailoring our EMV tracker to news about petroleum markets yields a measure that rises and falls with the implied and realized volatility of oil prices.},
urldate = {2022-09-15},
publisher = {National Bureau of Economic Research},
author = {Baker, Scott R. and Bloom, Nicholas and Davis, Steven J. and Kost, Kyle J.},
month = mar,
year = {2019},
doi = {10.3386/w25720},
}

@article{hassan_firm-level_nodate,
title = {{FIRM}-{LEVEL} {POLITICAL} {RISK}: {MEASUREMENT} {AND} {EFFECTS}},
abstract = {We adapt simple tools from computational linguistics to construct a new measure of political risk faced by individual US ﬁrms: the share of their quarterly earnings conference calls that they devote to political risks. We validate our measure by showing it correctly identiﬁes calls containing extensive conversations on risks that are political in nature, that it varies intuitively over time and across sectors, and that it correlates with the ﬁrm’s actions and stock market volatility in a manner that is highly indicative of political risk. Firms exposed to political risk retrench hiring and investment and actively lobby and donate to politicians. These results continue to hold after controlling for news about the mean (as opposed to the variance) of political shocks. Interestingly, the vast majority of the variation in our measure is at the ﬁrm level rather than at the aggregate or sector level, in the sense that it is neither captured by the interaction of sector and time ﬁxed eﬀects, nor by heterogeneous exposure of individual ﬁrms to aggregate political risk. The dispersion of this ﬁrm-level political risk increases signiﬁcantly at times with high aggregate political risk. Decomposing our measure of political risk by topic, we ﬁnd that ﬁrms that devote more time to discussing risks associated with a given political topic tend to increase lobbying on that topic, but not on other topics, in the following quarter.},
language = {en},
author = {Hassan, Tarek A and van Lent, Laurence and Hollander, Stephan and Tahoun, Ahmed},
pages = {52},
}

@article{routledge_machine_2019,
title = {Machine learning and asset allocation},
volume = {48},
issn = {1755-053X},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/fima.12303},
doi = {10.1111/fima.12303},
abstract = {Investors have access to a large array of structured and unstructured data. We consider how these data can be incorporated into financial decisions through the lens of the canonical asset allocation decision. We characterize investor preference for simplicity in models of the data used in the asset allocation decision. The simplicity parameters then guide asset allocation along with the usual risk aversion parameter. We use three distinct and diverse macroeconomic data sets to implement the model to forecast equity returns (the equity risk premium). The data sets we use are (a) price-dividend ratios, (b) an array of macroeconomic series, and (c) text data from the Federal Reserve's Federal Open Market Committee (FOMC) meetings.},
language = {en},
number = {4},
urldate = {2022-09-15},
journal = {Financial Management},
author = {Routledge, Bryan R.},
year = {2019},
note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/fima.12303},
pages = {1069--1094},
}

@article{baird_writing_2021,
title = {On {Writing} {Research} {Articles} {Well}:  {A} {Guide} for {Writing} {IS} {Papers}},
volume = {22},
issn = {1536-9323},
shorttitle = {On {Writing} {Research} {Articles} {Well}},
url = {https://aisel.aisnet.org/jais/vol22/iss5/11},
doi = {10.17705/1jais.00711},
number = {5},
journal = {Journal of the Association for Information Systems},
author = {Baird, Aaron},
month = jan,
year = {2021},
pages = {1197--1211},
}

@article{kane_how_2022,
title = {How to {Write} an “{A}” {Paper}},
volume = {23},
issn = {1536-9323},
url = {https://aisel.aisnet.org/jais/vol23/iss5/9},
doi = {10.17705/1jais.00765},
number = {5},
journal = {Journal of the Association for Information Systems},
author = {Kane, Gerald},
month = jan,
year = {2022},
pages = {1071--1079},
}

@book{salganik_bit_2019,
title = {Bit by {Bit}: {Social} {Research} in the {Digital} {Age}},
isbn = {978-0-691-19610-7},
shorttitle = {Bit by {Bit}},
abstract = {An innovative and accessible guide to doing social research in the digital age. In just the past several years, we have witnessed the birth and rapid spread of social media, mobile phones, and numerous other digital marvels. In addition to changing how we live, these tools enable us to collect and process data about human behavior on a scale never before imaginable, offering entirely new approaches to core questions about social behavior. Bit by Bit is the key to unlocking these powerful methods-a landmark book that will fundamentally change how the next generation of social scientists and data scientists explores the world around us. Bit by Bit is the essential guide to mastering the key principles of doing social research in this fast-evolving digital age. In this comprehensive yet accessible book, Matthew Salganik explains how the digital revolution is transforming how social scientists observe behavior, ask questions, run experiments, and engage in mass collaborations. He provides a wealth of real-world examples throughout, and also lays out a principles-based approach to handling ethical challenges in the era of social media. Bit by Bit is an invaluable resource for social scientists who want to harness the research potential of big data and a must-read for data scientists interested in applying the lessons of social science to tomorrow's technologies.},
language = {en},
publisher = {Princeton University Press},
author = {Salganik, Matthew J.},
month = aug,
year = {2019},
note = {Google-Books-ID: 58iXDwAAQBAJ},
keywords = {Computers / Computer Science, Computers / Information Technology, Computers / Internet / General, Computers / Internet / Search Engines, Social Science / Media Studies, Social Science / Methodology, Social Science / Popular Culture, Social Science / Research, Social Science / Sociology / General, Social Science / Statistics, digital trace},
}

@book{foster_managing_2016,
title = {Managing {Digital} {Cultural} {Objects}: {Analysis}, discovery and retrieval},
isbn = {978-1-85604-941-2},
shorttitle = {Managing {Digital} {Cultural} {Objects}},
abstract = {This book explores the analysis and interpretation, discovery and retrieval of a variety of non-textual objects, including image, music and moving image. Bringing together chapters written by leading experts in the field, this book provides an overview of the theoretical and academic aspects of digital cultural documentation and considers both technical and strategic issues relating to cultural heritage projects, digital asset management and sustainability. Managing Digital Cultural Objects: Analysis, discovery and retrieval draws from disciplines including information retrieval, library and information science (LIS), digital preservation, digital humanities, cultural theory, digital media studies and art history. It’s argued that this multidisciplinary and interdisciplinary approach is both necessary and useful in the age of the ubiquitous and mobile Web. Key topics covered include: •	Managing, searching and finding digital cultural objects •	Data modelling for analysis, discovery and retrieval •	Social media data as a historical source •	Visual digital humanities •	Digital preservation of audio content •	Searching and creating affinities in web music collections •	Film retrieval on the web. Readership: The book will provide inspiration for students seeking to develop creative and innovative research projects at Masters and PhD levels and will be essential reading for those studying digital cultural object management as well as practitioners in the field.},
language = {en},
publisher = {Facet Publishing},
author = {Foster, Allen and Rafferty, Pauline},
month = jul,
year = {2016},
note = {Google-Books-ID: 3AcUDgAAQBAJ},
keywords = {Language Arts \& Disciplines / Library \& Information Science / General, digital trace},
}

@misc{noauthor_strengths_nodate,
title = {Strengths \& {Weaknesses} of {Digital} {Trace} {Data}},
url = {https://sicss.io/2020/materials/day2-digital-trace-data/strengths-weaknesses/rmarkdown/Strengths_and_Weaknesses.html},
urldate = {2022-09-12},
keywords = {digital trace},
}

@article{monteiro_qualitative_nodate,
title = {Qualitative {Methods} in {IS}: {A} {Call} for {Phenomenon}-focused {Problematization}},
language = {en},
author = {Monteiro, Eric and Constantinides, Panos and Scott, Susan and Shaikh, Maha and Burton-Jones, Andrew},
pages = {31},
}

@inproceedings{lin_sensemood_2020,
address = {New York, NY, USA},
series = {{ICMR} '20},
title = {{SenseMood}: {Depression} {Detection} on {Social} {Media}},
isbn = {978-1-4503-7087-5},
shorttitle = {{SenseMood}},
url = {https://doi.org/10.1145/3372278.3391932},
doi = {10.1145/3372278.3391932},
abstract = {More than 300 million people have been affected by depression all over the world. Due to the medical equipment and knowledge limitations, most of them are not diagnosed at the early stages. Recent work attempts to use social media to detect depression since the patterns of opinions and thoughts expression of the posted text and images, can reflect users' mental state to some extent. In this work, we design a system dubbed SenseMood to demonstrate that the users with depression can be efficiently detected and analyzed by using proposed system. A deep visual-textual multimodal learning approach has been proposed to reveal the psychological state of the users on social networks. The posted images and tweets data from users with/without depression on Twitter have been collected and used for depression detection. CNN-based classifier and Bert are applied to extract the deep features from the pictures and text posted by users respectively. Then visual and textual features are combined to reflect the emotional expression of users. Finally our system classifies the users with depression and normal users through a neural network and the analysis report is generated automatically.},
urldate = {2022-08-25},
booktitle = {Proceedings of the 2020 {International} {Conference} on {Multimedia} {Retrieval}},
publisher = {Association for Computing Machinery},
author = {Lin, Chenhao and Hu, Pengwei and Su, Hui and Li, Shaochun and Mei, Jing and Zhou, Jie and Leung, Henry},
month = jun,
year = {2020},
keywords = {deep neural network, depression detection, multimodal learning},
pages = {407--411},
}

@misc{hu_optimal_2020,
title = {Optimal {Sparse} {Decision} {Trees}},
url = {http://arxiv.org/abs/1904.12847},
doi = {10.48550/arXiv.1904.12847},
abstract = {Decision tree algorithms have been among the most popular algorithms for interpretable (transparent) machine learning since the early 1980's. The problem that has plagued decision tree algorithms since their inception is their lack of optimality, or lack of guarantees of closeness to optimality: decision tree algorithms are often greedy or myopic, and sometimes produce unquestionably suboptimal models. Hardness of decision tree optimization is both a theoretical and practical obstacle, and even careful mathematical programming approaches have not been able to solve these problems efficiently. This work introduces the first practical algorithm for optimal decision trees for binary variables. The algorithm is a co-design of analytical bounds that reduce the search space and modern systems techniques, including data structures and a custom bit-vector library. Our experiments highlight advantages in scalability, speed, and proof of optimality.},
urldate = {2022-08-23},
publisher = {arXiv},
author = {Hu, Xiyang and Rudin, Cynthia and Seltzer, Margo},
month = sep,
year = {2020},
note = {arXiv:1904.12847 [cs, stat]},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{rai_editors_2017,
title = {Editor's {Comments}:  {Diversity} of {Design} {Science} {Research}},
volume = {41},
issn = {ISSN 0276-7783/ISSN 2162-9730},
shorttitle = {Editor's {Comments}},
url = {https://aisel.aisnet.org/misq/vol41/iss1/2},
number = {1},
journal = {Management Information Systems Quarterly},
author = {Rai, Arun},
month = mar,
year = {2017},
pages = {iii--xviii},
}

@article{bhogal_pattern_2017,
title = {Pattern {Analysis} of {Oxygen} {Saturation} {Variability} in {Healthy} {Individuals}: {Entropy} of {Pulse} {Oximetry} {Signals} {Carries} {Information} about {Mean} {Oxygen} {Saturation}},
volume = {8},
issn = {1664-042X},
shorttitle = {Pattern {Analysis} of {Oxygen} {Saturation} {Variability} in {Healthy} {Individuals}},
url = {https://www.frontiersin.org/articles/10.3389/fphys.2017.00555},
abstract = {Pulse oximetry is routinely used for monitoring patients' oxygen saturation levels with little regard to the variability of this physiological variable. There are few published studies on oxygen saturation variability (OSV), with none describing the variability and its pattern in a healthy adult population. The aim of this study was to characterize the pattern of OSV using several parameters; the regularity (sample entropy analysis), the self-similarity [detrended fluctuation analysis (DFA)] and the complexity [multiscale entropy (MSE) analysis]. Secondly, to determine if there were any changes that occur with age. The study population consisted of 36 individuals. The “young” population consisted of 20 individuals [Mean (±1 SD) age = 21.0 (±1.36 years)] and the “old” population consisted of 16 individuals [Mean (±1 SD) age = 50.0 (±10.4 years)]. Through DFA analysis, OSV was shown to exhibit fractal-like patterns. The sample entropy revealed the variability to be more regular than heart rate variability and respiratory rate variability. There was also a significant inverse correlation between mean oxygen saturation and sample entropy in healthy individuals. Additionally, the MSE analysis described a complex fluctuation pattern, which was reduced with age (p {\textless} 0.05). These findings suggest partial “uncoupling” of the cardio-respiratory control system that occurs with aging. Overall, this study has characterized OSV using pre-existing tools. We have showed that entropy analysis of pulse oximetry signals carries information about body oxygenation. This may have the potential to be used in clinical practice to detect differences in diseased patient subsets.},
urldate = {2022-08-06},
journal = {Frontiers in Physiology},
author = {Bhogal, Amar S. and Mani, Ali R.},
year = {2017},
}

@inproceedings{yin_domain_2019,
title = {Domain {Knowledge} {Guided} {Deep} {Learning} with {Electronic} {Health} {Records}},
doi = {10.1109/ICDM.2019.00084},
abstract = {Due to their promising performance in clinical risk prediction with Electronic Health Records (EHRs), deep learning methods have attracted significant interest from healthcare researchers. However, there are 4 challenges: (i) Data insufficiency. Many methods require large amounts of training data to achieve satisfactory results. (ii) Interpretability. Results from many methods are hard to explain to clinicians (e.g., why the models make particular predictions and which events cause clinical outcomes). (iii) Domain knowledge integration. No existing method dynamically exploits complicated medical knowledge (e.g., relations such as cause and is-caused-by between clinical events). (iv) Time interval information. Most existing methods only consider the relative order of visits from EHRs, but ignore the irregular time intervals between neighboring visits. In the study, we propose a new model, Domain Knowledge Guided Recurrent Neural Networks (DG-RNN), by directly introducing domain knowledge from the medical knowledge graph into an RNN architecture, as well as taking the irregular time intervals into account. Experimental results on heart failure risk prediction tasks show that our model not only outperforms state-of-the-art deep-learning based risk prediction models, but also associates individual medical events with heart failure onset, thus paving the way for interpretable accurate clinical risk predictions.},
booktitle = {2019 {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM})},
author = {Yin, Changchang and Zhao, Rongjian and Qian, Buyue and Lv, Xin and Zhang, Ping},
month = nov,
year = {2019},
note = {ISSN: 2374-8486},
keywords = {EHR, RNN, deep learning, knowledge graph, risk prediction},
pages = {738--747},
}

@article{pittappilly_vital_2019,
title = {Vital signs on hospital discharge and re admission rates},
volume = {112},
issn = {1460-2725},
url = {https://doi.org/10.1093/qjmed/hcz002},
doi = {10.1093/qjmed/hcz002},
abstract = {Assessing the stability of a patient's vital signs in the 24 hours before discharge has been suggested as an objective and inexpensive way to determine safety for discharge.To determine the association between unstable vital signs at the time of discharge with the readmission rate over a one-year period.An observational cohort multi-center study at three urban community hospitals using electronic health record data collected from November 1, 2016, to October 30, 2017.A total of 29322 hospitalizations to medical floors with complete sets of vital signs were included. The final vital signs collected on the day of discharge were used for analysis. The readmission rates were compared using different variables such as age, sex, insurance payer (Medicare or Medicaid), discharge time, discharge disposition, length of stay at the hospital, the number, and type of abnormal vital signs at discharge.Unstable vital signs at discharge were found in 2862 patients (9.8\%). The readmission rate was highest in patients with two (11.3\%) unstable vital signs compared to those with one (8.5\%) and three or more (0\%) instabilities. Patients with a combination of heart rate \&gt;100 beats/min and respiratory rate \&gt;20 breaths/min at discharge had a 14.1\% seven-day readmission rate (P = 0.0057, Odds Ratio = 1.87, Confidence Interval = 1.19–2.95).Vital sign instabilities in the 24 hours before discharge are associated with increased seven-day readmission rate.},
number = {4},
urldate = {2022-08-09},
journal = {QJM: An International Journal of Medicine},
author = {Pittappilly, M and Sarao, M S and Bambach, W L and Helmuth, A and Nookala, V},
month = apr,
year = {2019},
pages = {275--279},
}

@article{donnelly_hospital_2019,
title = {Hospital readmission rates: the importance of unstable vital signs on discharge},
volume = {112},
issn = {1460-2725},
shorttitle = {Hospital readmission rates},
url = {https://doi.org/10.1093/qjmed/hcz059},
doi = {10.1093/qjmed/hcz059},
abstract = {Hospital readmissions are costly to patients, the healthcare system and society. A significant portion of healthcare spending is attributed to the cost of readmissions. Annual costs of up to \$17 billion in the USA have been classified as potentially avoidable. In the US healthcare system, hospitals with higher readmission rates are penalized financially with a reduction in Medicare payments of up to 3\% if the hospital is deemed to have a higher-than-expected number of readmissions.Therefore, we welcome the study by Dr Pittappilly and colleagues from the University of Pittsburgh Medical Centre who analysed whether an individual patients unstable vital signs 24 h prior to discharge was a marker of a patient group with a significantly higher 7-day readmission rate. They report on an impressive 29 322 acute medical admissions across their healthcare group and found a significant enhanced readmission rate with one or more unstable vital signs. In particular, a combined heart rate \&gt; 100/min and a respiratory rate \&gt; 20 breaths/min was associated with a 165\% enhanced chance of readmission compared with those with one unstable sign only. In addition the authors found an added significant risk of readmission when the patients were discharged out-of normal working hours.},
number = {4},
urldate = {2022-08-09},
journal = {QJM: An International Journal of Medicine},
author = {Donnelly, Seamas C},
month = apr,
year = {2019},
pages = {245},
}

@article{ubaid_identifying_2019,
title = {Identifying the relationship between unstable vital signs and intensive care unit ({ICU}) readmissions: an analysis of 10-year of hospital {ICU} readmissions},
volume = {9},
issn = {2190-7196},
shorttitle = {Identifying the relationship between unstable vital signs and intensive care unit ({ICU}) readmissions},
url = {https://doi.org/10.1007/s12553-018-0255-1},
doi = {10.1007/s12553-018-0255-1},
abstract = {Advanced healthcare information systems capture extensive electronic healthcare records (EHR) to provide accurate healthcare delivery and make informed clinical and management decisions. EHR also include records of Intensive Care Unit (ICU) admissions, discharges, readmissions and more. This study aims to investigate trends and patterns from electronically recorded vital signs and identify the relationship between vital signs and ICU readmissions. After appropriate ethics approvals and permissions, we obtained access to the MIMIC-III dataset. A total of 150 patient data has been selected from the MIMIC-III dataset to evaluate the vital signs patterns, which included heart rate, respiratory rate, temperature for patients admitted twice in the ICU. Statistical analysis was conducted to identify the key patterns associated with the vital signs of the selected patient samples. The study findings indicate that the mean value of heart rate and respiratory rate was within the normal range for all incidents. However, there was a small difference between the readmission-day of the vital signs compared with the previous admission recordings. The finding also suggests that hospital length of stay (LOS) for patients was high for the second admission compared to the first admission. We identified a key relationship between the vital signs and ICU readmissions, it is evident that discharges with unstable vitals are directly linked to readmissions. Additionally, it is also observed that the LOS varies depending on the stability of the vital signs. In future, a larger sample with more variables are required, such as modifiable (medications, procedures, room temperature, discharge time) and non-modifiable (age, ethnicity, family history) which could explain the significance of longer LOS and its impact on patient-condition, readmission and mortality rate.},
language = {en},
number = {1},
urldate = {2022-08-09},
journal = {Health and Technology},
author = {Ubaid, Abdulla and Mirza, Farhaan and Baig, Mirza Mansoor and GholamHosseini, Hamid},
month = jan,
year = {2019},
keywords = {Electronic health records, ICU readmission, Predictive model, Vital signs monitoring},
pages = {77--85},
}

@article{rajendra_acharya_heart_2006,
title = {Heart rate variability: a review},
volume = {44},
issn = {1741-0444},
shorttitle = {Heart rate variability},
url = {https://doi.org/10.1007/s11517-006-0119-0},
doi = {10.1007/s11517-006-0119-0},
abstract = {Heart rate variability (HRV) is a reliable reflection of the many physiological factors modulating the normal rhythm of the heart. In fact, they provide a powerful means of observing the interplay between the sympathetic and parasympathetic nervous systems. It shows that the structure generating the signal is not only simply linear, but also involves nonlinear contributions. Heart rate (HR) is a nonstationary signal; its variation may contain indicators of current disease, or warnings about impending cardiac diseases. The indicators may be present at all times or may occur at random—during certain intervals of the day. It is strenuous and time consuming to study and pinpoint abnormalities in voluminous data collected over several hours. Hence, HR variation analysis (instantaneous HR against time axis) has become a popular noninvasive tool for assessing the activities of the autonomic nervous system. Computer based analytical tools for in-depth study of data over daylong intervals can be very useful in diagnostics. Therefore, the HRV signal parameters, extracted and analyzed using computers, are highly useful in diagnostics. In this paper, we have discussed the various applications of HRV and different linear, frequency domain, wavelet domain, nonlinear techniques used for the analysis of the HRV.},
language = {en},
number = {12},
urldate = {2022-08-06},
journal = {Medical and Biological Engineering and Computing},
author = {Rajendra Acharya, U. and Paul Joseph, K. and Kannathal, N. and Lim, Choo Min and Suri, Jasjit S.},
month = dec,
year = {2006},
keywords = {ANOVA test, Approximate entropy, Autonomic nervous system, Correlation dimension, Heart rate variability, Hurst exponent, Lyapunov exponent, Phase space plot, Poincare plot, Recurrent plot, Sample entropy, Surrogate data, Wavelet transform},
pages = {1031--1051},
}

@article{yuan_respiratory_2013,
title = {Respiratory {Rate} and {Breathing} {Pattern}},
volume = {10},
abstract = {The respiratory rate is a vital sign with an underappreciated significance that can, in acute situations, prognosticate patients’ mortality rate and need for invasive ventilation. In addition, identifying abnormal breathing patterns can localize disorders within the respiratory system and help refine the differential diagnosis. Understanding how to properly measure and interpret the respiratory rate is a valuable clinical skill.},
language = {en},
number = {1},
journal = {McMaster University Medical Journal},
author = {Yuan, George and Drost, Nicole A and McIvor, R Andrew},
year = {2013},
pages = {3},
}

@article{woo_patterns_1992,
title = {Patterns of beat-to-beat heart rate variability in advanced heart failure},
volume = {123},
issn = {0002-8703},
url = {https://www.sciencedirect.com/science/article/pii/0002870392905103},
doi = {10.1016/0002-8703(92)90510-3},
abstract = {Diminished heart rate variability is associated with high sympathetic tone and an increased mortality rate in heart failure cases. We constructed Poincaré plots of each sinus R-R interval plotted against the subsequent R-R interval from 24-hour Holter recordings of 24 healthy subjects (control group) and 24 patients with heart failure. Every subject in the control group had a comet-shaped Poincaré plot resulting from an increase in beat-to-beat dispersion as heart rate slowed. No patient with heart failure had this comet-shaped pattern. Instead, three distinctive patterns were identified: (1) a torpedo-shaped pattern resulting from low R-R interval dispersion over the entire range of heart rates, (2) a fanshaped pattern resulting from restriction of overall R-R interval ranges with enhanced dispersion, and (3) complex patterns with clusters of points characteristic of stepwise changes in R-R intervals. Poincaré pattern could not be predicted from standard deviations of R-R intervals. This first use of Poincaré plots in heart rate variability analysis reveals a complexity not readily perceived from standard deviation information. Further study is warranted to determine if this method will allow refined assessment of cardiac-autonomic integrity in heart failure, which could help identify patients at highest risk for sudden death.},
language = {en},
number = {3},
urldate = {2022-08-06},
journal = {American Heart Journal},
author = {Woo, Mary A. and Stevenson, William G. and Moser, Debra K. and Trelease, Robert B. and Harper, Ronald M.},
month = mar,
year = {1992},
pages = {704--710},
}

@article{tobin_breathing_1992,
title = {Breathing pattern analysis},
volume = {18},
issn = {1432-1238},
url = {https://doi.org/10.1007/BF01709831},
doi = {10.1007/BF01709831},
language = {en},
number = {4},
urldate = {2022-08-06},
journal = {Intensive Care Medicine},
author = {Tobin, M. J.},
month = apr,
year = {1992},
keywords = {Breathing Pattern, Breathing Pattern Analysis, Emergency Medicine, Pattern Analysis, Public Health},
pages = {193--201},
}

@misc{liu_long-range_2019,
title = {Long-range {Prediction} of {Vital} {Signs} {Using} {Generative} {Boosting} via {LSTM} {Networks}},
url = {http://arxiv.org/abs/1911.06621},
doi = {10.48550/arXiv.1911.06621},
abstract = {Vital signs including heart rate, respiratory rate, body temperature and blood pressure, are critical in the clinical decision making process. Effective early prediction of vital signs help to alert medical practitioner ahead of time and may prevent adverse health outcomes. In this paper, we suggest a new approach called generative boosting, in order to effectively perform early prediction of vital signs. Generative boosting consists of a generative model, to generate synthetic data for next few time steps, and several predictive models, to directly make long-range predictions based on observed and generated data. We explore generative boosting via long short-term memory (LSTM) for both the predictive and generative models, leading to a scheme called generative LSTM (GLSTM). Our experiments indicate that GLSTM outperforms a diverse range of strong benchmark models, with and without generative boosting. Finally, we use a mutual information based clustering algorithm to select a more representative dataset to train the generative model of GLSTM. This significantly improves the long-range predictive performance of high variation vital signs such as heart rate and systolic blood pressure.},
urldate = {2022-08-06},
publisher = {arXiv},
author = {Liu, Shiyu and Motani, Mehul},
month = nov,
year = {2019},
note = {arXiv:1911.06621 [cs, eess]},
keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, research ideas},
}

@inproceedings{forkan_probabilistic_2016,
title = {A probabilistic model for early prediction of abnormal clinical events using vital sign correlations in home-based monitoring},
doi = {10.1109/PERCOM.2016.7456519},
abstract = {Chronic diseases are major causes of deaths in Australia and throughout the world. This necessitates the need for a self-care, preventive, predictive and protective assisted living system where a patient can be monitored continuously using wearable and wireless sensors. In real-time home monitoring system, various biological signals of a patient are obtained continuously using a mobile device (smart phone or tablet) and sent to the cloud to discover patient-specific abnormalities. The objective of this work is to develop a probabilistic model that identifies the future clinical abnormalities of a patient using recent and past values of multiple vital signs (e.g. heart rate, blood pressure, respiratory rate). Chronic patients living alone in home die of various diseases for the lack of an efficient automated system having prior prediction ability in the irregularities of vital signs. In this paper, Hidden Markov Model (HMM) is adopted to predict different clinical onsets using the temporal behaviours of six biosignals. The HMM models are trained and evaluated using continuous monitoring data of more than 1000 patients collected from the MIMIC-II database of MIT physiobank archive. The best models are selected using expectation maximisation (EM) algorithm and used in personalized remote monitoring system to forecast the most probable forthcoming clinical states of a continuously monitored patient. The scalable power of cloud computing is utilized for fast learning of various clinical events from large samples. The results obtained from the innovative home-based monitoring application show a new approach of detecting clinical anomalies using multi-parameter trends.},
booktitle = {2016 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} ({PerCom})},
author = {Forkan, Abdur Rahim Mohammad and Khalil, Ibrahim},
month = mar,
year = {2016},
keywords = {Biological system modeling, Biomedical monitoring, Cloud computing, Computational modeling, Data models, Hidden Markov models, Monitoring},
pages = {1--9},
}

@article{yoon_prediction_2020,
title = {Prediction of hypotension events with physiologic vital sign signatures in the intensive care unit},
volume = {24},
issn = {1364-8535},
url = {https://doi.org/10.1186/s13054-020-03379-3},
doi = {10.1186/s13054-020-03379-3},
abstract = {Even brief hypotension is associated with increased morbidity and mortality. We developed a machine learning model to predict the initial hypotension event among intensive care unit (ICU) patients and designed an alert system for bedside implementation.},
number = {1},
urldate = {2022-08-06},
journal = {Critical Care},
author = {Yoon, Joo Heung and Jeanselme, Vincent and Dubrawski, Artur and Hravnak, Marilyn and Pinsky, Michael R. and Clermont, Gilles},
month = nov,
year = {2020},
keywords = {Artificial intelligence, Hypotension, Machine learning, Prediction},
pages = {661},
}

@article{molani_risk_2022,
title = {Risk factors for severe {COVID}-19 differ by age for hospitalized adults},
volume = {12},
copyright = {2022 The Author(s)},
issn = {2045-2322},
url = {https://www.nature.com/articles/s41598-022-10344-3},
doi = {10.1038/s41598-022-10344-3},
abstract = {Risk stratification for hospitalized adults with COVID-19 is essential to inform decisions about individual patients and allocation of resources. So far, risk models for severe COVID outcomes have included age but have not been optimized to best serve the needs of either older or younger adults. Models also need to be updated to reflect improvements in COVID-19 treatments. This retrospective study analyzed data from 6906 hospitalized adults with COVID-19 from a community health system across five states in the western United States. Risk models were developed to predict mechanical ventilation illness or death across one to 56 days of hospitalization, using clinical data available within the first hour after either admission with COVID-19 or a first positive SARS-CoV-2 test. For the seven-day interval, models for age ≥ 18 and {\textless} 50 years reached AUROC 0.81 (95\% CI 0.71–0.91) and models for age ≥ 50 years reached AUROC 0.82 (95\% CI 0.77–0.86). Models revealed differences in the statistical significance and relative predictive value of risk factors between older and younger patients including age, BMI, vital signs, and laboratory results. In addition, for hospitalized patients, sex and chronic comorbidities had lower predictive value than vital signs and laboratory results.},
language = {en},
number = {1},
urldate = {2022-08-06},
journal = {Scientific Reports},
author = {Molani, Sevda and Hernandez, Patricia V. and Roper, Ryan T. and Duvvuri, Venkata R. and Baumgartner, Andrew M. and Goldman, Jason D. and Ertekin-Taner, Nilüfer and Funk, Cory C. and Price, Nathan D. and Rappaport, Noa and Hadlock, Jennifer J.},
month = apr,
year = {2022},
note = {Number: 1
Publisher: Nature Publishing Group},
keywords = {Epidemiology, Machine learning, Risk factors, Viral infection},
pages = {6568},
}

@article{youssef_ali_amer_vital_2021,
title = {Vital {Signs} {Prediction} for {COVID}-19 {Patients} in {ICU}},
volume = {21},
issn = {1424-8220},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8662454/},
doi = {10.3390/s21238131},
abstract = {This study introduces machine learning predictive models to predict the future values of the monitored vital signs of COVID-19 ICU patients. The main vital sign predictors include heart rate, respiration rate, and oxygen saturation. We investigated the performances of the developed predictive models by considering different approaches. The first predictive model was developed by considering the following vital signs: heart rate, blood pressure (systolic, diastolic and mean arterial, pulse pressure), respiration rate, and oxygen saturation. Similar to the first approach, the second model was developed using the same vital signs, but it was trained and tested based on a leave-one-subject-out approach. The third predictive model was developed by considering three vital signs: heart rate (HR), respiration rate (RR), and oxygen saturation (SpO2). The fourth model was a leave-one-subject-out model for the three vital signs. Finally, the fifth predictive model was developed based on the same three vital signs, but with a five-minute observation rate, in contrast with the aforementioned four models, where the observation rate was hourly to bi-hourly. For the five models, the predicted measurements were those of the three upcoming observations (on average, three hours ahead). Based on the obtained results, we observed that by limiting the number of vital sign predictors (i.e., three vital signs), the prediction performance was still acceptable, with the average mean absolute percentage error (MAPE) being 12\%,5\%, and 21.4\% for heart rate, oxygen saturation, and respiration rate, respectively. Moreover, increasing the observation rate could enhance the prediction performance to be, on average, 8\%,4.8\%, and 17.8\% for heart rate, oxygen saturation, and respiration rate, respectively. It is envisioned that such models could be integrated with monitoring systems that could, using a limited number of vital signs, predict the health conditions of COVID-19 ICU patients in real-time.},
number = {23},
urldate = {2022-08-06},
journal = {Sensors (Basel, Switzerland)},
author = {Youssef Ali Amer, Ahmed and Wouters, Femke and Vranken, Julie and Dreesen, Pauline and de Korte-de Boer, Dianne and van Rosmalen, Frank and van Bussel, Bas C. T. and Smit-Fun, Valérie and Duflot, Patrick and Guiot, Julien and van der Horst, Iwan C. C. and Mesotten, Dieter and Vandervoort, Pieter and Aerts, Jean-Marie and Vanrumste, Bart},
month = dec,
year = {2021},
pmid = {34884136},
pmcid = {PMC8662454},
pages = {8131},
}

@article{yanamala_vital_2021,
title = {A vital sign-based prediction algorithm for differentiating {COVID}-19 versus seasonal influenza in hospitalized patients},
volume = {4},
copyright = {2021 The Author(s)},
issn = {2398-6352},
url = {https://www.nature.com/articles/s41746-021-00467-8},
doi = {10.1038/s41746-021-00467-8},
abstract = {Patients with influenza and SARS-CoV2/Coronavirus disease 2019 (COVID-19) infections have a different clinical course and outcomes. We developed and validated a supervised machine learning pipeline to distinguish the two viral infections using the available vital signs and demographic dataset from the first hospital/emergency room encounters of 3883 patients who had confirmed diagnoses of influenza A/B, COVID-19 or negative laboratory test results. The models were able to achieve an area under the receiver operating characteristic curve (ROC AUC) of at least 97\% using our multiclass classifier. The predictive models were externally validated on 15,697 encounters in 3125 patients available on TrinetX database that contains patient-level data from different healthcare organizations. The influenza vs COVID-19-positive model had an AUC of 98.8\%, and 92.8\% on the internal and external test sets, respectively. Our study illustrates the potentials of machine-learning models for accurately distinguishing the two viral infections. The code is made available at https://github.com/ynaveena/COVID-19-vs-Influenzaand may have utility as a frontline diagnostic tool to aid healthcare workers in triaging patients once the two viral infections start cocirculating in the communities.},
language = {en},
number = {1},
urldate = {2022-08-06},
journal = {npj Digital Medicine},
author = {Yanamala, Naveena and Krishna, Nanda H. and Hathaway, Quincy A. and Radhakrishnan, Aditya and Sunkara, Srinidhi and Patel, Heenaben and Farjo, Peter and Patel, Brijesh and Sengupta, Partho P.},
month = jun,
year = {2021},
note = {Number: 1
Publisher: Nature Publishing Group},
keywords = {Diagnosis, Diseases, Health care},
pages = {1--10},
}

@article{hong_how_2013,
title = {How accurate are vital signs in predicting clinical outcomes in critically ill emergency department patients},
volume = {20},
issn = {0969-9546},
url = {https://journals.lww.com/euro-emergencymed/fulltext/2013/02000/how_accurate_are_vital_signs_in_predicting.6.aspx},
doi = {10.1097/MEJ.0b013e32834fdcf3},
abstract = {Objectives 
    We aimed to evaluate the predictive value of pulse rate (PR), systolic blood pressure (SBP), diastolic blood pressure, respiratory rate (RR), oxygen saturation (SaO2), and the Glasgow Coma Scale (GCS) for cardiac arrest and death in critically ill patients.
    Methods 
    In total, 1025 patients had vital signs recorded at triage at our Emergency Department and were followed up for three clinical outcomes: cardiac arrest in 72 h, admission to ICU, and death within 30 days. Vital signs were used in univariate and multivariate analyses for outcomes. Age was added in multivariate analysis.
    Results 
    PR, SBP, RR, SaO2, and GCS were significantly associated with cardiac arrest within 72 h, whereas PR, SBP, RR, SaO2, and GCS were associated with death within 30 days. Only PR and GCS were associated with ICU admission. In the multivariate analysis, age, PR ({\textgreater}100) [odds ratio (OR) 1.65; 95\% confidence interval (CI) 1.00–2.71], SBP ({\textgreater}140; OR 0.41; 95\% CI: 0.21–0.79), RR ({\textgreater}20; OR 2.90; 95\% CI: 1.67–5.03), and GCS ({\textless}15; OR 5.71; 95\% CI: 3.40–9.57) were significantly associated with death. Vital signs with age have low sensitivity (cardiac arrest 11.54\%, death 22.73\%, ICU 12.50\%) and high specificity (cardiac arrest 99.28\%, death 97.22\%, ICU 93.80\%). Age and GCS were found to be independent predictors of all three outcomes.
    Conclusion 
    Not all vital signs are useful in the prediction of clinical outcomes. Vital signs had high specificity but very low sensitivity as predictors of clinical outcomes. Clinicians should always remember to treat patients and not numbers.},
language = {en-US},
number = {1},
urldate = {2022-08-06},
journal = {European Journal of Emergency Medicine},
author = {Hong, Weili and Earnest, Arul and Sultana, Papia and Koh, Zhixiong and Shahidah, Nur and Ong, Marcus Eng Hock},
month = feb,
year = {2013},
pages = {27--32},
}

@article{auzinger_intensive_2008,
title = {Intensive care management of acute liver failure},
volume = {14},
issn = {1070-5295},
url = {https://journals.lww.com/co-criticalcare/Abstract/2008/04000/Intensive_care_management_of_acute_liver_failure.11.aspx},
doi = {10.1097/MCC.0b013e3282f6a450},
abstract = {Purpose of review 
    The mortality of acute liver failure remains unacceptably high and liver transplantation is the only effective treatment available to date. This review focuses on new research developments in the field and aims to provide a pragmatic organ-based treatment approach for liver failure patients requiring intensive care support.
    Recent findings 
    The pathophysiological basis for cerebral edema formation in acute liver failure continued to be the focus of various investigations. In-vivo observations confirmed the link between ammonia, cerebral glutamine content and intracranial hypertension. The role of arterial ammonia as an important prognostic indicator formed the basis of prospective, observational studies. Reduced monocytic HLA-DR expression linked acute liver failure with poor prognosis, and the cerebral effects and side effects of vasoactive therapy with terlipressin were investigated with two studies showing contradictory results.
    Summary 
    Despite increased knowledge of the pathophysiological events leading to organ dysfunction in acute liver failure, supportive treatment options remain limited in their efficacy and largely noncurative.},
language = {en-US},
number = {2},
urldate = {2022-08-03},
journal = {Current Opinion in Critical Care},
author = {Auzinger, Georg and Wendon, Julia},
month = apr,
year = {2008},
pages = {179--188},
}

@misc{noauthor_monitoring_nodate,
title = {Monitoring of {Patients} in the {ICU}},
url = {https://www.physio-pedia.com/Monitoring_of_Patients_in_the_ICU},
abstract = {Original Editor - Merinda Rodseth},
language = {en},
urldate = {2022-08-03},
journal = {Physiopedia},
}

@article{viglianti_heterogeneity_2019,
title = {The heterogeneity of prolonged {ICU} hospitalisations},
volume = {74},
copyright = {© Author(s) (or their employer(s)) 2019. No commercial re-use. See rights and permissions. Published by BMJ.},
issn = {0040-6376, 1468-3296},
url = {https://thorax.bmj.com/content/74/11/1015},
doi = {10.1136/thoraxjnl-2019-213779},
abstract = {Prolonged intensive care unit (ICU) hospitalisations are costly, increasing in prevalence and strain ICU resources.1–4 One-year mortality is high and the recovery for survivors of prolonged ICU hospitalisations is typically long and marked by new morbidities.3 4 Thus, with advances in critical care technology, patients with prolonged ICU hospitalisations, their families and physicians are challenged to make complex, high-stakes decisions without clear guidance about long-term prognosis.

Recent work has focused on who these patients are and why they remain in the ICU for prolonged periods of time.5–8 Commonly measured patient characteristics on admission such as age and comorbidities have not consistently been associated with the need for prolonged ICU hospitalisations. (Of note, other premorbid patient characteristics, such as frailty, have not been studied as a risk factor for persistent critical illness.) These findings have challenged preconceived beliefs that prolonged ICU hospitalisations only occur for older patients or those with multiple comorbidities.5 8 Instead, observational data suggest the development of new organ dysfunctions not present on admission contributes to the development of prolonged ICU hospitalisations.6 7 This finding moves our understanding of prolonged ICU hospitalisations beyond the prototype of chronic critical illness—a patient with unresolving respiratory failure—and towards a more complete picture of how prolonged ICU hospitalisations emerge over time in the ICU.3 (figure 1)



Figure 1 
New framework of prolonged ICU hospitalisations.



Hermans et al describe the long-term mortality and morbidity of patients with prolonged ICU hospitalisations who are matched to short-stayers (patients who remained in the ICU for {\textless}8 days).9 The authors created three different matched cohorts to evaluate long-term mortality (total and post-28-day 5-year mortality) and morbidity. The authors performed a re-analysis of prospectively collected data of the EPaNIC-trial, which was a randomised control trial conducted in seven …},
language = {en},
number = {11},
urldate = {2022-08-02},
journal = {Thorax},
author = {Viglianti, Elizabeth Marie and Kruser, Jacqueline M. and Iwashyna, Theodore},
month = nov,
year = {2019},
pmid = {31534030},
note = {Publisher: BMJ Publishing Group Ltd
Section: Editorial},
keywords = {Clinical Epidemiology, Critical Care},
pages = {1015--1017},
}

@article{leligdowicz_heterogeneity_2019,
title = {Heterogeneity in sepsis: new biological evidence with clinical applications},
volume = {23},
issn = {1364-8535},
shorttitle = {Heterogeneity in sepsis},
url = {https://doi.org/10.1186/s13054-019-2372-2},
doi = {10.1186/s13054-019-2372-2},
abstract = {This article is one of ten reviews selected from the Annual Update in Intensive Care and Emergency Medicine 2019. Other selected articles can be found online at https://www.biomedcentral.com/collections/annualupdate2019. Further information about the Annual Update in Intensive Care and Emergency Medicine is available from http://www.springer.com/series/8901.},
number = {1},
urldate = {2022-08-02},
journal = {Critical Care},
author = {Leligdowicz, Aleksandra and Matthay, Michael A.},
month = mar,
year = {2019},
pages = {80},
}

@article{pirracchio_heterogeneity_2019,
title = {Heterogeneity in {Intensive} {Care}: {Low} {Severity} {Does} {Not} {Mean} {Low} {Risk}!},
volume = {130},
issn = {0003-3022},
shorttitle = {Heterogeneity in {Intensive} {Care}},
url = {https://doi.org/10.1097/ALN.0000000000002537},
doi = {10.1097/ALN.0000000000002537},
abstract = {Intensivists often treat syndromes rather than diseases. Syndromes are defined as sets of medical signs and symptoms that are correlated with each other and, often, with a particular disease. Therefore, syndromes are heterogeneous entities that may be related to variety of underlying causes. Among the most frequent conditions leading to intensive care unit admission are shock, acute kidney injury, and acute lung injury, all of which are syndromes with diverse causation. In practice, this heterogeneity translates into a wide range of severity and broad potential for evolution and has great implications for research and therapeutics. Acute respiratory distress syndrome (ARDS) is a typical example of a very heterogeneous critical syndrome. Similar to the Acute Kidney Injury Network’s definition for acute kidney injury,1 the recent Berlin definition2 for ARDS was adopted to provide clinicians and researchers with a more specific definition for this entity. Besides refining the diagnostic criterion, the Berlin task force created three severity grades of ARDS (mild, moderate, and severe) based on the Pao2/Fio2 ratio. Within each of these subgroups, the patients are supposed to be more similar, i.e., less heterogeneous.1,2 The article by Pham et al. in this issue of Anesthesiology eloquently shows that mild ARDS is substantially under appreciated.3},
number = {2},
urldate = {2022-08-02},
journal = {Anesthesiology},
author = {Pirracchio, Romain and Gropper, Michael A.},
month = feb,
year = {2019},
pages = {190--191},
}

@article{colantuoni_heterogeneity_2021,
title = {Heterogeneity in design and analysis of {ICU} delirium randomized trials: a systematic review},
volume = {22},
issn = {1745-6215},
shorttitle = {Heterogeneity in design and analysis of {ICU} delirium randomized trials},
doi = {10.1186/s13063-021-05299-1},
abstract = {BACKGROUND: There is a growing number of randomized controlled trials (RCTs) evaluating interventions to prevent or treat delirium in the intensive care unit (ICU). Efforts to improve the conduct of delirium RCTs are underway, but none address issues related to statistical analysis. The purpose of this review is to evaluate heterogeneity in the design and analysis of delirium outcomes and advance methodological recommendations for delirium RCTs in the ICU.
METHODS: Relevant databases, including PubMed and Embase, were searched with no restrictions on language or publication date; the search was conducted on July 8, 2019. RCTs conducted on adult ICU patients with delirium as the primary outcome were included where trial results were available. Data on frequency and duration of delirium assessments, delirium outcome definitions, and statistical methods were independently extracted in duplicate. The review was registered with PROSPERO (CRD42020141204).
RESULTS: Among 65 eligible RCTs, 44 (68\%) targeted the prevention of delirium. The duration of follow-up varied, with 31 (48\%) RCTs having ≤7 days of follow-up, and only 24 (37\%) conducting delirium assessments after ICU discharge. The incidence of delirium was the most common outcome (50 RCTs, 77\%) for which 8 unique statistical methods were applied. The most common method, applied to 51 of 56 (91\%) delirium incidence outcomes, was the two-sample test comparing the proportion of patients who ever experienced delirium. In the presence of censoring of patients at ICU discharge or death, this test may be misleading. The impact of censoring was also not considered in most analyses of the duration of delirium, as evaluated in 24 RCTs, with 21 (88\%) delirium duration outcomes analyzed using a non-parametric test or two-sample t test. Composite outcomes (e.g., rank-based delirium- and coma-free days), used in 11 (17\%) RCTs, seldom explicitly defined how ICU discharge, and death were incorporated into the definition and were analyzed using non-parametric tests (11 of 13 (85\%) composite outcomes).
CONCLUSIONS: To improve delirium RCTs, outcomes should be explicitly defined. To account for censoring due to ICU discharge or death, survival analysis methods should be considered for delirium incidence and duration outcomes; non-parametric tests are recommended for rank-based delirium composite outcomes.
TRIAL REGISTRATION: PROSPERO CRD42020141204 . Registration date: 7/3/2019.},
language = {eng},
number = {1},
journal = {Trials},
author = {Colantuoni, Elizabeth and Koneru, Mounica and Akhlaghi, Narjes and Li, Ximin and Hashem, Mohamed D. and Dinglas, Victor D. and Neufeld, Karin J. and Harhay, Michael O. and Needham, Dale M.},
month = may,
year = {2021},
pmid = {34016134},
pmcid = {PMC8136095},
keywords = {Adult, Critical Illness, Critically ill patients, Delirium, Humans, Intensive Care Units, Outcome definition, Randomized Controlled Trials as Topic, Randomized trials, Statistical methods, Systematic review},
pages = {354},
}

@article{cuadrado_methods_2021,
title = {Methods and measures to quantify {ICU} patient heterogeneity},
volume = {117},
issn = {1532-0480},
doi = {10.1016/j.jbi.2021.103768},
abstract = {Patients in intensive care units are heterogeneous and the daily prediction of their days to discharge (DTD) a complex task that practitioners and computers are not always able to solve satisfactorily. In order to make more precise DTD predictors, it is necessary to have tools for the analysis of the heterogeneity of the patients. Unfortunately, the number of publications in this field is almost non-existent. In order to alleviate this lack of tools, we propose four methods and their corresponding measures to quantify the heterogeneity of intensive patients in the process of determining the DTD. These new methods and measures have been tested with patients admitted over four years to a tertiary hospital in Spain. The results deepen the understanding of the intensive patient and can serve as a basis for the construction of better DTD predictors.},
language = {eng},
journal = {Journal of Biomedical Informatics},
author = {Cuadrado, David and Riaño, David and Gómez, Josep and Rodríguez, Alejandro and Bodí, María},
month = may,
year = {2021},
pmid = {33839305},
keywords = {Case-mix, Days to discharge prediction, Humans, Intensive Care Units, Intensive care unit, Patient Discharge, Patient heterogeneity, Patient similarity, Spain},
pages = {103768},
}

@article{berente_research_2019,
title = {Research {Commentary}—{Data}-{Driven} {Computationally} {Intensive} {Theory} {Development}},
volume = {30},
issn = {1047-7047},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.2018.0774},
doi = {10.1287/isre.2018.0774},
abstract = {Increasingly abundant trace data provide an opportunity for information systems researchers to generate new theory. In this research commentary, we draw on the largely “manual” tradition of the grounded theory methodology and the highly “automated” process of computational theory discovery in the sciences to develop a general approach to computationally intensive theory development from trace data. This approach involves the iterative application of four general processes: sampling, synchronic analysis, lexical framing, and diachronic analysis. We provide examples from recent research in information systems.},
number = {1},
urldate = {2022-08-02},
journal = {Information Systems Research},
author = {Berente, Nicholas and Seidel, Stefan and Safadi, Hani},
month = mar,
year = {2019},
note = {Publisher: INFORMS},
keywords = {GTM, computational, computational theory discovery, grounded theory methodology, inductive, lexicon, theory development, trace data},
pages = {50--64},
}

@inproceedings{hedman_digital_nodate,
title = {Digital {Traces} of {Information} {Systems}: {Sociomateriality} {Made} {Researchable}},
shorttitle = {Digital {Traces} of {Information} {Systems}},
abstract = {In this paper, we point to the potential and implications of digital traces as novel data source in the study of contemporary activities and behaviors. We do this to raise awareness of IS researchers of such traces in increasingly complex sociomaterial practices. We develop a two-dimensional framework of data sources (subjective/objective and digitalized/non-digitalized) for analyzing a six-year literature survey comprised of five leading IS journals. The analysis positions current data sources employed within the framework, and sheds light on the under utilization of digitalized data sources. This disconcerting result suggests that IS researchers must pay more attention to the changing landscape of data sources. To motivate and guide fellow colleagues to establish the credibility and reliability of digital traces, we develop a future research agenda that covers both opportunities in theory generation and challenges in data collection.},
booktitle = {in {Proceedings} of 34th {International} {Conference} on {Information} {Systems}},
author = {Hedman, Jonas and Srinivasan, Nikhil and Lindgren, Rikard},
pages = {15--18},
}

@article{abbasi_dont_2019,
title = {Don’t {Mention} {It}? {Analyzing} {User}-{Generated} {Content} {Signals} for {Early} {Adverse} {Event} {Warnings}},
volume = {30},
issn = {1047-7047},
shorttitle = {Don’t {Mention} {It}?},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.2019.0847},
doi = {10.1287/isre.2019.0847},
abstract = {With greater impetus on broad postmarket surveillance, the Voice of the Customer (VoC) has emerged as an important source of information for understanding consumer experiences and identifying potential issues. In organizations, risk management groups are increasingly interested in working with their information technology teams to develop robust VoC listening platforms. Two key challenges have impeded success. First, prior work has leveraged diverse sets of channels, adverse event types, and modeling methods, resulting in diverging conclusions regarding the viability and efficacy of various user-generated channels and accompanying modeling methods. Second, many existing detection methods rely on “mention models” that have low detection rates, have high false positives, and lack timeliness. Following the information systems design science approach, in this research note we propose a framework for examining key design elements for VoC listening platforms. As part of our framework, we also develop a novel heuristic-based method for detecting adverse events. We evaluate our framework and method on two large test beds each encompassing millions of tweets, forums postings, and search query logs pertaining to hundreds of adverse events related to the pharmaceutical and automotive industries. The results shed light on the interplay between user-generated channels and event types, as well as the potential for more robust event modeling methods that go beyond basic mention models. Our analysis framework reveals that user-generated content channels can facilitate timelier detection of adverse events: on average, two to three years or earlier than commonly used databases. The inclusion of negative sentiment polarity in the models can further reduce false-positive rates. Additionally, we find social media channels provide higher detection rates but lower precision than do search-based signals. The search and web forum channels are timelier than Twitter. The proposed heuristic-based method attains markedly better results than do existing methods—with earlier detection rates of 50\%–80\% and far fewer false positives across an array of VoC channels and event types. The heuristic method is also well suited for signal fusion across channels. Our note makes several contributions to research. The results also have important implications for various practitioner groups, including regulatory agencies and risk management teams at product manufacturing firms.},
number = {3},
urldate = {2022-08-02},
journal = {Information Systems Research},
author = {Abbasi, Ahmed and Li, Jingjing and Adjeroh, Donald and Abate, Marie and Zheng, Wanhong},
month = sep,
year = {2019},
note = {Publisher: INFORMS},
keywords = {data mining, healthcare analytics, healthcare information technologies, predictive analytics, signal detection, smart health, social media},
pages = {1007--1028},
}

@article{li_path_2020,
title = {Path to {Purpose}? {How} {Online} {Customer} {Journeys} {Differ} for {Hedonic} {Versus} {Utilitarian} {Purchases}},
volume = {84},
issn = {0022-2429},
shorttitle = {Path to {Purpose}?},
url = {https://doi.org/10.1177/0022242920911628},
doi = {10.1177/0022242920911628},
abstract = {The authors examine consumers’ information channel usage during the customer journey by employing a hedonic and utilitarian (H/U) perspective, an important categorization of consumption purpose. Taking a retailer-category viewpoint to measure the H/U characteristics of 20 product categories at 40 different retailers, this study combines large-scale secondary clickstream and primary survey data to offer actionable insights for retailers in a competitive landscape. The data reveal that, when making hedonic purchases (e.g., toys), consumers employ social media and on-site product pages as early as two weeks before the final purchase. By contrast, for utilitarian purchases (e.g., office supplies), consumers utilize third-party reviews up to two weeks before the final purchase and make relatively greater usage of search engines, deals, and competitors’ product pages closer to the time of purchase. Importantly, channel usage is different for sessions in which no purchase is made, indicating that consumers’ information channel choices vary significantly with the H/U characteristics of purchases. The article closes with an extensive discussion of the significant implications for managing customer touchpoints.},
language = {en},
number = {4},
urldate = {2022-08-02},
journal = {Journal of Marketing},
author = {Li, Jingjing and Abbasi, Ahmed and Cheema, Amar and Abraham, Linda B.},
month = jul,
year = {2020},
note = {Publisher: SAGE Publications Inc},
keywords = {customer journey, hedonic and utilitarian products, information sources, path to purchase, touchpoint management},
pages = {127--146},
}

@article{lin_healthcare_2017,
title = {Healthcare {Predictive} {Analytics} for {Risk} {Profiling} in {Chronic} {Care}: {A} {Bayesian} {Multitask} {Learning} {Approach}},
shorttitle = {Healthcare {Predictive} {Analytics} for {Risk} {Profiling} in {Chronic} {Care}},
doi = {10.25300/MISQ/2017/41.2.07},
abstract = {Clinical intelligence about a patient's risk of future adverse health events can support clinical decision making in personalized and preventive care. Healthcare predictive analytics using electronic health records offers a promising direction to address the challenging tasks of risk profiling. Patients with chronic diseases often face risks of not just one, but an array of adverse health events. However, existing risk models typically focus on one specific event and do not predict multiple outcomes. To attain enhanced risk profiling, we adopt the design science paradigm and propose a principled approach called Bayesian multitask learning (BMTL). Considering the model development for an event as a single task, our BMTL approach is to coordinate a set of baseline models—one for each event—and communicate training information across the models. The BMTL approach allows healthcare providers to achieve multifaceted risk profiling and model an arbitrary number of events simultaneously. Our experimental evaluations demonstrate that the BMTL approach attains an improved predictive performance when compared with the alternatives that model multiple events separately. We also find that, in most cases, the BMTL approach significantly outperforms existing multitask learning techniques. More importantly, our analysis shows that the BMTL approach can create significant potential impacts on clinical practice in reducing the failures and delays in preventive interventions. We discuss several implications of this study for health IT, big data and predictive analytics, and design science research.},
journal = {MIS Q.},
author = {Lin, Yu-Kai and Chen, H. and Brown, Randall A. and Li, Shu-Hsing and Yang, Hung-Jen},
year = {2017},
}

@article{hevner_design_2004,
title = {Design {Science} in {Information} {Systems} {Research}},
volume = {28},
issn = {02767783},
url = {http://ezproxy.library.arizona.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=12581935&site=ehost-live},
abstract = {Two paradigms characterize much of the research in the Information Systems discipline: behavioral science and design science. The behavioral science paradigm seeks to develop and verify theories that explain or predict human or organizational capabilities by creating new and innovative artifacts. Both paradigms are foundational to the IS discipline, positioned as it is at the confluence of people, organizations, and technology. Our objective is to describe the performance of design-science research in Information Systems via a concise conceptual framework and clear guidelines for understanding, executing, and evaluating the research. In the design-science paradigm, knowledge and understanding of a problem domain and its solution are achieved in the building and application of the designed artifact. Three recent exemplars in the research literature are used to demonstrate the application of these guidelines. We conclude with an analysis of the challenges of performing high-quality design-science research in the context of the broader IS community.},
number = {1},
journal = {MIS Quarterly},
author = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
month = mar,
year = {2004},
keywords = {Database searching, Industrial efficiency, Information Systems research methodologies, Information resources, Information science, Information technology research, Organizational behavior, Psychology, RESEARCH, Research methodology, Standard operating procedure, Work environment, business environment, creativity, design artifact, design science, experimental methods, search strategies, technology infrastructure},
pages = {75--105},
}

@article{gregor_positioning_2013,
title = {Positioning and {Presenting} {Design} {Science} {Research} for {Maximum} {Impact}},
volume = {37},
issn = {ISSN 0276-7783/ISSN 2162-9730},
url = {https://aisel.aisnet.org/misq/vol37/iss2/3},
number = {2},
journal = {Management Information Systems Quarterly},
author = {Gregor, Shirley and Hevner, Alan},
month = jun,
year = {2013},
pages = {337--355},
}

@article{yang_getting_2022,
title = {Getting {Personal}: {A} {Deep} {Learning} {Artifact} for {Text}-{Based} {Measurement} of {Personality}},
issn = {1047-7047},
shorttitle = {Getting {Personal}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.2022.1111},
doi = {10.1287/isre.2022.1111},
abstract = {Analysts, managers, and policymakers are interested in predictive analytics capable of offering better foresight. It is generally accepted that in forecasting scenarios involving organizational policies or consumer decision making, personal characteristics, including personality, may be an important predictor of downstream outcomes. The inclusion of personality features in forecasting models has been hindered by the fact that traditional measurement mechanisms are often infeasible. Text-based personality detection has garnered attention because of the public availability of digital textual traces. However, the text machine learning space has bifurcated into two branches: feature-based methods relying on manually crafted human intuition, or deep learning language models that leverage big data and compute, the main commonality being that neither branch generates accurate personality assessments, thereby making personality measures infeasible for downstream forecasting applications. In this study, we propose DeepPerson, a design artifact for text-based personality detection that bridges these two branches by leveraging concepts from relevant psycholinguistic theories in conjunction with advanced deep learning strategies. DeepPerson incorporates novel transfer learning and hierarchical attention network methods that use psychological concepts and data augmentation in conjunction with person-level linguistic information. We evaluate the utility of the proposed artifact using an extensive design evaluation on three personality data sets in comparison with state-of-the-art methods proposed in academia and industry. DeepPerson can improve detection of personality dimensions by 10–20 percentage points relative to the best comparison methods. Using case studies in the finance and health domains, we show that more accurate text-based personality detection can translate into significant improvements in downstream applications such as forecasting future firm performance or predicting pandemic infection rates. Our findings have important implications for research at the intersection of design and data science, and practical implications for managers focused on enabling, producing, or consuming predictive analytics.},
urldate = {2022-07-25},
journal = {Information Systems Research},
author = {Yang, Kai and Lau, Raymond Y. K. and Abbasi, Ahmed},
month = mar,
year = {2022},
note = {Publisher: INFORMS},
keywords = {NLP, deep learning, design science, personality text mining, predictive analytics, psychometrics},
}

@article{chau_finding_2020,
title = {Finding {People} with {Emotional} {Distress} in {Online} {Social} {Media}:  {A} {Design} {Combining} {Machine} {Learning} and {Rule}-{Based} {Classification}},
volume = {44},
issn = {ISSN 0276-7783/ISSN 2162-9730},
shorttitle = {Finding {People} with {Emotional} {Distress} in {Online} {Social} {Media}},
url = {https://aisel.aisnet.org/misq/vol44/iss2/16},
number = {2},
journal = {Management Information Systems Quarterly},
author = {Chau, Michael and Li, Tim and Wong, Paul and Xu, Jennifer and Yip, Paul and Chen, Hsinchun},
month = jun,
year = {2020},
pages = {933--955},
}

@article{meyer_machine_2014,
title = {A {Machine} {Learning} {Approach} to {Improving} {Dynamic} {Decision} {Making}},
volume = {25},
issn = {1047-7047},
url = {https://pubsonline.informs.org/doi/10.1287/isre.2014.0513},
doi = {10.1287/isre.2014.0513},
abstract = {Decision strategies in dynamic environments do not always succeed in producing desired outcomes, particularly in complex, ill-structured domains. Information systems often capture large amounts of data about such environments. We propose a domain-independent, iterative approach that (a) applies data mining classification techniques to the collected data in order to discover the conditions under which dynamic decision-making strategies produce undesired or suboptimal outcomes and (b) uses this information to improve the decision strategy under these conditions. In this paper, we formally develop this approach and illustrate it by providing detailed examples of its application to a chronic disease care problem in a healthcare management organization, specifically the treatment of patients with type 2 diabetes mellitus. In particular, the proposed iterative approach is used to improve treatment strategies by predicting and eliminating treatment failures, i.e., insufficient or excessive treatment actions, based on information that is available in electronic medical record systems. We also apply the proposed approach to a manufacturing task, resulting in substantial decision strategy improvements, which further demonstrates the generality and flexibility of the proposed approach.},
number = {2},
urldate = {2022-07-28},
journal = {Information Systems Research},
author = {Meyer, Georg and Adomavicius, Gediminas and Johnson, Paul E. and Elidrisi, Mohamed and Rush, William A. and Sperl-Hillen, JoAnn M. and O'Connor, Patrick J.},
month = jun,
year = {2014},
note = {Publisher: INFORMS},
keywords = {data mining, dynamic decision making, healthcare, machine learning, process control, process mining, simulation},
pages = {239--263},
}

@article{ben-assuli_trajectories_2020,
title = {Trajectories of {Repeated} {Readmissions} of {Chronic} {Disease} {Patients}:  {Risk} {Stratification}, {Profiling}, and {Prediction}},
volume = {44},
issn = {ISSN 0276-7783/ISSN 2162-9730},
shorttitle = {Trajectories of {Repeated} {Readmissions} of {Chronic} {Disease} {Patients}},
url = {https://aisel.aisnet.org/misq/vol44/iss1/10},
number = {1},
journal = {Management Information Systems Quarterly},
author = {Ben-Assuli, Ofir and Padman, Rema},
month = mar,
year = {2020},
pages = {201--226},
}

@article{nan_harnessing_2014,
title = {Harnessing the power of self-organization in an online community during organizational crisis},
volume = {38},
issn = {0276-7783},
url = {https://doi.org/10.25300/MISQ/2014/38.4.09},
doi = {10.25300/MISQ/2014/38.4.09},
abstract = {Organizational crisis management has traditionally favored a centralized plan-and-control approach. This study explores the possibility for an orderly crisis management process to arise unintentionally from decentralized and spontaneous actions in an online community (i.e., self-organization). Based on complex adaptive systems theory, a multilevel model is developed to account for the logical relation between individual-level actions and interactions in an online community and an organizational-level orderly and rational crisis management process, as described by the organizational crisis management literature. We apply this multilevel model to an analysis of 89,596 posts from an online community that was deeply embedded in an earthquake-induced organizational crisis. Results indicate that fluctuation of message content themes in this online community served to energize continuous input from ordinary organization members. These input actualized new possibilities offered by the technology platform for crisis management actions (i.e., actualized IT affordances). Concatenation of immediate impacts of message content themes and actualized IT affordances formed feedback loops that moderated the crisis management activities toward an efficient trajectory. Our findings challenge the traditional assumption that macro-level order requires micro-level order-seeking behaviors. They suggest the viability of self-organization as a new source of organizational order that complements the traditional centralized plan-and-control approach. Theoretical and empirical implications for harnessing the power of ordinary organization members connected by today's technology platforms are discussed.},
number = {4},
urldate = {2022-07-28},
journal = {MIS Quarterly},
author = {Nan, Ning and Lu, Yong},
month = dec,
year = {2014},
keywords = {complex adaptive systems, information technology, online community, organizational crisis, self-organization},
pages = {1135--1158},
}

@article{cotteleer_order_2006,
title = {Order {Lead}-{Time} {Improvement} following {Enterprise} {Information} {Technology} {Implementation}: {An} {Empirical} {Study}},
volume = {30},
issn = {0276-7783},
shorttitle = {Order {Lead}-{Time} {Improvement} following {Enterprise} {Information} {Technology} {Implementation}},
url = {https://www.jstor.org/stable/25148743},
doi = {10.2307/25148743},
abstract = {This paper investigates the influence of enterprise systems implementation on operational performance. The work extends the literature on enterprise systems by focusing on changes in process dynamics as a source for ongoing firm-level performance improvement. A case discussion of Tristen Corporation, a firm that implemented ERP and subsequently experienced benefits through gains to its continuous improvement efforts, is examined in light of theorized impacts of such implementations on process dynamics. Analyses of longitudinal data suggest that performance along a key metric motivating the ERP initiative (i.e., order fulfillment lead-time) showed a significant improvement immediately after system deployment. The data further suggest that the system implementation gave rise to an ongoing trend of performance improvement, in contrast to a stable performance trend prior to go-live.},
number = {3},
urldate = {2022-07-28},
journal = {MIS Quarterly},
author = {Cotteleer, Mark J. and Bendoly, Elliot},
year = {2006},
note = {Publisher: Management Information Systems Research Center, University of Minnesota},
pages = {643--660},
}

@article{wang_deep_2022,
title = {Deep {Learning} of {Spatiotemporal} {Patterns} for {Urban} {Mobility} {Prediction} {Using} {Big} {Data}},
volume = {33},
issn = {1526-5536},
url = {https://doi.org/10.1287/isre.2021.1072},
doi = {10.1287/isre.2021.1072},
abstract = {Timely and accurate prediction of human movement in urban areas offers instructive insights into transportation management, public safety, and location-based services, to name a few. Yet, modeling urban mobility is challenging and complex because of the spatiotemporal dynamics of movement behavior and the influence of exogenous factors such as weather, holidays, and local events. In this paper, we use bus transportation as a proxy to mine spatiotemporal travel patterns. We propose a deep-learning-based urban mobility prediction model that collectively forecasts passenger flows between pairs of city regions in an origin-destination (OD) matrix. We first process OD matrices in a convolutional neural network to capture spatial correlations. Intermediate results are reconstructed into three multivariate time series: hourly, daily, and weekly time series. Each time series is aggregated in a long short-term memory (LSTM) network with a novel attention mechanism to guide the aggregation. In addition, our model is context-aware by using contextual embeddings learned from exogenous factors. We dynamically merge results from LSTM components and context embeddings in a late fusion network to make a final prediction. The proposed model is implemented and evaluated using a large-scale transportation data set of more than 200 million bus trips with a suite of Big Data technologies developed for data processing. Through performance comparison, we show that our approach achieves sizable accuracy improvements in urban mobility prediction. Our work has major implications for efficient transportation system design and performance improvement. The proposed deep neural network structure is generally applicable for sequential graph data prediction.},
number = {2},
urldate = {2022-07-28},
journal = {Information Systems Research},
author = {Wang, Yun and Currim, Faiz and Ram, Sudha},
month = jun,
year = {2022},
keywords = {big data, deep learning, predictive modeling, smart transportation},
pages = {579--598},
}

@article{li_why_2010,
title = {Why {Do} {Software} {Firms} {Fail}? {Capabilities}, {Competitive} {Actions}, and {Firm} {Survival} in the {Software} {Industry} from 1995 to 2007},
volume = {21},
issn = {1047-7047},
shorttitle = {Why {Do} {Software} {Firms} {Fail}?},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.1100.0281},
doi = {10.1287/isre.1100.0281},
abstract = {This study examines why firms fail or survive in the volatile software industry. We provide a novel perspective by considering how software firms' capabilities and their competitive actions affect their ultimate survival. Drawing on the resource-based view (RBV), we conceptualize capabilities as a firm's ability to efficiently transform input resources into outputs, relative to its peers. We define three critical capabilities of software-producing firms—research and development (RD), marketing (MK), and operations (OP)—and hypothesize that in the dynamic, high-technology software industry, RD and MK capabilities are most important for firm survival. We then draw on the competitive dynamics literature to theorize that competitive actions distinguished by a greater emphasis on innovation-related moves will increase firm survival more than actions emphasizing resource-related moves. Finally, we postulate that firms' capabilities will complement their competitive actions in affecting firm survival. Our empirical evaluation examines a cross-sectional, time series panel of 5,827 observations on 870 software companies from 1995 to 2007. We use a stochastic frontier production function to measure the capability for each software firm in each time period. We then use the Cox proportional hazard regression technique to relate capabilities and competitive actions to software firms' failure rates. Unexpectedly, our results reveal that higher OP capability increases software firm survival more than higher MK and RD capabilities. Further, firms with a greater emphasis on innovation-related than resource-related competitive actions have a greater likelihood of survival, and this likelihood increases even further when these firms have higher MK and OP capabilities. Additional analyses of subsectors within the software industry reveal that firms producing visual applications (e.g., graphical and video game software) have the highest MK capability but the lowest OP and RD capabilities and make twice as many innovation-related as resource-related moves. These firms have the highest market values but the worst Altman Z scores, suggesting that they are valued highly but also are at high risk for failure, and indeed the firms in this sector fail at a greater rate than expected. In contrast, firms producing traditional decision-support applications and infrastructure software have different capabilities and make different competitive moves. Our findings suggest that the firms that persist and survive over the long term in the dynamic software industry are able to capitalize on their competitive actions because of their greater capabilities, and particularly OP capabilities.},
number = {3},
urldate = {2022-07-28},
journal = {Information Systems Research},
author = {Li, Shanling and Shang, Jennifer and Slaughter, Sandra A.},
month = sep,
year = {2010},
note = {Publisher: INFORMS},
keywords = {capability, competitive actions, competitive dynamics, marketing, operations, research and development, resource-based view, software industry, stochastic frontier production function, survival analysis},
pages = {631--654},
}

@article{song_ecosystem_2018,
title = {The ecosystem of software platform: a study of asymmetric cross-side network effects and platform governance},
volume = {42},
issn = {0276-7783},
shorttitle = {The ecosystem of software platform},
url = {https://doi.org/10.25300/MISQ/2018/13737},
doi = {10.25300/MISQ/2018/13737},
abstract = {In the context of software platforms, we examine how cross-side network effects (CNEs) on different platform sides (app-side and user-side) are temporally asymmetric, and how these CNEs are influenced by the platform's governance policies. Informed by a perspective of value creation and capture, we theorize how the app-side and the user-side react to each other with distinct value creation/capture processes, and how these processes are influenced by the platform's governance policies on app review and platform updates. We use a time-series analysis to empirically investigate the platform ecosystem of a leading web browser. Our findings suggest that while the growth in platform usage results in long-term growth in both the number and variety of apps, the growth in the number of apps and the variety of apps only leads to short-term growth in platform usage. We also find that long app review time weakens the long-term CNE of the user-side on the app-side, but not the short-term CNE of the app-side on the user-side. Moreover, we find that frequent platform updates weaken the CNEs of both the user-side and the app-side on each other. These findings generate important implications regarding how a software platform may better govern its ecosystem with different participants.},
number = {1},
urldate = {2022-07-28},
journal = {MIS Quarterly},
author = {Song, Peijian and Xue, Ling and Rai, Arun and Zhang, Cheng},
month = mar,
year = {2018},
keywords = {Software platform, network effects, platform governance, two-sided markets, value creation and capture},
pages = {121--142},
}

@article{wattal_web_2010,
title = {Web 2.0 and {Politics}: {The} 2008 {U}.{S}. {Presidential} {Election} and an {E}-{Politics} {Research} {Agenda}},
volume = {34},
issn = {0276-7783},
shorttitle = {Web 2.0 and {Politics}},
url = {https://www.jstor.org/stable/25750700},
doi = {10.2307/25750700},
abstract = {The Internet was a major factor in the 2008 U.S. presidential campaign and has become an important tool for political communication and persuasion. Yet, information systems research is generally silent on the role of the Internet in politics. In this paper, we argue that IS is positioned to enhance understanding of the influence of the Internet on politics, and, more specifically, the process of election campaigning using Internet-based technologies such as Web 2.0. In this paper, we discuss how these technologies can change the nature of competition in politics and replace or complement traditional media. Our empirical study on how Web 2.0 technologies were used by the candidates leading up to the 2008 U.S. presidential primaries sheds light on how these technologies influenced candidate performance. Finally, we outline a research agenda highlighting where IS can contribute to the academic discourse on e-politics.},
number = {4},
urldate = {2022-07-28},
journal = {MIS Quarterly},
author = {Wattal, Sunil and Schuff, David and Mandviwalla, Munir and Williams, Christine B.},
year = {2010},
note = {Publisher: Management Information Systems Research Center, University of Minnesota},
pages = {669--688},
}

@article{lee_time_2005,
title = {Time series analysis in the assessment of {ICT} impact at the aggregate level – lessons and implications for the new economy},
volume = {42},
issn = {0378-7206},
url = {https://www.sciencedirect.com/science/article/pii/S0378720604001569?via%3Dihub},
doi = {10.1016/j.im.2004.11.005},
abstract = {The major role of information and communication technology (ICT) in the new economy is well documented: countries worldwide are pouring resources into their ICT infrastructure despite the widely acknowledged “productivity paradox”. Evaluating the contribution of ICT investments has become an elusive but important goal of IS researchers and economists. But this area of research is fraught with complexity and we have used Solow's Residual together with time-series analysis tools to overcome some methodological inadequacies of previous studies. Using this approach, we conduct a study of 20 countries to determine if there was empirical evidence to support claims that ICT investments are worthwhile. The results show that ICT contributes to economic growth in many developed countries and newly industrialized economies (NIEs), but not in developing countries. We finally suggest ICT-complementary factors, in an attempt to rectify possible flaws in ICT policies as a contribution towards improvement in global productivity.},
number = {7},
urldate = {2022-07-28},
journal = {Information and Management},
author = {Lee, Sang-Yong T. and Gholami, Roghieh and Tonh, Tan Y.},
month = oct,
year = {2005},
keywords = {ICT, Solow's residual, economic growth, information and communication technology, productivity paradox, time series},
pages = {1009--1022},
}

@article{hu_network-based_2012,
title = {Network-{Based} {Modeling} and {Analysis} of {Systemic} {Risk} in {Banking} {Systems}},
volume = {36},
issn = {ISSN 0276-7783/ISSN 2162-9730},
url = {https://aisel.aisnet.org/misq/vol36/iss4/20},
number = {4},
journal = {Management Information Systems Quarterly},
author = {Hu, Daning and Zhao, J. and Hua, Zhimin and Wong, Michael},
month = dec,
year = {2012},
pages = {1269--1291},
}

@article{abbasi_phishing_2021,
title = {The {Phishing} {Funnel} {Model}: {A} {Design} {Artifact} to {Predict} {User} {Susceptibility} to {Phishing} {Websites}},
volume = {32},
issn = {1047-7047},
shorttitle = {The {Phishing} {Funnel} {Model}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.2020.0973},
doi = {10.1287/isre.2020.0973},
abstract = {Phishing is a significant security concern for organizations, threatening employees and members of the public. Phishing threats against employees can lead to severe security incidents, whereas those against the public can undermine trust, satisfaction, and brand equity. At the root of the problem is the inability of Internet users to identify phishing attacks even when using anti-phishing tools. We propose the phishing funnel model (PFM), a design artifact for predicting user susceptibility to phishing websites. PFM incorporates user, threat, and tool-related factors to predict actions during four key stages of the phishing process: visit, browse, consider legitimate, and intention to transact. We used a support vector ordinal regression with a custom kernel encompassing a cumulative-link mixed model for representing users’ decisions across funnel stages. We evaluated the efficacy of PFM in a 12-month longitudinal field experiment in two organizations involving 1,278 employees and 49,373 phishing interactions. PFM significantly outperformed competing models/methods by 8\%–52\% in area under the curve, correctly predicting visits to high-severity threats 96\% of the time—a result 10\% higher than the nearest competitor. A follow-up three-month field study revealed that employees using PFM were significantly less likely to interact with phishing threats relative to comparison models and baseline warnings. Furthermore, a cost-benefit analysis showed that interventions guided by PFM resulted in phishing-related cost reductions of nearly \$1,900 per employee more than comparison prediction methods. These results indicate strong external validity for PFM. Our findings have important implications for practice by demonstrating (1) the effectiveness of predicting user susceptibility to phishing as a real-time protection strategy, (2) the value of modeling each stage of the phishing process together, rather than focusing on a single user action, and (3) the considerable impact of anti-phishing tool and threat-related factors on susceptibility to phishing.},
number = {2},
urldate = {2022-07-27},
journal = {Information Systems Research},
author = {Abbasi, Ahmed and Dobolyi, David and Vance, Anthony and Zahedi, Fatemeh Mariam},
month = jun,
year = {2021},
note = {Publisher: INFORMS},
keywords = {design science, longitudinal field experiment, online security, phishing susceptibility, predictive analytics},
pages = {410--436},
}

@article{deasy_dynamic_2020,
title = {Dynamic survival prediction in intensive care units from heterogeneous time series without the need for variable selection or curation},
volume = {10},
copyright = {2020 The Author(s)},
issn = {2045-2322},
url = {https://www.nature.com/articles/s41598-020-79142-z},
doi = {10.1038/s41598-020-79142-z},
abstract = {Extensive monitoring in intensive care units (ICUs) generates large quantities of data which contain numerous trends that are difficult for clinicians to systematically evaluate. Current approaches to such heterogeneity in electronic health records (EHRs) discard pertinent information. We present a deep learning pipeline that uses all uncurated chart, lab, and output events for prediction of in-hospital mortality without variable selection. Over 21,000 ICU patients and tens of thousands of variables derived from the MIMIC-III database were used to train and validate our model. Recordings in the first few hours of a patient’s stay were found to be strongly predictive of mortality, outperforming models using SAPS II and OASIS scores, AUROC 0.72 and 0.76 at 24 h respectively, within just 12 h of ICU admission. Our model achieves a very strong predictive performance of AUROC 0.85 (95\% CI 0.83–0.86) after 48 h. Predictive performance increases over the first 48 h, but suffers from diminishing returns, providing rationale for time-limited trials of critical care and suggesting that the timing of decision making can be optimised and individualised.},
language = {en},
number = {1},
urldate = {2022-07-27},
journal = {Scientific Reports},
author = {Deasy, Jacob and Liò, Pietro and Ercole, Ari},
month = dec,
year = {2020},
note = {Number: 1
Publisher: Nature Publishing Group},
keywords = {Health care, Medical research, Outcomes research},
pages = {22129},
}

@misc{noauthor_complete_nodate,
title = {The {Complete} {Guide} to {Time} {Series} {Data}},
url = {https://www.clarify.io/learn/time-series-data},
abstract = {What is time series and what are the databases, visualization tools \& techniques. Learn how to analyse and work with time series data.},
language = {en},
urldate = {2022-07-27},
}

@article{zeger_time_2006,
title = {On time series analysis of public health and biomedical data},
volume = {27},
issn = {0163-7525},
url = {https://jhu.pure.elsevier.com/en/publications/on-time-series-analysis-of-public-health-and-biomedical-data-4},
doi = {10.1146/annurev.publhealth.26.021304.144517},
language = {English (US)},
urldate = {2022-07-27},
journal = {Annual review of public health},
author = {Zeger, Scott L. and Irizarry, Rafael and Peng, Roger D.},
year = {2006},
pmid = {16533109},
note = {Publisher: Annual Reviews Inc.},
pages = {57--79},
}

@misc{noauthor_8generative_nodate,
title = {8.{Generative} {Adversarial} {Network} ({GAN})},
}

@misc{noauthor_7special_nodate,
title = {7.{Special} {Training} {Technology}},
}

@article{heikkinen_recent_1994,
title = {Recent life events, social support and suicide},
volume = {377},
issn = {0065-1591},
doi = {10.1111/j.1600-0447.1994.tb05805.x},
abstract = {The occurrence of recent life events during the last 3 months, and social support received were studied in a nationwide suicide population (N = 1,067) in Finland. Recent life events were reported in 80\% of the suicides. Job problems (28\%), family discord (23\%), somatic illness (22\%), financial trouble (18\%), unemployment (16\%), separation (14\%), death (13\%) and illness in family (12\%) were the most common life events. Sex differences were found in recent life events: any life event, separation, financial trouble, job problems and unemployment were more common among males. The mean number of life events was also higher among males. Living alone was more common among female victims. Females had children more often than males. In terms of friendships, more females had a close friend, whereas more males had friends sharing common interests. Females had complained of loneliness more often than males. Those females who had lived alone had encountered a recent death more often than other females. The male victims who had lived alone had experienced separation, financial trouble and unemployment during the last 3 months more frequently than other males, suggesting a concurrent stressor effect of these recent life events with living alone in male suicides.},
language = {eng},
journal = {Acta Psychiatrica Scandinavica. Supplementum},
author = {Heikkinen, M. and Aro, H. and Lönnqvist, J.},
year = {1994},
pmid = {8053369},
keywords = {Adolescent, Adult, Aged, Aged, 80 and over, Cross-Sectional Studies, Female, Finland, Humans, Incidence, Life Change Events, Male, Middle Aged, Personality Assessment, Risk Factors, Social Support, Suicide},
pages = {65--72},
}

@article{musen_protege_2015,
title = {The {Protégé} {Project}: {A} {Look} {Back} and a {Look} {Forward}},
volume = {1},
issn = {2372-3483},
shorttitle = {The {Protégé} {Project}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4883684/},
doi = {10.1145/2757001.2757003},
number = {4},
urldate = {2022-07-16},
journal = {AI matters},
author = {Musen, Mark A.},
month = jun,
year = {2015},
pmid = {27239556},
pmcid = {PMC4883684},
pages = {4--12},
}

@book{smith_ontology_2012,
title = {Ontology},
isbn = {978-94-012-0779-9},
url = {https://brill.com/view/book/9789401207799/B9789401207799-s005.xml},
language = {en},
urldate = {2022-07-16},
publisher = {Brill},
author = {Smith, Barry},
month = jan,
year = {2012},
doi = {10.1163/9789401207799_005},
note = {Pages: 47-68
Section: The furniture of the world},
keywords = {Epistemology \& Metaphysics, Philosophy},
}

@article{paykel_life_1994,
title = {Life events, {Social} support and depression},
volume = {89},
issn = {1600-0447},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0447.1994.tb05803.x},
doi = {10.1111/j.1600-0447.1994.tb05803.x},
abstract = {This paper reviews current findings regarding Social stress and support in clinical depression. Comparisons of recent life events at depressive onset and in general population controls show consistently raised event rates. The events span a range of threatening and undesirable experiences, with limited selectivity to exit events and interpersonal losses. Effects are similar in endogenous and non-endogenous symptom pictures, and there are suggestive findings in bipolar disorder, but these require further study. Events are also related to outcome and to relapse. Effects are moderate in degree, but relatively short-term of over six months to a year. For Social support there are greater problems in the extent to which Social support may be determined by the individual's own behaviour. Absence of Social support appears to be associated with onset and relapse of depression, both acting independently and modifying effects of life events. Social stress findings have implications for prevention. The occurrence of major life events signals a period of increased risk when supportive interventions may prevent evolution of distress to disorder.},
language = {en},
number = {s377},
urldate = {2022-07-16},
journal = {Acta Psychiatrica Scandinavica},
author = {Paykel, E. S.},
year = {1994},
note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1600-0447.1994.tb05803.x},
keywords = {Depression, Social support, life change events},
pages = {50--58},
}

@inproceedings{kolyvakis_deepalignment_2018,
address = {New Orleans, Louisiana},
title = {{DeepAlignment}: {Unsupervised} {Ontology} {Matching} with {Refined} {Word} {Vectors}},
shorttitle = {{DeepAlignment}},
url = {https://aclanthology.org/N18-1072},
doi = {10.18653/v1/N18-1072},
abstract = {Ontologies compartmentalize types and relations in a target domain and provide the semantic backbone needed for a plethora of practical applications. Very often different ontologies are developed independently for the same domain. Such “parallel” ontologies raise the need for a process that will establish alignments between their entities in order to unify and extend the existing knowledge. In this work, we present a novel entity alignment method which we dub DeepAlignment. DeepAlignment refines pre-trained word vectors aiming at deriving ontological entity descriptions which are tailored to the ontology matching task. The absence of explicit information relevant to the ontology matching task during the refinement process makes DeepAlignment completely unsupervised. We empirically evaluate our method using standard ontology matching benchmarks. We present significant performance improvements over the current state-of-the-art, demonstrating the advantages that representation learning techniques bring to ontology matching.},
urldate = {2022-07-14},
booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
publisher = {Association for Computational Linguistics},
author = {Kolyvakis, Prodromos and Kalousis, Alexandros and Kiritsis, Dimitris},
month = jun,
year = {2018},
pages = {787--798},
}

@incollection{smith_ontology_2003,
title = {Ontology},
booktitle = {Blackwell {Guide} to the {Philosophy} of {Computing} and {Information}},
publisher = {Oxford: Blackwell},
author = {Smith, Barry},
editor = {Floridi, Luciano},
year = {2003},
pages = {155--166},
}

@article{chu_optimizing_2020,
title = {Optimizing {Ontology} {Alignment} in {Vector} {Space}},
volume = {21},
copyright = {Copyright (c) 2020 Journal of Internet Technology},
issn = {2079-4029},
url = {https://jit.ndhu.edu.tw/article/view/2218},
abstract = {Ontology matching technique aims at determining the identical entities, which can effectively solve the ontology heterogeneity problem and implement the collaborations among ontology-based intelligent systems. Typically, an ontology consists of a set of concepts which are described by various properties, and they deﬁne a space such that each distinct concept and property represents one dimension in that space. Therefore, it is an effective way to model an ontology in a vector space, and use the vector space based similarity measure to calculate two entities’ similarity. In this work, the entities’ structure information is utilized to model an ontology in a vector space, and then, their linguistic information is used to reduce the number of dimensions, which can improve the eﬃciency of the similarity calculation and entity matching process. After that, a discrete optimization model is constructed for the ontology matching problem, and a compact Evolutionary Algorithm (cEA) based ontology matching technique is proposed to eﬃciently address it. The experiment uses the benchmark track provided by Ontology Alignment Evaluation Initiative (OAEI) to test our proposal’s performance, and the comparing results with state-of-the-art ontology matching systems show that our approach can eﬃciently determine high-quality ontology alignments.},
language = {en-US},
number = {1},
urldate = {2022-07-14},
journal = {Journal of Internet Technology},
author = {Chu, Shu-Chuan and Xue, Xingsi and Pan, Jeng-Shyang and Wu, Xiaojing},
month = jan,
year = {2020},
note = {Number: 1},
pages = {15--22},
}

@inproceedings{tous_vector_2006,
address = {Berlin, Heidelberg},
series = {Lecture {Notes} in {Computer} {Science}},
title = {A {Vector} {Space} {Model} for {Semantic} {Similarity} {Calculation} and {OWL} {Ontology} {Alignment}},
isbn = {978-3-540-37872-3},
doi = {10.1007/11827405_30},
abstract = {Ontology alignment (or matching) is the operation that takes two ontologies and produces a set of semantic correspondences (usually semantic similarities) between some elements of one of them and some elements of the other. A rigorous, efficient and scalable similarity measure is a pre-requisite of an ontology alignment process. This paper presents a semantic similarity measure based on a matrix represention of nodes from an RDF labelled directed graph. An entity is described with respect to how it relates to other entities using N-dimensional vectors, being N the number of selected external predicates. We adapt a known graph matching algorithm when applying this idea to the alignment of two ontologies. We have successfully tested the model with the public testcases of the Ontology Alignment Evaluation Initiative 2005.},
language = {en},
booktitle = {Database and {Expert} {Systems} {Applications}},
publisher = {Springer},
author = {Tous, Rubén and Delgado, Jaime},
editor = {Bressan, Stéphane and Küng, Josef and Wagner, Roland},
year = {2006},
keywords = {Bipartite Graph, Resource Description Framework, Semantic Similarity, Semantic Similarity Measure, Vector Space Model},
pages = {307--316},
}

@misc{chen_deep_2019,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {Deep {Learning} in {Asset} {Pricing}},
url = {https://papers.ssrn.com/abstract=3350138},
doi = {10.2139/ssrn.3350138},
abstract = {We use deep neural networks to estimate an asset pricing model for individual stock returns that takes advantage of the vast amount of conditioning information, while keeping a fully flexible form and accounting for time-variation. The key innovations are to use the fundamental no-arbitrage condition as criterion function, to construct the most informative test assets with an adversarial approach and to extract the states of the economy from many macroeconomic time series. Our asset pricing model outperforms out-of-sample all benchmark approaches in terms of Sharpe ratio, explained variation and pricing errors and identifies the key factors that drive asset prices.},
language = {en},
urldate = {2022-07-11},
author = {Chen, Luyang and Pelger, Markus and Zhu, Jason},
month = apr,
year = {2019},
keywords = {GMM, No-arbitrage, big data, conditional asset pricing model, deep learning, hidden states, machine learning, neural networks, non-linear factor model, stock returns},
}

@article{gu_empirical_2020,
title = {Empirical {Asset} {Pricing} via {Machine} {Learning}},
volume = {33},
issn = {0893-9454},
url = {https://doi.org/10.1093/rfs/hhaa009},
doi = {10.1093/rfs/hhaa009},
abstract = {We perform a comparative analysis of machine learning methods for the canonical problem of empirical asset pricing: measuring asset risk premiums. We demonstrate large economic gains to investors using machine learning forecasts, in some cases doubling the performance of leading regression-based strategies from the literature. We identify the best-performing methods (trees and neural networks) and trace their predictive gains to allowing nonlinear predictor interactions missed by other methods. All methods agree on the same set of dominant predictive signals, a set that includes variations on momentum, liquidity, and volatility.Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.},
number = {5},
urldate = {2022-07-11},
journal = {The Review of Financial Studies},
author = {Gu, Shihao and Kelly, Bryan and Xiu, Dacheng},
month = may,
year = {2020},
pages = {2223--2273},
}

@misc{noauthor_markus_nodate,
title = {Markus {Pelger}},
url = {https://mpelger.people.stanford.edu/},
language = {en},
urldate = {2022-07-11},
}

@article{khurana_when_2019,
title = {When a {Doctor} {Knows}, {It} {Shows}: {An} {Empirical} {Analysis} of {Doctors}’ {Responses} in a {Q}\&{A} {Forum} of an {Online} {Healthcare} {Portal}},
volume = {30},
issn = {1047-7047},
shorttitle = {When a {Doctor} {Knows}, {It} {Shows}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.2019.0836},
doi = {10.1287/isre.2019.0836},
abstract = {Question-and-answer (Q\&A) forums are gaining popularity as a user-engagement tool to drive traffic on multiservice portals. In a platform market model, demand-side users seek answers from supply-side users because such answers can indicate value offered, reduce buyer uncertainty, and offer social proof. Analyzing user-generated content on the Q\&A forum of a prominent healthcare portal, we find that the introduction of doctors’ responses has a significant causal impact on demand-side user perception of medical services offered. More importantly, our research suggests that doctors’ specialty, experience, qualifications, transparency in appointment booking, service fees, and response quality moderate the effect of doctors’ Q\&A responses on user recommendations. These results demonstrate that because of information asymmetry in healthcare, doctors use thoughtful online responses not only to socially interact with patients but also to signal their expertise.},
number = {3},
urldate = {2022-07-11},
journal = {Information Systems Research},
author = {Khurana, Sandeep and Qiu, Liangfei and Kumar, Subodha},
month = sep,
year = {2019},
note = {Publisher: INFORMS},
keywords = {Q\&A forums, digital platforms, healthcare, user-generated content},
pages = {872--891},
}

@misc{yan_prosocial_2019,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {Prosocial {Behaviors} and {Economic} {Performance}: {Evidence} from an {Online} {Mental} {Healthcare} {Platform}},
shorttitle = {Prosocial {Behaviors} and {Economic} {Performance}},
url = {https://papers.ssrn.com/abstract=3493138},
abstract = {With the growth of online mental healthcare platforms, health professionals have been providing online consultation services in their spare time. However, little is known about the behaviors of health professionals on these platforms and their impact on achieving healthcare professionals’ online career success. In this research, we study how the prosocial behaviors of mental healthcare service providers influence their social and economic returns. Based on signaling and commitment theory, this study uses a panel dataset from a Chinese online mental healthcare platform to examine how counselors’ prosocial behaviors influence their relationship returns and reputation returns, furthermore, how the relationship and reputation return transform to economic returns. Our findings show that participating in prosocial activities in the previous week is positively associated with counselors’ relationship and reputation returns in the current week. We further find that the relationship returns accumulated in the past week is positively associated with counselors’ economic returns in the current week. Contrary to previous literature posited that reputation level positively indicates economic returns, our results suggest that the reputation return accumulated in the past week does not positively predict the economic returns in the current week.},
language = {en},
urldate = {2022-07-11},
author = {Yan, Zhijun and Kuang, Lini and Qiu, Liangfei},
month = nov,
year = {2019},
keywords = {economic return, online mental healthcare platform, prosocial behaviors, relationship return, reputation return},
}

@article{chen_designing_2021,
title = {Designing {Personalized} {Treatment} {Plans} for {Breast} {Cancer}},
volume = {32},
issn = {1047-7047},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.2021.1002},
doi = {10.1287/isre.2021.1002},
abstract = {Breast cancer remains the leading cause of cancer deaths among women around the world. Contemporary treatment for breast cancer is complex and involves highly specialized medical professionals collaborating in a series of information-intensive processes. This poses significant challenges to personalization and customization of treatment plans for individual patients. In this research, we follow the information systems design science paradigm and propose a novel framework for decision support of treatment planning for early stage breast cancer patients undergoing radiotherapy. The core of our framework consists of a predictive model that predicts patient outcome of a treatment plan based on clinical and patient characteristics, and an optimization model that optimizes the treatment plan based on predicted outcomes of different plans. Using a series of simulation experiments, we show that the treatment plans generated from our framework consistently outperform those from the existing practices in balancing the risk of local tumor recurrence and radiation-induced adverse effects, thereby reducing the treatment cost associated with these adverse effects. Our research contributes to the growing literature that examines the potential of healthcare information technologies in delivering cost-effective care. Further, we also contribute to healthcare practices by providing models and tools that have pragmatic value as part of the clinical care delivery system.},
number = {3},
urldate = {2022-07-11},
journal = {Information Systems Research},
author = {Chen, Wei and Lu, Yixin and Qiu, Liangfei and Kumar, Subodha},
month = sep,
year = {2021},
note = {Publisher: INFORMS},
keywords = {clinical decision support, design science, healthcare information technologies, personalized medicine, treatment planning},
pages = {932--949},
}

@article{xiaofei_effects_2021,
title = {Effects of emotional attachment on mobile health-monitoring service usage: {An} affect transfer perspective},
volume = {58},
issn = {0378-7206},
shorttitle = {Effects of emotional attachment on mobile health-monitoring service usage},
url = {https://www.sciencedirect.com/science/article/pii/S0378720620302457},
doi = {10.1016/j.im.2020.103312},
abstract = {Mobile health-monitoring services (MMSs) empower patients with chronic illnesses to self-manage their health concerns; however, in practice, many patients become inactive users after employing MMSs for a short time. The reasons for this usage pattern remain unclear. By extending the literature that focuses on the cognitive reasoning behind system usage, our study takes an affect transfer perspective to examine how these patients develop emotional attachment to MMSs that subsequently drives their usage. Drawing on affect transfer theory, we hypothesize that patients’ satisfaction with MMS components influences their emotional attachment to the service through both cognitive and misattribution routines, and that the combined effects of these two routines are contingent on patients’ health rationality. Our hypotheses are tested with survey data collected from 228 patients with chronic illnesses. This study contributes to the mobile health (mHealth) literature by investigating patients’ actual behavior based on their interactions with MMSs from an affect transfer perspective. It also informs service providers of MMSs regarding how to motivate service usage by patients with chronic illnesses by adopting a strategic design.},
language = {en},
number = {2},
urldate = {2022-07-08},
journal = {Information \& Management},
author = {Xiaofei, Zhang and Guo, Xitong and Ho, Shuk Ying and Lai, Kee-hung and Vogel, Doug},
month = mar,
year = {2021},
keywords = {Affect transfer, Device satisfaction, Emotional attachment, Feedback satisfaction, Health rationality, mHealth monitoring service},
pages = {103312},
}

@article{yang_not_2021,
title = {Not just for the money? {An} examination of the motives behind physicians’ sharing of paid health information},
issn = {0165-5515},
shorttitle = {Not just for the money?},
url = {https://doi.org/10.1177/0165551521991029},
doi = {10.1177/0165551521991029},
abstract = {Online platforms make it possible for physicians to share online information with the public, however, few studies have explored the underlying mechanism of physicians’ sharing of paid health information. Drawing on motivation theory, this study developed a theoretical framework to explore the effects of extrinsic motivation, enjoyment, and professional motivation on the sharing of paid information, as well as the contingent role of income ratio (online to offline) and online reputation. The model was tested with both objective and subjective data, which contain responses from 298 physicians. The results show that extrinsic motivation, enjoyment, and professional motivation play significant roles in inducing physicians to share paid information. Furthermore, income ratio can moderate the effects of motives on paid information sharing. Besides, the effect of professional motivation can be more effective in certain situations (low-level income ratio or high online reputation). This study contributes to the literature on knowledge sharing, online health behaviour, and motivation theory, and provides implications for practitioners.},
language = {en},
urldate = {2022-07-08},
journal = {Journal of Information Science},
author = {Yang, Yulin and Zhu, Xuekun and Song, Ruidi and Zhang, Xiaofei and Guo, Feng},
month = feb,
year = {2021},
note = {Publisher: SAGE Publications Ltd},
keywords = {Enjoyment, extrinsic motivation, income ratio, online health communities, online reputation, professional motivation, sharing of paid health information},
pages = {0165551521991029},
}

@article{hoberg_text-based_2016,
title = {Text-{Based} {Network} {Industries} and {Endogenous} {Product} {Differentiation}},
volume = {124},
issn = {0022-3808},
url = {https://www.journals.uchicago.edu/doi/full/10.1086/688176},
doi = {10.1086/688176},
abstract = {We study how firms differ from their competitors using new time-varying measures of product similarity based on text-based analysis of firm 10-K product descriptions. This year-by-year set of product similarity measures allows us to generate a new set of industries in which firms can have their own distinct set of competitors. Our new sets of competitors explain specific discussion of high competition, rivals identified by managers as peer firms, and changes to industry competitors following exogenous industry shocks. We also find evidence that firm R\&D and advertising are associated with subsequent differentiation from competitors, consistent with theories of endogenous product differentiation.},
number = {5},
urldate = {2022-07-08},
journal = {Journal of Political Economy},
author = {Hoberg, Gerard and Phillips, Gordon},
month = oct,
year = {2016},
note = {Publisher: The University of Chicago Press},
pages = {1423--1465},
}

@article{hoberg_conglomerate_2018,
title = {Conglomerate {Industry} {Choice} and {Product} {Language}},
volume = {64},
issn = {0025-1909, 1526-5501},
url = {http://pubsonline.informs.org/doi/10.1287/mnsc.2016.2693},
doi = {10.1287/mnsc.2016.2693},
abstract = {We analyze the words that ﬁrms use to describe their products so we can examine the determinants of which industries conglomerate ﬁrms operate within. Our central ﬁnding is that multiple-industry ﬁrms operate across industries with higher product language overlap. Multiple-industry ﬁrms also avoid industries with more distinct language boundaries and those with more specialized within-industry language. We also ﬁnd evidence linking these results to speciﬁc synergies such as potential entry into new markets and realized synergies in the form of higher 10-K product description growth. These ﬁndings are consistent with multiple-product ﬁrms operating primarily in industries that lack language specialization. Our ﬁndings show that most conglomerates are not true diversiﬁed conglomerates with little overlap in their lines of business, as most ﬁrms that operate across multiple industries choose industries with high language overlap and potential synergies. Our results support theories of ﬁrm organization and organizational language.},
language = {en},
number = {8},
urldate = {2022-07-08},
journal = {Management Science},
author = {Hoberg, Gerard and Phillips, Gordon},
month = sep,
year = {2018},
keywords = {conglomerates, firm organization, organizational language, product market language, synergies, text analytics},
pages = {3735--3755},
}

@article{beam_big_2018,
title = {Big {Data} and {Machine} {Learning} in {Health} {Care}},
volume = {319},
issn = {0098-7484},
url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.2017.18391},
doi = {10.1001/jama.2017.18391},
language = {en},
number = {13},
urldate = {2022-07-08},
journal = {JAMA},
author = {Beam, Andrew L. and Kohane, Isaac S.},
month = apr,
year = {2018},
pages = {1317},
}

@inproceedings{sundararajan_axiomatic_2017,
title = {Axiomatic {Attribution} for {Deep} {Networks}},
url = {https://proceedings.mlr.press/v70/sundararajan17a.html},
abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms—Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
language = {en},
urldate = {2022-07-07},
booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
publisher = {PMLR},
author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
month = jul,
year = {2017},
note = {ISSN: 2640-3498},
keywords = {Computer Science - Machine Learning},
pages = {3319--3328},
}

@inproceedings{yang_ontobayes_2005,
title = {{OntoBayes}: {An} {Ontology}-{Driven} {Uncertainty} {Model}},
volume = {1},
shorttitle = {{OntoBayes}},
doi = {10.1109/CIMCA.2005.1631307},
abstract = {This paper describes an ontology-driven model, which integrates Bayesian Networks (BN) into the Ontology Web Language (OWL) to preserve the advantages of both. This model makes use of probability and dependency-annotated OWL to represent uncertain information in BN structures. These extensions enhance knowledge representation in OWL and enable agents to act under uncertainty and complex structured open environments at the same time. This paper presents the underlying principles and scratches the surface of the decision theoretic agent system design based on "OntoBayes".},
booktitle = {International {Conference} on {Computational} {Intelligence} for {Modelling}, {Control} and {Automation} and {International} {Conference} on {Intelligent} {Agents}, {Web} {Technologies} and {Internet} {Commerce} ({CIMCA}-{IAWTIC}'06)},
author = {Yang, Yi and Calmet, J.},
month = nov,
year = {2005},
keywords = {Bayesian methods, Frequency, Intelligent agent, Intelligent systems, Knowledge representation, Machine intelligence, OWL, Ontologies, Semantic Web, Uncertainty},
pages = {457--463},
}

@article{che_interpretable_2017,
title = {Interpretable {Deep} {Models} for {ICU} {Outcome} {Prediction}},
volume = {2016},
issn = {1942-597X},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5333206/},
abstract = {Exponential surge in health care data, such as longitudinal data from electronic health records (EHR), sensor data from intensive care unit (ICU), etc., is providing new opportunities to discover meaningful data-driven characteristics and patterns ofdiseases. Recently, deep learning models have been employedfor many computational phenotyping and healthcare prediction tasks to achieve state-of-the-art performance. However, deep models lack interpretability which is crucial for wide adoption in medical research and clinical decision-making. In this paper, we introduce a simple yet powerful knowledge-distillation approach called interpretable mimic learning, which uses gradient boosting trees to learn interpretable models and at the same time achieves strong prediction performance as deep learning models. Experiment results on Pediatric ICU dataset for acute lung injury (ALI) show that our proposed method not only outperforms state-of-the-art approaches for morality and ventilator free days prediction tasks but can also provide interpretable models to clinicians.},
urldate = {2020-11-14},
journal = {AMIA Annual Symposium Proceedings},
author = {Che, Zhengping and Purushotham, Sanjay and Khemani, Robinder and Liu, Yan},
month = feb,
year = {2017},
pmid = {28269832},
pmcid = {PMC5333206},
pages = {371--380},
}

@article{guidotti_survey_2018,
title = {A {Survey} of {Methods} for {Explaining} {Black} {Box} {Models}},
volume = {51},
issn = {0360-0300},
url = {https://doi.org/10.1145/3236009},
doi = {10.1145/3236009},
abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
number = {5},
urldate = {2022-07-05},
journal = {ACM Computing Surveys},
author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
month = aug,
year = {2018},
keywords = {Open the black box, explanations, interpretability, transparent models},
pages = {93:1--93:42},
}

@article{chen_rare_2022,
title = {A rare variant analysis framework using public genotype summary counts to prioritize disease-predisposition genes},
volume = {13},
copyright = {2022 The Author(s)},
issn = {2041-1723},
url = {https://www.nature.com/articles/s41467-022-30248-0},
doi = {10.1038/s41467-022-30248-0},
abstract = {Sequencing cases without matched healthy controls hinders prioritization of germline disease-predisposition genes. To circumvent this problem, genotype summary counts from public data sets can serve as controls. However, systematic inflation and false positives can arise if confounding factors are not controlled. We propose a framework, consistent summary counts based rare variant burden test (CoCoRV), to address these challenges. CoCoRV implements consistent variant quality control and filtering, ethnicity-stratified rare variant association test, accurate estimation of inflation factors, powerful FDR control, and detection of rare variant pairs in high linkage disequilibrium. When we applied CoCoRV to pediatric cancer cohorts, the top genes identified were cancer-predisposition genes. We also applied CoCoRV to identify disease-predisposition genes in adult brain tumors and amyotrophic lateral sclerosis. Given that potential confounding factors were well controlled after applying the framework, CoCoRV provides a cost-effective solution to prioritizing disease-risk genes enriched with rare pathogenic variants.},
language = {en},
number = {1},
urldate = {2022-06-01},
journal = {Nature Communications},
author = {Chen, Wenan and Wang, Shuoguo and Tithi, Saima Sultana and Ellison, David W. and Schaid, Daniel J. and Wu, Gang},
month = may,
year = {2022},
note = {Number: 1
Publisher: Nature Publishing Group},
keywords = {Genetic association study, Mutation, Next-generation sequencing, Software, Statistical methods, rare disease, read here},
pages = {2592},
}

@misc{kapishnikov_xrai_2019,
title = {{XRAI}: {Better} {Attributions} {Through} {Regions}},
shorttitle = {{XRAI}},
url = {http://arxiv.org/abs/1906.02825},
abstract = {Saliency methods can aid understanding of deep neural networks. Recent years have witnessed many improvements to saliency methods, as well as new ways for evaluating them. In this paper, we 1) present a novel region-based attribution method, XRAI, that builds upon integrated gradients (Sundararajan et al. 2017), 2) introduce evaluation methods for empirically assessing the quality of image-based saliency maps (Performance Information Curves (PICs)), and 3) contribute an axiom-based sanity check for attribution methods. Through empirical experiments and example results, we show that XRAI produces better results than other saliency methods for common models and the ImageNet dataset.},
urldate = {2022-07-07},
publisher = {arXiv},
author = {Kapishnikov, Andrei and Bolukbasi, Tolga and Viégas, Fernanda and Terry, Michael},
month = aug,
year = {2019},
note = {arXiv:1906.02825 [cs, stat]},
keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
}

@article{adadi_peeking_2018,
title = {Peeking {Inside} the {Black}-{Box}: {A} {Survey} on {Explainable} {Artificial} {Intelligence} ({XAI})},
volume = {6},
issn = {2169-3536},
shorttitle = {Peeking {Inside} the {Black}-{Box}},
doi = {10.1109/ACCESS.2018.2870052},
abstract = {At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.},
journal = {IEEE Access},
author = {Adadi, Amina and Berrada, Mohammed},
year = {2018},
note = {Conference Name: IEEE Access},
keywords = {Biological system modeling, Conferences, Explainable artificial intelligence, Machine learning, Machine learning algorithms, Market research, Prediction algorithms, black-box models, interpretable machine learning},
pages = {52138--52160},
}

@article{barredo_arrieta_explainable_2020,
title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, taxonomies, opportunities and challenges toward responsible {AI}},
volume = {58},
issn = {1566-2535},
shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
url = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
doi = {10.1016/j.inffus.2019.12.012},
abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
language = {en},
urldate = {2022-07-07},
journal = {Information Fusion},
author = {Barredo Arrieta, Alejandro and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and Gil-Lopez, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
month = jun,
year = {2020},
keywords = {Accountability, Comprehensibility, Data Fusion, Deep Learning, Explainable Artificial Intelligence, Fairness, Interpretability, Machine Learning, Privacy, Responsible Artificial Intelligence, Transparency},
pages = {82--115},
}

@inproceedings{li_deep_2018,
address = {New Orleans, Louisiana, USA},
series = {{AAAI}'18/{IAAI}'18/{EAAI}'18},
title = {Deep learning for case-based reasoning through prototypes: a neural network that explains its predictions},
isbn = {978-1-57735-800-8},
shorttitle = {Deep learning for case-based reasoning through prototypes},
abstract = {Deep neural networks are widely used for classification. These deep models often suffer from a lack of interpretability - they are particularly difficult to understand because of their non-linear nature. As a result, neural networks are often treated as "black box" models, and in the past, have been trained purely to optimize the accuracy of predictions. In this work, we create a novel network architecture for deep learning that naturally explains its own reasoning for each prediction. This architecture contains an autoencoder and a special prototype layer, where each unit of that layer stores a weight vector that resembles an encoded training input. The encoder of the autoencoder allows us to do comparisons within the latent space, while the decoder allows us to visualize the learned prototypes. The training objective has four terms: an accuracy term, a term that encourages every prototype to be similar to at least one encoded input, a term that encourages every encoded input to be close to at least one prototype, and a term that encourages faithful reconstruction by the autoen-coder. The distances computed in the prototype layer are used as part of the classification process. Since the prototypes are learned during training, the learned network naturally comes with explanations for each prediction, and the explanations are loyal to what the network actually computes.},
urldate = {2022-07-06},
booktitle = {Proceedings of the {Thirty}-{Second} {AAAI} {Conference} on {Artificial} {Intelligence} and {Thirtieth} {Innovative} {Applications} of {Artificial} {Intelligence} {Conference} and {Eighth} {AAAI} {Symposium} on {Educational} {Advances} in {Artificial} {Intelligence}},
publisher = {AAAI Press},
author = {Li, Oscar and Liu, Hao and Chen, Chaofan and Rudin, Cynthia},
month = feb,
year = {2018},
pages = {3530--3537},
}

@article{rudin_stop_2019,
title = {Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
volume = {1},
copyright = {2019 Springer Nature Limited},
issn = {2522-5839},
url = {https://www.nature.com/articles/s42256-019-0048-x},
doi = {10.1038/s42256-019-0048-x},
abstract = {Black box machine learning models are currently being used for high-stakes decision making throughout society, causing problems in healthcare, criminal justice and other domains. Some people hope that creating methods for explaining these black box models will alleviate some of the problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practice and can potentially cause great harm to society. The way forward is to design models that are inherently interpretable. This Perspective clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare and computer vision.},
language = {en},
number = {5},
urldate = {2022-07-06},
journal = {Nature Machine Intelligence},
author = {Rudin, Cynthia},
month = may,
year = {2019},
note = {Number: 5
Publisher: Nature Publishing Group},
keywords = {Computer science, Criminology, Science, Statistics, technology and society},
pages = {206--215},
}

@misc{stopnitzky_limitations_2021,
title = {Limitations of {Integrated} {Gradients} for {Feature} {Attribution}},
url = {https://towardsdatascience.com/limitations-of-integrated-gradients-for-feature-attribution-ca2a50e7d269},
abstract = {The popular method in interpretable AI has important drawbacks},
language = {en},
urldate = {2022-07-05},
journal = {Medium},
author = {Stopnitzky, Elan},
month = oct,
year = {2021},
}

@misc{noauthor_6special_nodate,
title = {6.{Special} {Network} {Structure}},
}

@article{wang_knowledge_2017,
title = {Knowledge {Graph} {Embedding}: {A} {Survey} of {Approaches} and {Applications}},
volume = {29},
issn = {1558-2191},
shorttitle = {Knowledge {Graph} {Embedding}},
doi = {10.1109/TKDE.2017.2754499},
abstract = {Knowledge graph (KG) embedding is to embed components of a KG including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the KG. It can benefit a variety of downstream tasks such as KG completion and relation extraction, and hence has quickly gained massive attention. In this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. Particularly, we make the review based on the type of information used in the embedding task. Techniques that conduct embedding using only facts observed in the KG are first introduced. We describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. After that, we discuss techniques that further incorporate additional information besides facts. We focus specifically on the use of entity types, relation paths, textual descriptions, and logical rules. Finally, we briefly introduce how KG embedding can be applied to and benefit a wide variety of downstream tasks such as KG completion, relation extraction, question answering, and so forth.},
number = {12},
journal = {IEEE Transactions on Knowledge and Data Engineering},
author = {Wang, Quan and Mao, Zhendong and Wang, Bin and Guo, Li},
month = dec,
year = {2017},
note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
keywords = {Graphical models, Knowledge discovery, Market research, Matrix decomposition, Semantics, Statistical analysis, Statistical relational learning, Systematics, knowledge graph embedding, latent factor models, tensor/matrix factorization models},
pages = {2724--2743},
}

@misc{noauthor_tutorial_nodate,
title = {Tutorial: on domain adaptation and transfer learning},
urldate = {2017-06-03},
journal = {tutorial on domain adaptation and transfer learning},
}

@inproceedings{gutierrez-basulto_knowledge_2018,
title = {From {Knowledge} {Graph} {Embedding} to {Ontology} {Embedding}? {An} {Analysis} of the {Compatibility} between {Vector} {Space} {Representations} and {Rules}},
copyright = {Authors who publish a paper in this conference agree to the following terms:     Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.   The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered   The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys\&rsquo; fees incurred therein.   Author(s) retain all proprietary rights other than copyright (such as patent rights).   Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.   Author(s) may reproduce, or have reproduced, their article/paper for the author\&rsquo;s personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author\&rsquo;s employer, and then only on the author\&rsquo;s or the employer\&rsquo;s own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author\&rsquo;s or the employer\&rsquo;s creation (including tables of contents with links to other papers) without AAAI\&rsquo;s written permission.   Author(s) may make limited distribution of all or portions of their article/paper prior to publication.   In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.   In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
shorttitle = {From {Knowledge} {Graph} {Embedding} to {Ontology} {Embedding}?},
url = {https://www.aaai.org/ocs/index.php/KR/KR18/paper/view/18013},
abstract = {Recent years have witnessed the successful application of low-dimensional vector space representations of knowledge graphs to predict missing facts or find erroneous ones. However, it is not yet well-understood to what extent ontological knowledge, e.g. given as a set of (existential) rules, can be embedded in a principled way. To address this shortcoming, in this paper we introduce a general framework based on a view of relations as regions, which allows us to study the compatibility between ontological knowledge and different types of vector space embeddings. Our technical contribution is two-fold. First, we show that some of the most popular existing embedding methods are not capable of modelling even very simple types of rules, which in particular also means that they are not able to learn the type of dependencies captured by such rules. Second, we study a model in which relations are modelled as convex regions. We show particular that ontologies which are expressed using so-called quasi-chained existential rules can be exactly represented using convex regions, such that any set of facts which is induced using that vector space embedding is logically consistent and deductively closed with respect to the input ontology.},
language = {en},
urldate = {2022-06-25},
booktitle = {Sixteenth {International} {Conference} on {Principles} of {Knowledge} {Representation} and {Reasoning}},
author = {Gutierrez-Basulto, Vıctor and Schockaert, Steven},
month = sep,
year = {2018},
}

@article{thelwall_autism_2020,
title = {Autism {Spectrum} {Disorder} on {Twitter} during {COVID}-19: {Account} {Types}, {Self}-{Descriptions} and {Tweeting} {Themes}},
issn = {1556-5068},
shorttitle = {Autism {Spectrum} {Disorder} on {Twitter} during {COVID}-19},
url = {https://www.ssrn.com/abstract=3826169},
doi = {10.2139/ssrn.3826169},
abstract = {Social media can be used to share experiences of health-related conditions, such as Autism Spectrum Disorder (ASD), and to advertise support. Knowledge about how this occurs can inform those seeking to guide those with the condition. This article reports three related studies to investigate ASD on Twitter in the USA, derived from Covid-19 tweets between March 10 and June 30, 2020. Study 1: Twitter accounts mentioning ASD in author biographies were classified with content analysis by type, finding parents and people declaring ASD to be both common, with support, advocates and specialists also represented. Study 2: The biographies of these accounts were analysed using word association thematic analysis (WATA), finding a strong family relationships theme amongst the parent tweeters, for example. The results also suggested common identity aspects of people declaring ASD, including gaming and artistic interests. Study 3: Covid-19-related tweets from the same accounts were analysed using WATA, finding no ASD-specific themes for parents or people declaring ASD. The results suggest that ASD in the USA is represented for Covid-19 through parents, individuals declaring it, and supporters, but without raising concerns particular to the disorder.},
language = {en},
urldate = {2022-06-21},
journal = {SSRN Electronic Journal},
author = {Thelwall, Saheeda and Thelwall, Michael},
year = {2020},
}

@misc{noauthor_5computational_nodate,
title = {5.{Computational} {Graph}},
}

@misc{noauthor_2theory_nodate,
title = {2.{Theory} {I} - {Why} {Deep} {Structure}?},
}

@misc{noauthor_4theory_nodate,
title = {4.{Theory} 3 - {Generalization}},
}

@misc{noauthor_mlds_nodate,
title = {{MLDS} 2018 {Spring}},
url = {https://speech.ee.ntu.edu.tw/~hylee/mlds/2018-spring.php},
urldate = {2022-06-03},
}

@misc{noauthor_3theory_nodate,
title = {3.{Theory} 2 - {Optimization}},
}

@article{colace_ontology_2010,
title = {Ontology for {E}-{Learning}: {A} {Bayesian} {Approach}},
volume = {53},
issn = {1557-9638},
shorttitle = {Ontology for {E}-{Learning}},
doi = {10.1109/TE.2009.2012537},
abstract = {In the last decade, the evolution of educational technologies has forced an extraordinary interest in new methods for delivering learning content to learners. Today, distance education represents an effective way for supporting and sometimes substituting the traditional formative processes, thanks to the technological improvements achieved in the field in recent years. However, the role of technology has often been overestimated. The amount of information students can obtain from the Internet is huge, and as a result, they can easily be confused. Teachers can also be disconcerted by this vast quantity of content and are often unable to suggest the correct content to their students. In the open scientific literature, it is widely recognized that an important factor for success in delivering learning content is related to the capability for customizing the learning process for the specific needs of a given learner. This task is still far from having been fully accomplished, and there is a real interest in investigating new approaches and tools to adapt the formative process to specific individual needs. In this scenario, the introduction of ontology formalism can improve the quality of the formative process, allowing the introduction of new and effective services. Ontologies can lead to important improvements in the definition of a course's knowledge domain, in the generation of an adapted learning path, and in the assessment phase. This paper provides an initial discussion of the role of ontologies in the context of e-learning. The improvements related to the introduction of ontologies formalism in the e-learning field are discussed, and a novel algorithm for ontology building through the use of Bayesian networks is shown. Finally, the application of this algorithm in the assessment process and some experimental results are illustrated.},
number = {2},
journal = {IEEE Transactions on Education},
author = {Colace, Francesco and De Santo, Massimo},
month = may,
year = {2010},
note = {Conference Name: IEEE Transactions on Education},
keywords = {Adaptive assessment tool, Bayesian methods, Bayesian network, Buildings, Data mining, Electronic learning, Ontologies, Vocabulary, adaptive hypermedia system, e-learning, learning technology, ontology},
pages = {223--233},
}

@inproceedings{fenz_ontology-based_2009,
title = {Ontology-{Based} {Generation} of {Bayesian} {Networks}},
doi = {10.1109/CISIS.2009.33},
abstract = {Bayesian networks are indispensable for determining the probability of events which are influenced by various components. Bayesian probabilities encode degrees of belief about certain events and a dynamic knowledge body is used to strengthen, update, or weaken these assumptions. The creation of Bayesian networks requires at least three challenging tasks: (i) the determination of relevant influence factors, (ii) the determination of relationships between the identified influence factors, and (iii) the calculation of the conditional probability tables for each node in the Bayesian network.Based on existing domain ontologies, we propose a method for the ontology-based generation of Bayesian networks. The ontology is used to provide the necessary knowledge about relevant influence factors, their relationships, their weights, and the scale which represents potential states of the identified influence factors.The developed method enables, based on existing ontologies, the semi-automatic generation and alternation of Bayesian networks.},
booktitle = {2009 {International} {Conference} on {Complex}, {Intelligent} and {Software} {Intensive} {Systems}},
author = {Fenz, Stefan and Tjoa, A. Min and Hudec, Marcus},
month = mar,
year = {2009},
keywords = {Bayesian methods, Bayesian networks, Competitive intelligence, Intelligent networks, Interactive systems, Ontologies, Probability, Scientific computing, Software systems, Tail, Vocabulary, information security, ontology, threat probability},
pages = {712--717},
}

@inproceedings{zheng_ontology-based_2008,
address = {Berlin, Heidelberg},
series = {Lecture {Notes} in {Computer} {Science}},
title = {An {Ontology}-{Based} {Bayesian} {Network} {Approach} for {Representing} {Uncertainty} in {Clinical} {Practice} {Guidelines}},
isbn = {978-3-540-89765-1},
doi = {10.1007/978-3-540-89765-1_10},
abstract = {Clinical Practice Guidelines (CPGs) play an important role in improving quality of care and patient outcomes. Although several machine-readable representations of practice guidelines have been implemented with semantic web technologies, there is no implementation to represent uncertainty in activity graphs in clinical practice guidelines. In this paper, we explore a Bayesian Network(BN) approach for representing the uncertainty in CPGs based on ontologies. Using this representation, we can evaluate the effect of an activity on the whole clinical process, which can help doctors judge the risk of uncertainty for other activities when making a decision. A variable elimination algorithm is applied to implement the BN inference and a validation of an aspirin therapy scenario for diabetic patients is proposed.},
language = {en},
booktitle = {Uncertainty {Reasoning} for the {Semantic} {Web} {I}},
publisher = {Springer},
author = {Zheng, Hai-Tao and Kang, Bo-Yeong and Kim, Hong-Gee},
editor = {da Costa, Paulo Cesar G. and d’Amato, Claudia and Fanizzi, Nicola and Laskey, Kathryn B. and Laskey, Kenneth J. and Lukasiewicz, Thomas and Nickles, Matthias and Pool, Michael},
year = {2008},
keywords = {Aspirin Therapy, Bayesian Network, Clinical Practice Guideline, Clinical Process, Tobacco User},
pages = {161--173},
}

@book{american_psychiatric_association_diagnostic_2013,
address = {Washington, D.C},
edition = {5th ed},
title = {Diagnostic and statistical manual of mental disorders: {DSM}-5},
isbn = {978-0-89042-554-1 978-0-89042-555-8},
shorttitle = {Diagnostic and statistical manual of mental disorders},
language = {en},
publisher = {American Psychiatric Association},
editor = {American Psychiatric Association and American Psychiatric Association},
year = {2013},
keywords = {Classification, Diagnosis, Diagnostic and statistical manual of mental disorders, Mental Disorders, Mental illness, classification, diagnosis},
}

@techreport{he_bertmap_2022,
title = {{BERTMap}: {A} {BERT}-based {Ontology} {Alignment} {System}},
shorttitle = {{BERTMap}},
url = {http://arxiv.org/abs/2112.02682},
abstract = {Ontology alignment (a.k.a ontology matching (OM)) plays a critical role in knowledge integration. Owing to the success of machine learning in many domains, it has been applied in OM. However, the existing methods, which often adopt ad-hoc feature engineering or non-contextual word embeddings, have not yet outperformed rule-based systems especially in an unsupervised setting. In this paper, we propose a novel OM system named BERTMap which can support both unsupervised and semi-supervised settings. It first predicts mappings using a classifier based on fine-tuning the contextual embedding model BERT on text semantics corpora extracted from ontologies, and then refines the mappings through extension and repair by utilizing the ontology structure and logic. Our evaluation with three alignment tasks on biomedical ontologies demonstrates that BERTMap can often perform better than the leading OM systems LogMap and AML.},
number = {arXiv:2112.02682},
urldate = {2022-06-02},
institution = {arXiv},
author = {He, Yuan and Chen, Jiaoyan and Antonyrajah, Denvar and Horrocks, Ian},
month = may,
year = {2022},
doi = {10.48550/arXiv.2112.02682},
note = {arXiv:2112.02682 [cs]
type: article},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@inproceedings{liu_rethinking_2018,
title = {Rethinking the {Value} of {Network} {Pruning}},
url = {https://openreview.net/forum?id=rJlnB3C5Ym},
abstract = {In structured network pruning, fine-tuning a pruned model only gives comparable performance with training it from scratch.},
language = {en},
urldate = {2022-05-19},
author = {Liu, Zhuang and Sun, Mingjie and Zhou, Tinghui and Huang, Gao and Darrell, Trevor},
month = sep,
year = {2018},
}

@inproceedings{lecun_optimal_1989,
title = {Optimal {Brain} {Damage}},
volume = {2},
url = {https://proceedings.neurips.cc/paper/1989/hash/6c9882bbac1c7093bd25041881277658-Abstract.html},
abstract = {We  have used  information-theoretic ideas  to derive  a class of prac(cid:173) tical  and  nearly  optimal schemes  for  adapting the size  of a  neural  network.  By  removing  unimportant  weights  from  a  network,  sev(cid:173) eral  improvements  can  be  expected:  better  generalization,  fewer  training examples required,  and improved speed  of learning and/or  classification.  The  basic  idea  is  to  use  second-derivative  informa(cid:173) tion to make a  tradeoff between  network  complexity  and  training  set error.  Experiments confirm  the usefulness  of the methods on a  real-world  application.},
urldate = {2022-05-19},
booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
publisher = {Morgan-Kaufmann},
author = {LeCun, Yann and Denker, John and Solla, Sara},
year = {1989},
}

@misc{noauthor_1introduction_nodate,
title = {1.{Introduction}},
}

@misc{noauthor_course_nodate,
title = {course syllabus},
url = {http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html},
urldate = {2022-05-18},
}

@article{castillo-sanchez_suicide_2020,
title = {Suicide {Risk} {Assessment} {Using} {Machine} {Learning} and {Social} {Networks}: a {Scoping} {Review}},
volume = {44},
issn = {1573-689X},
shorttitle = {Suicide {Risk} {Assessment} {Using} {Machine} {Learning} and {Social} {Networks}},
url = {https://doi.org/10.1007/s10916-020-01669-5},
doi = {10.1007/s10916-020-01669-5},
abstract = {According to the World Health Organization (WHO) report in 2016, around 800,000 of individuals have committed suicide. Moreover, suicide is the second cause of unnatural death in people between 15 and 29 years. This paper reviews state of the art on the literature concerning the use of machine learning methods for suicide detection on social networks. Consequently, the objectives, data collection techniques, development process and the validation metrics used for suicide detection on social networks are analyzed. The authors conducted a scoping review using the methodology proposed by Arksey and O’Malley et al. and the PRISMA protocol was adopted to select the relevant studies. This scoping review aims to identify the machine learning techniques used to predict suicide risk based on information posted on social networks. The databases used are PubMed, Science Direct, IEEE Xplore and Web of Science. In total, 50\% of the included studies (8/16) report explicitly the use of data mining techniques for feature extraction, feature detection or entity identification. The most commonly reported method was the Linguistic Inquiry and Word Count (4/8, 50\%), followed by Latent Dirichlet Analysis, Latent Semantic Analysis, and Word2vec (2/8, 25\%). Non-negative Matrix Factorization and Principal Component Analysis were used only in one of the included studies (12.5\%). In total, 3 out of 8 research papers (37.5\%) combined more than one of those techniques. Supported Vector Machine was implemented in 10 out of the 16 included studies (62.5\%). Finally, 75\% of the analyzed studies implement machine learning-based models using Python.},
language = {en},
number = {12},
urldate = {2022-05-09},
journal = {Journal of Medical Systems},
author = {Castillo-Sánchez, Gema and Marques, Gonçalo and Dorronzoro, Enrique and Rivera-Romero, Octavio and Franco-Martín, Manuel and De la Torre-Díez, Isabel},
month = nov,
year = {2020},
keywords = {Algorithm, Data mining, Machine learning, Natural processing language, Sentiment analysis, Social networks, Suicide},
pages = {205},
}

@article{giuntini_review_2020,
title = {A review on recognizing depression in social networks: challenges and opportunities},
volume = {11},
issn = {1868-5145},
shorttitle = {A review on recognizing depression in social networks},
url = {https://doi.org/10.1007/s12652-020-01726-4},
doi = {10.1007/s12652-020-01726-4},
abstract = {Social networks have become another resource for supporting mental health specialists in making inferences and finding indications of mental disorders, such as depression. This paper addresses the state-of-the-art regarding studies on recognition of depressive mood disorders in social networks through approaches and techniques of sentiment  and emotion analysis. The systematic research conducted focused on social networks, social media, and the most employed techniques, feelings, and emotions were analyzed to find predecessors of a depressive disorder. Discussions on the research gaps identified aimed at improving the effectiveness of the analysis process, bringing the analysis close to the user’s reality. Twitter, Facebook, Blogs and Forums, Reddit, Live Journal, and Instagram are the most employed social networks regarding the identification of depressive mood disorders, and the most used information wastext, followed by emoticons, user log information, and images. The selected studies usually employ classic off-the-shelf classifiers for the analysis of the available information, combined with lexicons such as NRC Word-Emoticon Association Lexicon, WordNet-Affect, Anew, and LIWC tool. The challenges include the analysis of temporal information and a combination of different types of information.},
language = {en},
number = {11},
urldate = {2022-05-09},
journal = {Journal of Ambient Intelligence and Humanized Computing},
author = {Giuntini, Felipe T. and Cazzolato, Mirela T. and dos Reis, Maria de Jesus Dutra and Campbell, Andrew T. and Traina, Agma J. M. and Ueyama, Jó},
month = nov,
year = {2020},
keywords = {Affective computing, Depressive disorders, Emotion recognition, Mental health, Sentiment analysis, Social media, Social networks, User behavior},
pages = {4713--4729},
}

@article{jung_ontology-based_2017,
title = {Ontology-{Based} {Approach} to {Social} {Data} {Sentiment} {Analysis}: {Detection} of {Adolescent} {Depression} {Signals}},
volume = {19},
issn = {1439-4456},
shorttitle = {Ontology-{Based} {Approach} to {Social} {Data} {Sentiment} {Analysis}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5547245/},
doi = {10.2196/jmir.7452},
abstract = {Background
Social networking services (SNSs) contain abundant information about the feelings, thoughts, interests, and patterns of behavior of adolescents that can be obtained by analyzing SNS postings. An ontology that expresses the shared concepts and their relationships in a specific field could be used as a semantic framework for social media data analytics.

Objective
The aim of this study was to refine an adolescent depression ontology and terminology as a framework for analyzing social media data and to evaluate description logics between classes and the applicability of this ontology to sentiment analysis.

Methods
The domain and scope of the ontology were defined using competency questions. The concepts constituting the ontology and terminology were collected from clinical practice guidelines, the literature, and social media postings on adolescent depression. Class concepts, their hierarchy, and the relationships among class concepts were defined. An internal structure of the ontology was designed using the entity-attribute-value (EAV) triplet data model, and superclasses of the ontology were aligned with the upper ontology. Description logics between classes were evaluated by mapping concepts extracted from the answers to frequently asked questions (FAQs) onto the ontology concepts derived from description logic queries. The applicability of the ontology was validated by examining the representability of 1358 sentiment phrases using the ontology EAV model and conducting sentiment analyses of social media data using ontology class concepts.

Results
We developed an adolescent depression ontology that comprised 443 classes and 60 relationships among the classes; the terminology comprised 1682 synonyms of the 443 classes. In the description logics test, no error in relationships between classes was found, and about 89\% (55/62) of the concepts cited in the answers to FAQs mapped onto the ontology class. Regarding applicability, the EAV triplet models of the ontology class represented about 91.4\% of the sentiment phrases included in the sentiment dictionary. In the sentiment analyses, “academic stresses” and “suicide” contributed negatively to the sentiment of adolescent depression.

Conclusions
The ontology and terminology developed in this study provide a semantic foundation for analyzing social media data on adolescent depression. To be useful in social media data analysis, the ontology, especially the terminology, needs to be updated constantly to reflect rapidly changing terms used by adolescents in social media postings. In addition, more attributes and value sets reflecting depression-related sentiments should be added to the ontology.},
number = {7},
urldate = {2022-05-09},
journal = {Journal of Medical Internet Research},
author = {Jung, Hyesil and Park, Hyeoun-Ae and Song, Tae-Min},
month = jul,
year = {2017},
pmid = {28739560},
pmcid = {PMC5547245},
pages = {e259},
}

@article{arsene_medicine_2011,
title = {Medicine expert system dynamic {Bayesian} {Network} and ontology based},
volume = {38},
issn = {0957-4174},
url = {https://www.sciencedirect.com/science/article/pii/S095741741100858X},
doi = {10.1016/j.eswa.2011.05.074},
abstract = {The paper proposes an application framework to be used for medicine assisted diagnosis based on ontology and Bayesian Network (DBNO). There are two goals: (1) to separate the domain knowledge from the probabilistic information and (2) to create an intuitive user interface. The framework architecture has three layers: knowledge, uncertainty model and user interface. The contributions of the domain experts are decoupled, the ontology builder will create the domain concepts and relationships focusing on the domain knowledge only. The uncertainty model is Bayesian Network and the probabilities of the variables states are stored in a profile repository. The diagnostician will use the user interface feeded with the domain ontology and one uncertainty profile. The application was tested on a sample medicine model for the diagnose of heart disease.},
language = {en},
number = {12},
urldate = {2022-05-04},
journal = {Expert Systems with Applications},
author = {Arsene, Octavian and Dumitrache, Ioan and Mihu, Ioana},
month = nov,
year = {2011},
keywords = {Bayesian Network, Expert system, Ontology},
pages = {15253--15261},
}

@inproceedings{chang_depression_2013,
title = {Depression {Diagnosis} {Based} on {Ontologies} and {Bayesian} {Networks}},
doi = {10.1109/SMC.2013.589},
abstract = {Recently, depression become a general disease in the world due to the promotion of life quality and technology development. Most of people are not aware of the possibility of getting depressed himself in daily life. To accurately diagnose getting depressed becomes an important issue. In this paper, we utilize ontologies and Bayesian networks techniques to build the inference model for inferring the possibility of depression. We propose an ontology model to build the terminology of depression and utilize the Bayesian networks to infer the probability of depression. In addition, the paper also proposes an agent-based platform and addresses the implementation issue. The result shows that it can be well-inferring in the depression diagnosis.},
booktitle = {2013 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics}},
author = {Chang, Yue-Shan and Hung, Wan-Chun and Juang, Tong-Ying},
month = oct,
year = {2013},
note = {ISSN: 1062-922X},
keywords = {Bayes methods, Bayesian Networks, Depression, Diagnosis, Diseases, Fatigue, Knowledge Discovery, OWL, Ontologies, Ontology, Uncertainty},
pages = {3452--3457},
}

@inproceedings{choudhury_predicting_2013,
title = {Predicting {Depression} via {Social} {Media}},
copyright = {Authors who publish a paper in this conference agree to the following terms:    1. Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.    2. The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.    3. The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys’ fees incurred therein.    4. Author(s) retain all proprietary rights other than copyright (such as patent rights).    5. Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.    6. Author(s) may reproduce, or have reproduced, their article/paper for the author’s personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author’s employer, and then only on the author’s or the employer’s own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author’s or the employer’s creation (including tables of contents with links to other papers) without AAAI’s written permission.    7. Author(s) may make limited distribution of all or portions of their article/paper prior to publication.    8. In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.    9. In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
url = {https://www.aaai.org/ocs/index.php/ICWSM/ICWSM13/paper/view/6124},
abstract = {Major depression constitutes a serious challenge in personal and public health. Tens of millions of people each year suffer from depression and only a fraction receives adequate treatment. We explore the potential to use social media to detect and diagnose major depressive disorder in individuals. We first employ crowdsourcing to compile a set of Twitter users who report being diagnosed with clinical depression, based on a standard psychometric instrument. Through their social media postings over a year preceding the onset of depression, we measure behavioral attributes relating to social engagement, emotion, language and linguistic styles, ego network, and mentions of antidepressant medications. We leverage these behavioral cues, to build a statistical classifier that provides estimates of the risk of depression, before the reported onset. We find that social media contains useful signals for characterizing the onset of depression in individuals, as measured through decrease in social activity, raised negative affect, highly clustered egonetworks, heightened relational and medicinal concerns, and greater expression of religious involvement. We believe our findings and methods may be useful in developing tools for identifying the onset of major depression, for use by healthcare agencies; or on behalf of individuals, enabling those suffering from depression to be more proactive about their mental health.},
language = {en},
urldate = {2019-08-13},
booktitle = {Seventh {International} {AAAI} {Conference} on {Weblogs} and {Social} {Media}},
author = {Choudhury, Munmun De and Gamon, Michael and Counts, Scott and Horvitz, Eric},
month = jun,
year = {2013},
}

@article{aalbers_social_2019,
title = {Social media and depression symptoms: {A} network perspective},
volume = {148},
issn = {1939-2222(Electronic),0096-3445(Print)},
shorttitle = {Social media and depression symptoms},
doi = {10.1037/xge0000528},
abstract = {Passive social media use (PSMU)—for example, scrolling through social media news feeds—has been associated with depression symptoms. It is unclear, however, if PSMU causes depression symptoms or vice versa. In this study, 125 students reported PSMU, depression symptoms, and stress 7 times daily for 14 days. We used multilevel vector autoregressive time-series models to estimate (a) contemporaneous, (b) temporal, and (c) between-subjects associations among these variables. (a) More time spent on PSMU was associated with higher levels of interest loss, concentration problems, fatigue, and loneliness. (b) Fatigue and loneliness predicted PSMU across time, but PSMU predicted neither depression symptoms nor stress. (c) Mean PSMU levels were positively correlated with several depression symptoms (e.g., depressed mood and feeling inferior), but these associations disappeared when controlling for all other variables. Altogether, we identified complex relations between PSMU and specific depression symptoms that warrant further research into potentially causal relationships. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
number = {8},
journal = {Journal of Experimental Psychology: General},
author = {Aalbers, George and McNally, Richard J. and Heeren, Alexandre and de Wit, Sanne and Fried, Eiko I.},
year = {2019},
note = {Place: US
Publisher: American Psychological Association},
keywords = {Fatigue, Loneliness, Major Depression, News Media, Social Media, Stress, Symptoms, Test Construction},
pages = {1454--1462},
}

@inproceedings{baytas_patient_2017,
address = {Halifax NS Canada},
title = {Patient {Subtyping} via {Time}-{Aware} {LSTM} {Networks}},
isbn = {978-1-4503-4887-4},
url = {https://dl.acm.org/doi/10.1145/3097983.3097997},
doi = {10.1145/3097983.3097997},
abstract = {In the study of various diseases, heterogeneity among patients usually leads to di erent progression pa erns and may require di erent types of therapeutic intervention. erefore, it is important to study patient subtyping, which is grouping of patients into disease characterizing subtypes. Subtyping from complex patient data is challenging because of the information heterogeneity and temporal dynamics. Long-Short Term Memory (LSTM) has been successfully used in many domains for processing sequential data, and recently applied for analyzing longitudinal patient records. e LSTM units are designed to handle data with constant elapsed times between consecutive elements of a sequence. Given that time lapse between successive elements in patient records can vary from days to months, the design of traditional LSTM may lead to suboptimal performance. In this paper, we propose a novel LSTM unit called Time-Aware LSTM (T-LSTM) to handle irregular time intervals in longitudinal patient records. We learn a subspace decomposition of the cell memory which enables time decay to discount the memory content according to the elapsed time. We propose a patient subtyping model that leverages the proposed T-LSTM in an auto-encoder to learn a powerful single representation for sequential records of patients, which are then used to cluster patients into clinical subtypes. Experiments on synthetic and real world datasets show that the proposed T-LSTM architecture captures the underlying structures in the sequences with time irregularities.},
language = {en},
urldate = {2022-04-26},
booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
publisher = {ACM},
author = {Baytas, Inci M. and Xiao, Cao and Zhang, Xi and Wang, Fei and Jain, Anil K. and Zhou, Jiayu},
month = aug,
year = {2017},
keywords = {long-short term memory, patient subtyping, recurrent neural network},
pages = {65--74},
}

@article{turc_well-read_2019,
title = {Well-{Read} {Students} {Learn} {Better}: {On} the {Importance} of {Pre}-training {Compact} {Models}},
shorttitle = {Well-{Read} {Students} {Learn} {Better}},
url = {http://arxiv.org/abs/1908.08962},
abstract = {Recent developments in natural language representations have been accompanied by large and expensive models that leverage vast amounts of general-domain text through self-supervised pre-training. Due to the cost of applying such models to down-stream tasks, several model compression techniques on pre-trained language representations have been proposed (Sun et al., 2019; Sanh, 2019). However, surprisingly, the simple baseline of just pre-training and fine-tuning compact models has been overlooked. In this paper, we first show that pre-training remains important in the context of smaller architectures, and fine-tuning pre-trained compact models can be competitive to more elaborate methods proposed in concurrent work. Starting with pre-trained compact models, we then explore transferring task knowledge from large fine-tuned models through standard knowledge distillation. The resulting simple, yet effective and general algorithm, Pre-trained Distillation, brings further improvements. Through extensive experiments, we more generally explore the interaction between pre-training and distillation under two variables that have been under-studied: model size and properties of unlabeled task data. One surprising observation is that they have a compound effect even when sequentially applied on the same data. To accelerate future research, we will make our 24 pre-trained miniature BERT models publicly available.},
urldate = {2022-04-29},
journal = {arXiv:1908.08962 [cs]},
author = {Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
month = sep,
year = {2019},
note = {arXiv: 1908.08962},
keywords = {Computer Science - Computation and Language},
}

@inproceedings{coppersmith_adhd_2015,
address = {Denver, Colorado},
title = {From {ADHD} to {SAD}: {Analyzing} the {Language} of {Mental} {Health} on {Twitter} through {Self}-{Reported} {Diagnoses}},
shorttitle = {From {ADHD} to {SAD}},
url = {https://www.aclweb.org/anthology/W15-1201},
doi = {10.3115/v1/W15-1201},
urldate = {2021-05-05},
booktitle = {Proceedings of the 2nd {Workshop} on {Computational} {Linguistics} and {Clinical} {Psychology}: {From} {Linguistic} {Signal} to {Clinical} {Reality}},
publisher = {Association for Computational Linguistics},
author = {Coppersmith, Glen and Dredze, Mark and Harman, Craig and Hollingshead, Kristy},
month = jun,
year = {2015},
pages = {1--10},
}

@article{lin_association_2016,
title = {Association {Between} {Social} {Media} {Use} and {Depression} {Among} {U}.s. {Young} {Adults}},
volume = {33},
copyright = {© 2016 Wiley Periodicals, Inc.},
issn = {1520-6394},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/da.22466},
doi = {10.1002/da.22466},
abstract = {Background Social media (SM) use is increasing among U.S. young adults, and its association with mental well-being remains unclear. This study assessed the association between SM use and depression in a nationally representative sample of young adults. Methods We surveyed 1,787 adults ages 19 to 32 about SM use and depression. Participants were recruited via random digit dialing and address-based sampling. SM use was assessed by self-reported total time per day spent on SM, visits per week, and a global frequency score based on the Pew Internet Research Questionnaire. Depression was assessed using the Patient-Reported Outcomes Measurement Information System (PROMIS) Depression Scale Short Form. Chi-squared tests and ordered logistic regressions were performed with sample weights. Results The weighted sample was 50.3\% female and 57.5\% White. Compared to those in the lowest quartile of total time per day spent on SM, participants in the highest quartile had significantly increased odds of depression (AOR = 1.66, 95\% CI = 1.14–2.42) after controlling for all covariates. Compared with those in the lowest quartile, individuals in the highest quartile of SM site visits per week and those with a higher global frequency score had significantly increased odds of depression (AOR = 2.74, 95\% CI = 1.86–4.04; AOR = 3.05, 95\% CI = 2.03–4.59, respectively). All associations between independent variables and depression had strong, linear, dose–response trends. Results were robust to all sensitivity analyses. Conclusions SM use was significantly associated with increased depression. Given the proliferation of SM, identifying the mechanisms and direction of this association is critical for informing interventions that address SM use and depression.},
language = {en},
number = {4},
urldate = {2019-08-13},
journal = {Depression and Anxiety},
author = {Lin, Liu yi and Sidani, Jaime E. and Shensa, Ariel and Radovic, Ana and Miller, Elizabeth and Colditz, Jason B. and Hoffman, Beth L. and Giles, Leila M. and Primack, Brian A.},
year = {2016},
keywords = {communications media, depression, internet, social media, young adult},
pages = {323--331},
}

@article{shensa_social_2018,
title = {Social {Media} {Use} and {Depression} and {Anxiety} {Symptoms}: {A} {Cluster} {Analysis}},
volume = {42},
shorttitle = {Social {Media} {Use} and {Depression} and {Anxiety} {Symptoms}},
doi = {10.5993/AJHB.42.2.11},
abstract = {Objectives: Individuals use social media with varying quantity, emotional, and behavioral at- tachment that may have differential associations with mental health outcomes. In this study, we sought to identify distinct patterns of social media use (SMU) and to assess associations between
those patterns and depression and anxiety symptoms. Methods: In October 2014, a nationally-representative sample of 1730 US adults ages 19 to 32 completed an online survey. Cluster analysis was used to identify patterns of SMU. Depression and anxiety were measured using respective 4-item Patient-Reported
Outcome Measurement Information System (PROMIS) scales. Multivariable logistic regression models were used to assess associations between clus- ter membership and depression and anxiety. Results: Cluster analysis yielded a 5-cluster solu- tion. Participants were characterized as "Wired," "Connected,"
"Diffuse Dabblers," "Concentrated Dabblers," and "Unplugged." Membership in 2 clusters – "Wired" and "Connected" – increased the odds of elevated depression and anxiety symptoms (AOR = 2.7, 95\% CI = 1.5-4.7; AOR = 3.7, 95\% CI = 2.1-6.5, respectively, and AOR = 2.0, 95\% CI = 1.3-3.2;
AOR = 2.0, 95\% CI = 1.3-3.1, respectively). Conclusions: SMU pattern characterization of a large population suggests 2 pat- terns are associated with risk for depression and anxiety. Developing educational interventions that address use patterns rather than single aspects of SMU (eg, quantity)
would likely be useful.},
number = {2},
journal = {American Journal of Health Behavior},
author = {Shensa, Ariel and Sidani, Jaime E and Dew, Mary Amanda and Escobar-Viera, César G. and Primack, Brian A.},
month = mar,
year = {2018},
keywords = {ANXIETY, CLUSTER ANALYSIS, DEPRESSION, PROMIS, SOCIAL MEDIA},
pages = {116--128},
}

@inproceedings{li_biomedical_2019,
address = {Minneapolis, Minnesota},
title = {Biomedical {Event} {Extraction} based on {Knowledge}-driven {Tree}-{LSTM}},
url = {https://aclanthology.org/N19-1145},
doi = {10.18653/v1/N19-1145},
abstract = {Event extraction for the biomedical domain is more challenging than that in the general news domain since it requires broader acquisition of domain-specific knowledge and deeper understanding of complex contexts. To better encode contextual information and external background knowledge, we propose a novel knowledge base (KB)-driven tree-structured long short-term memory networks (Tree-LSTM) framework, incorporating two new types of features: (1) dependency structures to capture wide contexts; (2) entity properties (types and category descriptions) from external ontologies via entity linking. We evaluate our approach on the BioNLP shared task with Genia dataset and achieve a new state-of-the-art result. In addition, both quantitative and qualitative studies demonstrate the advancement of the Tree-LSTM and the external knowledge representation for biomedical event extraction.},
urldate = {2021-07-14},
booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
publisher = {Association for Computational Linguistics},
author = {Li, Diya and Huang, Lifu and Ji, Heng and Han, Jiawei},
month = jun,
year = {2019},
keywords = {research ideas},
pages = {1421--1430},
}

@article{keles_systematic_2020,
title = {A systematic review: the influence of social media on depression, anxiety and psychological distress in adolescents},
volume = {25},
issn = {0267-3843},
shorttitle = {A systematic review},
url = {https://doi.org/10.1080/02673843.2019.1590851},
doi = {10.1080/02673843.2019.1590851},
abstract = {While becoming inextricable to our daily lives, online social media are blamed for increasing mental health problems in younger people. This systematic review synthesized evidence on the influence of social media use on depression, anxiety and psychological distress in adolescents. A search of PsycINFO, Medline, Embase, CINAHL and SSCI databases reaped 13 eligible studies, of which 12 were cross-sectional. Findings were classified into four domains of social media: time spent, activity, investment and addiction. All domains correlated with depression, anxiety and psychological distress. However, there are considerable caveats due to methodological limitations of cross-sectional design, sampling and measures. Mechanisms of the putative effects of social media on mental health should be explored further through qualitative enquiry and longitudinal cohort studies.},
number = {1},
urldate = {2021-04-26},
journal = {International Journal of Adolescence and Youth},
author = {Keles, Betul and McCrae, Niall and Grealish, Annmarie},
month = dec,
year = {2020},
note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/02673843.2019.1590851},
keywords = {Adolescents, anxiety, depression, psychological distress, social media},
pages = {79--93},
}

@article{guntuku_detecting_2017,
series = {Big data in the behavioural sciences},
title = {Detecting depression and mental illness on social media: an integrative review},
volume = {18},
issn = {2352-1546},
shorttitle = {Detecting depression and mental illness on social media},
url = {http://www.sciencedirect.com/science/article/pii/S2352154617300384},
doi = {10.1016/j.cobeha.2017.07.005},
abstract = {Although rates of diagnosing mental illness have improved over the past few decades, many cases remain undetected. Symptoms associated with mental illness are observable on Twitter, Facebook, and web forums, and automated methods are increasingly able to detect depression and other mental illnesses. In this paper, recent studies that aimed to predict mental illness using social media are reviewed. Mentally ill users have been identified using screening surveys, their public sharing of a diagnosis on Twitter, or by their membership in an online forum, and they were distinguishable from control users by patterns in their language and online activity. Automated detection methods may help to identify depressed or otherwise at-risk individuals through the large-scale passive monitoring of social media, and in the future may complement existing screening procedures.},
urldate = {2019-08-13},
journal = {Current Opinion in Behavioral Sciences},
author = {Guntuku, Sharath Chandra and Yaden, David B and Kern, Margaret L and Ungar, Lyle H and Eichstaedt, Johannes C},
month = dec,
year = {2017},
pages = {43--49},
}

@inproceedings{de_choudhury_social_2013,
address = {New York, NY, USA},
series = {{WebSci} '13},
title = {Social {Media} {As} a {Measurement} {Tool} of {Depression} in {Populations}},
isbn = {978-1-4503-1889-1},
url = {http://doi.acm.org/10.1145/2464464.2464480},
doi = {10.1145/2464464.2464480},
abstract = {Depression is a serious and widespread public health challenge. We examine the potential for leveraging social media postings as a new type of lens in understanding depression in populations. Information gleaned from social media bears potential to complement traditional survey techniques in its ability to provide finer grained measurements over time while radically expanding population sample sizes. We present work on using a crowdsourcing methodology to build a large corpus of postings on Twitter that have been shared by individuals diagnosed with clinical depression. Next, we develop a probabilistic model trained on this corpus to determine if posts could indicate depression. The model leverages signals of social activity, emotion, and language manifested on Twitter. Using the model, we introduce a social media depression index that may serve to characterize levels of depression in populations. Geographical, demographic and seasonal patterns of depression given by the measure confirm psychiatric findings and correlate highly with depression statistics reported by the Centers for Disease Control and Prevention (CDC).},
urldate = {2019-08-13},
booktitle = {Proceedings of the 5th {Annual} {ACM} {Web} {Science} {Conference}},
publisher = {ACM},
author = {De Choudhury, Munmun and Counts, Scott and Horvitz, Eric},
year = {2013},
note = {event-place: Paris, France},
keywords = {Twitter, behavior, depression, emotion, health, language, mental health, public health, social media, wellness},
pages = {47--56},
}

@article{devlin_bert_2018,
title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
shorttitle = {{BERT}},
url = {http://arxiv.org/abs/1810.04805},
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4\% (7.6\% absolute improvement), MultiNLI accuracy to 86.7 (5.6\% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5\% absolute improvement), outperforming human performance by 2.0\%.},
urldate = {2019-03-18},
journal = {arXiv:1810.04805 [cs]},
author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
month = oct,
year = {2018},
note = {arXiv: 1810.04805},
keywords = {Computer Science - Computation and Language},
}

@article{nadeau_survey_2007,
title = {A survey of named entity recognition and classification},
volume = {30},
issn = {0378-4169, 1569-9927},
url = {http://www.jbe-platform.com/content/journals/10.1075/li.30.1.03nad},
doi = {10.1075/li.30.1.03nad},
abstract = {This survey covers fifteen years of research in the Named Entity Recognition and Classification (NERC) field, from 1991 to 2006. We report observations about languages, named entity types, domains and textual genres studied in the literature. From the start, NERC systems have been developed using hand-made rules, but now machine learning techniques are widely used. These techniques are surveyed along with other critical aspects of NERC such as features and evaluation methods. Features are word-level, dictionary-level and corpus-level representations of words in a document. Evaluation techniques, ranging from intuitive exact match to very complex matching techniques with adjustable cost of errors, are an indisputable key to progress.},
number = {1},
urldate = {2017-04-23},
journal = {Lingvisticæ Investigationes},
author = {Nadeau, David and Sekine, Satoshi},
month = jan,
year = {2007},
pages = {3--26},
}

@article{dyer_transition-based_2015,
title = {Transition-{Based} {Dependency} {Parsing} with {Stack} {Long} {Short}-{Term} {Memory}},
url = {http://arxiv.org/abs/1505.08075},
abstract = {We propose a technique for learning representations of parser states in transition-based dependency parsers. Our primary innovation is a new control structure for sequence-to-sequence neural networks---the stack LSTM. Like the conventional stack data structures used in transition-based parsing, elements can be pushed to or popped from the top of the stack in constant time, but, in addition, an LSTM maintains a continuous space embedding of the stack contents. This lets us formulate an efficient parsing model that captures three facets of a parser's state: (i) unbounded look-ahead into the buffer of incoming words, (ii) the complete history of actions taken by the parser, and (iii) the complete contents of the stack of partially built tree fragments, including their internal structures. Standard backpropagation techniques are used for training and yield state-of-the-art parsing performance.},
urldate = {2022-04-30},
journal = {arXiv:1505.08075 [cs]},
author = {Dyer, Chris and Ballesteros, Miguel and Ling, Wang and Matthews, Austin and Smith, Noah A.},
month = may,
year = {2015},
note = {arXiv: 1505.08075},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{losada_overview_2018,
address = {Cham},
series = {Lecture {Notes} in {Computer} {Science}},
title = {Overview of {eRisk}: {Early} {Risk} {Prediction} on the {Internet}},
isbn = {978-3-319-98932-7},
shorttitle = {Overview of {eRisk}},
doi = {10.1007/978-3-319-98932-7_30},
abstract = {This paper provides an overview of eRisk 2018. This was the second year that this lab was organized at CLEF. The main purpose of eRisk was to explore issues of evaluation methodology, effectiveness metrics and other processes related to early risk detection. Early detection technologies can be employed in different areas, particularly those related to health and safety. The second edition of eRisk had two tasks: a task on early risk detection of depression and a task on early risk detection of anorexia.},
language = {en},
booktitle = {Experimental {IR} {Meets} {Multilinguality}, {Multimodality}, and {Interaction}},
publisher = {Springer International Publishing},
author = {Losada, David E. and Crestani, Fabio and Parapar, Javier},
editor = {Bellot, Patrice and Trabelsi, Chiraz and Mothe, Josiane and Murtagh, Fionn and Nie, Jian Yun and Soulier, Laure and SanJuan, Eric and Cappellato, Linda and Ferro, Nicola},
year = {2018},
keywords = {Depressed Users, Early Risk Detection, Erisken, Standard Classification Measures, Test Collection},
pages = {343--361},
}

@article{losada_overview_nodate,
title = {Overview of {eRisk} at {CLEF} 2019 {Early} {Risk} {Prediction} on the {Internet} (extended overview)},
abstract = {This paper provides an overview of eRisk 2019, the third edition of this lab under the CLEF conference. The main purpose of eRisk is to explore issues of evaluation methodology, effectiveness metrics and other processes related to early risk detection. Early detection technologies can be employed in different areas, particularly those related to health and safety. This edition of eRisk had three tasks. Two of them shared the same format and focused on early detecting signs of depression (T1) or self-harm (T2). The third task (T3) focused on an innovative challenge related to automatically ﬁlling a depression questionnaire based on user interactions in social media.},
language = {en},
author = {Losada, David E and Crestani, Fabio and Parapar, Javier},
pages = {21},
}

@article{bengio_learning_1994,
title = {Learning long-term dependencies with gradient descent is difficult},
volume = {5},
issn = {1941-0093},
doi = {10.1109/72.279181},
abstract = {Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered.{\textless}{\textgreater}},
number = {2},
journal = {IEEE Transactions on Neural Networks},
author = {Bengio, Y. and Simard, P. and Frasconi, P.},
month = mar,
year = {1994},
note = {Conference Name: IEEE Transactions on Neural Networks},
keywords = {Computer networks, Cost function, Delay effects, Discrete transforms, Displays, Intelligent networks, Neural networks, Neurofeedback, Production, Recurrent neural networks},
pages = {157--166},
}

@article{mitchell_understanding_2008,
title = {Understanding {Depression}: {A} {Complete} {Guide} to {Its} {Diagnosis} and {Treatment}, 2nd ed.},
volume = {10},
issn = {1523-5998},
shorttitle = {Understanding {Depression}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2446480/},
number = {3},
urldate = {2022-04-29},
journal = {Primary Care Companion to The Journal of Clinical Psychiatry},
author = {Mitchell, Jeff},
year = {2008},
pmid = {null},
pmcid = {PMC2446480},
pages = {257},
}

@book{apa_diagnostic_2013,
edition = {5},
title = {The {Diagnostic} and {Statistical} {Manual} of {Mental} {Disorders}},
isbn = {978-0-89042-578-7},
url = {https://doi.org/10.1176/appi.books.9780890425787},
abstract = {The Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition, is the 2013 update to the Diagnostic and Statistical Manual of Mental Disorders, the taxonomic and diagnostic tool published by the American Psychiatric Association.},
language = {EN},
author = {APA, American Psychiatric Association},
year = {2013},
}

@article{lin_why_2011,
series = {Group {Awareness} in {CSCL} {Environments}},
title = {Why people use social networking sites: {An} empirical study integrating network externalities and motivation theory},
volume = {27},
issn = {0747-5632},
shorttitle = {Why people use social networking sites},
url = {https://www.sciencedirect.com/science/article/pii/S0747563210003766},
doi = {10.1016/j.chb.2010.12.009},
abstract = {Fast-developing social networking sites (SNS) have become the major media by which people develop their personal network online in recent years. To explore factors affecting user’s joining SNS, this study applies network externalities and motivation theory to explain why people continue to join SNS. This study used an online questionnaire to conduct empirical research, and collected and analyzed data of 402 samples by structural equation modeling (SEM) approach. The findings show that enjoyment is the most influential factor in people’s continued use of SNS, followed by number of peers, and usefulness. The number of peers and perceived complementarity have stronger influence than the number of members on perceived benefits (usefulness and enjoyment). This work also ran clustering analysis by gender, which found notable difference in both number of peers and number of members between men and women. The number of peers is an important factor affecting the continued intention to use for women but not for men; the number of members has no significant effect on enjoyment for men. The findings suggest that gender difference also produces different influences. The implication of research and discussions provides reference for SNS operators in marketing and operation.},
language = {en},
number = {3},
urldate = {2022-04-29},
journal = {Computers in Human Behavior},
author = {Lin, Kuan-Yu and Lu, Hsi-Peng},
month = may,
year = {2011},
keywords = {Continued intention to use, Motivation theory, Network externalities, Perceived benefit, Social networking site},
pages = {1152--1161},
}

@article{whiting_why_2013,
title = {Why people use social media: a uses and gratifications approach},
volume = {16},
issn = {1352-2752},
shorttitle = {Why people use social media},
url = {https://doi.org/10.1108/QMR-06-2013-0041},
doi = {10.1108/QMR-06-2013-0041},
abstract = {Purpose – This paper seeks to demonstrate the importance of uses and gratifications theory to social media. By applying uses and gratifications theory, this paper will explore and discuss the uses and gratifications that consumer receive from using social media. This paper seeks to provide a better and more comprehensive understanding of why consumers use social media. Design/methodology/approach – Exploratory study was conducted. 25 in‐depth interviews were conducted with individuals who use social media. Findings – This study identified ten uses and gratifications for using social media. The ten uses and gratifications are: social interaction, information seeking, pass time, entertainment, relaxation, communicatory utility, convenience utility, expression of opinion, information sharing, and surveillance/knowledge about others. Research limitations/implications – Limitations are small sample size. Research implications are that uses and gratifications theory has specific relevance to social media and should be given more prominence. Uses and gratifications theory helps explain the many and varied reasons why consumers use social media. Practical implications – This paper helps organizations to understand why consumers use social media and what gratifications they receive from social media. Originality/value – This paper makes the contribution that uses and gratifications theory has specific relevance and should be given more prominence within the area of social media. This paper also provides a rich and vivid understanding of why consumers use social media.},
number = {4},
urldate = {2022-04-29},
journal = {Qualitative Market Research: An International Journal},
author = {Whiting, Anita and Williams, David},
month = jan,
year = {2013},
note = {Publisher: Emerald Group Publishing Limited},
keywords = {Consumer generated media, Exploratory study, In‐depth interviews, Qualitative study, Social media, Uses and gratifications theory, Uses of social media, Web 2.0},
pages = {362--369},
}

@article{prince_no_2007,
title = {No health without mental health},
volume = {370},
issn = {0140-6736, 1474-547X},
url = {https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(07)61238-0/fulltext},
doi = {10.1016/S0140-6736(07)61238-0},
language = {English},
number = {9590},
urldate = {2022-04-29},
journal = {The Lancet},
author = {Prince, Martin and Patel, Vikram and Saxena, Shekhar and Maj, Mario and Maselko, Joanna and Phillips, Michael R. and Rahman, Atif},
month = sep,
year = {2007},
pmid = {17804063},
note = {Publisher: Elsevier},
pages = {859--877},
}

@article{andrade_epidemiology_2003,
title = {The epidemiology of major depressive episodes: results from the {International} {Consortium} of {Psychiatric} {Epidemiology} ({ICPE}) {Surveys}},
volume = {12},
issn = {1049-8931},
shorttitle = {The epidemiology of major depressive episodes},
doi = {10.1002/mpr.138},
abstract = {Absence of a common diagnostic interview has hampered cross-national syntheses of epidemiological evidence on major depressive episodes (MDE). Community epidemiological surveys using the World Health Organization Composite International Diagnostic Interview administered face-to-face were carried out in 10 countries in North America (Canada and the US), Latin America (Brazil, Chile, and Mexico), Europe (Czech Republic, Germany, the Netherlands, and Turkey), and Asia (Japan). The total sample size was more than 37,000. Lifetime prevalence estimates of hierarchy-free DSM-III-R/DSM-IV MDE varied widely, from 3\% in Japan to 16.9\% in the US, with the majority in the range of 8\% to 12\%. The 12-month/lifetime prevalence ratio was in the range 40\% to 55\%, the 30-day/12-month prevalence ratio in the range 45\% to 65\%, and median age of onset in the range 20 to 25 in most countries. Consistent socio-demographic correlates included being female and unmarried. Respondents in recent cohorts reported higher lifetime prevalence, but lower persistence than those in earlier cohorts. Major depressive episodes were found to be strongly co-morbid with, and temporally secondary to, anxiety disorders in all countries, with primary panic and generalized anxiety disorders the most powerful predictors of the first onset of secondary MDE. Major depressive episodes are a commonly occurring disorder that usually has a chronic-intermittent course. Effectiveness trials are needed to evaluate the impact of early detection and treatment on the course of MDE as well as to evaluate whether timely treatment of primary anxiety disorders would reduce the subsequent onset, persistence, and severity of secondary MDE.},
language = {eng},
number = {1},
journal = {International Journal of Methods in Psychiatric Research},
author = {Andrade, Laura and Caraveo-Anduaga, Jorge J. and Berglund, Patricia and Bijl, Rob V. and De Graaf, Ron and Vollebergh, Wilma and Dragomirecka, Eva and Kohn, Robert and Keller, Martin and Kessler, Ronald C. and Kawakami, Norito and Kiliç, Cengiz and Offord, David and Ustun, T. Bedirhan and Wittchen, Hans-Ulrich},
year = {2003},
pmid = {12830306},
pmcid = {PMC6878531},
keywords = {Adolescent, Adult, Aged, Cross-Sectional Studies, Data Collection, Depressive Disorder, Major, Female, Global Health, Humans, International Cooperation, Male, Middle Aged, Prevalence},
pages = {3--21},
}

@misc{openminds_us_2019,
title = {The {U}.{S}. {Mental} {Health} {Market}: \$225.1 {Billion} {In} {Spending} {In} 2019: {An} {OPEN} {MINDS} {Market} {Intelligence} {Report}},
shorttitle = {The {U}.{S}. {Mental} {Health} {Market}},
url = {https://openminds.com/intelligence-report/the-u-s-mental-health-market-225-1-billion-in-spending-in-2019-an-open-minds-market-intelligence-report/},
abstract = {Executive Summary The layers of overlapping stakeholders and delivery systems in the U.S. mental health market —and their implications for access and unmet mental health needs—result in systems that are … Continued},
language = {en-US},
urldate = {2022-04-29},
journal = {OPEN MINDS},
author = {OpenMinds},
year = {2019},
}

@misc{nih_major_2022,
title = {Major {Depression}},
url = {https://www.nimh.nih.gov/health/statistics/major-depression},
abstract = {An overview of statistics for major depression. Major depression is one of the most common mental disorders in the United States. For some individuals, major depression can result in severe impairments that interfere with or limit one’s ability to carry out major life activities.},
language = {en},
urldate = {2022-04-29},
journal = {National Institute of Mental Health (NIMH)},
author = {NIH},
year = {2022},
}

@misc{who_who_2022,
title = {{WHO} fact sheet on depression},
url = {https://www.who.int/news-room/fact-sheets/detail/depression},
abstract = {WHO fact sheet on depression providing key facts and information on  types and symptoms, contributing factors, diagnosis and treatment, WHO response.},
language = {en},
urldate = {2022-04-29},
author = {WHO},
month = apr,
year = {2022},
}

@article{yadav_survey_2019,
title = {A {Survey} on {Recent} {Advances} in {Named} {Entity} {Recognition} from {Deep} {Learning} models},
url = {http://arxiv.org/abs/1910.11470},
abstract = {Named Entity Recognition (NER) is a key component in NLP systems for question answering, information retrieval, relation extraction, etc. NER systems have been studied and developed widely for decades, but accurate systems using deep neural networks (NN) have only been introduced in the last few years. We present a comprehensive survey of deep neural network architectures for NER, and contrast them with previous approaches to NER based on feature engineering and other supervised or semi-supervised learning algorithms. Our results highlight the improvements achieved by neural networks, and show how incorporating some of the lessons learned from past work on feature-based NER systems can yield further improvements.},
urldate = {2022-04-28},
journal = {arXiv:1910.11470 [cs]},
author = {Yadav, Vikas and Bethard, Steven},
month = oct,
year = {2019},
note = {arXiv: 1910.11470},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@inproceedings{zhang_time-aware_2020,
title = {Time-{Aware} {Transformer}-based {Network} for {Clinical} {Notes} {Series} {Prediction}},
url = {https://proceedings.mlr.press/v126/zhang20c.html},
abstract = {A patient’s clinical notes correspond to a sequence of free-form text documents generated by healthcare professionals over time. Rich and unique information in clinical notes is useful for clinical decision making. In this work, we propose a time-aware transformer-based hierarchical architecture, which we call Flexible Time-aware LSTM Transformer (FTL-Trans), for classifying a patient’s health state based on her series of clinical notes. FTL-Trans addresses the problem that current transformer-based architectures cannot handle, which is the multi-level structure inherent in clinical note series where a note contains a sequence of chucks and a chuck contains further a sequence of words. At the bottom layer, FTL-Trans encodes equal-length subsequences of a patient’s clinical notes ("chunks") into content embeddings using a pre-trained ClinicalBERT model. Unlike ClinicalBERT, however, FTL-Trans merges each content embedding and sequential information into a new position-enhanced chunk representation in the second layer by an augmented multi-level position embedding. Next, the time-aware layer tackles the irregularity in the spacing of notes in the note series by learning a flexible time decay function and utilizing the time decay function to incorporate both the position-enhanced chunk embedding and time information into a patient representation. This patient representation is then fed into the top layer for classification. Together, this hierarchical design of FTL-Trans successfully captures the multi-level sequential structure of the note series. Our extensive experimental evaluation conducted using multiple patient cohorts extracted from the MIMIC dataset illustrates that, while addressing the aforementioned issues, FTL-Trans consistently outperforms the state-of-the-art transformer-based architectures up to 5\% in AUROC and 6\% in Accuracy.},
language = {en},
urldate = {2022-04-26},
booktitle = {Proceedings of the 5th {Machine} {Learning} for {Healthcare} {Conference}},
publisher = {PMLR},
author = {Zhang, Dongyu and Thadajarassiri, Jidapa and Sen, Cansu and Rundensteiner, Elke},
month = sep,
year = {2020},
note = {ISSN: 2640-3498},
pages = {566--588},
}

@article{rudin_interpretable_2021,
title = {Interpretable {Machine} {Learning}: {Fundamental} {Principles} and 10 {Grand} {Challenges}},
shorttitle = {Interpretable {Machine} {Learning}},
url = {http://arxiv.org/abs/2103.11251},
abstract = {Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the "Rashomon set" of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.},
urldate = {2022-04-19},
journal = {arXiv:2103.11251 [cs, stat]},
author = {Rudin, Cynthia and Chen, Chaofan and Chen, Zhi and Huang, Haiyang and Semenova, Lesia and Zhong, Chudi},
month = jul,
year = {2021},
note = {arXiv: 2103.11251},
keywords = {68T01, Computer Science - Machine Learning, I.2.6, Statistics - Machine Learning},
}

@inproceedings{zhou_learning_2016,
address = {Las Vegas, NV, USA},
title = {Learning {Deep} {Features} for {Discriminative} {Localization}},
isbn = {978-1-4673-8851-1},
url = {http://ieeexplore.ieee.org/document/7780688/},
doi = {10.1109/CVPR.2016.319},
abstract = {In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. While this technique was previously proposed as a means for regularizing training, we ﬁnd that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1\% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation.We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classiﬁcation task1.},
language = {en},
urldate = {2022-04-19},
booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
publisher = {IEEE},
author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
month = jun,
year = {2016},
pages = {2921--2929},
}

@article{lundberg_unified_2017,
title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
url = {http://arxiv.org/abs/1705.07874},
abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
urldate = {2022-04-19},
journal = {arXiv:1705.07874 [cs, stat]},
author = {Lundberg, Scott and Lee, Su-In},
month = nov,
year = {2017},
note = {arXiv: 1705.07874},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{chen_this_2019,
title = {This {Looks} {Like} {That}: {Deep} {Learning} for {Interpretable} {Image} {Recognition}},
shorttitle = {This {Looks} {Like} {That}},
url = {http://arxiv.org/abs/1806.10574},
abstract = {When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture -- prototypical part network (ProtoPNet), that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training without any annotations for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the Stanford Cars dataset. Our experiments show that ProtoPNet can achieve comparable accuracy with its analogous non-interpretable counterpart, and when several ProtoPNets are combined into a larger network, it can achieve an accuracy that is on par with some of the best-performing deep models. Moreover, ProtoPNet provides a level of interpretability that is absent in other interpretable deep models.},
urldate = {2022-04-19},
journal = {arXiv:1806.10574 [cs, stat]},
author = {Chen, Chaofan and Li, Oscar and Tao, Chaofan and Barnett, Alina Jade and Su, Jonathan and Rudin, Cynthia},
month = dec,
year = {2019},
note = {arXiv: 1806.10574},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{dong_using_2022,
title = {Using {Simulation} in {Information} {Systems} {Research}},
volume = {23},
issn = {1536-9323},
url = {https://aisel.aisnet.org/jais/vol23/iss2/8},
doi = {10.17705/1jais.00743},
number = {2},
journal = {Journal of the Association for Information Systems},
author = {Dong, John Qi},
month = jan,
year = {2022},
pages = {408--417},
}

@article{sak_long_2014,
title = {Long {Short}-{Term} {Memory} {Based} {Recurrent} {Neural} {Network} {Architectures} for {Large} {Vocabulary} {Speech} {Recognition}},
url = {https://arxiv.org/abs/1402.1128v1},
doi = {10.48550/arXiv.1402.1128},
abstract = {Long Short-Term Memory (LSTM) is a recurrent neural network (RNN) architecture that has been designed to address the vanishing and exploding gradient problems of conventional RNNs. Unlike feedforward neural networks, RNNs have cyclic connections making them powerful for modeling sequences. They have been successfully used for sequence labeling and sequence prediction tasks, such as handwriting recognition, language modeling, phonetic labeling of acoustic frames. However, in contrast to the deep neural networks, the use of RNNs in speech recognition has been limited to phone recognition in small scale tasks. In this paper, we present novel LSTM based RNN architectures which make more effective use of model parameters to train acoustic models for large vocabulary speech recognition. We train and compare LSTM, RNN and DNN models at various numbers of parameters and configurations. We show that LSTM models converge quickly and give state of the art speech recognition performance for relatively small sized models.},
language = {en},
urldate = {2022-03-17},
author = {Sak, Haşim and Senior, Andrew and Beaufays, Françoise},
month = feb,
year = {2014},
}

@article{burton-jones_examining_2021,
title = {Examining {Assumptions}: {Provocations} on the {Nature}, {Impact}, and {Implications} of {Is} {Theory}},
volume = {45},
issn = {02767783},
shorttitle = {Examining {Assumptions}},
url = {https://search.ebscohost.com/login.aspx?direct=true&AuthType=shib,ip&db=bsh&AN=149296200&site=ehost-live&custid=s8875136},
doi = {10.25300/MISQ/2021/15434.1},
abstract = {Articles on alleged assumptions regarding the relationship between information systems research and theory are introduced with a focus on topics including information technology and digitization, theory building vis-a-vis machine learning, and the ethics of smart information systems.},
number = {1},
urldate = {2022-03-14},
journal = {MIS Quarterly},
author = {Burton-Jones, Andrew and Butler, Brian S. and Scott, Susan V. and {Sean Xin Xu}},
month = mar,
year = {2021},
note = {Publisher: MIS Quarterly},
keywords = {Digitization, Information technology, Machine learning, Management information systems, Technology \& ethics, Theory},
pages = {453--454},
}

@article{ram_focusing_2021,
title = {Focusing on {Programmatic} {High} {Impact} {Information} {Systems} {Research}, {Not} {Theory}, to {Address} {Grand} {Challenges}},
volume = {45},
issn = {02767783},
url = {https://search.ebscohost.com/login.aspx?direct=true&AuthType=shib,ip&db=bsh&AN=149296205&site=ehost-live&custid=s8875136},
doi = {10.25300/MISQ/2021/15434.1.5},
abstract = {The article calls for high impact information systems research to address social challenges. Examples of previous high impact information systems research are provided including the Human Genome Project, the World Wide Web, and the entity relationship model, further examples of high impact research from the University of Arizona are offered, and the design science paradigm is questioned in the light of big data and data science.},
number = {1},
urldate = {2022-03-14},
journal = {MIS Quarterly},
author = {Ram, Sudha and Goes, Paulo},
month = mar,
year = {2021},
note = {Publisher: MIS Quarterly},
keywords = {Big data, Data science, Design science, Interdisciplinary research, Management information systems, Social problems},
pages = {479--483},
}

@article{padmanabhan_machine_2022,
title = {Machine {Learning} in {Information} {Systems} {Research}},
volume = {46},
issn = {ISSN 0276-7783/ISSN 2162-9730},
url = {https://aisel.aisnet.org/misq/vol46/iss1/4},
number = {1},
journal = {Management Information Systems Quarterly},
author = {Padmanabhan, Balaji and fang, xiao and Sahoo, Nachiketa and Burton-Jones, Andrew},
month = mar,
year = {2022},
pages = {iii--xix},
}

@techreport{wang_every_2019,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {Every {Bit} {Counts}: {Using} {Deep} {Learning} and {Vectorization} to {Analyze} {Healthcare} {Big} {Data}},
shorttitle = {Every {Bit} {Counts}},
url = {https://papers.ssrn.com/abstract=3378896},
abstract = {The rapid digitization of healthcare has generated large volumes of rich and complex data from sources such as claims and electronic health records. Traditional analytic approaches, however, only utilize small subsets of these data and often require deep domain knowledge. New methods are needed to handle both the scale and complexity of big data in healthcare. We employ a recent breakthrough in computer science to develop a new Deep Learning-based Vectorization (DLV) approach for more comprehensive and efficient analysis of healthcare data. This approach automatically converts data elements into standardized numeric vectors, empowering new types of computing and improve performance in traditional data analysis. We demonstrate the potential of DLV to predict 30-day readmission using discharge records that cover all emergency department visits and inpatient hospitalizations in Florida. We find that while traditional approaches struggle even to load large amounts of clinical information (including non-numeric variables), DLV handles this information easily. Furthermore, DLV significantly improves the accuracy of 30-day readmission prediction in the presence of high-dimensional data. While traditional logistic regression yields an AUC of 0.61, DLV gives us 0.79, a 163\% improvement in the lift over the baseline of 0.50. In addition, we demonstrate that the vector representations offered by DLV afford easy visualization for better understanding of the clinical data. Overall, the DLV approach thus shows great potential in facilitating the analysis of big healthcare data and can complement traditional methods in high-dimensional environments.},
language = {en},
number = {ID 3378896},
urldate = {2022-02-12},
institution = {Social Science Research Network},
author = {Wang, Weiguang and Chen, Min (Michelle) and Gao, Guodong (Gordon) and McCullough, Jeffrey},
month = apr,
year = {2019},
doi = {10.2139/ssrn.3378896},
keywords = {Every Bit Counts: Using Deep Learning and Vectorization to Analyze Healthcare Big Data, Guodong (Gordon) Gao, Jeffrey McCullough, Min (Michelle) Chen, SSRN, Weiguang Wang},
}

@article{xie_readmission_2021,
title = {Readmission {Prediction} for {Patients} with {Heterogeneous} {Medical} {History}: {A} {Trajectory}-{Based} {Deep} {Learning} {Approach}},
volume = {13},
issn = {2158-656X},
shorttitle = {Readmission {Prediction} for {Patients} with {Heterogeneous} {Medical} {History}},
url = {https://doi.org/10.1145/3468780},
doi = {10.1145/3468780},
abstract = {Hospital readmission refers to the situation where a patient is re-hospitalized with the same primary diagnosis within a specific time interval after discharge. Hospital readmission causes \$26 billion preventable expenses to the U.S. health systems annually and often indicates suboptimal patient care. To alleviate those severe financial and health consequences, it is crucial to proactively predict patients’ readmission risk. Such prediction is challenging because the evolution of patients’ medical history is dynamic and complex. The state-of-the-art studies apply statistical models which use static predictors in a period, failing to consider patients’ heterogeneous medical history. Our approach – Trajectory-BAsed DEep Learning (TADEL) – is motivated to tackle the deficiencies of the existing approaches by capturing dynamic medical history. We evaluate TADEL on a five-year national Medicare claims dataset including 3.6 million patients per year over all hospitals in the United States, reaching an F1 score of 87.3\% and an AUC of 88.4\%. Our approach significantly outperforms all the state-of-the-art methods. Our findings suggest that health status factors and insurance coverage are important predictors for readmission. This study contributes to IS literature and analytical methodology by formulating the trajectory-based readmission prediction problem and developing a novel deep-learning-based readmission risk prediction framework. From a health IT perspective, this research delivers implementable methods to assess patients’ readmission risk and take early interventions to avoid potential negative consequences.},
number = {2},
urldate = {2022-02-12},
journal = {ACM Transactions on Management Information Systems},
author = {Xie, Jiaheng and Zhang, Bin and Ma, Jian and Zeng, Daniel and Lo-Ciganic, Jenny},
month = oct,
year = {2021},
keywords = {Hospital readmission, computational design science, deep learning, predictive analytics},
pages = {14:1--14:27},
}

@misc{noauthor_named_nodate,
title = {Named entity recognition},
url = {http://nlpprogress.com/english/named_entity_recognition.html},
abstract = {Repository to track the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks.},
language = {en-US},
urldate = {2022-01-28},
journal = {NLP-progress},
}

@article{lample_neural_2016,
title = {Neural {Architectures} for {Named} {Entity} {Recognition}},
url = {http://arxiv.org/abs/1603.01360},
abstract = {State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.},
urldate = {2022-01-28},
journal = {arXiv:1603.01360 [cs]},
author = {Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
month = apr,
year = {2016},
note = {arXiv: 1603.01360},
keywords = {Computer Science - Computation and Language},
}

@techreport{lin_first_2020,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {First, {Do} {No} {Harm}: {Predictive} {Analytics} to {Reduce} {In}-{Hospital} {Adverse} {Events}},
shorttitle = {First, {Do} {No} {Harm}},
url = {https://papers.ssrn.com/abstract=3273203},
abstract = {Inadequate patient safety is a serious issue in current medical practice. Medical errors cause adverse events (AEs) for patients and lead to premature deaths, unintended complications, prolonged hospital stays, and higher medical costs. Although the importance of AE prediction and prevention is well recognized in the information systems literature, there is a dearth of research on modeling and predicting AEs caused by medical errors. Following the design science research paradigm, this study describes the search, design, and evaluation of a novel in-hospital AE prediction model, called StoChastic AutoRegressions for LatEnt Trajectories (SCARLET). The proposed model integrates generalized linear mixed model with multitask learning and stochastic time-series processes. Results from our large-scale empirical evaluation show that SCARLET outperforms prior state-of-the-art techniques in predicting harms from medical errors during patients’ hospital stays. Through a simulated experiment, we further demonstrate significant cost savings potential when hospitals implement and integrate SCARLET in their inpatient clinical workflow.},
language = {en},
number = {ID 3273203},
urldate = {2022-01-28},
institution = {Social Science Research Network},
author = {Lin, Yu-Kai and Fang, Xiao},
month = sep,
year = {2020},
doi = {10.2139/ssrn.3273203},
keywords = {adverse events, design science, healthcare predictive analytics, medical errors, patient safety},
}

@article{song_learning_2021,
title = {Learning from {Noisy} {Labels} with {Deep} {Neural} {Networks}: {A} {Survey}},
shorttitle = {Learning from {Noisy} {Labels} with {Deep} {Neural} {Networks}},
url = {http://arxiv.org/abs/2007.08199},
abstract = {Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies. All the contents will be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.},
urldate = {2022-01-28},
journal = {arXiv:2007.08199 [cs, stat]},
author = {Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil},
month = nov,
year = {2021},
note = {arXiv: 2007.08199},
keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{haque_deep_2021,
title = {Deep {Learning} for {Suicide} and {Depression} {Identification} with {Unsupervised} {Label} {Correction}},
url = {http://arxiv.org/abs/2102.09427},
abstract = {Early detection of suicidal ideation in depressed individuals can allow for adequate medical attention and support, which in many cases is life-saving. Recent NLP research focuses on classifying, from a given piece of text, if an individual is suicidal or clinically healthy. However, there have been no major attempts to differentiate between depression and suicidal ideation, which is an important clinical challenge. Due to the scarce availability of EHR data, suicide notes, or other similar verified sources, web query data has emerged as a promising alternative. Online sources, such as Reddit, allow for anonymity that prompts honest disclosure of symptoms, making it a plausible source even in a clinical setting. However, these online datasets also result in lower performance, which can be attributed to the inherent noise in web-scraped labels, which necessitates a noise-removal process. Thus, we propose SDCNL, a suicide versus depression classification method through a deep learning approach. We utilize online content from Reddit to train our algorithm, and to verify and correct noisy labels, we propose a novel unsupervised label correction method which, unlike previous work, does not require prior noise distribution information. Our extensive experimentation with multiple deep word embedding models and classifiers display the strong performance of the method in anew, challenging classification application. We make our code and dataset available at https://github.com/ayaanzhaque/SDCNL},
urldate = {2022-01-28},
journal = {arXiv:2102.09427 [cs]},
author = {Haque, Ayaan and Reddi, Viraaj and Giallanza, Tyler},
month = jun,
year = {2021},
note = {arXiv: 2102.09427},
keywords = {Computer Science - Machine Learning},
}

@article{leidner_whats_2020,
title = {What's in a {Contribution}?},
volume = {21},
issn = {1536-9323},
url = {https://aisel.aisnet.org/jais/vol21/iss1/2},
doi = {10.17705/1jais.00598},
number = {1},
journal = {Journal of the Association for Information Systems},
author = {Leidner, Dorothy},
month = feb,
year = {2020},
}

@misc{noauthor_econlp_nodate,
title = {{ECONLP} 2021},
url = {https://lt3.ugent.be/econlp/},
urldate = {2021-12-22},
}

@article{king_logistic_2001,
title = {Logistic {Regression} in {Rare} {Events} {Data}},
copyright = {open},
issn = {1047-1987},
url = {https://dash.harvard.edu/handle/1/4125045},
abstract = {We study rare events data, binary dependent variables with dozens to thousands of times fewer ones (events, such as wars, vetoes, cases of political activism, or epidemiological infections) than zeros (“nonevents”). In many literatures, these variables have proven difficult to explain and predict, a problem that seems to have at least two sources. First, popular statistical procedures, such as logistic regression, can sharply underestimate the probability of rare events. We recommend corrections that outperform existing methods and change the estimates of absolute and relative risks by as much as some estimated effects reported in the literature. Second, commonly used data collection strategies are grossly inefficient for rare events data. The fear of collecting data with too few events has 
led to data collections with huge numbers of observations but relatively few, and poorly measured, explanatory variables, such as in international conflict data with more than a quarter-million dyads, only a few of which are at war. As it turns out, more efficient sampling 
designs exist for making valid inferences, such as sampling all available events (e.g., wars) and a tiny fraction of nonevents (peace). This enables scholars to save as much as 99\% of their (nonfixed) data collection costs or to collect much more meaningful explanatory 
variables.We provide methods that link these two results, enabling both types of corrections to work simultaneously, and software that implements the methods developed.},
language = {en\_US},
urldate = {2021-12-21},
journal = {Political Analysis -Ann Arbor then Oxford-},
author = {King, Gary and Zeng, Langche},
year = {2001},
note = {Accepted: 2010-05-21T20:40:13Z
Publisher: Oxford University Press},
}

@article{salvador_disease_2019,
title = {Disease management at the wildlife-livestock interface: {Using} whole-genome sequencing to study the role of elk in {Mycobacterium} bovis transmission in {Michigan}, {USA}},
volume = {28},
issn = {1365-294X},
shorttitle = {Disease management at the wildlife-livestock interface},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mec.15061},
doi = {10.1111/mec.15061},
abstract = {The role of wildlife in the persistence and spread of livestock diseases is difficult to quantify and control. These difficulties are exacerbated when several wildlife species are potentially involved. Bovine tuberculosis (bTB), caused by Mycobacterium bovis, has experienced an ecological shift in Michigan, with spillover from cattle leading to an endemically infected white-tailed deer (deer) population. It has potentially substantial implications for the health and well-being of both wildlife and livestock and incurs a significant economic cost to industry and government. Deer are known to act as a reservoir of infection, with evidence of M. bovis transmission to sympatric elk and cattle populations. However, the role of elk in the circulation of M. bovis is uncertain; they are few in number, but range further than deer, so may enable long distance spread. Combining Whole Genome Sequences (WGS) for M. bovis isolates from exceptionally well-observed populations of elk, deer and cattle with spatiotemporal locations, we use spatial and Bayesian phylogenetic analyses to show strong spatiotemporal admixture of M. bovis isolates. Clustering of bTB in elk and cattle suggests either intraspecies transmission within the two populations, or exposure to a common source. However, there is no support for significant pathogen transfer amongst elk and cattle, and our data are in accordance with existing evidence that interspecies transmission in Michigan is likely only maintained by deer. This study demonstrates the value of whole genome population studies of M. bovis transmission at the wildlife-livestock interface, providing insights into bTB management in an endemic system.},
language = {en},
number = {9},
urldate = {2021-12-17},
journal = {Molecular Ecology},
author = {Salvador, Liliana C. M. and O'Brien, Daniel J. and Cosgrove, Melinda K. and Stuber, Tod P. and Schooley, Angie M. and Crispell, Joseph and Church, Steven V. and Gröhn, Yrjö T. and Robbe-Austerman, Suelee and Kao, Rowland R.},
year = {2019},
note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/mec.15061},
keywords = {Bayesian statistics, bovine tuberculosis, interspecies transmission, spillover, whole genome sequencing, wildlife-livestock interface},
pages = {2192--2205},
}

@article{khan_modeling_2019,
title = {Modeling the transmission dynamics of tuberculosis in {Khyber} {Pakhtunkhwa} {Pakistan}},
volume = {11},
issn = {1687-8140},
url = {https://doi.org/10.1177/1687814019854835},
doi = {10.1177/1687814019854835},
abstract = {This article addresses the dynamics of the bacterial disease tuberculosis in Khyber Pakhtunkhwa, Pakistan, through a mathematical model. In this work, the latent compartment is divided into slow and fast kinds of progresses. The model is parameterized based on the reported tuberculosis-infected cases in Khyber Pakhtunkhwa for the period 2002–2017. We obtain the basic reproduction number R0R0{\textless}math display="inline" id="math1-1687814019854835" overflow="scroll" altimg="eq-00001.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}msub{\textgreater}{\textless}mrow{\textgreater}{\textless}mi mathvariant="script"{\textgreater}R{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}mrow{\textgreater}{\textless}mn{\textgreater}0{\textless}/mn{\textgreater}{\textless}/mrow{\textgreater}{\textless}/msub{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} of the model using the next-generation method. The estimated value of R0R0{\textless}math display="inline" id="math2-1687814019854835" overflow="scroll" altimg="eq-00002.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}msub{\textgreater}{\textless}mrow{\textgreater}{\textless}mi mathvariant="script"{\textgreater}R{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}mrow{\textgreater}{\textless}mn{\textgreater}0{\textless}/mn{\textgreater}{\textless}/mrow{\textgreater}{\textless}/msub{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} for the given period is approximately 1.38. Furthermore, it is shown that the model has two types of equilibria: disease-free and endemic equilibriums. The global stability analysis of the model equilibria is shown via Lyapunov functions. We also perform the sensitivity analysis of R0R0{\textless}math display="inline" id="math3-1687814019854835" overflow="scroll" altimg="eq-00003.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}msub{\textgreater}{\textless}mrow{\textgreater}{\textless}mi mathvariant="script"{\textgreater}R{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}mrow{\textgreater}{\textless}mn{\textgreater}0{\textless}/mn{\textgreater}{\textless}/mrow{\textgreater}{\textless}/msub{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} and present their corresponding graphical results to examine the relative importance of various model parameters to tuberculosis transmission and prevalence. Finally, some numerical simulations are done for the estimated parameters and the key parameters effects are considered on the curtailing tuberculosis disease. From the numerical results and model sensitivity analysis, it is found that the spread of tuberculosis can be minimized by increasing the treatment rate γγ{\textless}math display="inline" id="math4-1687814019854835" overflow="scroll" altimg="eq-00004.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}γ{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} of infected people and decreasing the effective disease transmission rate ββ{\textless}math display="inline" id="math5-1687814019854835" overflow="scroll" altimg="eq-00005.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}β{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} and the rate δδ{\textless}math display="inline" id="math6-1687814019854835" overflow="scroll" altimg="eq-00006.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}δ{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} at which the individuals leave treated class reenter infected classes.},
language = {en},
number = {6},
urldate = {2021-12-17},
journal = {Advances in Mechanical Engineering},
author = {Khan, Muhammad Altaf and Ahmad, Manzoor and Ullah, Saif and Farooq, Muhammad and Gul, Taza},
month = jun,
year = {2019},
note = {Publisher: SAGE Publications},
keywords = {Tuberculosis, global stability, mathematical model, parameter estimation, sensitivity, stability results},
pages = {1687814019854835},
}

@article{peffers_design_2007,
title = {A {Design} {Science} {Research} {Methodology} for {Information} {Systems} {Research}},
volume = {24},
issn = {0742-1222, 1557-928X},
url = {https://www.tandfonline.com/doi/full/10.2753/MIS0742-1222240302},
doi = {10.2753/MIS0742-1222240302},
abstract = {The paper motivates, presents, demonstrates in use, and evaluates a methodology for conducting design science (DS) research in information systems (IS). DS is of importance in a discipline oriented to the creation of successful artifacts. Several researchers have pioneered DS research in IS, yet over the past 15 years, little DS research has been done within the discipline. The lack of a methodology to serve as a commonly accepted framework for DS research and of a template for its presentation may have contributed to its slow adoption. The design science research methodology (DSRM) presented here incorporates principles, practices, and procedures required to carry out such research and meets three objectives: it is consistent with prior literature, it provides a nominal process model for doing DS research, and it provides a mental model for presenting and evaluating DS research in IS. The DS process includes six steps: problem identiﬁcation and motivation, deﬁnition of the objectives for a solution, design and development, demonstration, evaluation, and communication. We demonstrate and evaluate the methodology by presenting four case studies in terms of the DSRM, including cases that present the design of a database to support health assessment methods, a software reuse measure, an Internet video telephony application, and an IS planning method. The designed methodology effectively satisﬁes the three objectives and has the potential to help aid the acceptance of DS research in the IS discipline.},
language = {en},
number = {3},
urldate = {2021-12-15},
journal = {Journal of Management Information Systems},
author = {Peffers, Ken and Tuunanen, Tuure and Rothenberger, Marcus A. and Chatterjee, Samir},
month = dec,
year = {2007},
pages = {45--77},
}

@book{mitchell_machine_1997,
address = {New York},
edition = {1st edition},
title = {Machine {Learning}},
isbn = {978-0-07-042807-2},
language = {English},
publisher = {McGraw-Hill Education},
author = {Mitchell, Tom M.},
month = mar,
year = {1997},
}

@inproceedings{gilpin_explaining_2018,
title = {Explaining {Explanations}: {An} {Overview} of {Interpretability} of {Machine} {Learning}},
shorttitle = {Explaining {Explanations}},
doi = {10.1109/DSAA.2018.00018},
abstract = {There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.},
booktitle = {2018 {IEEE} 5th {International} {Conference} on {Data} {Science} and {Advanced} {Analytics} ({DSAA})},
author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
month = oct,
year = {2018},
keywords = {Artificial intelligence, Biological neural networks, Complexity theory, Computational modeling, Decision trees, Deep learning and deep analytics, Fairness and transparency in data science, Machine learning theories, Models and systems, Taxonomy},
pages = {80--89},
}

@misc{noauthor_ars_nodate,
title = {{ARS} {AI} {Innovation} {Fund} {\textbar} {SCINet} {\textbar} {USDA} {Scientific} {Computing} {Initiative}},
url = {https://scinet.usda.gov/opportunities/ai-innovation},
urldate = {2021-10-29},
}

@misc{noauthor_-_nodate,
title = {- {College} of {Veterinary} {Medicine} - {Iowa} {State} {University}},
url = {https://influenza.cvm.iastate.edu/index.php},
urldate = {2021-10-29},
}

@misc{noauthor_usda_nodate,
title = {{USDA} - {National} {Agricultural} {Statistics} {Service} {Homepage}},
url = {https://www.nass.usda.gov/},
urldate = {2021-10-29},
}

@article{brennan_shifting_2017,
title = {Shifting brucellosis risk in livestock coincides with spreading seroprevalence in elk},
volume = {12},
issn = {1932-6203},
doi = {10.1371/journal.pone.0178780},
abstract = {Tracking and preventing the spillover of disease from wildlife to livestock can be difficult when rare outbreaks occur across large landscapes. In these cases, broad scale ecological studies could help identify risk factors and patterns of risk to inform management and reduce incidence of disease. Between 2002 and 2014, 21 livestock herds in the Greater Yellowstone Area (GYA) were affected by brucellosis, a bacterial disease caused by Brucella abortus, while no affected herds were detected between 1990 and 2001. Using a Bayesian analysis, we examined several ecological covariates that may be associated with affected livestock herds across the region. We showed that livestock risk has been increasing over time and expanding outward from the historical nexus of brucellosis in wild elk on Wyoming's feeding grounds where elk are supplementally fed during the winter. Although elk were the presumed source of cattle infections, occurrences of affected livestock herds were only weakly associated with the density of seropositive elk across the GYA. However, the shift in livestock risk did coincide with recent increases in brucellosis seroprevalence in unfed elk populations. As increasing brucellosis in unfed elk likely stemmed from high levels of the disease in fed elk, disease-related costs of feeding elk have probably been incurred across the entire GYA, rather than solely around the feeding grounds. Our results suggest that focused disease mitigation in areas where seroprevalence in unfed elk is high could reduce the spillover of brucellosis to livestock. We also highlight the need to better understand the epidemiology of spillover events with detailed histories of disease testing, calving, and movement of infected livestock. Finally, we recommend using case-control studies to investigate local factors important to livestock risk.},
language = {eng},
number = {6},
journal = {PloS One},
author = {Brennan, Angela and Cross, Paul C. and Portacci, Katie and Scurlock, Brandon M. and Edwards, William H.},
year = {2017},
pmid = {28609437},
pmcid = {PMC5469469},
keywords = {Animals, Animals, Wild, Bayes Theorem, Bison, Brucella abortus, Brucellosis, Cattle, Deer, Disease Outbreaks, Geography, Host-Pathogen Interactions, Idaho, Incidence, Livestock, Models, Theoretical, Montana, Risk Factors, Seroepidemiologic Studies, Wyoming},
pages = {e0178780},
}

@article{rambo-martin_influenza_nodate,
title = {Influenza {A} {Virus} {Field} {Surveillance} at a {Swine}-{Human} {Interface}},
volume = {5},
url = {https://journals.asm.org/doi/10.1128/mSphere.00822-19},
doi = {10.1128/mSphere.00822-19},
number = {1},
urldate = {2021-10-22},
journal = {mSphere},
author = {Rambo-Martin, Benjamin L. and Keller, Matthew W. and Wilson, Malania M. and Nolting, Jacqueline M. and Anderson, Tavis K. and Vincent, Amy L. and Bagal, Ujwal R. and Jang, Yunho and Neuhaus, Elizabeth B. and Davis, C. Todd and Bowman, Andrew S. and Wentworth, David E. and Barnes, John R.},
note = {Publisher: American Society for Microbiology},
pages = {e00822--19},
}

@article{zeller_spatial_2021,
title = {Spatial and {Temporal} {Coevolution} of {N2} {Neuraminidase} and {H1} and {H3} {Hemagglutinin} {Genes} of {Influenza} {A} {Virus} in {United} {States} {Swine}},
issn = {2057-1577},
url = {https://doi.org/10.1093/ve/veab090},
doi = {10.1093/ve/veab090},
abstract = {The neuraminidase (NA) and hemagglutinin (HA) are essential surface glycoproteins of influenza A virus (IAV). In this study, the evolution of subtype N2 NA paired with H1 and H3 subtype HA in swine was evaluated to understand if genetic diversity of HA and NA were linked. Using time-scaled Bayesian phylodynamic analyses, the relationships of paired swine N2 with H1 or H3 from 2009 to 2018 were evaluated. These data demonstrated increased relative genetic diversity within the major N2 clades circulating in swine in the United States (N2.1998 between 2014-2017 and N2.2002 between 2010-2016). Preferential pairing was observed among specific NA and HA genetic clades. Gene reassortment between cocirculating influenza A strains resulted in novel pairings that persisted. The changes of genetic diversity in the NA gene were quantified using Bayesian phylodynamic analyses and increases in diversity were observed subsequent to novel NA-HA reassortment events. The rate of evolution among NA-N2 clades and HA-H1 and HA-H3 clades were similar. Bayesian phylodynamic analyses demonstrated strong spatial patterns in N2 genetic diversity, but frequent interstate movement of rare N2 clades provided opportunity for reassortment and emergence of new N2-HA pairings. The frequent regional movement of pigs and their influenza viruses is an explanation for the documented patterns of reassortment and subsequent changes in gene diversity. The reassortment and evolution of NA and linked HA evolution may result in antigenic drift of both major surface glycoproteins, reducing vaccine efficacy, with subsequent impact on animal health.},
number = {veab090},
urldate = {2021-10-22},
journal = {Virus Evolution},
author = {Zeller, Michael A and Chang, Jennifer and Vincent, Amy L and Gauger, Phillip C and Anderson, Tavis K},
month = oct,
year = {2021},
}

@article{anderson_swine_2020,
title = {Swine {Influenza} {A} {Viruses} and the {Tangled} {Relationship} with {Humans}},
issn = {, 2157-1422},
url = {http://perspectivesinmedicine.cshlp.org/content/early/2020/01/27/cshperspect.a038737},
doi = {10.1101/cshperspect.a038737},
abstract = {Influenza A viruses (IAVs) are the causative agents of one of the most important viral respiratory diseases in pigs and humans. Human and swine IAV are prone to interspecies transmission, leading to regular incursions from human to pig and vice versa. This bidirectional transmission of IAV has heavily influenced the evolutionary history of IAV in both species. Transmission of distinct human seasonal lineages to pigs, followed by sustained within-host transmission and rapid adaptation and evolution, represent a considerable challenge for pig health and production. Consequently, although only subtypes of H1N1, H1N2, and H3N2 are endemic in swine around the world, extensive diversity can be found in the hemagglutinin (HA) and neuraminidase (NA) genes, as well as the remaining six genes. We review the complicated global epidemiology of IAV in swine and the inextricably entangled implications for public health and influenza pandemic planning.},
language = {en},
urldate = {2021-10-22},
journal = {Cold Spring Harbor Perspectives in Medicine},
author = {Anderson, Tavis K. and Chang, Jennifer and Arendsee, Zebulun W. and Venkatesh, Divya and Souza, Carine K. and Kimble, J. Brian and Lewis, Nicola S. and Davis, C. Todd and Vincent, Amy L.},
month = jan,
year = {2020},
pmid = {31988203},
note = {Publisher: Cold Spring Harbor Laboratory Press},
pages = {a038737},
}

@article{garcia_del_valle_disease_2019,
title = {Disease networks and their contribution to disease understanding: {A} review of their evolution, techniques and data sources},
volume = {94},
issn = {1532-0464},
shorttitle = {Disease networks and their contribution to disease understanding},
url = {https://www.sciencedirect.com/science/article/pii/S1532046419301248},
doi = {10.1016/j.jbi.2019.103206},
abstract = {Over a decade ago, a new discipline called network medicine emerged as an approach to understand human diseases from a network theory point-of-view. Disease networks proved to be an intuitive and powerful way to reveal hidden connections among apparently unconnected biomedical entities such as diseases, physiological processes, signaling pathways, and genes. One of the fields that has benefited most from this improvement is the identification of new opportunities for the use of old drugs, known as drug repurposing. The importance of drug repurposing lies in the high costs and the prolonged time from target selection to regulatory approval of traditional drug development. In this document we analyze the evolution of disease network concept during the last decade and apply a data science pipeline approach to evaluate their functional units. As a result of this analysis, we obtain a list of the most commonly used functional units and the challenges that remain to be solved. This information can be very valuable for the generation of new prediction models based on disease networks.},
language = {en},
urldate = {2021-10-18},
journal = {Journal of Biomedical Informatics},
author = {García del Valle, Eduardo P. and Lagunes García, Gerardo and Prieto Santamaría, Lucía and Zanin, Massimiliano and Menasalvas Ruiz, Ernestina and Rodríguez-González, Alejandro},
month = jun,
year = {2019},
keywords = {Data science pipeline, Disease networks, Disease similarity, Disease understanding, Drug repurposing},
pages = {103206},
}

@article{jiang_epidemiological_2018,
title = {An {Epidemiological} {Human} {Disease} {Network} {Derived} from {Disease} {Co}-occurrence in {Taiwan}},
volume = {8},
copyright = {2018 The Author(s)},
issn = {2045-2322},
url = {https://www.nature.com/articles/s41598-018-21779-y},
doi = {10.1038/s41598-018-21779-y},
abstract = {In “classic” biomedical research, diseases have usually been studied individually. The pioneering human disease network (HDN) studies jointly consider a large number of diseases, analyse their interconnections, and provide a more comprehensive description of diseases. However, most of the existing HDN studies are based on molecular information and can only partially describe disease interconnections. Building on the unique Taiwan National Health Insurance Research Database (NHIRD), in this study, we construct the epidemiological HDN (eHDN), where two diseases are concluded as interconnected if their observed probability of co-occurrence deviating that expected under independence. Advancing from the existing HDN, the eHDN can also accommodate non-molecular connections and have more important practical implications. Building on the network construction, we examine important network properties such as connectivity, module, hub, and others and describe their temporal patterns. This study is among the first to systematically construct the eHDN and can have important implications for human disease research and health care and management.},
language = {en},
number = {1},
urldate = {2021-10-18},
journal = {Scientific Reports},
author = {Jiang, Yefei and Ma, Shuangge and Shia, Ben-Chang and Lee, Tian-Shyug},
month = mar,
year = {2018},
note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Comorbidities;Diseases;Epidemiology
Subject\_term\_id: comorbidities;diseases;epidemiology},
pages = {4557},
}

@article{choi_retain_2016,
title = {{RETAIN}: {An} {Interpretable} {Predictive} {Model} for {Healthcare} using {Reverse} {Time} {Attention} {Mechanism}},
shorttitle = {{RETAIN}},
url = {http://arxiv.org/abs/1608.05745},
abstract = {Accuracy and interpretability are two dominant features of successful predictive models. Typically, a choice must be made in favor of complex black box models such as recurrent neural networks (RNN) for accuracy versus less accurate but more interpretable traditional models such as logistic regression. This tradeoff poses challenges in medicine where both accuracy and interpretability are important. We addressed this challenge by developing the REverse Time AttentIoN model (RETAIN) for application to Electronic Health Records (EHR) data. RETAIN achieves high accuracy while remaining clinically interpretable and is based on a two-level neural attention model that detects influential past visits and significant clinical variables within those visits (e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR data in a reverse time order so that recent clinical visits are likely to receive higher attention. RETAIN was tested on a large health system EHR dataset with 14 million visits completed by 263K patients over an 8 year period and demonstrated predictive accuracy and computational scalability comparable to state-of-the-art methods such as RNN, and ease of interpretability comparable to traditional models.},
urldate = {2019-06-06},
journal = {arXiv:1608.05745 [cs]},
author = {Choi, Edward and Bahadori, Mohammad Taha and Kulas, Joshua A. and Schuetz, Andy and Stewart, Walter F. and Sun, Jimeng},
month = aug,
year = {2016},
note = {arXiv: 1608.05745},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{shmueli_predictive_2011,
title = {Predictive {Analytics} in {Information} {Systems} {Research}},
volume = {35},
issn = {ISSN 0276-7783/ISSN 2162-9730},
url = {https://aisel.aisnet.org/misq/vol35/iss3/5},
number = {3},
journal = {Management Information Systems Quarterly},
author = {Shmueli, Galit and Koppius, Otto},
month = sep,
year = {2011},
keywords = {read here},
pages = {553--572},
}

@inproceedings{yang_hierarchical_2016,
address = {San Diego, California},
title = {Hierarchical {Attention} {Networks} for {Document} {Classification}},
url = {https://aclanthology.org/N16-1174},
doi = {10.18653/v1/N16-1174},
urldate = {2021-07-14},
booktitle = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
publisher = {Association for Computational Linguistics},
author = {Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard},
month = jun,
year = {2016},
keywords = {read here},
pages = {1480--1489},
}

@article{deng_correlation_2021,
title = {Correlation {Tensor} {Decomposition} and {Its} {Application} in {Spatial} {Imaging} {Data}},
volume = {0},
issn = {0162-1459},
url = {https://doi.org/10.1080/01621459.2021.1938083},
doi = {10.1080/01621459.2021.1938083},
abstract = {Multi-dimensional tensor data have gained increasing attention in the recent years, especially in biomedical imaging analyses. However, the most existing tensor models are only based on the mean information of imaging pixels. Motivated by multimodal optical imaging data in a breast cancer study, we develop a new tensor learning approach to use pixel-wise correlation information, which is represented through the higher order correlation tensor. We proposed a novel semi-symmetric correlation tensor decomposition method which effectively captures the informative spatial patterns of pixel-wise correlations to facilitate cancer diagnosis. We establish the theoretical properties for recovering structure and for classification consistency. In addition, we develop an efficient algorithm to achieve computational scalability. Our simulation studies and an application on breast cancer imaging data all indicate that the proposed method outperforms other competing methods in terms of pattern recognition and prediction accuracy.},
number = {0},
urldate = {2021-10-18},
journal = {Journal of the American Statistical Association},
author = {Deng, Yujia and Tang, Xiwei and Qu, Annie},
month = jun,
year = {2021},
note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2021.1938083},
keywords = {Dimension reduction, Image processing, Multidimensional data, Spatial correlation, Tensor decomposition},
pages = {1--17},
}

@article{min_predictive_2019,
title = {Predictive {Modeling} of the {Hospital} {Readmission} {Risk} from {Patients}’ {Claims} {Data} {Using} {Machine} {Learning}: {A} {Case} {Study} on {COPD}},
volume = {9},
issn = {2045-2322},
shorttitle = {Predictive {Modeling} of the {Hospital} {Readmission} {Risk} from {Patients}’ {Claims} {Data} {Using} {Machine} {Learning}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6382784/},
doi = {10.1038/s41598-019-39071-y},
abstract = {Chronic Obstructive Pulmonary Disease (COPD) is a prevalent chronic pulmonary condition that affects hundreds of millions of people all over the world. Many COPD patients got readmitted to hospital within 30 days after discharge due to various reasons. Such readmission can usually be avoided if additional attention is paid to patients with high readmission risk and appropriate actions are taken. This makes early prediction of the hospital readmission risk an important problem. The goal of this paper is to conduct a systematic study on developing different types of machine learning models, including both deep and non-deep ones, for predicting the readmission risk of COPD patients. We evaluate those different approaches on a real world database containing the medical claims of 111,992 patients from the Geisinger Health System from January 2004 to September 2015. The patient features we build the machine learning models upon include both knowledge-driven ones, which are the features extracted according to clinical knowledge potentially related to COPD readmission, and data-driven features, which are extracted from the patient data themselves. Our analysis showed that the prediction performance in terms of Area Under the receiver operating characteristic (ROC) Curve (AUC) can be improved from around 0.60 using knowledge-driven features, to 0.653 by combining both knowledge-driven and data-driven features, based on the one-year claims history before discharge. Moreover, we also demonstrate that the complex deep learning models in this case cannot really improve the prediction performance, with the best AUC around 0.65.},
urldate = {2021-10-05},
journal = {Scientific Reports},
author = {Min, Xu and Yu, Bin and Wang, Fei},
month = feb,
year = {2019},
pmid = {30787351},
pmcid = {PMC6382784},
pages = {2362},
}

@article{dubois_effective_2018,
title = {Effective {Representations} of {Clinical} {Notes}},
url = {http://arxiv.org/abs/1705.07025},
abstract = {Clinical notes are a rich source of information about patient state. However, using them to predict clinical events with machine learning models is challenging. They are very high dimensional, sparse and have complex structure. Furthermore, training data is often scarce because it is expensive to obtain reliable labels for many clinical events. These difficulties have traditionally been addressed by manual feature engineering encoding task specific domain knowledge. We explored the use of neural networks and transfer learning to learn representations of clinical notes that are useful for predicting future clinical events of interest, such as all causes mortality, inpatient admissions, and emergency room visits. Our data comprised 2.7 million notes and 115 thousand patients at Stanford Hospital. We used the learned representations, along with commonly used bag of words and topic model representations, as features for predictive models of clinical events. We evaluated the effectiveness of these representations with respect to the performance of the models trained on small datasets. Models using the neural network derived representations performed significantly better than models using the baseline representations with small (\$N {\textless} 1000\$) training datasets. The learned representations offer significant performance gains over commonly used baseline representations for a range of predictive modeling tasks and cohort sizes, offering an effective alternative to task specific feature engineering when plentiful labeled training data is not available.},
urldate = {2021-09-13},
journal = {arXiv:1705.07025 [cs, stat]},
author = {Dubois, Sebastien and Romano, Nathanael and Kale, David C. and Shah, Nigam and Jung, Kenneth},
month = aug,
year = {2018},
note = {arXiv: 1705.07025},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, read here},
}

@article{noauthor_hospital_nodate,
title = {Hospital {Toolkit} for {Adult} {Sepsis} {Surveillance}},
language = {en},
pages = {32},
}

@article{verburg_which_2017,
title = {Which {Models} {Can} {I} {Use} to {Predict} {Adult} {ICU} {Length} of {Stay}? {A} {Systematic} {Review}*},
volume = {45},
shorttitle = {Which {Models} {Can} {I} {Use} to {Predict} {Adult} {ICU} {Length} of {Stay}?},
doi = {10.1097/CCM.0000000000002054},
abstract = {Objective:
We systematically reviewed models to predict adult ICU length of stay. 
Data Sources:
We searched the Ovid EMBASE and MEDLINE databases for studies on the development or validation of ICU length of stay prediction models. 
Study Selection:
We identified 11 studies describing the development of 31 prediction models and three describing external validation of one of these models. 
Data Extraction:
Clinicians use ICU length of stay predictions for planning ICU capacity, identifying unexpectedly long ICU length
of stay, and benchmarking ICUs. We required the model variables to have been published and for the models to be free of organizational characteristics and to produce accurate predictions, as assessed by R2 across patients for planning and identifying unexpectedly long ICU length
of stay and across ICUs for benchmarking, with low calibration bias. We assessed the reporting quality using the Checklist for Critical Appraisal and Data Extraction for Systematic Reviews of Prediction Modelling Studies. 
Data Synthesis:
The number of admissions ranged
from 253 to 178,503. Median ICU length of stay was between 2 and 6.9 days. Two studies had not published model variables and three included organizational characteristics. None of the models produced predictions with low bias. The R2 was 0.05–0.28 across patients and 0.01–0.64
across ICUs. The reporting scores ranged from 49 of 78 to 60 of 78 and the methodologic scores from 12 of 22 to 16 of 22. 
Conclusion:
No models completely satisfy our requirements for planning, identifying unexpectedly long ICU length of stay, or for benchmarking purposes.
Physicians using these models to predict ICU length of stay should interpret them with reservation.},
number = {2},
journal = {Critical Care Medicine},
author = {Verburg, Ilona Willempje Maria and Atashi, Alireza and Eslami, Saeid and Holman, Rebecca and Abu-Hanna, Ameen and de Jonge, Everet and Peek, Niels and de Keizer, Nicolette Fransisca},
month = feb,
year = {2017},
keywords = {benchmarking, intensive care units, length of stay, prediction, review},
pages = {e222--e231},
}

@misc{noauthor_22_nodate,
title = {2.2. {Manifold} learning — scikit-learn 0.24.2 documentation},
url = {https://scikit-learn.org/stable/modules/manifold.html},
urldate = {2021-07-30},
}

@article{zimmerman_acute_2006,
title = {Acute {Physiology} and {Chronic} {Health} {Evaluation} ({APACHE}) {IV}: {Hospital} mortality assessment for today’s critically ill patients*},
volume = {34},
issn = {0090-3493},
shorttitle = {Acute {Physiology} and {Chronic} {Health} {Evaluation} ({APACHE}) {IV}},
url = {https://journals.lww.com/ccmjournal/Fulltext/2006/05000/A_comparison_of_severity_of_illness_scoring.00001.aspx?casa_token=GcN6sZvfYzEAAAAA:_PbMhIXlutBhGMt8XHicFLDe5QwyPJCXCH8qpJucqWGE18XjLLE0SzHXvRVj77X4WyQnFT_Ap5Y2XzzzNHVXTB_EvtU},
doi = {10.1097/01.CCM.0000215112.84523.F0},
abstract = {Objective: 
    To improve the accuracy of the Acute Physiology and Chronic Health Evaluation (APACHE) method for predicting hospital mortality among critically ill adults and to evaluate changes in the accuracy of earlier APACHE models.
    Design: 
    Observational cohort study.
    Setting: 
    A total of 104 intensive care units (ICUs) in 45 U.S. hospitals.
    Patients: 
    A total of 131,618 consecutive ICU admissions during 2002 and 2003, of which 110,558 met inclusion criteria and had complete data.
    Interventions: 
    None.
    Measurements and Main Results: 
    We developed APACHE IV using ICU day 1 information and a multivariate logistic regression procedure to estimate the probability of hospital death for randomly selected patients who comprised 60\% of the database. Predictor variables were similar to those in APACHE III, but new variables were added and different statistical modeling used. We assessed the accuracy of APACHE IV predictions by comparing observed and predicted hospital mortality for the excluded patients (validation set). We tested discrimination and used multiple tests of calibration in aggregate and for patient subgroups. APACHE IV had good discrimination (area under the receiver operating characteristic curve = 0.88) and calibration (Hosmer-Lemeshow C statistic = 16.9, p = .08). For 90\% of 116 ICU admission diagnoses, the ratio of observed to predicted mortality was not significantly different from 1.0. We also used the validation data set to compare the accuracy of APACHE IV predictions to those using APACHE III versions developed 7 and 14 yrs previously. There was little change in discrimination, but aggregate mortality was systematically overestimated as model age increased. When examined across disease, predictive accuracy was maintained for some diagnoses but for others seemed to reflect changes in practice or therapy.
    Conclusions: 
    APACHE IV predictions of hospital mortality have good discrimination and calibration and should be useful for benchmarking performance in U.S. ICUs. The accuracy of predictive models is dynamic and should be periodically retested. When accuracy deteriorates they should be revised and updated.},
language = {en-US},
number = {5},
urldate = {2021-07-28},
journal = {Critical Care Medicine},
author = {Zimmerman, Jack E. and Kramer, Andrew A. and McNair, Douglas S. and Malila, Fern M.},
month = may,
year = {2006},
pages = {1297--1310},
}

@article{kelly_intensive_2014,
title = {Intensive care medicine is 60 years old: the history and future of the intensive care unit},
volume = {14},
issn = {1470-2118},
shorttitle = {Intensive care medicine is 60 years old},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4952830/},
doi = {10.7861/clinmedicine.14-4-376},
abstract = {Intensive care is celebrating its 60th anniversary this year. The concept arose from the devastating Copenhagen polio epidemic of 1952, which resulted in hundreds of victims experiencing respiratory and bulbar failure. Over 300 patients required artificial ventilation for several weeks. This was provided by 1,000 medical and dental students who were employed to hand ventilate the lungs of these patients via tracheostomies. By 1953, Bjorn Ibsen, the anaesthetist who had suggested that positive pressure ventilation should be the treatment of choice during the epidemic, had set up the first intensive care unit (ICU) in Europe, gathering together physicians and physiologists to manage sick patients – many would consider him to be the ‘father’ of intensive care. Here, we discuss the events surrounding the 1952 polio epidemic, the subsequent development of ICUs throughout the UK, the changes that have occurred in intensive care over the past 10 years and what the future holds for the specialty.},
number = {4},
urldate = {2021-07-28},
journal = {Clinical Medicine},
author = {Kelly, Fiona E and Fong, Kevin and Hirsch, Nicholas and Nolan, Jerry P},
month = aug,
year = {2014},
pmid = {25099838},
pmcid = {PMC4952830},
pages = {376--379},
}

@article{talwalkar_large-scale_2013,
title = {Large-scale {SVD} and {Manifold} {Learning}},
volume = {14},
issn = {1533-7928},
url = {http://jmlr.org/papers/v14/talwalkar13a.html},
abstract = {This paper examines the efficacy of sampling-based low-rank approximation techniques when applied to large dense kernel matrices. We analyze two common approximate singular value decomposition techniques, namely the Nystrom and Column sampling methods. We present a theoretical comparison between these two methods, provide novel insights regarding their suitability for various tasks and present experimental results that support our theory. Our results illustrate the relative strengths of each method. We next examine the performance of these two techniques on the large-scale task of extracting low-dimensional manifold structure given millions of high-dimensional face images. We address the computational challenges of non-linear dimensionality reduction via Isomap and Laplacian Eigenmaps, using a graph containing about 
18
18
million nodes and 
65
65
million edges. We present extensive experiments on learning low- dimensional embeddings for two large face data sets: CMU-PIE (
35
35
thousand faces) and a web data set (
18
18
million faces). Our comparisons show that the Nystrom approximation is superior to the Column sampling method for this task. Furthermore, approximate Isomap tends to perform better than Laplacian Eigenmaps on both clustering and classification with the labeled CMU-PIE data set.},
number = {60},
urldate = {2021-07-26},
journal = {Journal of Machine Learning Research},
author = {Talwalkar, Ameet and Kumar, Sanjiv and Mohri, Mehryar and Rowley, Henry},
year = {2013},
pages = {3129--3152},
}

@inproceedings{wang_attention-based_2016,
address = {Austin, Texas},
title = {Attention-based {LSTM} for {Aspect}-level {Sentiment} {Classification}},
url = {https://aclanthology.org/D16-1058},
doi = {10.18653/v1/D16-1058},
urldate = {2021-07-14},
booktitle = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
publisher = {Association for Computational Linguistics},
author = {Wang, Yequan and Huang, Minlie and Zhu, Xiaoyan and Zhao, Li},
month = nov,
year = {2016},
pages = {606--615},
}

@article{mo_evaluating_2021,
title = {Evaluating and clustering retrosynthesis pathways with learned strategy},
volume = {12},
issn = {2041-6539},
url = {https://pubs.rsc.org/en/content/articlelanding/2021/sc/d0sc05078d},
doi = {10.1039/D0SC05078D},
abstract = {With recent advances in the computer-aided synthesis planning (CASP) powered by data science and machine learning, modern CASP programs can rapidly identify thousands of potential pathways for a given target molecule. However, the lack of a holistic pathway evaluation mechanism makes it challenging to systematically prioritize strategic pathways except for using some simple heuristics. Herein, we introduce a data-driven approach to evaluate the relative strategic levels of retrosynthesis pathways using a dynamic tree-structured long short-term memory (tree-LSTM) model. We first curated a retrosynthesis pathway database, containing 238k patent-extracted pathways along with ∼55 M artificial pathways generated from an open-source CASP program, ASKCOS. The tree-LSTM model was trained to differentiate patent-extracted and artificial pathways with the same target molecule in order to learn the strategic relationship among single-step reactions within the patent-extracted pathways. The model achieved a top-1 ranking accuracy of 79.1\% to recognize patent-extracted pathways. In addition, the trained tree-LSTM model learned to encode pathway-level information into a representative latent vector, which can facilitate clustering similar pathways to help illustrate strategically diverse pathways generated from CASP programs.},
language = {en},
number = {4},
urldate = {2021-07-14},
journal = {Chemical Science},
author = {Mo, Yiming and Guan, Yanfei and Verma, Pritha and Guo, Jiang and Fortunato, Mike E. and Lu, Zhaohong and Coley, Connor W. and Jensen, Klavs F.},
month = feb,
year = {2021},
note = {Publisher: The Royal Society of Chemistry},
pages = {1469--1478},
}

@article{liang_querying_2021,
title = {Querying knowledge graphs in natural language},
volume = {8},
issn = {2196-1115},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7799375/},
doi = {10.1186/s40537-020-00383-w},
abstract = {Knowledge graphs are a powerful concept for querying large amounts of data. These knowledge graphs are typically enormous and are often not easily accessible to end-users because they require specialized knowledge in query languages such as SPARQL. Moreover, end-users need a deep understanding of the structure of the underlying data models often based on the Resource Description Framework (RDF). This drawback has led to the development of Question-Answering (QA) systems that enable end-users to express their information needs in natural language. While existing systems simplify user access, there is still room for improvement in the accuracy of these systems. In this paper we propose a new QA system for translating natural language questions into SPARQL queries. The key idea is to break up the translation process into 5 smaller, more manageable sub-tasks and use ensemble machine learning methods as well as Tree-LSTM-based neural network models to automatically learn and translate a natural language question into a SPARQL query. The performance of our proposed QA system is empirically evaluated using the two renowned benchmarks-the 7th Question Answering over Linked Data Challenge (QALD-7) and the Large-Scale Complex Question Answering Dataset (LC-QuAD). Experimental results show that our QA system outperforms the state-of-art systems by 15\% on the QALD-7 dataset and by 48\% on the LC-QuAD dataset, respectively. In addition, we make our source code available.},
number = {1},
urldate = {2021-07-14},
journal = {Journal of Big Data},
author = {Liang, Shiqi and Stockinger, Kurt and de Farias, Tarcisio Mendes and Anisimova, Maria and Gil, Manuel},
year = {2021},
pmid = {33489717},
pmcid = {PMC7799375},
pages = {3},
}

@inproceedings{ahmed_identifying_2019,
title = {Identifying {Protein}-{Protein} {Interaction} {Using} {Tree} {LSTM} and {Structured} {Attention}},
doi = {10.1109/ICOSC.2019.8665584},
abstract = {Identifying interactions between proteins is important to understand underlying biological processes. Extracting a protein-protein interaction (PPI) from the raw text is often very difficult. Previous supervised learning methods have used handcrafted features on human-annotated data sets. In this paper, we propose a novel tree recurrent neural network with structured attention architecture for doing PPI. Our architecture achieves state of the art results (precision, recall, and F1-score) on the AIMed and BioInfer benchmark data sets. Moreover, our models achieve a significant improvement over previous best models without any explicit feature extraction. Our experimental results show that traditional recurrent networks have inferior performance compared to tree recurrent networks for the supervised PPI problem.},
booktitle = {2019 {IEEE} 13th {International} {Conference} on {Semantic} {Computing} ({ICSC})},
author = {Ahmed, Mahtab and Islam, Jumayel and Samee, Muhammad Rifayat and Mercer, Robert E.},
month = jan,
year = {2019},
note = {ISSN: 2325-6516},
keywords = {Bioinformatics, Biological system modeling, Feature extraction, Kernel, Logic gates, Protein-Protein Interaction, Proteins, Recurrent neural networks, Structured Attention, Syntactics, Tree LSTM},
pages = {224--231},
}

@misc{noauthor_tree-lstm_nodate,
title = {Tree-{LSTM} in {DGL} — {DGL} 0.6.1 documentation},
url = {https://docs.dgl.ai/en/0.6.x/tutorials/models/2_small_graph/3_tree-lstm.html},
urldate = {2021-07-14},
}

@article{tai_improved_2015,
title = {Improved {Semantic} {Representations} {From} {Tree}-{Structured} {Long} {Short}-{Term} {Memory} {Networks}},
url = {http://arxiv.org/abs/1503.00075},
abstract = {Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).},
urldate = {2021-07-14},
journal = {arXiv:1503.00075 [cs]},
author = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D.},
month = may,
year = {2015},
note = {arXiv: 1503.00075},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{zhou_graph_2021,
title = {Graph {Neural} {Networks}: {A} {Review} of {Methods} and {Applications}},
shorttitle = {Graph {Neural} {Networks}},
url = {http://arxiv.org/abs/1812.08434},
abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.},
urldate = {2021-06-01},
journal = {arXiv:1812.08434 [cs, stat]},
author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
month = apr,
year = {2021},
note = {arXiv: 1812.08434},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Deep learning, Graph neural network, Statistics - Machine Learning},
}

@article{rothe_deep_2016,
title = {Deep {Expectation} of {Real} and {Apparent} {Age} from a {Single} {Image} {Without} {Facial} {Landmarks}},
issn = {0920-5691, 1573-1405},
url = {https://link.springer.com/article/10.1007/s11263-016-0940-3},
doi = {10.1007/s11263-016-0940-3},
abstract = {In this paper we propose a deep learning solution to age estimation from a single face image without the use of facial landmarks and introduce the IMDB-WIKI dataset, the largest public dataset of face images with age and gender labels. If the real age estimation research spans over decades, the study of apparent age estimation or the age as perceived by other humans from a face image is a recent endeavor. We tackle both tasks with our convolutional neural networks (CNNs) of VGG-16 architecture which are pre-trained on ImageNet for image classification. We pose the age estimation problem as a deep classification problem followed by a softmax expected value refinement. The key factors of our solution are: deep learned models from large data, robust face alignment, and expected value formulation for age regression. We validate our methods on standard benchmarks and achieve state-of-the-art results for both real and apparent age estimation.},
language = {en},
urldate = {2017-07-19},
journal = {International Journal of Computer Vision},
author = {Rothe, Rasmus and Timofte, Radu and Gool, Luc Van},
month = aug,
year = {2016},
pages = {1--14},
}

@article{bodenreider_unified_2004,
title = {The {Unified} {Medical} {Language} {System} ({UMLS}): integrating biomedical terminology},
volume = {32},
issn = {0305-1048},
shorttitle = {The {Unified} {Medical} {Language} {System} ({UMLS})},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC308795/},
doi = {10.1093/nar/gkh061},
abstract = {The Unified Medical Language System (http://umlsks.nlm.nih.gov) is a repository of biomedical vocabularies developed by the US National Library of Medicine. The UMLS integrates over 2 million names for some 900 000 concepts from more than 60 families of biomedical vocabularies, as well as 12 million relations among these concepts. Vocabularies integrated in the UMLS Metathesaurus include the NCBI taxonomy, Gene Ontology, the Medical Subject Headings (MeSH), OMIM and the Digital Anatomist Symbolic Knowledge Base. UMLS concepts are not only inter-related, but may also be linked to external resources such as GenBank. In addition to data, the UMLS includes tools for customizing the Metathesaurus (MetamorphoSys), for generating lexical variants of concept names (lvg) and for extracting UMLS concepts from text (MetaMap). The UMLS knowledge sources are updated quarterly. All vocabularies are available at no fee for research purposes within an institution, but UMLS users are required to sign a license agreement. The UMLS knowledge sources are distributed on CD-ROM and by FTP.},
number = {Database issue},
urldate = {2021-07-08},
journal = {Nucleic Acids Research},
author = {Bodenreider, Olivier},
month = jan,
year = {2004},
pmid = {14681409},
pmcid = {PMC308795},
pages = {D267--D270},
}

@misc{noauthor_9_nodate,
title = {9. {BERT} and its family},
}

@article{wu_comprehensive_2021,
title = {A {Comprehensive} {Survey} on {Graph} {Neural} {Networks}},
volume = {32},
issn = {2162-237X, 2162-2388},
url = {http://arxiv.org/abs/1901.00596},
doi = {10.1109/TNNLS.2020.2978386},
abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.},
number = {1},
urldate = {2021-06-29},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
month = jan,
year = {2021},
note = {arXiv: 1901.00596},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
pages = {4--24},
}

@article{bean_conceptual_1982,
title = {Conceptual models of student attrition: {How} theory can help the institutional researcher},
volume = {1982},
issn = {0271-0579, 1536-075X},
shorttitle = {Conceptual models of student attrition},
url = {http://doi.wiley.com/10.1002/ir.37019823604},
doi = {10.1002/ir.37019823604},
language = {en},
number = {36},
urldate = {2021-06-29},
journal = {New Directions for Institutional Research},
author = {Bean, John P.},
month = dec,
year = {1982},
pages = {17--33},
}

@article{deschepper_hospital_2019,
title = {A hospital wide predictive model for unplanned readmission using hierarchical {ICD} data},
volume = {173},
issn = {1872-7565},
doi = {10.1016/j.cmpb.2019.02.007},
abstract = {BACKGROUND AND OBJECTIVE: Hospitals already acquire a large amount of data, mainly for administrative, billing and registration purposes. Tapping on these already available data for additional purposes, aiming at improving care, without significant incremental effort and cost. This potential of secondary patient data is explored through modeling administrative and billing data, as well as the hierarchical structure of pathology codes of the International Classification of Diseases (ICD) in the prediction of unplanned readmissions, as a clinically relevant outcome parameter that can be impacted on in a quality improvement program.
METHODS: In this single-center, hospital-wide observational cohort study, we included all adult patients discharged in 2016 after applying an exclusion protocol (n = 29,702). In addition to administrative variables, such as age and length of stay, structured pathology data were taken into account in predictive models. As a first research question, we compared logistic regression against penalized logistic regression, gradient boosting and Random Forests to predict unplanned readmission. As a second research goal, we investigated the level of hierarchy within the pathology data needed to achieve the best accuracy. Finally, we investigated which prediction variables play a prominent role in predicting hospital readmission. The performance of all models was evaluated using the Area Under the ROC Curve (AUC) measure.
RESULTS: All models have the best predictive results using Random Forests. An added value of 7\% is observed compared to a baseline method such as logistic regression. The best model, based on Random Forests, achieved an AUC of 0.77, using the diagnosis category and procedure code as lowest level of the hierarchical pathology data.
CONCLUSIONS: The most accurate model to predict hospital wide unplanned readmission is based on Random Forests and includes the ICD hierarchy, especially diagnosis category. Such an approach lowers the number of predictor variables and yields a higher interpretability than a model based on a detailed diagnosis. The performance of the model proved high enough to be used as a decision support tool.},
language = {eng},
journal = {Computer Methods and Programs in Biomedicine},
author = {Deschepper, M. and Eeckloo, K. and Vogelaers, D. and Waegeman, W.},
month = may,
year = {2019},
pmid = {30777619},
keywords = {Adult, Aged, Area Under Curve, Boosting, Cohort Studies, Data Mining, Decision Making, Decision Support Systems, Clinical, Decision support, Female, Hospitals, Humans, ICD-10 diagnosis, International Classification of Diseases, Logistic Models, Machine Learning, Machine learning, Male, Medical Informatics, Middle Aged, Patient Readmission, Predictive Value of Tests, Random Forests, Readmission, Regression Analysis, Risk Factors, Time Factors},
pages = {177--183},
}

@article{sutskever_sequence_2014,
title = {Sequence to {Sequence} {Learning} with {Neural} {Networks}},
url = {http://arxiv.org/abs/1409.3215},
abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
urldate = {2016-08-31},
journal = {arXiv:1409.3215 [cs]},
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
month = sep,
year = {2014},
note = {arXiv: 1409.3215},
keywords = {Computer Science - Computation and Language, Computer Science - Learning, Computer Science - Machine Learning, paper vesion},
}

@article{rasmy_representation_2020,
title = {Representation of {EHR} data for predictive modeling: a comparison between {UMLS} and other terminologies},
volume = {27},
issn = {1527-974X},
shorttitle = {Representation of {EHR} data for predictive modeling},
doi = {10.1093/jamia/ocaa180},
abstract = {OBJECTIVE: Predictive disease modeling using electronic health record data is a growing field. Although clinical data in their raw form can be used directly for predictive modeling, it is a common practice to map data to standard terminologies to facilitate data aggregation and reuse. There is, however, a lack of systematic investigation of how different representations could affect the performance of predictive models, especially in the context of machine learning and deep learning.
MATERIALS AND METHODS: We projected the input diagnoses data in the Cerner HealthFacts database to Unified Medical Language System (UMLS) and 5 other terminologies, including CCS, CCSR, ICD-9, ICD-10, and PheWAS, and evaluated the prediction performances of these terminologies on 2 different tasks: the risk prediction of heart failure in diabetes patients and the risk prediction of pancreatic cancer. Two popular models were evaluated: logistic regression and a recurrent neural network.
RESULTS: For logistic regression, using UMLS delivered the optimal area under the receiver operating characteristics (AUROC) results in both dengue hemorrhagic fever (81.15\%) and pancreatic cancer (80.53\%) tasks. For recurrent neural network, UMLS worked best for pancreatic cancer prediction (AUROC 82.24\%), second only (AUROC 85.55\%) to PheWAS (AUROC 85.87\%) for dengue hemorrhagic fever prediction.
DISCUSSION/CONCLUSION: In our experiments, terminologies with larger vocabularies and finer-grained representations were associated with better prediction performances. In particular, UMLS is consistently 1 of the best-performing ones. We believe that our work may help to inform better designs of predictive models, although further investigation is warranted.},
language = {eng},
number = {10},
journal = {Journal of the American Medical Informatics Association: JAMIA},
author = {Rasmy, Laila and Tiryaki, Firat and Zhou, Yujia and Xiang, Yang and Tao, Cui and Xu, Hua and Zhi, Degui},
month = oct,
year = {2020},
pmid = {32930711},
pmcid = {PMC7647355},
keywords = {Aged, Databases, Factual, Electronic Health Records, Female, Humans, Male, Middle Aged, ROC Curve, UMLS, Unified Medical Language System, Vocabulary, Controlled, electronic health records, predictive modeling, terminology representation},
pages = {1593--1599},
}

@misc{noauthor_8_nodate,
title = {8. {NLP} tasks},
}

@article{noauthor_research_nodate,
title = {Research {Curations}},
url = {https://www.misqresearchcurations.org/mis-quarterly-research-curations},
language = {en-US},
urldate = {2021-06-25},
journal = {MIS Quarterly},
}

@misc{noauthor_big_nodate,
title = {The {Big} {Band} {Season} 2 2020-07-28 {\textbar} {iQiyi}},
url = {https://www.iq.com/play/the-big-band-season-2-19rrhl8olx?lang=en_us},
abstract = {Forget about their past! Whether they’re veterans or nobodies, in this season of The Big Band, their existing labels won’t matter! Their passion for music is the only reason and answer to how far they’ll go. Superstars are coming!},
language = {en},
urldate = {2021-06-24},
}

@article{rifat_measuring_2020,
title = {Measuring {Community} {Disaster} {Resilience} in the {Conterminous} {Coastal} {United} {States}},
volume = {9},
copyright = {http://creativecommons.org/licenses/by/3.0/},
url = {https://www.mdpi.com/2220-9964/9/8/469},
doi = {10.3390/ijgi9080469},
abstract = {In recent years, building resilient communities to disasters has become one of the core objectives in the field of disaster management globally. Despite being frequently targeted and severely impacted by disasters, the geographical extent in studying disaster resilience of the coastal communities of the United States (US) has been limited. In this study, we developed a composite community disaster resilience index (CCDRI) for the coastal communities of the conterminous US that considers different dimensions of disaster resilience. The resilience variables used to construct the CCDRI were justified by examining their influence on disaster losses using ordinary least squares (OLS) and geographically weighted regression (GWR) models. Results suggest that the CCDRI score ranges from −12.73 (least resilient) to 8.69 (most resilient), and northeastern communities are comparatively more resilient than southeastern communities in the study area. Additionally, resilience components used in this study have statistically significant impact on minimizing disaster losses. The GWR model performs much better in explaining the variances while regressing the disaster property damage against the resilience components (explains 72\% variance) than the OLS (explains 32\% variance) suggesting that spatial variations of resilience components should be accounted for an effective disaster management program. Moreover, findings from this study could provide local emergency managers and decision-makers with unique insights for enhancing overall community resilience to disasters and minimizing disaster impacts in the study area.},
language = {en},
number = {8},
urldate = {2021-06-24},
journal = {ISPRS International Journal of Geo-Information},
author = {Rifat, Shaikh Abdullah Al and Liu, Weibo},
month = aug,
year = {2020},
note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
keywords = {coastal United States, composite community disaster resilience index (CCDRI), geographically weighted regression (GWR), ordinary least squares (OLS)},
pages = {469},
}

@article{cai_synthesis_2018,
title = {A synthesis of disaster resilience measurement methods and indices},
volume = {31},
issn = {2212-4209},
url = {https://www.sciencedirect.com/science/article/pii/S2212420918304618},
doi = {10.1016/j.ijdrr.2018.07.015},
abstract = {Disaster resilience has become an important societal goal which captures the attention of academics and decision makers from various disciplines and sectors. Developing tools or metrics for measuring and monitoring progress of resilience is a critical component that requires extensive research to achieve better understanding. However, different fields have different emphases and the knowledge gained from the various studies are scattered and fragmented. To provide an integration of the literature and reflect on the current state of resilience measurement, we conducted a synthesis analysis through a systematic review of 174 scholarly articles on disaster resilience measurement from 2005 to 2017. Using a review table designed for this study and content analysis, we extracted key information from each article on resilience definition, type of measurement method, resilience indicators used, and proposed adaptation strategies. Results indicate that 39.7\% of the articles used qualitative methods for resilience measurement and 39.1\% of the articles used quantitative methods. However, only 10.3\% of all the 174 articles conducted empirical validation of their proposed resilience indices. The three most frequently suggested adaptation strategies were empowering local governments and leaders, raising community awareness, and enhancing community infrastructure and communication. These findings suggest that future research need to incorporate validation and inferential ability into resilience measurement. Extending from static resilience measurement to dynamic system modeling and bridging the disconnection between resilience scientific research and practical actions are also pressing needs.},
language = {en},
urldate = {2021-06-24},
journal = {International Journal of Disaster Risk Reduction},
author = {Cai, Heng and Lam, Nina S. N. and Qiang, Yi and Zou, Lei and Correll, Rachel M. and Mihunov, Volodymyr},
month = oct,
year = {2018},
keywords = {Adaptation strategies, Disaster resilience measurement, Resilience indices, Synthesis analysis, Validation},
pages = {844--855},
}

@article{tang_predictive_2018,
title = {Predictive modeling in urgent care: a comparative study of machine learning approaches},
volume = {1},
issn = {2574-2531},
shorttitle = {Predictive modeling in urgent care},
url = {https://doi.org/10.1093/jamiaopen/ooy011},
doi = {10.1093/jamiaopen/ooy011},
abstract = {The growing availability of rich clinical data such as patients’ electronic health records provide great opportunities to address a broad range of real-world questions in medicine. At the same time, artificial intelligence and machine learning (ML)-based approaches have shown great premise on extracting insights from those data and helping with various clinical problems. The goal of this study is to conduct a systematic comparative study of different ML algorithms for several predictive modeling problems in urgent care.We assess the performance of 4 benchmark prediction tasks (eg mortality and prediction, differential diagnostics, and disease marker discovery) using medical histories, physiological time-series, and demographics data from the Medical Information Mart for Intensive Care (MIMIC-III) database.For each given task, performance was estimated using standard measures including the area under the receiver operating characteristic (AUC) curve, F-1 score, sensitivity, and specificity. Microaveraged AUC was used for multiclass classification models.Our results suggest that recurrent neural networks show the most promise in mortality prediction where temporal patterns in physiologic features alone can capture in-hospital mortality risk (AUC \&gt; 0.90). Temporal models did not provide additional benefit compared to deep models in differential diagnostics. When comparing the training–testing behaviors of readmission and mortality models, we illustrate that readmission risk may be independent of patient stability at discharge. We also introduce a multiclass prediction scheme for length of stay which preserves sensitivity and AUC with outliers of increasing duration despite decrease in sample size.},
number = {1},
urldate = {2021-06-23},
journal = {JAMIA Open},
author = {Tang, Fengyi and Xiao, Cao and Wang, Fei and Zhou, Jiayu},
month = jul,
year = {2018},
pages = {87--98},
}

@article{gupta_swings_2020,
title = {Swings and {Roundabouts}: {Attention}-{Structure} {Interaction} {Effect} in {Deep} {Semantic} {Matching}},
volume = {28},
issn = {2329-9304},
shorttitle = {Swings and {Roundabouts}},
doi = {10.1109/TASLP.2020.3013703},
abstract = {In the context of deep learning models for semantic matching problems, we propose a novel Multi-View Progressive Attention (MV-PA) mechanism general enough to operate on various linguistic structures of text. More importantly, we study the interaction effect between explicit linguistic structures (e.g., linear, constituency, and dependency) and implicit structures elicited by attention mechanisms. Empirical results on multiple datasets demonstrate salient patterns of substitutability between the two families of structures (explicit and implicit). Our findings not only provide intellectual foundations for the popular use of “linear LSTM + attention” architectures in NLP/QA research, but also have implications in other modalities and domains.},
journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
author = {Gupta, Amulya and Zhang, Zhu},
year = {2020},
note = {Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing},
keywords = {Computational modeling, Hidden Markov models, Linguistics, Recurrent neural networks, Semantic matching, Semantics, Syntactics, Task analysis, attention mechanisms, long short-term memory networks, tree-LSTM},
pages = {2295--2307},
}

@article{freitas_phe2vec_2020,
title = {Phe2vec: {Automated} {Disease} {Phenotyping} based on {Unsupervised} {Embeddings} from {Electronic} {Health} {Records}},
copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
shorttitle = {Phe2vec},
url = {https://www.medrxiv.org/content/10.1101/2020.11.14.20231894v1},
doi = {10.1101/2020.11.14.20231894},
abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater} {\textless}p{\textgreater}We introduce Phe2vec, an automated framework for disease phenotyping from electronic health records (EHRs) based on unsupervised learning. We assess its effectiveness against standard rule-based algorithms from the Phenotype KnowledgeBase (PheKB).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Materials and Methods{\textless}/h3{\textgreater} {\textless}p{\textgreater}Phe2vec is based on pre-computing embeddings of medical concepts and patients’ longitudinal clinical history. Disease phenotypes are then derived from a seed concept and its neighbors in the embedding space. Patients are similarly linked to a disease if their embedded representation is close to the phenotype. We evaluated Phe2vec using 49,234 medical concepts from structured EHRs and clinical notes from 1,908,741 patients in the Mount Sinai Health System. We assessed performance on ten diverse diseases having a PheKB algorithm, and one disease without, namely Lyme disease.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater} {\textless}p{\textgreater}Phe2vec phenotypes derived using Word2vec, GloVe, and Fasttext embeddings led to promising performance in disease definition and patient cohort identification as compared with standard PheKB definitions. When comparing head-to-head Phe2vec and PheKB disease patient cohorts using chart review, Phe2vec performed on par or better in nine out of ten diseases in terms of predictive positive values. Additionally, Phe2vec effectively identified phenotype definition and patient cohort for Lyme disease, a condition not covered in PheKB.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Discussion{\textless}/h3{\textgreater} {\textless}p{\textgreater}Phe2vec offers a solution to improve time-consuming phenotyping pipelines. Differently from other automated approaches in the literature, it is fully unsupervised, can easily scale to any disease and was validated against widely adopted expert-based standards.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusion{\textless}/h3{\textgreater} {\textless}p{\textgreater}Phe2vec aims to optimize clinical informatics research by augmenting current frameworks to characterize patients by condition and derive reliable disease cohorts.{\textless}/p{\textgreater}},
language = {en},
urldate = {2021-06-22},
journal = {medRxiv},
author = {Freitas, Jessica K. De and Johnson, Kipp W. and Golden, Eddye and Nadkarni, Girish N. and Dudley, Joel T. and Bottinger, Erwin P. and Glicksberg, Benjamin S. and Miotto, Riccardo},
month = nov,
year = {2020},
note = {Publisher: Cold Spring Harbor Laboratory Press},
pages = {2020.11.14.20231894},
}

@article{cho_learning_2014,
title = {Learning {Phrase} {Representations} using {RNN} {Encoder}-{Decoder} for {Statistical} {Machine} {Translation}},
url = {http://arxiv.org/abs/1406.1078},
abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
urldate = {2021-06-21},
journal = {arXiv:1406.1078 [cs, stat]},
author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
month = sep,
year = {2014},
note = {arXiv: 1406.1078},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{noauthor_7_nodate,
title = {7. {Speaker} {Verification}},
}

@article{peary_utilization_2012,
title = {Utilization of {Social} {Media} in the {East} {Japan} {Earthquake} and {Tsunami} and its {Effectiveness}},
volume = {34},
doi = {10.2328/jnds.34.3},
abstract = {During the 2011 East Japan Earthquake and Tsunami, newly popular social media such as Twitter and Facebook served as a lifeline for directly affected individuals, a means of information sharing, and a way for people inside and outside Japan to volunteer and to provide information-based support to affected individuals. Social media was used to perform vital relief functions such as safety identification, displaced-persons locating, damage information provision, support for disabled individuals, volunteer organization, fund-raising, and moral support systems. This study discusses the potential for public, civil society, and government organizations to utilize social media in disaster preparedness and response.},
number = {1},
journal = {Journal of Natural Disaster Science},
author = {Peary, Brett D. M. and Shaw, Rajib and Takeuchi, Yukiko},
year = {2012},
keywords = {2011 East Japan Earthquake and Tsunami, disaster prevention, disaster relief, social networking, ‌Social media},
pages = {3--18},
}

@techreport{michael_chui_social_2012,
title = {The social economy: {Unlocking} value and productivity through social technologies {\textbar} {McKinsey}},
url = {https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-social-economy#},
urldate = {2021-06-18},
institution = {McKinsey \& Company},
author = {{Michael Chui} and {James Manyika} and {Jacques Bughin} and {Richard Dobbs} and {Charles Roxburgh} and {Hugo Sarrazin} and {Geoffrey Sands} and {Magdalena Westergren}},
month = jul,
year = {2012},
}

@techreport{greenwood_social_2016,
title = {Social media update 2016.},
institution = {Pew Research Center},
author = {Greenwood, Shannon and Perrin, Andrew and Duggan, Maeve},
month = nov,
year = {2016},
pages = {10},
}

@article{fox_will_2021,
title = {{WILL} {PODCASTING} {AND} {SOCIAL} {MEDIA} {REPLACE} {JOURNALS} {AND} {TRADITIONAL} {SCIENCE} {COMMUNICATION}? {NO}, {BUT}...},
issn = {0002-9262},
shorttitle = {{WILL} {PODCASTING} {AND} {SOCIAL} {MEDIA} {REPLACE} {JOURNALS} {AND} {TRADITIONAL} {SCIENCE} {COMMUNICATION}?},
url = {https://doi.org/10.1093/aje/kwab172},
doi = {10.1093/aje/kwab172},
abstract = {The digital world in which we live is changing rapidly. The changing media environment is having a direct impact on traditional forms of communication and knowledge translation in public health and epidemiology. Openly accessible digital media can be used to reach a broader and more diverse audience of trainees, scientists, and the lay public than traditional forms of scientific communication. The new digital landscape for delivering content is vast and new platforms are continuously being added. We focus on several, including Twitter and podcasting and discuss their relevance to epidemiology and science communication. We highlight three key reasons why we think epidemiologists should be engaging with these mediums: 1) science communication, 2) career advancement, 3) development of a community and public service. Other positive and negative consequences of engaging in these forms of new media are also discussed. The authors of this commentary are all engaged in social media and podcasting for scientific communication and in this manuscript, we reflect on our experience with these mediums as tools to advance the field of epidemiology.},
number = {kwab172},
urldate = {2021-06-18},
journal = {American Journal of Epidemiology},
author = {Fox, Matthew P and Carr, Kareem and D’Agostino McGowan, Lucy and Murray, Eleanor J and Hidalgo, Bertha and Banack, Hailey R},
month = jun,
year = {2021},
}

@article{martinez-castano_big_2020,
title = {A {Big} {Data} {Platform} for {Real} {Time} {Analysis} of {Signs} of {Depression} in {Social} {Media}},
volume = {17},
copyright = {http://creativecommons.org/licenses/by/3.0/},
url = {https://www.mdpi.com/1660-4601/17/13/4752},
doi = {10.3390/ijerph17134752},
abstract = {In this paper we propose a scalable platform for real-time processing of Social Media data. The platform ingests huge amounts of contents, such as Social Media posts or comments, and can support Public Health surveillance tasks. The processing and analytical needs of multiple screening tasks can easily be handled by incorporating user-defined execution graphs. The design is modular and supports different processing elements, such as crawlers to extract relevant contents or classifiers to categorise Social Media. We describe here an implementation of a use case built on the platform that monitors Social Media users and detects early signs of depression.},
language = {en},
number = {13},
urldate = {2021-06-15},
journal = {International Journal of Environmental Research and Public Health},
author = {Martínez-Castaño, Rodrigo and Pichel, Juan C. and Losada, David E.},
month = jan,
year = {2020},
note = {Number: 13
Publisher: Multidisciplinary Digital Publishing Institute},
keywords = {Social Media, depression, public health surveillance, real-time processing, research ideas, stream processing, text mining},
pages = {4752},
}

@article{sessler_broadly_2010,
title = {Broadly {Applicable} {Risk} {Stratification} {System} for {Predicting} {Duration} of {Hospitalization} and {Mortality}},
volume = {113},
issn = {0003-3022},
url = {https://doi.org/10.1097/ALN.0b013e3181f79a8d},
doi = {10.1097/ALN.0b013e3181f79a8d},
abstract = {Hospitals are increasingly required to publicly report outcomes, yet performance is best interpreted in the context of population and procedural risk. We sought to develop a risk-adjustment method using administrative claims data to assess both national-level and hospital-specific performance.A total of 35,179,507 patient stay records from 2001-2006 Medicare Provider Analysis and Review (MEDPAR) files were randomly divided into development and validation sets. Risk stratification indices (RSIs) for length of stay and mortality endpoints were derived from aggregate risk associated with individual diagnostic and procedure codes. Performance of RSIs were tested prospectively on the validation database, as well as a single institution registry of 103,324 adult surgical patients, and compared with the Charlson comorbidity index, which was designed to predict 1-yr mortality. The primary outcome was the C statistic indicating the discriminatory power of alternative risk-adjustment methods for prediction of outcome measures.A single risk-stratification model predicted 30-day and 1-yr postdischarge mortality; separate risk-stratification models predicted length of stay and in-hospital mortality. The RSIs performed well on the national dataset (C statistics for median length of stay and 30-day mortality were 0.86 and 0.84). They performed significantly better than the Charlson comorbidity index on the Cleveland Clinic registry for all outcomes. The C statistics for the RSIs and Charlson comorbidity index were 0.89 versus 0.60 for median length of stay, 0.98 versus 0.65 for in-hospital mortality, 0.85 versus 0.76 for 30-day mortality, and 0.83 versus 0.77 for 1-yr mortality. Addition of demographic information only slightly improved performance of the RSI.RSI is a broadly applicable and robust system for assessing hospital length of stay and mortality for groups of surgical patients based solely on administrative data.},
number = {5},
urldate = {2021-06-16},
journal = {Anesthesiology},
author = {Sessler, Daniel I. and Sigl, Jeffrey C. and Manberg, Paul J. and Kelley, Scott D. and Schubert, Armin and Chamoun, Nassib G.},
month = nov,
year = {2010},
keywords = {read here},
pages = {1026--1037},
}

@misc{noauthor_concept_nodate,
title = {Concept: {Elixhauser} {Comorbidity} {Index}},
url = {http://mchp-appserv.cpe.umanitoba.ca/viewConcept.php?printer=Y&conceptID=1436},
urldate = {2021-06-16},
}

@misc{noauthor_concept_nodate-1,
title = {Concept: {Charlson} {Comorbidity} {Index}},
url = {http://mchp-appserv.cpe.umanitoba.ca/viewConcept.php?printer=Y&conceptID=1098},
urldate = {2021-06-16},
}

@article{mcinnes_using_2007,
title = {Using {UMLS} {Concept} {Unique} {Identifiers} ({CUIs}) for {Word} {Sense} {Disambiguation} in the {Biomedical} {Domain}},
volume = {2007},
issn = {1942-597X},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2655788/},
abstract = {This paper explores the use of Concept Unique Identifiers (CUIs) as assigned by MetaMap as features for a supervised learning approach to word sense disambiguation of biomedical text. We compare the use of CUIs that occur in abstracts containing an instance of the target word with using the CUIs that occur in sentences containing an instance of the target word. We also experiment with frequency cutoffs for determining which CUIs should be included as features. We find that a Naive Bayesian classifier where the features represent CUIs that occur two or more times in abstracts containing the target word attains accuracy 9\% greater than Leroy and Rindflesch’s approach, which includes features based on semantic types assigned by MetaMap. Our results are comparable to those of Joshi, et. al. and Liu, et. al., who use feature sets that do not contain biomedical information.},
urldate = {2021-06-16},
journal = {AMIA Annual Symposium Proceedings},
author = {McInnes, Bridget T. and Pedersen, Ted and Carlis, John},
year = {2007},
pmid = {18693893},
pmcid = {PMC2655788},
pages = {533--537},
}

@inproceedings{alawad_retrofitting_2018,
title = {Retrofitting {Word} {Embeddings} with the {UMLS} {Metathesaurus} for {Clinical} {Information} {Extraction}},
doi = {10.1109/BigData.2018.8621999},
abstract = {Deep learning has surged in popularity and proven to be effective for various artificial intelligence applications including information extraction from cancer pathology reports. Since word representation is a core unit that enables deep learning algorithms to understand words and be able to perform NLP, this representation must include as much information as possible to help these algorithms achieve high classification performance. Therefore, in this work in addition to the distributional information of words in large sized corpora, we use UMLS vocabulary resources to enrich the vector space representation of words with the semantic relations between words. These resources provide many terminologies pertaining to cancer. The refined word embeddings are used with a convolutional neural (CNN) model to extract four data elements from cancer pathology reports; ICD-O-3 tumor topography codes, tumor laterality, behavior, and histological grade. We observed that using UMLS vocabulary resources to enrich word embeddings of CNN models consistently outperformed CNN models without pre-training word embeddings and even with pre-trained word embeddings on a domain specific corpus across all four tasks. The results show marginal improvement on the laterality task, but a significant improvement on the other tasks, especially for the macro-f score. Specifically, the improvements are 3\%, 13\%, and 15\% for tumor site, histological grade, and behavior tasks, respectively. This approach is encouraging to enrich word embeddings with more clinical data resources to be used for information abstraction tasks from clinical pathology reports.},
booktitle = {2018 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
author = {Alawad, Mohammed and Hasan, S.M. Shamimul and Blair Christian, J. and Tourassi, Georgia},
month = dec,
year = {2018},
keywords = {Cancer, Pathology, Semantics, Task analysis, Tumors, UMLS, Unified modeling language, Vocabulary, Word embeddings, convolutional neural networks, natural language processing},
pages = {2838--2846},
}

@article{heeks_conceptualising_2019,
title = {Conceptualising the link between information systems and resilience: {A} developing country field study},
volume = {29},
copyright = {© 2018 John Wiley \& Sons Ltd},
issn = {1365-2575},
shorttitle = {Conceptualising the link between information systems and resilience},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/isj.12177},
doi = {10.1111/isj.12177},
abstract = {Resilience—the ability of systems to cope with external shocks and trends—is a topic of increasing interest to research and practice. That growing interest is reflected within information systems (IS), but a structured review of IS literature shows a number of knowledge gaps around the conceptual and empirical application of resilience. This paper investigates what the subdiscipline of information and communication technologies for development (ICT4D) can contribute; finding that it offers the IS discipline fresh insights that can be built into a new framework of resilience, and an arena within which this new framework can appropriately be field tested. Application of the resilience framework was undertaken through interviews and a survey in an urban community in Costa Rica; benchmarking both community resilience and “e-resilience” (understood here as the contribution of ICTs to community resilience), and developing from these a set of action priorities. The paper reflects on what can be learned generally from this conceptualisation and operationalisation of resilience. It also reflects on what ICTs contribute to resilience in developing countries and on what this ICT4D-based research specifically contributes to the identified IS knowledge gaps. This includes identification of a future research agenda on information systems and resilience.},
language = {en},
number = {1},
urldate = {2021-06-16},
journal = {Information Systems Journal},
author = {Heeks, Richard and Ospina, Angelica V.},
year = {2019},
note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/isj.12177},
keywords = {Costa Rica, ICT4D, adaptation, read here, resilience},
pages = {70--96},
}

@article{battenberg_location-relative_2020,
title = {Location-{Relative} {Attention} {Mechanisms} {For} {Robust} {Long}-{Form} {Speech} {Synthesis}},
url = {http://arxiv.org/abs/1910.10288},
abstract = {Despite the ability to produce human-level speech for in-domain text, attention-based end-to-end text-to-speech (TTS) systems suffer from text alignment failures that increase in frequency for out-of-domain text. We show that these failures can be addressed using simple location-relative attention mechanisms that do away with content-based query/key comparisons. We compare two families of attention mechanisms: location-relative GMM-based mechanisms and additive energy-based mechanisms. We suggest simple modifications to GMM-based attention that allow it to align quickly and consistently during training, and introduce a new location-relative attention mechanism to the additive energy-based family, called Dynamic Convolution Attention (DCA). We compare the various mechanisms in terms of alignment speed and consistency during training, naturalness, and ability to generalize to long utterances, and conclude that GMM attention and DCA can generalize to very long utterances, while preserving naturalness for shorter, in-domain utterances.},
urldate = {2021-06-16},
journal = {arXiv:1910.10288 [cs, eess]},
author = {Battenberg, Eric and Skerry-Ryan, R. J. and Mariooryad, Soroosh and Stanton, Daisy and Kao, David and Shannon, Matt and Bagby, Tom},
month = apr,
year = {2020},
note = {arXiv: 1910.10288},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@article{goodday_maximizing_2020,
title = {Maximizing the use of social and behavioural information from secondary care mental health electronic health records},
volume = {107},
issn = {1532-0464},
url = {https://www.sciencedirect.com/science/article/pii/S1532046420300575},
doi = {10.1016/j.jbi.2020.103429},
abstract = {Purpose
The contribution of social and behavioural factors in the development of mental health conditions and treatment effectiveness is widely supported, yet there are weak population level data sources on social and behavioural determinants of mental health. Enriching these data gaps will be crucial to accelerating precision medicine. Some have suggested the broader use of electronic health records (EHR) as a source of non-clinical determinants, although social and behavioural information are not systematically collected metrics in EHRs, internationally.
Objective
In this commentary, we highlight the nature and quality of key available structured and unstructured social and behavioural data using a case example of value counts from secondary mental health data available in the UK from the UK Clinical Record Interactive Search (CRIS) database; highlight the methodological challenges in the use of such data; and possible solutions and opportunities involving the use of natural language processing (NLP) of unstructured EHR text.
Conclusions
Most structured non-clinical data fields within secondary care mental health EHR data have too much missing data for adequate use. The utility of other non-clinical fields reported semi-consistently (e.g., ethnicity and marital status) is entirely dependent on treating them appropriately in analyses, quantifying the many reasons behind missingness in consideration of selection biases. Advancements in NLP offer new opportunities in the exploitation of unstructured text from secondary care EHR data particularly given that clinical notes and attachments are available in large volumes of patients and are more routinely completed by clinicians. Tackling ways to re-use, harmonize, and improve our existing and future secondary care mental health data, leveraging advanced analytics such as NLP is worth the effort in an attempt to fill the data gap on social and behavioural contributors to mental health conditions and will be necessary to fulfill all of the domains needed to inform personalized interventions.},
language = {en},
urldate = {2021-06-15},
journal = {Journal of Biomedical Informatics},
author = {Goodday, S. M. and Kormilitzin, A. and Vaci, N. and Liu, Q. and Cipriani, A. and Smith, T. and Nevado-Holgado, A.},
month = jul,
year = {2020},
keywords = {Data quality, Electronic health records, Mental health, Natural language processing, Precision medicine, Selection bias},
pages = {103429},
}

@article{senior_identifying_2020,
title = {Identifying {Predictors} of {Suicide} in {Severe} {Mental} {Illness}: {A} {Feasibility} {Study} of a {Clinical} {Prediction} {Rule} ({Oxford} {Mental} {Illness} and {Suicide} {Tool} or {OxMIS})},
volume = {11},
issn = {1664-0640},
shorttitle = {Identifying {Predictors} of {Suicide} in {Severe} {Mental} {Illness}},
url = {https://www.frontiersin.org/articles/10.3389/fpsyt.2020.00268/full?report=reader},
doi = {10.3389/fpsyt.2020.00268},
abstract = {BACKGROUND: Oxford Mental Illness and Suicide tool (OxMIS) is a brief, scalable, freely available, structured risk assessment tool to assess suicide risk in patients with severe mental illness (schizophrenia-spectrum disorders or bipolar disorder). OxMIS requires further external validation, but a lack of large-scale cohorts with relevant variables makes this challenging. Electronic Health Records provide possible data sources for external validation of risk prediction tools. However, they contain large amounts of information within free-text documents that is not readily extractable. In this study, we examined the feasibility of identifying suicide predictors needed to validate OxMIS in routinely collected Electronic Health Records. METHODS: In study 1, we manually reviewed electronic health records of 57 patients with severe mental illness to calculate OxMIS risk scores. In study 2, we examined the feasibility of using natural language processing to scale up this process. We used anonymized free-text documents from the Clinical Record Interactive Search database to train a Named Entity Recognition model, a machine learning technique which recognizes concepts in free-text. The model identified 8 concepts relevant for suicide risk assessment: medication (antidepressant/antipsychotic treatment), violence, education, self-harm, benefits receipt, drug/alcohol use disorder, suicide, and psychiatric admission. We assessed model performance in terms of precision (similar to positive predictive value), recall (similar to sensitivity) and F1 statistic (an overall performance measure). RESULTS: In study 1, we were able to manually extract information on all variables used by OxMIS from routine clinical records. Four variables were missing in a small number: education, parental drug and alcohol use disorder, benefits recipient, and parental psychiatric admission. In study 2, the Named Entity Recognition model had an overall precision of 0.77, recall of 0.90 and F1 score of 0.83. The concept with the best precision and recall was medication (precision 0.84, recall 0.96) and the weakest were suicide (precision 0.37), and drug/alcohol use disorder (recall 0.61). CONCLUSIONS: Some predictors of suicide used in scalable risk prediction tools can be identified in routine clinical records and extracted using natural language processing. However, methodological challenges are substantial because electronic health records differ from other data sources, particularly for family history variables.},
language = {English},
urldate = {2021-06-15},
journal = {Frontiers in Psychiatry},
author = {Senior, Morwenna and Burghart, Matthias and Yu, Rongqin and Kormilitzin, Andrey and Liu, Qiang and Vaci, Nemanja and Nevado-Holgado, Alejo and Pandit, Smita and Zlodre, Jakov and Fazel, Seena},
year = {2020},
note = {Publisher: Frontiers},
keywords = {Bipolar Disorder, Electronic health records - EHR, OxMIS, Schizophrenia, Suicide, feasibility, natural language processing (NLP), risk assesment},
}

@article{vaci_natural_2020,
title = {Natural language processing for structuring clinical text data on depression using {UK}-{CRIS}},
volume = {23},
issn = {1362-0347, 1468-960X},
url = {https://ebmh.bmj.com/lookup/doi/10.1136/ebmental-2019-300134},
doi = {10.1136/ebmental-2019-300134},
abstract = {Background
          Utilisation of routinely collected electronic health records from secondary care offers unprecedented possibilities for medical science research but can also present difficulties. One key issue is that medical information is presented as free-form text and, therefore, requires time commitment from clinicians to manually extract salient information. Natural language processing (NLP) methods can be used to automatically extract clinically relevant information.
        
        
          Objective
          Our aim is to use natural language processing (NLP) to capture real-world data on individuals with depression from the Clinical Record Interactive Search (CRIS) clinical text to foster the use of electronic healthcare data in mental health research.
        
        
          Methods
          We used a combination of methods to extract salient information from electronic health records. First, clinical experts define the information of interest and subsequently build the training and testing corpora for statistical models. Second, we built and fine-tuned the statistical models using active learning procedures.
        
        
          Findings
          Results show a high degree of accuracy in the extraction of drug-related information. Contrastingly, a much lower degree of accuracy is demonstrated in relation to auxiliary variables. In combination with state-of-the-art active learning paradigms, the performance of the model increases considerably.
        
        
          Conclusions
          This study illustrates the feasibility of using the natural language processing models and proposes a research pipeline to be used for accurately extracting information from electronic health records.
        
        
          Clinical implications
          Real-world, individual patient data are an invaluable source of information, which can be used to better personalise treatment.},
language = {en},
number = {1},
urldate = {2021-06-15},
journal = {Evidence Based Mental Health},
author = {Vaci, Nemanja and Liu, Qiang and Kormilitzin, Andrey and De Crescenzo, Franco and Kurtulmus, Ayse and Harvey, Jade and O'Dell, Bessie and Innocent, Simeon and Tomlinson, Anneka and Cipriani, Andrea and Nevado-Holgado, Alejo},
month = feb,
year = {2020},
pages = {21--26},
}

@misc{noauthor_6_nodate,
title = {6. {Speech} {Synthesis}},
}

@article{gatys_neural_2015,
title = {A {Neural} {Algorithm} of {Artistic} {Style}},
url = {http://arxiv.org/abs/1508.06576},
abstract = {In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition near-human performance was recently demonstrated by a class of biologically inspired vision models called Deep Neural Networks. Here we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and biological vision, our work offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery.},
urldate = {2021-06-09},
journal = {arXiv:1508.06576 [cs, q-bio]},
author = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
month = sep,
year = {2015},
note = {arXiv: 1508.06576},
keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition},
}

@article{huang_arbitrary_2017,
title = {Arbitrary {Style} {Transfer} in {Real}-time with {Adaptive} {Instance} {Normalization}},
url = {http://arxiv.org/abs/1703.06868},
abstract = {Gatys et al. recently introduced a neural algorithm that renders a content image in the style of another image, achieving so-called style transfer. However, their framework requires a slow iterative optimization process, which limits its practical application. Fast approximations with feed-forward neural networks have been proposed to speed up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed set of styles and cannot adapt to arbitrary new styles. In this paper, we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time. At the heart of our method is a novel adaptive instance normalization (AdaIN) layer that aligns the mean and variance of the content features with those of the style features. Our method achieves speed comparable to the fastest existing approach, without the restriction to a pre-defined set of styles. In addition, our approach allows flexible user controls such as content-style trade-off, style interpolation, color \& spatial controls, all using a single feed-forward neural network.},
urldate = {2021-06-09},
journal = {arXiv:1703.06868 [cs]},
author = {Huang, Xun and Belongie, Serge},
month = jul,
year = {2017},
note = {arXiv: 1703.06868},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{chou_one-shot_2019,
title = {One-shot {Voice} {Conversion} by {Separating} {Speaker} and {Content} {Representations} with {Instance} {Normalization}},
url = {http://arxiv.org/abs/1904.05742},
abstract = {Recently, voice conversion (VC) without parallel data has been successfully adapted to multi-target scenario in which a single model is trained to convert the input voice to many different speakers. However, such model suffers from the limitation that it can only convert the voice to the speakers in the training data, which narrows down the applicable scenario of VC. In this paper, we proposed a novel one-shot VC approach which is able to perform VC by only an example utterance from source and target speaker respectively, and the source and target speaker do not even need to be seen during training. This is achieved by disentangling speaker and content representations with instance normalization (IN). Objective and subjective evaluation shows that our model is able to generate the voice similar to target speaker. In addition to the performance measurement, we also demonstrate that this model is able to learn meaningful speaker representations without any supervision.},
urldate = {2021-06-09},
journal = {arXiv:1904.05742 [cs, eess, stat]},
author = {Chou, Ju-chieh and Yeh, Cheng-chieh and Lee, Hung-yi},
month = aug,
year = {2019},
note = {arXiv: 1904.05742},
keywords = {Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Statistics - Machine Learning},
}

@article{mavrodieva_social_2021,
title = {Social {Media} in {Disaster} {Management}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7972070/},
doi = {10.1007/978-981-16-0285-6_4},
abstract = {The role of social media in disaster response and recovery is becoming more and more prominent, as it was seen during and after the 2010 earthquake in Haiti, the 2011 Tohoku earthquake and tsunami in Japan, the 2012 Hurricane Sandy in the USA, and a great number of crisis events ever since. Social media platforms are also increasingly used by a variety of actors—from ordinary residents, to local and international organizations, governments, and traditional media outlets—to a different degree and to different effects. Facebook, Twitter, Instagram, Youtube and others are now among the primary means for information dissemination, mapping and sending instant reports, organizing volunteers and help groups, connecting with family members, and donation gathering. Nonetheless, some concerns over personal data privacy, “fake” news, scams, misinformation and difficulties in outreach to older populations have also been identified. This chapter will provide a brief overview of the available literature on the role of social media for disaster management, and the types, uses, benefits and potential threats and challenges. A review of relevant case studies is included to identify some good and bad practices and derive lessons learnt. Finally, the chapter will pinpoint some key takeaway messages for practitioners and policy-makers in an attempt to chart the way forward.},
urldate = {2021-06-08},
journal = {Media and Disaster Risk Reduction},
author = {Mavrodieva, Aleksandrina V. and Shaw, Rajib},
month = jan,
year = {2021},
pmid = {null},
pmcid = {PMC7972070},
pages = {55--73},
}

@misc{ethics_impact_2019,
title = {The {Impact} of {Social} {Media}: {Is} it {Irreplaceable}?},
shorttitle = {The {Impact} of {Social} {Media}},
url = {https://knowledge.wharton.upenn.edu/article/impact-of-social-media/},
abstract = {The impact of social media over the last 20 years has been significant, but current trends indicate that the sector's future will include more oversight.},
language = {en},
urldate = {2021-06-08},
journal = {Knowledge@Wharton},
author = {Ethics, Business and Policy, Law {and} Public and Focus, Global and America, North},
month = jul,
year = {2019},
note = {Section: Business Ethics},
}

@article{bruhn_are_2012,
title = {Are social media replacing traditional media in terms of brand equity creation?},
volume = {35},
issn = {2040-8269},
url = {https://doi.org/10.1108/01409171211255948},
doi = {10.1108/01409171211255948},
abstract = {Purpose – The purpose of this paper is to investigate the relative impact of brand communication on brand equity through social media as compared to traditional media. In a juxtaposition of different industries it aims at: investigating whether both communication instruments have an impact on consumer‐based brand equity; comparing the effect sizes of these two communication instruments; and separating the effects of firm‐created and user‐generated social media communication. Design/methodology/approach – A total of 393 data sets from three different industries, namely tourism, telecommunications, and pharmaceuticals, were generated using a standardized online‐survey. Structural equation modeling was used in the analysis of the data obtained to investigate the interplay of social media and traditional media in general, as well as in an examination of industry‐specific differences. Findings – The results of the empirical study show that both traditional communications and social media communications have a significant impact on brand equity. While traditional media has a stronger impact on brand awareness, social media communications strongly influence brand image. Firm‐created social media communication is shown to have an important impact on functional brand image, while user‐generated social media communication exerts a major influence on hedonic brand image. Furthermore, the present study highlights significant differences between the industries under investigation. Originality/value – The research described in this paper is pioneering in that it juxtaposes the impacts of social media and traditional media on brand equity – a topic of increasing interest to firms in the era of Facebook and Twitter but so far largely uninvestigated. Moreover, the differentiation between firm‐created and user‐generated social media communication, which is gaining increasingly in importance, as companies see their brand marketing power devolve to the consumer through social media platforms, offers valuable insights to marketing practitioners and academics.},
number = {9},
urldate = {2021-06-08},
journal = {Management Research Review},
author = {Bruhn, Manfred and Schoenmueller, Verena and Schäfer, Daniela B.},
editor = {S. Coulter, Keith},
month = jan,
year = {2012},
note = {Publisher: Emerald Group Publishing Limited},
keywords = {Brand equity, Brand management, Marketing communications, Social media, Traditional media, Word of mouth},
pages = {770--790},
}

@inproceedings{vajjala_study_2017,
address = {Copenhagen, Denmark},
title = {A study of {N}-gram and {Embedding} {Representations} for {Native} {Language} {Identification}},
url = {https://www.aclweb.org/anthology/W17-5026},
doi = {10.18653/v1/W17-5026},
abstract = {We report on our experiments with N-gram and embedding based feature representations for Native Language Identification (NLI) as a part of the NLI Shared Task 2017 (team name: NLI-ISU). Our best performing system on the test set for written essays had a macro F1 of 0.8264 and was based on word uni, bi and trigram features. We explored n-grams covering word, character, POS and word-POS mixed representations for this task. For embedding based feature representations, we employed both word and document embeddings. We had a relatively poor performance with all embedding representations compared to n-grams, which could be because of the fact that embeddings capture semantic similarities whereas L1 differences are more stylistic in nature.},
urldate = {2021-06-07},
booktitle = {Proceedings of the 12th {Workshop} on {Innovative} {Use} of {NLP} for {Building} {Educational} {Applications}},
publisher = {Association for Computational Linguistics},
author = {Vajjala, Sowmya and Banerjee, Sagnik},
month = sep,
year = {2017},
pages = {240--248},
}

@misc{noauthor_science_nodate,
title = {The science behind the service},
url = {https://cloud.ibm.com/docs/personality-insights?topic=personality-insights-science},
urldate = {2021-06-07},
}

@article{chowdhury_natural_2003,
title = {Natural language processing},
volume = {37},
copyright = {Copyright © 2002 American Society for Information Science and Technology},
issn = {1550-8382},
url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/aris.1440370103},
doi = {https://doi.org/10.1002/aris.1440370103},
language = {en},
number = {1},
urldate = {2021-06-07},
journal = {Annual Review of Information Science and Technology},
author = {Chowdhury, Gobinda G.},
year = {2003},
note = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/aris.1440370103},
pages = {51--89},
}

@misc{noauthor_5_nodate,
title = {5. {Speech} {Separation}},
}

@misc{noauthor_7_nodate,
title = {7 {Top} {Social} {Media} {Sites} in 2020 {\textbar} {Adobe} {Spark}},
url = {https://www.adobe.com/express/learn/blog/top-social-media-sites.html},
abstract = {Build your brand and your audience with the help of Adobe Spark and the array of digital tools it offers. Ignite your creativity and inspire your followers to create meaningful engagements and long-lasting impressions.},
language = {en},
urldate = {2021-06-03},
}

@misc{noauthor_4_nodate,
title = {4. {Voice} {Conversion}},
}

@misc{noauthor_3_nodate,
title = {3. {Language} {Model}},
}

@article{zhang_spatial-temporal_2019,
title = {Spatial-{Temporal} {Recurrent} {Neural} {Network} for {Emotion} {Recognition}},
volume = {49},
issn = {2168-2267, 2168-2275},
url = {http://arxiv.org/abs/1705.04515},
doi = {10.1109/TCYB.2017.2788081},
abstract = {Emotion analysis is a crucial problem to endow artifact machines with real intelligence in many large potential applications. As external appearances of human emotions, electroencephalogram (EEG) signals and video face signals are widely used to track and analyze human's affective information. According to their common characteristics of spatial-temporal volumes, in this paper we propose a novel deep learning framework named spatial-temporal recurrent neural network (STRNN) to unify the learning of two different signal sources into a spatial-temporal dependency model. In STRNN, to capture those spatially cooccurrent variations of human emotions, a multi-directional recurrent neural network (RNN) layer is employed to capture longrange contextual cues by traversing the spatial region of each time slice from multiple angles. Then a bi-directional temporal RNN layer is further used to learn discriminative temporal dependencies from the sequences concatenating spatial features of each time slice produced from the spatial RNN layer. To further select those salient regions of emotion representation, we impose sparse projection onto those hidden states of spatial and temporal domains, which actually also increases the model discriminant ability because of this global consideration. Consequently, such a two-layer RNN model builds spatial dependencies as well as temporal dependencies of the input signals. Experimental results on the public emotion datasets of EEG and facial expression demonstrate the proposed STRNN method is more competitive over those state-of-the-art methods.},
number = {3},
urldate = {2021-06-01},
journal = {IEEE Transactions on Cybernetics},
author = {Zhang, Tong and Zheng, Wenming and Cui, Zhen and Zong, Yuan and Li, Yang},
month = mar,
year = {2019},
note = {arXiv: 1705.04515},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
pages = {839--847},
}

@article{thompson_emotional_1991,
title = {Emotional regulation and emotional development},
volume = {3},
issn = {1573-336X},
url = {https://doi.org/10.1007/BF01319934},
doi = {10.1007/BF01319934},
abstract = {Current neofunctionalist views of emotion underscore the biologically adaptive and psychologically constructive contributions of emotion to organized behavior, but little is known of the development of the emotional regulatory processes by which this is fostered. Emotional regulation refers to the extrinsic and intrinsic processes responsible for monitoring, evaluating, and modifying emotional reactions. This review provides a developmental outline of emotional regulation and its relation to emotional development throughout the life-span. The biological foundations of emotional self-regulation and individual differences in regulatory tendencies are summarized. Extrinsic influences on the early regulation of a child's emotion and their long-term significance are then discussed, including a parent's direct intervention strategies, selective reinforcement and modeling processes, affective induction, and the caregiver's ecological control of opportunity for heightened emotion and its management. Intrinsic contributors to the growth of emotional self-regulatory capacities include the emergence of language and cognitive skills, the child's growing emotional and self-understanding (and cognized strategies of emotional self-control), and the emergence of a “theory of personal emotion” in adolescence.},
language = {en},
number = {4},
urldate = {2021-06-01},
journal = {Educational Psychology Review},
author = {Thompson, Ross A.},
month = dec,
year = {1991},
pages = {269--307},
}

@article{miettunen_international_2006,
title = {International comparison of {Cloninger}’s temperament dimensions},
volume = {41},
issn = {0191-8869},
url = {https://www.sciencedirect.com/science/article/pii/S0191886906002248},
doi = {10.1016/j.paid.2006.06.006},
abstract = {Cloninger’s Tridimensional Personality Questionnaire (TPQ) and Temperament and Character Inventory (TCI) have been developed to measure the following temperament dimensions: novelty seeking (NS), harm avoidance (HA), reward dependence (RD) and persistence (P). We used our previous Finnish normative study of the TPQ and TCI (Miettunen et al., 2004) to estimate correction coefficients to convert TPQ scales to comparable TCI scales. Our aim was to compare these corrected temperament dimension scores across 20 countries adjusting for study sample differences in age and gender. In all, some variations were found in these temperament scores between countries. Differences were especially apparent between the Asian and the Western countries. By far the lowest mean score of the RD was in Japan (11.2 vs. 15.4 for other countries; effect size Cohen’s d=−5.74; z-test p{\textless}0.001) and the highest mean score in P was in USA (5.5 vs. 4.4; d=4.24, p=0.001). Some of the findings could be explained by sample differences (e.g. age and education); while some may reflect real differences in the ways which personality is related to cultural factors, such as individualism/collectivism. These differences should be considered when interpreting studies with data on TPQ/TCI from different countries.},
language = {en},
number = {8},
urldate = {2021-06-01},
journal = {Personality and Individual Differences},
author = {Miettunen, Jouko and Kantojärvi, Liisa and Veijola, Juha and Järvelin, Marjo-Riitta and Joukamaa, Matti},
month = dec,
year = {2006},
keywords = {Cross-cultural comparison, Meta-analysis, Personality, TCI, temperament, TPQ},
pages = {1515--1526},
}

@article{cloninger_tridimensional_1991,
title = {The {Tridimensional} {Personality} {Questionnaire}: {U}.{S}. {Normative} {Data}},
volume = {69},
issn = {0033-2941},
shorttitle = {The {Tridimensional} {Personality} {Questionnaire}},
url = {https://doi.org/10.2466/pr0.1991.69.3.1047},
doi = {10.2466/pr0.1991.69.3.1047},
abstract = {The Tridimensional Personality Questionnaire is a self-report personality inventory measuring three major personality dimensions: Novelty Seeking, Harm Avoidance, and Reward Dependence. Normative data, based on a U.S. national probability sample of 1,019 adults, are presented and the psychometric properties of the questionnaire are discussed.},
language = {en},
number = {3},
urldate = {2021-06-01},
journal = {Psychological Reports},
author = {Cloninger, C. Robert and Przybeck, Thomas R. and Svrakic, Dragan M.},
month = dec,
year = {1991},
note = {Publisher: SAGE Publications Inc},
pages = {1047--1057},
}

@article{mccourt_sensation_1993,
title = {Sensation seeking and novelty seeking: {Are} they the same?},
volume = {181},
issn = {1539-736X(Electronic),0022-3018(Print)},
shorttitle = {Sensation seeking and novelty seeking},
doi = {10.1097/00005053-199305000-00006},
abstract = {115 male inpatients (aged 23–69 yrs) hospitalized for treatment of alcohol and chemical dependence completed the Sensation Seeking Scale (SSS) and the Tridimensional Personality Questionnaire (TPQ). The TPQ consists of novelty seeking, harm avoidance, and reward-dependence dimensions. Results show that sensation seeking is positively associated with novelty seeking, negatively associated with hard avoidance, and unrelated to reward dependence. SSS-defined disinhibition is broadly related to novelty seeking. Four SSS subscales (adventure seeking, experience seeking, exploratory excitability vs stoic rigidity, and fear of uncertainty) appear to measure a general preference for novelty or change. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
number = {5},
journal = {Journal of Nervous and Mental Disease},
author = {McCourt, William F. and Gurrera, Ronald J. and Cutter, Henry S.},
year = {1993},
note = {Place: US
Publisher: Lippincott Williams \& Wilkins},
keywords = {Alcoholism, Drug Dependency, Personality Traits, Sensation Seeking},
pages = {309--312},
}

@article{oshio_construct_2003,
title = {Construct validity of the {Adolescent} {Resilience} {Scale}},
volume = {93},
issn = {0033-2941},
doi = {10.2466/pr0.2003.93.3f.1217},
abstract = {The aim of this study was to assess the construct validity of the Adolescent Resilience Scale which measures the psychological features of resilient individuals. Research involving this scale, the Negative Life Events Scale, and the General Health Questionnaire was conducted with a group of 207 Japanese undergraduate students (104 men and 103 women; M age=20.2 yr., SD=.9). A cluster analysis for the Negative Life Events Scale and General Health Questionnaire yielded three clusters: (1) mentally healthy with little experience of Negative Life Events, (2) poorer mental health with many experiences of Negative Life Events, (3) mentally healthy despite many experiences of Negative Life Events. These three groups were defined as (1) Well Adjusted, (2) Vulnerable, and (3) Resilient, respectively. Mean differences in scores on the Adolescent Resilience Scale among the three groups were subjected to one-way analysis of variance. The mean scores of both the Well Adjusted and Resilient groups were higher than that of the Vulnerable group, and therefore support the construct validity of the Adolescent Resilience Scale.},
language = {eng},
number = {3 Pt 2},
journal = {Psychological Reports},
author = {Oshio, Atsushi and Kaneko, Hitoshi and Nagamine, Shinji and Nakaya, Motoyuki},
month = dec,
year = {2003},
pmid = {14765593},
keywords = {Achievement, Adolescent, Adult, Cluster Analysis, Female, Humans, Interpersonal Relations, Life Change Events, Male, Surveys and Questionnaires},
pages = {1217--1222},
}

@article{friborg_new_2003,
title = {A new rating scale for adult resilience: what are the central protective resources behind healthy adjustment?},
volume = {12},
issn = {1049-8931},
shorttitle = {A new rating scale for adult resilience},
doi = {10.1002/mpr.143},
abstract = {Resources that protect against the development of psychiatric disturbances are reported to be a significant force behind healthy adjustment to life stresses, rather than the absence of risk factors. In this paper a new scale for measuring the presence of protective resources that promote adult resilience is validated. The preliminary version of the scale consisted of 45 items covering five dimensions: personal competence, social competence, family coherence, social support and personal structure. The Resilience Scale for Adults (RSA), the Sense of Coherence scale (SOC) and the Hopkins Symptom Checklist (HSCL) were given to 59 patients once, and to 276 normal controls twice, separated by four months. The factor structure was replicated. The respective dimensions had Cronbach's alphas of 0.90, 0.83, 0.87, 0.83 and 0.67, and four-month test-retest correlations of 0.79, 0.84, 0.77, 0.69 and 0.74. Construct validity was supported by positive correlations with SOC and negative correlations with HSCL. The RSA differentiated between patients and healthy control subjects. Discriminant validity was indicated by differential positive correlations between RSA subscales and SOC. The RSA-scale might be used as a valid and reliable measurement in health and clinical psychology to assess the presence of protective factors important to regain and maintain mental health.},
language = {eng},
number = {2},
journal = {International Journal of Methods in Psychiatric Research},
author = {Friborg, Oddgeir and Hjemdal, Odin and Rosenvinge, Jan H. and Martinussen, Monica},
year = {2003},
pmid = {12830300},
pmcid = {PMC6878238},
keywords = {Adaptation, Psychological, Adolescent, Adult, Aged, Case-Control Studies, Female, Humans, Internal-External Control, Male, Mental Disorders, Middle Aged, Personality Inventory, Psychometrics, Reproducibility of Results, Self Concept, Stress, Psychological, Surveys and Questionnaires},
pages = {65--76},
}

@article{windle_methodological_2011,
title = {A methodological review of resilience measurement scales},
volume = {9},
copyright = {2011 Windle et al; licensee BioMed Central Ltd.},
issn = {1477-7525},
url = {https://hqlo.biomedcentral.com/articles/10.1186/1477-7525-9-8},
doi = {10.1186/1477-7525-9-8},
abstract = {The evaluation of interventions and policies designed to promote resilience, and research to understand the determinants and associations, require reliable and valid measures to ensure data quality. This paper systematically reviews the psychometric rigour of resilience measurement scales developed for use in general and clinical populations. Eight electronic abstract databases and the internet were searched and reference lists of all identified papers were hand searched. The focus was to identify peer reviewed journal articles where resilience was a key focus and/or is assessed. Two authors independently extracted data and performed a quality assessment of the scale psychometric properties. Nineteen resilience measures were reviewed; four of these were refinements of the original measure. All the measures had some missing information regarding the psychometric properties. Overall, the Connor-Davidson Resilience Scale, the Resilience Scale for Adults and the Brief Resilience Scale received the best psychometric ratings. The conceptual and theoretical adequacy of a number of the scales was questionable. We found no current 'gold standard' amongst 15 measures of resilience. A number of the scales are in the early stages of development, and all require further validation work. Given increasing interest in resilience from major international funders, key policy makers and practice, researchers are urged to report relevant validation statistics when using the measures.},
language = {en},
number = {1},
urldate = {2021-06-01},
journal = {Health and Quality of Life Outcomes},
author = {Windle, Gill and Bennett, Kate M. and Noyes, Jane},
month = dec,
year = {2011},
note = {Number: 1
Publisher: BioMed Central},
pages = {1--18},
}

@article{di_fabio_developing_2016,
title = {Developing a {New} {Instrument} for {Assessing} {Acceptance} of {Change}},
volume = {7},
issn = {1664-1078},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4884749/},
doi = {10.3389/fpsyg.2016.00802},
abstract = {This article focuses on the usefulness of going beyond the concept of resistance to change and capitalizing on the use of a model that includes positivity and acceptance of change. We first discuss the theoretical background of this new construct in the work and organizational fields and then evaluate the psychometric properties of a new measure for assessing acceptance of change. The results of exploratory factor analysis indicated a factor structure with five principal dimensions; besides confirmatory factor analysis (CFA) goodness of fit indices indicated a good fit of the model to the data. All the dimensions showed good values of internal consistency. The results of the present study indicate that the Acceptance of Change Scale (ACS) is a brief and easily administered instrument with good psychometric properties that can promote the development of clients' strengths and the growth of a sense of Self, thereby helping them choose their own way without losing any opportunities in their lives and their work.},
urldate = {2021-06-01},
journal = {Frontiers in Psychology},
author = {Di Fabio, Annamaria and Gori, Alessio},
month = may,
year = {2016},
pmid = {27303356},
pmcid = {PMC4884749},
}

@book{redding_personal_2014,
title = {Personal {Competency}: {A} {Framework} for {Building} {Students}' {Capacity} to {Learn}},
shorttitle = {Personal {Competency}},
url = {https://eric.ed.gov/?id=ED558070},
abstract = {A chief purpose of schooling is for students to master the knowledge and skills contained in the curriculum. Schools, however, can also intentionally build personal competencies that are necessary for students' success in school, the purposeful navigation of life's challenges, and the pursuit of personal interests and ambitions. A personal competency is an ever-evolving accumulation of related capabilities that facilitate learning and other forms of goal attainment. Four personal competencies are particularly salient: cognitive competency, metacognitive competency, motivational competency, and social/emotional competency. These personal competencies can be enhanced through instruction and by example, as part of the academic curriculum, in extracurricular programs, and through engagement of families. They include their own specific clusters of knowledge and skills as well as values, attitudes, and learning habits (patterns of behavior). An expanded goal for education includes intentional enhancement of personal competencies as well as mastery of the curriculum's specific knowledge and skills. In asserting a higher profile for personal competencies in goals for education, a personal competency framework is in order. This document defines key components of a personal competency framework, then goes on to propose and detail six elements of a Personal Competency framework. They are: (1) Personal Competencies (Cognitive, Metacognitive, Motivational, Social/Emotional); (2) Learning Habits; (3) Mastery; (4) Competency Enhancement; (5) Competency Reinforcement; and (6) Contexts. Learning in school is a matter of goal attainment-the pursuit of myriad learning tasks in order to achieve mastery of the curriculum's knowledge and skills. As with other forms of goal attainment, school learning requires the integrated exercise of four personal competencies: cognitive, metacognitive, motivational, and social/emotional. As the personal competencies are routinely engaged in learning, they form patterns of behavior that students set in motion with each new learning challenge. The personal competencies are malleable, and they are enhanced most effectively when given focus in the curriculum, school culture, and instructional practices. A glossary is included.},
language = {en},
urldate = {2021-06-01},
publisher = {Center on Innovations in Learning, Temple University},
author = {Redding, Sam},
year = {2014},
note = {Publication Title: Center on Innovations in Learning, Temple University},
keywords = {Academic Persistence, Capacity Building, Competence, Educational Attitudes, Emotional Development, Goal Orientation, Interpersonal Competence, Learner Engagement, Mastery Learning, Memory, Metacognition, Prior Learning, Retention (Psychology), Self Esteem, Self Management, Social Development, Student Motivation, Study Habits},
}

@article{noauthor_regulating_2020,
title = {Regulating {Fake} {News} {Content} during {COVID}-19 {Pandemic}: {Evidence}-based {Reality}, {Trustworthy} {Sources}, and {Responsible} {Media} {Reporting}},
issn = {1841-5261},
shorttitle = {Regulating {Fake} {News} {Content} during {COVID}-19 {Pandemic}},
url = {https://www.ceeol.com/search/article-detail?id=892932},
language = {English},
number = {19},
urldate = {2021-06-01},
journal = {Review of Contemporary Philosophy},
year = {2020},
note = {Publisher: Addleton Academic Publishers},
pages = {43--49},
}

@article{noauthor_fake_2020,
title = {Fake {News} {Content} {Shaping} the {COVID}-19 {Pandemic} {Fear}: {Virus} {Anxiety}, {Emotional} {Contagion}, and {Responsible} {Media} {Reporting}},
issn = {1584-0778},
shorttitle = {Fake {News} {Content} {Shaping} the {COVID}-19 {Pandemic} {Fear}},
url = {https://www.ceeol.com/search/article-detail?id=913052},
language = {English},
number = {19},
urldate = {2021-06-01},
journal = {Analysis and Metaphysics},
year = {2020},
note = {Publisher: Addleton Academic Publishers},
pages = {94--100},
}

@misc{noauthor_credible_2014,
title = {Credible and {Non}-{Credible} {Sources} - {Definition} and {Examples}},
url = {https://www.academia-research.com/freelance-writing/crediblenon-credible-sources/},
abstract = {Credibility of the sources used in academic writing. Know the difference so you be able to find credible source for your paper.},
urldate = {2021-06-01},
journal = {Academia-research.com},
month = jul,
year = {2014},
}

@misc{white_galileouga_nodate,
title = {{GALILEO}@{UGA} {Subject} {Guides}: {Finding} {Reliable} {Sources}: {What} is a {Reliable} {Source}?},
copyright = {Copyright University of Georgia 2021},
shorttitle = {{GALILEO}@{UGA} {Subject} {Guides}},
url = {https://guides.libs.uga.edu/c.php?g=571070&p=3936511},
abstract = {GALILEO@UGA Subject Guides: Finding Reliable Sources: What is a Reliable Source?},
language = {en},
urldate = {2021-06-01},
author = {White, Elizabeth},
}

@article{oh_motivations_2015,
title = {Motivations for sharing information and social support in social media: {A} comparative analysis of {Facebook}, {Twitter}, {Delicious}, {YouTube}, and {Flickr}},
volume = {66},
copyright = {© 2015 ASIS\&T},
issn = {2330-1643},
shorttitle = {Motivations for sharing information and social support in social media},
url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.23320},
doi = {https://doi.org/10.1002/asi.23320},
abstract = {The success or failure of social media is highly dependent on the active participation of its users. In order to examine the influential factors that inspire dynamic and eager participation, this study investigates what motivates social media users to share their personal experiences, information, and social support with anonymous others. A variety of information-sharing activities in social media, including creating postings, photos, and videos in 5 different types of social media: Facebook, Twitter, Delicious, YouTube, and Flickr, were observed. Ten factors: enjoyment, self-efficacy, learning, personal gain, altruism, empathy, social engagement, community interest, reciprocity, and reputation, were tested to identify the motivations of social media users based on reviews of major motivation theories and models. Findings from this study indicate that all of the 10 motivations are influential in encouraging users' information sharing to some degree and strongly correlate with one another. At the same time, motivations differ across the 5 types of social media, given that they deliver different information content and serve different purposes. Understanding such differences in motivations could benefit social media developers and those organizations or institutes that would like to use social media to facilitate communication among their community members; appropriate types of social media could be chosen that would fit their own purposes and they could develop strategies that would encourage their members to contribute to their communities through social media.},
language = {en},
number = {10},
urldate = {2021-06-01},
journal = {Journal of the Association for Information Science and Technology},
author = {Oh, Sanghee and Syn, Sue Yeon},
year = {2015},
note = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.23320},
keywords = {information seeking, motivation},
pages = {2045--2060},
}

@inproceedings{fuhr_test_2016,
address = {Cham},
title = {A {Test} {Collection} for {Research} on {Depression} and {Language} {Use}},
volume = {9822},
isbn = {978-3-319-44563-2 978-3-319-44564-9},
url = {http://link.springer.com/10.1007/978-3-319-44564-9_3},
doi = {10.1007/978-3-319-44564-9_3},
abstract = {Several studies in the literature have shown that the words people use are indicative of their psychological states. In particular, depression was found to be associated with distinctive linguistic patterns. However, there is a lack of publicly available data for doing research on the interaction between language and depression. In this paper, we describe our ﬁrst steps to ﬁll this gap. We outline the methodology we have adopted to build and make publicly available a test collection on depression and language use. The resulting corpus includes a series of textual interactions written by diﬀerent subjects. The new collection not only encourages research on diﬀerences in language between depressed and non-depressed individuals, but also on the evolution of the language use of depressed individuals. Further, we propose a novel early detection task and deﬁne a novel eﬀectiveness measure to systematically compare early detection algorithms. This new measure takes into account both the accuracy of the decisions taken by the algorithm and the delay in detecting positive cases. We also present baseline results with novel detection methods that process users’ interactions in diﬀerent ways.},
language = {en},
urldate = {2021-05-18},
booktitle = {Experimental {IR} {Meets} {Multilinguality}, {Multimodality}, and {Interaction}},
publisher = {Springer International Publishing},
author = {Losada, David E. and Crestani, Fabio},
editor = {Fuhr, Norbert and Quaresma, Paulo and Gonçalves, Teresa and Larsen, Birger and Balog, Krisztian and Macdonald, Craig and Cappellato, Linda and Ferro, Nicola},
year = {2016},
note = {Series Title: Lecture Notes in Computer Science},
keywords = {Depressed Individual, Late Detection, Minority Class, Positive Case, Test Collection},
pages = {28--39},
}

@article{collobert_natural_nodate,
title = {Natural {Language} {Processing} ({Almost}) from {Scratch}},
abstract = {We propose a uniﬁed neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-speciﬁc engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.},
language = {en},
journal = {NATURAL LANGUAGE PROCESSING},
author = {Collobert, Ronan and Weston, Jason and Bottou, Leon and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
pages = {45},
}

@article{tardy_social_1985,
title = {Social support measurement},
volume = {13},
issn = {1573-2770(Electronic),0091-0562(Print)},
doi = {10.1007/BF00905728},
abstract = {Argues that the lack of agreement concerning the conceptualization and measurement of social support impedes the production of valid generalizations about its development and functioning. It is suggested that the solution to this problem resides in recognizing and discussing issues involved in defining the concept at the theoretical and operational levels. Five aspects of social support (direction, disposition, description-evaluation, and network) are identified and discussed. Seven instruments capable of assessing these components are described in an attempt to both clarify the decisions facing researchers and to organize the differences among the approaches taken by various authors. These instruments were the Arizona Social Support Interview (M. Barrera, 1981), Inventory of Socially Supportive Behaviors (Barrera, 1981), Perceived Social Support from Friends and Family Scale (M. E. Procidano and K. Heller; see record 1983-29365-001), Social Relationship Scale (A. H. McFarlane et al; see record 1982-00153-001), Social Support Questionnaire (I. G. Sarason et al; see record 1983-22463-001), and Social Support Vignettes (R. J. Turner; see record 1982-21202-001). Reliability and validity evidence associated with the measures are reviewed. (40 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
number = {2},
journal = {American Journal of Community Psychology},
author = {Tardy, Charles H.},
year = {1985},
note = {Place: US
Publisher: Plenum Publishing Corp.},
keywords = {Measurement, Social Support},
pages = {187--202},
}

@book{vaux_social_1988,
address = {New York, NY, England},
series = {Social support:  {Theory}, research, and intervention},
title = {Social support:  {Theory}, research, and intervention},
isbn = {978-0-275-92811-7},
shorttitle = {Social support},
abstract = {"Social Support" comprehensively evaluates research and theory from the perspective of both the scientist and human service provider. This work is sure to become the standard reference on the social support for the psychologist, sociologist, and service provider concerned with social factors in distress and well being.  The volume first examines the roots of, and current debates in, the conceptualization of social support. An integrative perspective is then proposed, presenting social support as a transactional process involving network resources, behavior, and appraisals. Further chapters review measures of support and develop the transactional model—examining links between resources, behavior, and appraisals, and exploring personal, social, and ecological influences on the support process. The book then turns to general models of support effects on psychological well-being, evaluating empirical evidence, noting problems with these models, and subsequently proposing more specific models of support mechanisms. The role of social support in social epidemiology is examined, as are neglected issues regarding developmental aspects of support across the life span. Interventions involving social support are the focus of the later chapters. Problems, both scientific and ideological, are discussed; prospects for interventions at different points in the support process and at various social levels are outlined; finally, support interventions are illustrated through extant programs. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
publisher = {Praeger Publishers},
author = {Vaux, Alan},
year = {1988},
note = {Pages: xiv, 346},
keywords = {Mental Health, Social Support},
}

@misc{noauthor_hung-yi_nodate,
title = {Hung-yi {Lee}},
url = {http://speech.ee.ntu.edu.tw/~tlkagk/courses_DLHLP20.html},
urldate = {2021-06-01},
}

@misc{noauthor_filter_nodate,
title = {Filter {Bank}},
}

@article{cutter_place-based_2008,
series = {Local evidence on vulnerabilities and adaptations to global environmental change},
title = {A place-based model for understanding community resilience to natural disasters},
volume = {18},
issn = {0959-3780},
url = {https://www.sciencedirect.com/science/article/pii/S0959378008000666},
doi = {10.1016/j.gloenvcha.2008.07.013},
abstract = {There is considerable research interest on the meaning and measurement of resilience from a variety of research perspectives including those from the hazards/disasters and global change communities. The identification of standards and metrics for measuring disaster resilience is one of the challenges faced by local, state, and federal agencies, especially in the United States. This paper provides a new framework, the disaster resilience of place (DROP) model, designed to improve comparative assessments of disaster resilience at the local or community level. A candidate set of variables for implementing the model are also presented as a first step towards its implementation.},
language = {en},
number = {4},
urldate = {2021-05-25},
journal = {Global Environmental Change},
author = {Cutter, Susan L. and Barnes, Lindsey and Berry, Melissa and Burton, Christopher and Evans, Elijah and Tate, Eric and Webb, Jennifer},
month = oct,
year = {2008},
keywords = {Disasters, Hazards, Resilience, Vulnerability science},
pages = {598--606},
}

@article{bruneau_framework_2003,
title = {A {Framework} to {Quantitatively} {Assess} and {Enhance} the {Seismic} {Resilience} of {Communities}},
volume = {19},
issn = {8755-2930},
url = {https://doi.org/10.1193/1.1623497},
doi = {10.1193/1.1623497},
abstract = {This paper presents a conceptual framework to define seismic resilience of communities and quantitative measures of resilience that can be useful for a coordinated research effort focusing on enhancing this resilience. This framework relies on the complementary measures of resilience: “Reduced failure probabilities,” “Reduced consequences from failures,” and “Reduced time to recovery.” The framework also includes quantitative measures of the “ends” of robustness and rapidity, and the “means” of resourcefulness and redundancy, and integrates those measures into the four dimensions of community resilience—technical, organizational, social, and economic—all of which can be used to quantify measures of resilience for various types of physical and organizational systems. Systems diagrams then establish the tasks required to achieve these objectives. This framework can be useful in future research to determine the resiliency of different units of analysis and systems, and to develop resiliency targets and detailed analytical procedures to generate these values.},
language = {en},
number = {4},
urldate = {2021-05-25},
journal = {Earthquake Spectra},
author = {Bruneau, Michel and Chang, Stephanie E. and Eguchi, Ronald T. and Lee, George C. and O'Rourke, Thomas D. and Reinhorn, Andrei M. and Shinozuka, Masanobu and Tierney, Kathleen and Wallace, William A. and von Winterfeldt, Detlof},
month = nov,
year = {2003},
note = {Publisher: SAGE Publications Ltd STM},
pages = {733--752},
}

@article{norris_community_2008,
title = {Community resilience as a metaphor, theory, set of capacities, and strategy for disaster readiness},
volume = {41},
issn = {0091-0562},
doi = {10.1007/s10464-007-9156-6},
abstract = {Communities have the potential to function effectively and adapt successfully in the aftermath of disasters. Drawing upon literatures in several disciplines, we present a theory of resilience that encompasses contemporary understandings of stress, adaptation, wellness, and resource dynamics. Community resilience is a process linking a network of adaptive capacities (resources with dynamic attributes) to adaptation after a disturbance or adversity. Community adaptation is manifest in population wellness, defined as high and non-disparate levels of mental and behavioral health, functioning, and quality of life. Community resilience emerges from four primary sets of adaptive capacities--Economic Development, Social Capital, Information and Communication, and Community Competence--that together provide a strategy for disaster readiness. To build collective resilience, communities must reduce risk and resource inequities, engage local people in mitigation, create organizational linkages, boost and protect social supports, and plan for not having a plan, which requires flexibility, decision-making skills, and trusted sources of information that function in the face of unknowns.},
language = {eng},
number = {1-2},
journal = {American Journal of Community Psychology},
author = {Norris, Fran H. and Stevens, Susan P. and Pfefferbaum, Betty and Wyche, Karen F. and Pfefferbaum, Rose L.},
month = mar,
year = {2008},
pmid = {18157631},
keywords = {Adaptation, Psychological, Community Participation, Disaster Planning, Humans, Models, Theoretical, Residence Characteristics, Social Support},
pages = {127--150},
}

@inproceedings{saha_what_2021,
address = {Yokohama Japan},
title = {What {Life} {Events} are {Disclosed} on {Social} {Media}, {How}, {When}, and {By} {Whom}?},
isbn = {978-1-4503-8096-6},
url = {https://dl.acm.org/doi/10.1145/3411764.3445405},
doi = {10.1145/3411764.3445405},
language = {en},
urldate = {2021-05-24},
booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
publisher = {ACM},
author = {Saha, Koustuv and Seybolt, Jordyn and Mattingly, Stephen M and Aledavood, Talayeh and Konjeti, Chaitanya and Martinez, Gonzalo J. and Grover, Ted and Mark, Gloria and De Choudhury, Munmun},
month = may,
year = {2021},
pages = {1--22},
}

@misc{lee_2_nodate,
title = {2. {Speech} {Recognition}},
language = {en},
author = {Lee, Hung-yi},
}

@misc{stanford_university_school_of_engineering_lecture_2017,
title = {Lecture 1 {\textbar} {Natural} {Language} {Processing} with {Deep} {Learning}},
url = {https://www.youtube.com/watch?v=OQQ-W_63UgQ&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6},
abstract = {692,558 views • Apr 3, 2017 • Lecture 1 introduces the concept of Natural Language Processing (NLP) and the problems NLP faces today. The concept of representing words as numeric vectors is then introduced, and popular approaches to designing word vectors are discussed. 

Key phrases: Natural Language Processing. Word Vectors. Singular Value Decomposition. Skip-gram. Continuous Bag of Words (CBOW). Negative Sampling. Hierarchical Softmax. Word2Vec.

-------------------------------------------------------------------------------

Natural Language Processing with Deep Learning

Instructors:
- Chris Manning
- Richard Socher

Natural language processing (NLP) deals with the key artificial intelligence technology of understanding complex human language communication. This lecture series provides a thorough introduction to the cutting-edge research in deep learning applied to NLP, an approach that has recently obtained very high performance across many different NLP tasks including question answering and machine translation. It emphasizes how to implement, train, debug, visualize, and design neural network models, covering the main technologies of word vectors, feed-forward models, recurrent neural networks, recursive neural networks, convolutional neural networks, and recent models involving a memory component.

For additional learning opportunities please visit:
http://stanfordonline.stanford.edu/
  






    Show less
  



    Show more},
urldate = {2021-05-23},
author = {{Stanford University School of Engineering}},
month = apr,
year = {2017},
}

@misc{lee_1_nodate,
title = {1. {Deep} {Learning} for {Human} {Language} {Processing}},
language = {en},
author = {Lee, Hung-yi},
}

@misc{noauthor_papers_nodate,
title = {Papers with {Code} - {eRisk} 2017 {Benchmark} ({Depression} {Detection})},
url = {https://paperswithcode.com/sota/depression-detection-on-erisk-2017},
abstract = {The current state-of-the-art on eRisk 2017 is t-SS3. See a full comparison of 13 papers with code.},
language = {en},
urldate = {2021-05-18},
}

@inproceedings{pirina_identifying_2018,
address = {Brussels, Belgium},
title = {Identifying {Depression} on {Reddit}: {The} {Effect} of {Training} {Data}},
shorttitle = {Identifying {Depression} on {Reddit}},
url = {https://www.aclweb.org/anthology/W18-5903},
doi = {10.18653/v1/W18-5903},
abstract = {This paper presents a set of classification experiments for identifying depression in posts gathered from social media platforms. In addition to the data gathered previously by other researchers, we collect additional data from the social media platform Reddit. Our experiments show promising results for identifying depression from social media texts. More importantly, however, we show that the choice of corpora is crucial in identifying depression and can lead to misleading conclusions in case of poor choice of data.},
urldate = {2021-05-18},
booktitle = {Proceedings of the 2018 {EMNLP} {Workshop} {SMM4H}: {The} 3rd {Social} {Media} {Mining} for {Health} {Applications} {Workshop} \& {Shared} {Task}},
publisher = {Association for Computational Linguistics},
author = {Pirina, Inna and Çöltekin, Çağrı},
month = oct,
year = {2018},
pages = {9--12},
}

@misc{noauthor_datasets_nodate,
title = {Datasets - {Arkaitz} {Zubiaga}},
url = {http://www.zubiaga.org/datasets/},
urldate = {2021-05-17},
}

@article{zubiaga_longitudinal_2018,
title = {A longitudinal assessment of the persistence of twitter datasets},
volume = {69},
copyright = {© 2018 ASIS\&T},
issn = {2330-1643},
url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.24026},
doi = {https://doi.org/10.1002/asi.24026},
abstract = {Social media datasets are not always completely replicable. Having to adhere to requirements of platforms such as Twitter, researchers can only release a list of unique identifiers, which others can then use to recollect the data themselves. This leads to subsets of the data no longer being available, as content can be deleted or user accounts deactivated. To quantify the long-term impact of this in the replicability of datasets, we perform a longitudinal analysis of the persistence of 30 Twitter datasets, which include more than 147 million tweets. By recollecting Twitter datasets ranging from 0 to 4 years old by using the tweet IDs, we look at four different factors quantifying the extent to which recollected datasets resemble original ones: completeness, representativity, similarity, and changingness. Although the ratio of available tweets keeps decreasing as the dataset gets older, we find that the textual content of the recollected subset is still largely representative of the original dataset. The representativity of the metadata, however, keeps fading over time, both because the dataset shrinks and because certain metadata, such as the users' number of followers, keeps changing. Our study has important implications for researchers sharing and using publicly shared Twitter datasets in their research.},
language = {en},
number = {8},
urldate = {2021-05-15},
journal = {Journal of the Association for Information Science and Technology},
author = {Zubiaga, Arkaitz},
year = {2018},
note = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24026},
pages = {974--984},
}

@article{benton_multi-task_2017,
title = {Multi-{Task} {Learning} for {Mental} {Health} using {Social} {Media} {Text}},
url = {http://arxiv.org/abs/1712.03538},
abstract = {We introduce initial groundwork for estimating suicide risk and mental health in a deep learning framework. By modeling multiple conditions, the system learns to make predictions about suicide risk and mental health at a low false positive rate. Conditions are modeled as tasks in a multi-task learning (MTL) framework, with gender prediction as an additional auxiliary task. We demonstrate the effectiveness of multi-task learning by comparison to a well-tuned single-task baseline with the same number of parameters. Our best MTL model predicts potential suicide attempt, as well as the presence of atypical mental health, with AUC {\textgreater} 0.8. We also find additional large improvements using multi-task learning on mental health tasks with limited training data.},
urldate = {2021-05-05},
journal = {arXiv:1712.03538 [cs]},
author = {Benton, Adrian and Mitchell, Margaret and Hovy, Dirk},
month = dec,
year = {2017},
note = {arXiv: 1712.03538},
keywords = {Computer Science - Computation and Language, I.2.7},
}

@article{nadeem_identifying_2016,
title = {Identifying {Depression} on {Twitter}},
url = {http://arxiv.org/abs/1607.07384},
abstract = {Social media has recently emerged as a premier method to disseminate information online. Through these online networks, tens of millions of individuals communicate their thoughts, personal experiences, and social ideals. We therefore explore the potential of social media to predict, even prior to onset, Major Depressive Disorder (MDD) in online personas. We employ a crowdsourced method to compile a list of Twitter users who profess to being diagnosed with depression. Using up to a year of prior social media postings, we utilize a Bag of Words approach to quantify each tweet. Lastly, we leverage several statistical classifiers to provide estimates to the risk of depression. Our work posits a new methodology for constructing our classifier by treating social as a text-classification problem, rather than a behavioral one on social media platforms. By using a corpus of 2.5M tweets, we achieved an 81\% accuracy rate in classification, with a precision score of .86. We believe that this method may be helpful in developing tools that estimate the risk of an individual being depressed, can be employed by physicians, concerned individuals, and healthcare agencies to aid in diagnosis, even possibly enabling those suffering from depression to be more proactive about recovering from their mental health.},
urldate = {2021-05-05},
journal = {arXiv:1607.07384 [cs, stat]},
author = {Nadeem, Moin},
month = jul,
year = {2016},
note = {arXiv: 1607.07384},
keywords = {Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@inproceedings{preotiuc-pietro_role_2015,
address = {Denver, Colorado},
title = {The role of personality, age, and gender in tweeting about mental illness},
url = {https://www.aclweb.org/anthology/W15-1203},
doi = {10.3115/v1/W15-1203},
urldate = {2021-05-05},
booktitle = {Proceedings of the 2nd {Workshop} on {Computational} {Linguistics} and {Clinical} {Psychology}: {From} {Linguistic} {Signal} to {Clinical} {Reality}},
publisher = {Association for Computational Linguistics},
author = {Preoţiuc-Pietro, Daniel and Eichstaedt, Johannes and Park, Gregory and Sap, Maarten and Smith, Laura and Tobolsky, Victoria and Schwartz, H. Andrew and Ungar, Lyle},
month = jun,
year = {2015},
pages = {21--30},
}

@inproceedings{coppersmith_quantifying_2014,
address = {Baltimore, Maryland, USA},
title = {Quantifying {Mental} {Health} {Signals} in {Twitter}},
url = {https://www.aclweb.org/anthology/W14-3207},
doi = {10.3115/v1/W14-3207},
urldate = {2021-05-05},
booktitle = {Proceedings of the {Workshop} on {Computational} {Linguistics} and {Clinical} {Psychology}: {From} {Linguistic} {Signal} to {Clinical} {Reality}},
publisher = {Association for Computational Linguistics},
author = {Coppersmith, Glen and Dredze, Mark and Harman, Craig},
month = jun,
year = {2014},
pages = {51--60},
}

@article{coppersmith_measuring_2014,
title = {Measuring {Post} {Traumatic} {Stress} {Disorder} in {Twitter}},
volume = {8},
copyright = {Copyright (c)},
issn = {2334-0770},
url = {https://ojs.aaai.org/index.php/ICWSM/article/view/14574},
language = {en},
number = {1},
urldate = {2021-05-05},
journal = {Proceedings of the International AAAI Conference on Web and Social Media},
author = {Coppersmith, Glen and Harman, Craig and Dredze, Mark},
month = may,
year = {2014},
note = {Number: 1},
keywords = {Public Health},
}

@article{kumar_ask_2016,
title = {Ask {Me} {Anything}: {Dynamic} {Memory} {Networks} for {Natural} {Language} {Processing}},
shorttitle = {Ask {Me} {Anything}},
url = {http://arxiv.org/abs/1506.07285},
abstract = {Most tasks in natural language processing can be cast into question answering (QA) problems over language input. We introduce the dynamic memory network (DMN), a neural network architecture which processes input sequences and questions, forms episodic memories, and generates relevant answers. Questions trigger an iterative attention process which allows the model to condition its attention on the inputs and the result of previous iterations. These results are then reasoned over in a hierarchical recurrent sequence model to generate answers. The DMN can be trained end-to-end and obtains state-of-the-art results on several types of tasks and datasets: question answering (Facebook's bAbI dataset), text classification for sentiment analysis (Stanford Sentiment Treebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). The training for these different tasks relies exclusively on trained word vector representations and input-question-answer triplets.},
urldate = {2021-05-05},
journal = {arXiv:1506.07285 [cs]},
author = {Kumar, Ankit and Irsoy, Ozan and Ondruska, Peter and Iyyer, Mohit and Bradbury, James and Gulrajani, Ishaan and Zhong, Victor and Paulus, Romain and Socher, Richard},
month = mar,
year = {2016},
note = {arXiv: 1506.07285},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{kim_character-aware_2015,
title = {Character-{Aware} {Neural} {Language} {Models}},
url = {http://arxiv.org/abs/1508.06615},
abstract = {We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway network over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60\% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.},
urldate = {2021-05-05},
journal = {arXiv:1508.06615 [cs, stat]},
author = {Kim, Yoon and Jernite, Yacine and Sontag, David and Rush, Alexander M.},
month = dec,
year = {2015},
note = {arXiv: 1508.06615},
keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@inproceedings{tang_learning_2014,
address = {Baltimore, Maryland},
title = {Learning {Sentiment}-{Specific} {Word} {Embedding} for {Twitter} {Sentiment} {Classification}},
url = {https://www.aclweb.org/anthology/P14-1146},
doi = {10.3115/v1/P14-1146},
urldate = {2021-05-05},
booktitle = {Proceedings of the 52nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
publisher = {Association for Computational Linguistics},
author = {Tang, Duyu and Wei, Furu and Yang, Nan and Zhou, Ming and Liu, Ting and Qin, Bing},
month = jun,
year = {2014},
pages = {1555--1565},
}

@inproceedings{chai_deep_2019,
title = {Deep {Learning} in {Natural} {Language} {Processing}: {A} {State}-of-the-{Art} {Survey}},
shorttitle = {Deep {Learning} in {Natural} {Language} {Processing}},
doi = {10.1109/ICMLC48188.2019.8949185},
abstract = {Deep learning raises interests of research community as their overwhelming successes in information processing such specific tasks as video/speech recognition. In this paper, we provide a state-of-the-art analysis of deep learning with its applications in an important direction: natural language processing. We attempt to provide a clear and critical summarization for researchers and participators who are interested in incorporating the deep learning techniques in their specific domains.},
booktitle = {2019 {International} {Conference} on {Machine} {Learning} and {Cybernetics} ({ICMLC})},
author = {Chai, Junyi and Li, Anming},
month = jul,
year = {2019},
note = {ISSN: 2160-1348},
keywords = {Deep Learning, Literature Review, Natural Language Processing, Video/Speech Recognition},
pages = {1--6},
}

@article{thies_effects_2016,
title = {Effects of {Social} {Interaction} {Dynamics} on {Platforms}},
volume = {33},
issn = {0742-1222},
url = {https://doi.org/10.1080/07421222.2016.1243967},
doi = {10.1080/07421222.2016.1243967},
abstract = {Despite the increasing relevance of online social interactions on platforms, there is still little research on the temporal interaction dynamics between electronic word-of-mouth (eWOM, a form of opinion-based social interaction), popularity information (a form of action-based social interaction), and consumer decision making. Drawing on a panel data set of more than 23,300 crowdfunding campaigns from Indiegogo, we investigate the dynamic effects of these social interactions on consumers’ funding decisions using the panel vector autoregressive methodology. Our analysis shows that both eWOM and popularity information are critical influencing mechanisms in crowdfunding. However, our overarching finding is that eWOM surrounding crowdfunding campaigns on Indiegogo or Facebook has a significant yet substantially weaker predictive power than popularity information. We also find that whereas popularity information has a more immediate effect on consumers’ funding behavior, its effectiveness decays rather quickly, while the impact of eWOM recedes more slowly. This study contributes to the extant literature by (1) providing a more nuanced understanding of the dynamic effects of opinion-based and action-based social interactions, (2) unraveling both within-platform and cross-platform dynamics, and (3) showing that social interactions are perceived as quality indicators on crowdfunding platforms that help consumers reduce risks associated with their investment decisions. These results can help platform providers and complementors to stimulate contribution behavior and increase the prosperity of a platform.},
number = {3},
urldate = {2021-05-04},
journal = {Journal of Management Information Systems},
author = {Thies, Ferdinand and Wessel, Michael and Benlian, Alexander},
month = jul,
year = {2016},
note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/07421222.2016.1243967},
keywords = {crowdfunding, eWOM, electronic word-of-mouth, informational cascades, online platforms, panel vector autoregression, platform success, popularity information, reward-based crowdfunding},
pages = {843--873},
}

@article{kane_whats_2014,
title = {What’{S} {Different} {About} {Social} {Media} {Networks}? {A} {Framework} and {Research} {Agenda}},
volume = {38},
issn = {0276-7783},
shorttitle = {What’{S} {Different} {About} {Social} {Media} {Networks}?},
url = {https://www.jstor.org/stable/26554878},
abstract = {In recent years, we have witnessed the rapid proliferation and widespread adoption of a new class of information technologies, commonly known as social media. Researchers often rely on social network analysis (SNA) when attempting to understand these technologies, often without considering how the novel capabilities of social media platforms might affect the underlying theories of SNA, which were developed primarily through studies of offline social networks. This article outlines several key differences between traditional offline social networks and online social media networks by juxtaposing an established typology of social network research with a well-regarded definition of social media platforms that articulates four key features. The results show that at four major points of intersection, social media has considerable theoretical implications for SNA. In exploring these points of intersection, this study outlines a series of theoretically distinct research questions for SNA in social media contexts. These points of intersection offer considerable opportunities for researchers to investigate the theoretical implications introduced by social media and lay the groundwork for a robust social media agenda potentially spanning multiple disciplines.},
number = {1},
urldate = {2021-05-04},
journal = {MIS Quarterly},
author = {Kane, Gerald C. and Alavi, Maryam and Labianca, Giuseppe (Joe) and Borgatti, Stephen P.},
year = {2014},
note = {Publisher: Management Information Systems Research Center, University of Minnesota},
pages = {275--304},
}

@article{huang_social_2017,
title = {Social network integration and user content generation: evidence from natural experiments},
volume = {41},
issn = {0276-7783},
shorttitle = {Social network integration and user content generation},
url = {https://doi.org/10.25300/MISQ/2017/41.4.02},
doi = {10.25300/MISQ/2017/41.4.02},
abstract = {This study examines how social network integration (i.e., integration of online platforms with other social media services, for example, with Facebook or Twitter) can affect the characteristics of user-generated content (volume and linguistic features) in the context of online reviews. Building on the social presence theory, we propose a number of hypotheses on how social network integration affects review volume and linguistic features of review text. We consider two natural experiments at leading online review platforms (Yelp.com and TripAdvisor.com), wherein each implemented a social network integration with Facebook. Constructing a unique panel dataset of online reviews for a matched set of restaurants across the two review sites, we estimate a difference-in-differences (DID) model to assess the impact of social network integration. We find that integration with Facebook increased the production of user-generated content and positive emotion in review text, while simultaneously decreasing cognitive language, negative emotion, and expressions of disagreement (negations) in review text. Our findings demonstrate that social network integration works as a double-edged sword. On the one hand, integration provides benefits in terms of increased review quantity. On the other hand, these benefits appear to come at the cost of reduced review quality, given past research which has found that positive, emotional reviews are perceived by users to be less helpful. We discuss the implications of these results as they relate to the creation of sustainable online social platforms for user content generation.},
number = {4},
urldate = {2021-05-04},
journal = {MIS Quarterly},
author = {Huang, Ni and Hong, Yili and Burtch, Gordon},
month = dec,
year = {2017},
keywords = {difference-in-differences, natural experiment, online reviews, social network integration, text analytics},
pages = {1035--1058},
}

@article{centola_spread_2010,
title = {The {Spread} of {Behavior} in an {Online} {Social} {Network} {Experiment}},
volume = {329},
copyright = {Copyright © 2010, American Association for the Advancement of Science},
issn = {0036-8075, 1095-9203},
url = {https://science.sciencemag.org/content/329/5996/1194},
doi = {10.1126/science.1185231},
abstract = {How do social networks affect the spread of behavior? A popular hypothesis states that networks with many clustered ties and a high degree of separation will be less effective for behavioral diffusion than networks in which locally redundant ties are rewired to provide shortcuts across the social space. A competing hypothesis argues that when behaviors require social reinforcement, a network with more clustering may be more advantageous, even if the network as a whole has a larger diameter. I investigated the effects of network structure on diffusion by studying the spread of health behavior through artificially structured online communities. Individual adoption was much more likely when participants received social reinforcement from multiple neighbors in the social network. The behavior spread farther and faster across clustered-lattice networks than across corresponding random networks.
An online experiment shows how network structure affects the spread of health behavior.
An online experiment shows how network structure affects the spread of health behavior.},
language = {en},
number = {5996},
urldate = {2021-05-04},
journal = {Science},
author = {Centola, Damon},
month = sep,
year = {2010},
pmid = {20813952},
note = {Publisher: American Association for the Advancement of Science
Section: Report},
pages = {1194--1197},
}

@article{aral_tie_2014,
title = {Tie {Strength}, {Embeddedness}, and {Social} {Influence}: {A} {Large}-{Scale} {Networked} {Experiment}},
volume = {60},
issn = {0025-1909},
shorttitle = {Tie {Strength}, {Embeddedness}, and {Social} {Influence}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2014.1936},
doi = {10.1287/mnsc.2014.1936},
abstract = {We leverage the newly emerging business analytical capability to rapidly deploy and iterate large-scale, microlevel, in vivo randomized experiments to understand how social influence in networks impacts consumer demand. Understanding peer influence is critical to estimating product demand and diffusion, creating effective viral marketing, and designing “network interventions” to promote positive social change. But several statistical challenges make it difficult to econometrically identify peer influence in networks. Though some recent studies use experiments to identify influence, they have not investigated the social or structural conditions under which influence is strongest. By randomly manipulating messages sent by adopters of a Facebook application to their 1.3 million peers, we identify the moderating effect of tie strength and structural embeddedness on the strength of peer influence. We find that both embeddedness and tie strength increase influence. However, the amount of physical interaction between friends, measured by coappearance in photos, does not have an effect. This work presents some of the first large-scale in vivo experimental evidence investigating the social and structural moderators of peer influence in networks. The methods and results could enable more effective marketing strategies and social policy built around a new understanding of how social structure and peer influence spread behaviors in society.This paper was accepted by Alok Gupta, special issue on business analytics.},
number = {6},
urldate = {2021-05-04},
journal = {Management Science},
author = {Aral, Sinan and Walker, Dylan},
month = apr,
year = {2014},
note = {Publisher: INFORMS},
pages = {1352--1370},
}

@article{zhao_finding_2014,
title = {Finding influential users of online health communities: a new metric based on sentiment influence},
volume = {21},
issn = {1067-5027},
shorttitle = {Finding influential users of online health communities},
url = {https://doi.org/10.1136/amiajnl-2013-002282},
doi = {10.1136/amiajnl-2013-002282},
abstract = {Objective Online health communities (OHCs) have become a major source of support for people with health problems. This research tries to improve our understanding of social influence and to identify influential users in OHCs. The outcome can facilitate OHC management, improve community sustainability, and eventually benefit OHC users.Methods Through text mining and sentiment analysis of users' online interactions, the research revealed sentiment dynamics in threaded discussions. A novel metric—the number of influential responding replies—was proposed to directly measure a user's ability to affect the sentiment of others.Results Using the dataset from a popular OHC, the research demonstrated that the proposed metric is highly effective in identifying influential users. In addition, combining the metric with other traditional measures further improves the identification of influential users.},
number = {e2},
urldate = {2021-05-04},
journal = {Journal of the American Medical Informatics Association},
author = {Zhao, Kang and Yen, John and Greer, Greta and Qiu, Baojun and Mitra, Prasenjit and Portier, Kenneth},
month = oct,
year = {2014},
pages = {e212--e218},
}

@article{susarla_social_2011,
title = {Social {Networks} and the {Diffusion} of {User}-{Generated} {Content}: {Evidence} from {YouTube}},
volume = {23},
issn = {1047-7047},
shorttitle = {Social {Networks} and the {Diffusion} of {User}-{Generated} {Content}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.1100.0339},
doi = {10.1287/isre.1100.0339},
abstract = {This paper is motivated by the success of YouTube, which is attractive to content creators as well as corporations for its potential to rapidly disseminate digital content. The networked structure of interactions on YouTube and the tremendous variation in the success of videos posted online lends itself to an inquiry of the role of social influence. Using a unique data set of video information and user information collected from YouTube, we find that social interactions are influential not only in determining which videos become successful but also on the magnitude of that impact. We also find evidence for a number of mechanisms by which social influence is transmitted, such as (i) a preference for conformity and homophily and (ii) the role of social networks in guiding opinion formation and directing product search and discovery. Econometrically, the problem in identifying social influence is that individuals' choices depend in great part upon the choices of other individuals, referred to as the reflection problem. Another problem in identification is to distinguish between social contagion and user heterogeneity in the diffusion process. Our results are in sharp contrast to earlier models of diffusion, such as the Bass model, that do not distinguish between different social processes that are responsible for the process of diffusion. Our results are robust to potential self-selection according to user tastes, temporal heterogeneity and the reflection problem. Implications for researchers and managers are discussed.},
number = {1},
urldate = {2021-05-04},
journal = {Information Systems Research},
author = {Susarla, Anjana and Oh, Jeong-Ha and Tan, Yong},
month = apr,
year = {2011},
note = {Publisher: INFORMS},
pages = {23--41},
}

@article{fang_predicting_2013,
title = {Predicting {Adoption} {Probabilities} in {Social} {Networks}},
volume = {24},
issn = {1047-7047},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.1120.0461},
doi = {10.1287/isre.1120.0461},
abstract = {In a social network, adoption probability refers to the probability that a social entity will adopt a product, service, or opinion in the foreseeable future. Such probabilities are central to fundamental issues in social network analysis, including the influence maximization problem. In practice, adoption probabilities have significant implications for applications ranging from social network-based target marketing to political campaigns, yet predicting adoption probabilities has not received sufficient research attention. Building on relevant social network theories, we identify and operationalize key factors that affect adoption decisions: social influence, structural equivalence, entity similarity, and confounding factors. We then develop the locally weighted expectation-maximization method for Naïve Bayesian learning to predict adoption probabilities on the basis of these factors. The principal challenge addressed in this study is how to predict adoption probabilities in the presence of confounding factors that are generally unobserved. Using data from two large-scale social networks, we demonstrate the effectiveness of the proposed method. The empirical results also suggest that cascade methods primarily using social influence to predict adoption probabilities offer limited predictive power and that confounding factors are critical to adoption probability predictions.},
number = {1},
urldate = {2021-05-04},
journal = {Information Systems Research},
author = {Fang, Xiao and Hu, Paul Jen-Hwa and Li, Zhepeng (Lionel) and Tsai, Weiyu},
month = jan,
year = {2013},
note = {Publisher: INFORMS},
pages = {128--145},
}

@article{bhattacharya_rt_2015,
title = {{RT} @news: {An} analysis of {News} agency ego networks in a microblogging environment},
volume = {6},
issn = {2158-656X},
shorttitle = {{RT} @news},
url = {https://arizona.pure.elsevier.com/en/publications/rt-news-an-analysis-of-news-agency-ego-networks-in-a-microbloggin},
doi = {10.1145/2811270},
language = {English (US)},
number = {3},
urldate = {2021-05-03},
journal = {ACM Transactions on Management Information Systems},
author = {Bhattacharya, Devipsita and Ram, Sudha},
month = sep,
year = {2015},
note = {Publisher: Association for Computing Machinery (ACM)},
pages = {11},
}

@inproceedings{bhattacharya_sharing_2012,
title = {Sharing {News} {Articles} {Using} 140 {Characters}: {A} {Diffusion} {Analysis} on {Twitter}},
shorttitle = {Sharing {News} {Articles} {Using} 140 {Characters}},
doi = {10.1109/ASONAM.2012.170},
abstract = {Is it possible to effectively spread news articles to a large audience using 140 characters? How does the microblogging website Twitter get used as a platform for the news media agencies to create awareness about the articles they publish on a daily basis? Our study of the diffusion patterns of news articles from 12 popular news sources, including BBC, New York Times, and Mash able on Twitter reveals that a large number of users not only consume and comment on these news articles but also share them in different ways. Combining the methods of network and temporal analyses, we examine and report on how news articles diffuse on Twitter, and how different propagation mechanisms result in different life spans for news articles.},
booktitle = {2012 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining}},
author = {Bhattacharya, Devipsita and Ram, Sudha},
month = aug,
year = {2012},
keywords = {Blogs, Data collection, Diseases, Information Diffusion, Media, Microblogging, News Diffusion, Predictive models, Social Media, Social Networks, Twitter},
pages = {966--971},
}

@article{liu_early_2018,
title = {Early {Detection} of {Fake} {News} on {Social} {Media} {Through} {Propagation} {Path} {Classification} with {Recurrent} and {Convolutional} {Networks}},
volume = {32},
copyright = {Copyright (c)},
issn = {2374-3468},
url = {https://ojs.aaai.org/index.php/AAAI/article/view/11268},
language = {en},
number = {1},
urldate = {2021-05-03},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
author = {Liu, Yang and Wu, Yi-Fang},
month = apr,
year = {2018},
note = {Number: 1},
keywords = {deep learning},
}

@inproceedings{jin_news_2014,
title = {News {Credibility} {Evaluation} on {Microblog} with a {Hierarchical} {Propagation} {Model}},
doi = {10.1109/ICDM.2014.91},
abstract = {Benefiting from its openness, collaboration and real-time features, Micro blog has become one of the most important news communication media in modern society. However, it is also filled with fake news. Without verification, such information could spread promptly through social network and result in serious consequences. To evaluate news credibility on Micro blog, we propose a hierarchical propagation model. We detect sub-events within a news event to describe its detailed aspects. Thus, for a news event, a three-layer credibility network consisting of event, sub-events and messages can represent it from different scale and reveal vital information for credibility evaluation. After linking these entities with their semantic and social associations, the credibility value of each entity is propagated on this network to achieve the final evaluation result. By formulating this propagation process as a graph optimization problem, we provide a globally optimal solution with an iterative algorithm. Experiments conducted on two real-world datasets show that the proposed model boosts the accuracy by more than 6\% and the F-score by more than 16\% over a baseline method.},
booktitle = {2014 {IEEE} {International} {Conference} on {Data} {Mining}},
author = {Jin, Zhiwei and Cao, Juan and Jiang, Yu-Gang and Zhang, Yongdong},
month = dec,
year = {2014},
note = {ISSN: 2374-8486},
keywords = {Clustering algorithms, Feature extraction, Media, Microblog, Optimization, Semantics, Social media credibility, Symmetric matrices, Vectors, news credibility, rumor detection},
pages = {230--239},
}

@inproceedings{ye_measuring_2010,
address = {Berlin, Heidelberg},
series = {Lecture {Notes} in {Computer} {Science}},
title = {Measuring {Message} {Propagation} and {Social} {Influence} on {Twitter}.com},
isbn = {978-3-642-16567-2},
doi = {10.1007/978-3-642-16567-2_16},
abstract = {Although extensive studies have been conducted on online social networks (OSNs), it is not clear how to characterize information propagation and social influence, two types of important but not well defined social behavior. This paper presents a measurement study of 58M messages collected from 700K users on Twitter.com , a popular social medium. We analyze the propagation patterns of general messages and show how breaking news (Michael Jackson’s death) spread through Twitter. Furthermore, we evaluate different social influences by examining their stabilities, assessments, and correlations. This paper addresses the complications as well as challenges we encounter when measuring message propagation and social influence on OSNs. We believe that our results here provide valuable insights for future OSN research.},
language = {en},
booktitle = {Social {Informatics}},
publisher = {Springer},
author = {Ye, Shaozhi and Wu, S. Felix},
editor = {Bolc, Leonard and Makowski, Marek and Wierzbicki, Adam},
year = {2010},
keywords = {Message Propagation, Online Social Network, Ranking List, Short Message Service, Twitter User},
pages = {216--231},
}

@inproceedings{phelan_using_2009,
address = {New York, NY, USA},
series = {{RecSys} '09},
title = {Using twitter to recommend real-time topical news},
isbn = {978-1-60558-435-5},
url = {https://doi.org/10.1145/1639714.1639794},
doi = {10.1145/1639714.1639794},
abstract = {Recommending news stories to users, based on their preferences, has long been a favourite domain for recommender systems research. In this paper, we describe a novel approach to news recommendation that harnesses real-time micro-blogging activity, from a service such as Twitter, as the basis for promoting news stories from a user's favourite RSS feeds. A preliminary evaluation is carried out on an implementation of this technique that shows promising results.},
urldate = {2021-04-29},
booktitle = {Proceedings of the third {ACM} conference on {Recommender} systems},
publisher = {Association for Computing Machinery},
author = {Phelan, Owen and McCarthy, Kevin and Smyth, Barry},
month = oct,
year = {2009},
keywords = {content-based recommendation, news recommendation, real-time recommendation, social recommendation, twitter},
pages = {385--388},
}

@article{go_twitter_nodate,
title = {Twitter {Sentiment} {Classiﬁcation} using {Distant} {Supervision}},
abstract = {We introduce a novel approach for automatically classifying the sentiment of Twitter messages. These messages are classiﬁed as either positive or negative with respect to a query term. This is useful for consumers who want to research the sentiment of products before purchase, or companies that want to monitor the public sentiment of their brands. There is no previous research on classifying sentiment of messages on microblogging services like Twitter. We present the results of machine learning algorithms for classifying the sentiment of Twitter messages using distant supervision. Our training data consists of Twitter messages with emoticons, which are used as noisy labels. This type of training data is abundantly available and can be obtained through automated means. We show that machine learning algorithms (Naive Bayes, Maximum Entropy, and SVM) have accuracy above 80\% when trained with emoticon data. This paper also describes the preprocessing steps needed in order to achieve high accuracy. The main contribution of this paper is the idea of using tweets with emoticons for distant supervised learning.},
language = {en},
author = {Go, Alec and Bhayani, Richa and Huang, Lei},
pages = {6},
}

@inproceedings{go_twitter_2009,
title = {Twitter {Sentiment} {Classification} using {Distant} {Supervision}},
url = {http://s3.amazonaws.com/academia.edu.documents/34632156/Twitter_Sentiment_Classification_using_Distant_Supervision.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1501106021&Signature=Y%2FZ0RZkYjq6lDGHmhWAZpIXnJzI%3D&response-content-disposition=inline%3B%20filename%3DTwitter_Sentiment_Classification_using_D.pdf},
abstract = {We introduce a novel approach for automatically classifying the sentiment of Twitter messages. These messages are classified as either positive or negative with respect to a query term. This is useful for consumers who want to research
the sentiment of products before purchase, or companies that want to monitor the public sentiment of their brands. There is no previous research on classifying sentiment of messages on microblogging services like Twitter. We present the results of machine learning algorithms for 
classifying the sentiment of Twitter messages using distant supervision. Our training data consists of Twitter messages with emoticons, which are used as noisy labels. This type of 
training data is abundantly available and can be obtained through automated means. We show that machine learning algorithms (Naive Bayes, Maximum Entropy, and SVM) have accuracy above 80\% when trained with emoticon data. 
This paper also describes the preprocessing steps needed in order to achieve high accuracy. The main contribution of this paper is the idea of using tweets with emoticons for distant supervised learning.},
publisher = {Stanford},
author = {Go, Alec and Bhayani, Richa and Huang, Lei},
month = dec,
year = {2009},
pages = {12--18},
}

@article{tumasjan_predicting_2010,
title = {Predicting {Elections} with {Twitter}: {What} 140 {Characters} {Reveal} about {Political} {Sentiment}},
volume = {4},
copyright = {Copyright (c)},
issn = {2334-0770},
shorttitle = {Predicting {Elections} with {Twitter}},
url = {https://ojs.aaai.org/index.php/ICWSM/article/view/14009},
language = {en},
number = {1},
urldate = {2021-04-29},
journal = {Proceedings of the International AAAI Conference on Web and Social Media},
author = {Tumasjan, Andranik and Sprenger, Timm and Sandner, Philipp and Welpe, Isabell},
month = may,
year = {2010},
note = {Number: 1},
keywords = {data mining},
}

@book{beck_depression_2014,
title = {Depression: {Causes} and treatment,},
isbn = {978-0-8122-9088-2},
url = {https://www.degruyter.com/document/doi/10.9783/9780812290882/html},
abstract = {The second edition of Depression: Causes and Treatment provides a contemporary review of the diagnosis, causes, and treatments of depression. Both biological and psychological treatment approaches are described.},
language = {en},
urldate = {2021-04-26},
publisher = {University of Pennsylvania Press},
author = {Beck, M. D. Aaron T. and Alford, Ph D. Brad A.},
month = apr,
year = {2014},
note = {Publication Title: Depression},
}

@article{goodfellow_generative_2014,
title = {Generative {Adversarial} {Networks}},
url = {http://arxiv.org/abs/1406.2661},
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
urldate = {2020-09-16},
journal = {arXiv:1406.2661 [cs, stat]},
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
month = jun,
year = {2014},
note = {arXiv: 1406.2661},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{krizhevsky_imagenet_2017,
title = {{ImageNet} classification with deep convolutional neural networks},
volume = {60},
issn = {0001-0782, 1557-7317},
url = {https://dl.acm.org/doi/10.1145/3065386},
doi = {10.1145/3065386},
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of ﬁve convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a ﬁnal 1000-way softmax. To make training faster, we used non-saturating neurons and a very efﬁcient GPU implementation of the convolution operation. To reduce overﬁtting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
language = {en},
number = {6},
urldate = {2020-12-30},
journal = {Communications of the ACM},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
month = may,
year = {2017},
pages = {84--90},
}

@article{jia_using_2019,
title = {Using the distance between sets of hierarchical taxonomic clinical concepts to measure patient similarity},
volume = {19},
issn = {1472-6947},
url = {https://doi.org/10.1186/s12911-019-0807-y},
doi = {10.1186/s12911-019-0807-y},
abstract = {Many clinical concepts are standardized under a categorical and hierarchical taxonomy such as ICD-10, ATC, etc. These taxonomic clinical concepts provide insight into semantic meaning and similarity among clinical concepts and have been applied to patient similarity measures. However, the effects of diverse set sizes of taxonomic clinical concepts contributing to similarity at the patient level have not been well studied.},
number = {1},
urldate = {2019-11-07},
journal = {BMC Medical Informatics and Decision Making},
author = {Jia, Zheng and Lu, Xudong and Duan, Huilong and Li, Haomin},
month = apr,
year = {2019},
keywords = {Concept similarity, Data visualization, ICD-10, Patient similarity, Predictive model, Taxonomic concept},
pages = {91},
}

@article{lee_applications_2018,
title = {Applications of machine learning algorithms to predict therapeutic outcomes in depression: {A} meta-analysis and systematic review},
volume = {241},
issn = {0165-0327},
shorttitle = {Applications of machine learning algorithms to predict therapeutic outcomes in depression},
url = {https://www.sciencedirect.com/science/article/pii/S0165032718304853},
doi = {10.1016/j.jad.2018.08.073},
abstract = {Background
No previous study has comprehensively reviewed the application of machine learning algorithms in mood disorders populations. Herein, we qualitatively and quantitatively evaluate previous studies of machine learning-devised models that predict therapeutic outcomes in mood disorders populations.
Methods
We searched Ovid MEDLINE/PubMed from inception to February 8, 2018 for relevant studies that included adults with bipolar or unipolar depression; assessed therapeutic outcomes with a pharmacological, neuromodulatory, or manual-based psychotherapeutic intervention for depression; applied a machine learning algorithm; and reported predictors of therapeutic response. A random-effects meta-analysis of proportions and meta-regression analyses were conducted.
Results
We identified 639 records: 75 full-text publications were assessed for eligibility; 26 studies (n=17,499) and 20 studies (n=6325) were included in qualitative and quantitative review, respectively. Classification algorithms were able to predict therapeutic outcomes with an overall accuracy of 0.82 (95\% confidence interval [CI] of [0.77, 0.87]). Pooled estimates of classification accuracy were significantly greater (p {\textless} 0.01) in models informed by multiple data types (e.g., composite of phenomenological patient features and neuroimaging or peripheral gene expression data; pooled proportion [95\% CI] = 0.93[0.86, 0.97]) when compared to models with lower-dimension data types (pooledproportion=0.68[0.62,0.74]to0.85[0.81,0.88]).
Limitations
Most studies were retrospective; differences in machine learning algorithms and their implementation (e.g., cross-validation, hyperparameter tuning); cannot infer importance of individual variables fed into learning algorithm.
Conclusions
Machine learning algorithms provide a powerful conceptual and analytic framework capable of integrating multiple data types and sources. An integrative approach may more effectively model neurobiological components as functional modules of pathophysiology embedded within the complex, social dynamics that influence the phenomenology of mental disorders.},
language = {en},
urldate = {2021-04-26},
journal = {Journal of Affective Disorders},
author = {Lee, Yena and Ragguett, Renee-Marie and Mansur, Rodrigo B. and Boutilier, Justin J. and Rosenblat, Joshua D. and Trevizol, Alisson and Brietzke, Elisa and Lin, Kangguang and Pan, Zihang and Subramaniapillai, Mehala and Chan, Timothy C. Y. and Fus, Dominika and Park, Caroline and Musial, Natalie and Zuckerman, Hannah and Chen, Vincent Chin-Hung and Ho, Roger and Rong, Carola and McIntyre, Roger S.},
month = dec,
year = {2018},
keywords = {Artificial intelligence, Automated pattern recognition, Bipolar disorder, Machine learning, Major depressive disorder, Mood disorders, Neural networks (computer), Treatment outcome},
pages = {519--532},
}

@article{longley_geotemporal_2015,
title = {The {Geotemporal} {Demographics} of {Twitter} {Usage}},
volume = {47},
issn = {0308-518X},
url = {https://doi.org/10.1068/a130122p},
doi = {10.1068/a130122p},
abstract = {This paper presents a preliminary empirical evaluation of the strategic importance of infusing Twitter social media data into classifications of small areas, as a way of moving beyond the nighttime residential geographies of conventional geodemographic classifications. We attempt an empirically based critique of the merits and drawbacks of the use of social media data, in which the value of high spatial and temporal granularity of revealed activity patterns is contrasted with the paucity of individual attribute information. We apply new and novel methods to enrich the profiles of Twitter users in order to generalize about activity patterns in London, our case-study city. More insidious problems in the use of social media data arise from the as-yet-unknown sources and operation of bias in their user bases. Our contribution is to begin to identify and assess the biases inherent in social media usage in social research, and use these to evaluate their deployment in research applications.},
language = {en},
number = {2},
urldate = {2021-04-26},
journal = {Environment and Planning A: Economy and Space},
author = {Longley, Paul A and Adnan, Muhammad and Lansley, Guy},
month = feb,
year = {2015},
note = {Publisher: SAGE Publications Ltd},
keywords = {GIS, geodemographics, social media},
pages = {465--484},
}

@article{sadah_study_2015,
title = {A {Study} of the {Demographics} of {Web}-{Based} {Health}-{Related} {Social} {Media} {Users}},
volume = {17},
url = {https://www.jmir.org/2015/8/e194},
doi = {10.2196/jmir.4308},
abstract = {Background: The rapid spread of Web-based social media in recent years has impacted how patients share health-related information. However, little work has studied the demographics of these users. Objective: Our aim was to study the demographics of users who participate in health-related Web-based social outlets to identify possible links to health care disparities. Methods: We analyze and compare three different types of health-related social outlets: (1) general Web-based social networks, Twitter and Google+, (2) drug review websites, and (3) health Web forums. We focus on the following demographic attributes: age, gender, ethnicity, location, and writing level. We build and evaluate domain-specific classifiers to infer missing data where possible. The estimated demographic statistics are compared against various baselines, such as Internet and social networks usage of the population. Results: We found that (1) drug review websites and health Web forums are dominated by female users, (2) the participants of health-related social outlets are generally older with the exception of the 65+ years bracket, (3) blacks are underrepresented in health-related social networks, (4) users in areas with better access to health care participate more in Web-based health-related social outlets, and (5) the writing level of users in health-related social outlets is significantly lower than the reading level of the population. Conclusions: We identified interesting and actionable disparities in the participation of various demographic groups to various types of health-related social outlets. These disparities are significantly distinct from the disparities in Internet usage or general social outlets participation.},
language = {EN},
number = {8},
urldate = {2021-04-26},
journal = {Journal of Medical Internet Research},
author = {Sadah, Shouq A. and Shahbazi, Moloud and Wiley, Matthew T. and Hristidis, Vagelis},
month = aug,
year = {2015},
note = {Company: Journal of Medical Internet Research
Distributor: Journal of Medical Internet Research
Institution: Journal of Medical Internet Research
Label: Journal of Medical Internet Research
Publisher: JMIR Publications Inc., Toronto, Canada},
pages = {e4308},
}

@article{mellon_twitter_2017,
title = {Twitter and {Facebook} are not representative of the general population: {Political} attitudes and demographics of {British} social media users},
volume = {4},
issn = {2053-1680},
shorttitle = {Twitter and {Facebook} are not representative of the general population},
url = {https://doi.org/10.1177/2053168017720008},
doi = {10.1177/2053168017720008},
abstract = {A growing social science literature has used Twitter and Facebook to study political and social phenomena including for election forecasting and tracking political conversations. This research note uses a nationally representative probability sample of the British population to examine how Twitter and Facebook users differ from the general population in terms of demographics, political attitudes and political behaviour. We find that Twitter and Facebook users differ substantially from the general population on many politically relevant dimensions including vote choice, turnout, age, gender, and education. On average social media users are younger and better educated than non-users, and they are more liberal and pay more attention to politics. Despite paying more attention to politics, social media users are less likely to vote than non-users, but they are more likely to support the left leaning Labour Party when they do vote. However, we show that these apparent differences mostly arise due to the demographic composition of social media users. After controlling for age, gender, and education, no statistically significant differences arise between social media users and non-users on political attention, values or political behaviour.},
language = {en},
number = {3},
urldate = {2021-04-26},
journal = {Research \& Politics},
author = {Mellon, Jonathan and Prosser, Christopher},
month = jul,
year = {2017},
note = {Publisher: SAGE Publications Ltd},
keywords = {British Election Study, Facebook, Twitter, election forecasting, representativeness, social media},
pages = {2053168017720008},
}

@article{murthy_urban_2016,
title = {Urban {Social} {Media} {Demographics}: {An} {Exploration} of {Twitter} {Use} in {Major} {American} {Cities}},
volume = {21},
issn = {1083-6101},
shorttitle = {Urban {Social} {Media} {Demographics}},
url = {https://doi.org/10.1111/jcc4.12144},
doi = {10.1111/jcc4.12144},
abstract = {This article explores intersections between place, race/ethnicity, and gender amongst American Twitter users and makes an argument that studying the intensity of tweets provides insights into how and why particular groups tweet. Given recent events in American political life such as the shooting in Ferguson, Missouri and the reactions by young, urban African Americans on Twitter, understanding the role of race, place, gender, and age is important. We observed the time between tweets of urban American Twitter users and explored whether the medium may be providing traditionally marginalized groups, such as young Black men, with potential avenues for mobilizing communication and access to resources.},
number = {1},
urldate = {2021-04-26},
journal = {Journal of Computer-Mediated Communication},
author = {Murthy, Dhiraj and Gross, Alexander and Pensavalle, Alexander},
month = jan,
year = {2016},
pages = {33--49},
}

@article{duggan_demographics_nodate,
title = {The {Demographics} of {Social} {Media} {Users} — 2012},
language = {en},
author = {Duggan, Maeve and Brenner, Joanna},
pages = {14},
}

@article{bik_introduction_2013,
title = {An {Introduction} to {Social} {Media} for {Scientists}},
volume = {11},
issn = {1545-7885},
url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001535},
doi = {10.1371/journal.pbio.1001535},
abstract = {Online social media tools can be some of the most rewarding and informative resources for scientists—IF you know how to use them.},
language = {en},
number = {4},
urldate = {2021-04-26},
journal = {PLOS Biology},
author = {Bik, Holly M. and Goldstein, Miriam C.},
month = apr,
year = {2013},
note = {Publisher: Public Library of Science},
keywords = {Apps, Facebook, Internet, Scientists, Social communication, Social media, Twitter, Verbal communication},
pages = {e1001535},
}

@article{yuan_social_2020,
title = {Social {Media} {Based} {Demographics} {Analysis} for {Understanding} {Disaster} {Response} {Disparity}},
url = {https://ascelibrary.org/doi/abs/10.1061/9780784482865.108},
doi = {10.1061/9780784482865.108},
abstract = {Social groups are characterized by their demographic characters such as race/ethnicity and gender. Different demographic groups were found to have experienced significantly varying impacts of the same disasters. For instance, ethnic minorities were impacted more severely than the white during Hurricane Katrina. These varying impacts can be reflected in their different crisis responses. However, research on disaster response disparities among different demographic groups remains a critical challenge due to the lack of disaggregated-level data classified by demographic characters. To fill in this gap, this research takes the first step to investigate the demographics of affected citizens during Hurricane Florence. This paper infers social media users’ demographic characters from their users’ names. The results are used for analyzing social media activities in different demographic groups. This study found the white groups performed most active while the black group acted least active in talking about the hurricane event on social media. Moreover, the female affected citizens were found to be less active than the male affected citizens on social media during Hurricane Florence. The comparative results of demographic compositions among the affected and not-affected citizens have presented different distributions. Our findings can help the classification of Twitter data by demographic groups. The classified Twitter data can be further used for exploring the sentiment and concerns of different demographic groups. The understanding of varying sentiment and concerns of different demographic groups can help crisis response managers design and implement on-target response strategies.},
language = {en},
urldate = {2021-04-26},
author = {Yuan, Faxi and Li, Min and Zhai, Wei and Qi, Bing and Liu, Rui},
month = nov,
year = {2020},
note = {Publisher: American Society of Civil Engineers},
pages = {1020--1028},
}

@inproceedings{nambisan_social_2015,
title = {Social {Media}, {Big} {Data}, and {Public} {Health} {Informatics}: {Ruminating} {Behavior} of {Depression} {Revealed} through {Twitter}},
shorttitle = {Social {Media}, {Big} {Data}, and {Public} {Health} {Informatics}},
doi = {10.1109/HICSS.2015.351},
abstract = {Undiagnosed and untreated depressive disorders have become a serious public health issue and it is prevalent among people of all ages, gender and race. Social media sites, such as Twitter, have become a major venue for people to express/disclose their thoughts and feelings. The tweets from these micro-blogging sites could be used to screen for and potentially detect depression. To date, studies in this area have focused on developing and validating the terms and vocabulary used by users with depression, or evaluating tweets related to depression by using terms that are synonymous with depression. This approach has not produced reliable findings. In this study, we depart from this approach and instead, base our analysis on research on depressive disorders, which indicates the critical significance of repetitive thoughts and ruminating behavior of people with depression. The current study and findings hold important implications for research on depression, social media, and public health informatics.},
booktitle = {2015 48th {Hawaii} {International} {Conference} on {System} {Sciences}},
author = {Nambisan, Priya and Luo, Zhihui and Kapoor, Akshat and Patrick, Timothy B. and Cisler, Ron A.},
month = jan,
year = {2015},
note = {ISSN: 1530-1605},
keywords = {Media, Mood, Pain, Public healthcare, Sociology, Statistics, Twitter},
pages = {2906--2913},
}

@article{kircaburun_self-esteem_2016,
title = {Self-{Esteem}, {Daily} {Internet} {Use} and {Social} {Media} {Addiction} as {Predictors} of {Depression} among {Turkish} {Adolescents}},
volume = {7},
issn = {2222-1735},
url = {https://eric.ed.gov/?id=EJ1112856},
abstract = {In this study, direct and indirect effects of self-esteem, daily internet use and social media addiction to depression levels of adolescents have been investigated by testing a model. This descriptive study was conducted with 1130 students aged between 12 and 18 who are enrolled at different schools in southern region of Aegean. In order to collect data, "Children's Depression Inventory", "Rosenberg Self-esteem Scale" and "Social Media Addiction Scale" have been used. In order to test the hypotheses Pearson's correlation and structural equation modeling were performed. The findings revealed that self-esteem and social media addiction predict 20\% of the daily internet use. Furthermore, while depression was associated with self-esteem and daily internet use directly, social media addiction was affecting depression indirectly. Tested model was able to predict 28\% of the depression among adolescents.},
language = {en},
number = {24},
urldate = {2021-04-26},
journal = {Journal of Education and Practice},
author = {Kircaburun, Kagan},
year = {2016},
note = {Publisher: IISTE},
keywords = {Addictive Behavior, Adolescents, Computer Use, Correlation, Depression (Psychology), Foreign Countries, Internet, Measures (Individuals), Self Concept Measures, Self Esteem, Social Media, Statistical Analysis, Structural Equation Models, Symptoms (Individual Disorders)},
pages = {64--72},
}

@article{jasso-medrano_measuring_2018,
title = {Measuring the relationship between social media use and addictive behavior and depression and suicide ideation among university students},
volume = {87},
issn = {0747-5632},
url = {https://www.sciencedirect.com/science/article/pii/S0747563218302292},
doi = {10.1016/j.chb.2018.05.003},
abstract = {Addictive behavior to social network sites is considered an alarming phenomenon where other psychopathological problems can be manifested. The purpose of the study is to analyze the relationship between the use and the addictive behavior of social media and the use of mobile devices, depression, and suicidal ideation. The questionnaires were applied to a sample of 374 university students where 58.6\% were women and 41.4\% men, with an average age of 20.01 years (SD = 1.84). Unlike the use of social media, addictive behavior was significantly related to depression and suicidal ideation. 36.1\% of the sample reported having at least one idea in relation to suicide in the last two weeks. We propose an explanatory model that was adjusted appropriately and explained the addictive behavior with the frequency of mobile phone use, daily hours, depression, and suicidal ideation, the last one in a negative direction. It is concluded that, unlike excessive use, addictive behavior is associated with negative psychological characteristics. However, addictive behavior can also be considered a protective factor against suicidal ideation when relating to depression.},
language = {en},
urldate = {2021-04-26},
journal = {Computers in Human Behavior},
author = {Jasso-Medrano, José Luis and López-Rosales, Fuensanta},
month = oct,
year = {2018},
keywords = {Addictive behavior, Depression, Excessive use, Mobile phone, Social media, Suicidal ideation},
pages = {183--191},
}

@inproceedings{vedula_emotional_2017,
address = {New York, NY, USA},
series = {{DH} '17},
title = {Emotional and {Linguistic} {Cues} of {Depression} from {Social} {Media}},
isbn = {978-1-4503-5249-9},
url = {https://doi.org/10.1145/3079452.3079465},
doi = {10.1145/3079452.3079465},
abstract = {Health outcomes in modern society are often shaped by peer interactions. Increasingly, a significant fraction of such interactions happen online and can have an impact on various mental health and behavioral health outcomes. Guided by appropriate social and psychological research, we conduct an observational study to understand the interactions between clinically depressed users and their ego-network when contrasted with a differential control group of normal users and their ego-network. Specifically, we examine if one can identify relevant linguistic and emotional signals from social media exchanges to detect symptomatic cues of depression. We observe significant deviations in the behavior of depressed users from the control group. Reduced and nocturnal online activity patterns, reduced active and passive network participation, increase in negative sentiment or emotion, distinct linguistic styles (e.g. self-focused pronoun usage), highly clustered and tightly-knit neighborhood structure, and little to no exchange of influence between depressed users and their ego-network over time are some of the observed characteristics. Based on our observations, we then describe an approach to extract relevant features and show that building a classifier to predict depression based on such features can achieve an F-score of 90\%.},
urldate = {2021-04-26},
booktitle = {Proceedings of the 2017 {International} {Conference} on {Digital} {Health}},
publisher = {Association for Computing Machinery},
author = {Vedula, Nikhita and Parthasarathy, Srinivasan},
month = jul,
year = {2017},
keywords = {depression prediction, social media},
pages = {127--136},
}

@article{shen_depression_nodate,
title = {Depression {Detection} via {Harvesting} {Social} {Media}: {A} {Multimodal} {Dictionary} {Learning} {Solution}},
abstract = {Depression is a major contributor to the overall global burden of diseases. Traditionally, doctors diagnose depressed people face to face via referring to clinical depression criteria. However, more than 70\% of the patients would not consult doctors at early stages of depression, which leads to further deterioration of their conditions. Meanwhile, people are increasingly relying on social media to disclose emotions and sharing their daily lives, thus social media have successfully been leveraged for helping detect physical and mental diseases. Inspired by these, our work aims to make timely depression detection via harvesting social media data. We construct well-labeled depression and non-depression dataset on Twitter, and extract six depression-related feature groups covering not only the clinical depression criteria, but also online behaviors on social media. With these feature groups, we propose a multimodal depressive dictionary learning model to detect the depressed users on Twitter. A series of experiments are conducted to validate this model, which outperforms (+3\% to +10\%) several baselines. Finally, we analyze a large-scale dataset on Twitter to reveal the underlying online behaviors between depressed and non-depressed users.},
language = {en},
author = {Shen, Guangyao and Jia, Jia and Nie, Liqiang and Feng, Fuli and Zhang, Cunjun and Hu, Tianrui and Chua, Tat-Seng and Zhu, Wenwu},
pages = {7},
}

@article{primack_temporal_2021,
title = {Temporal {Associations} {Between} {Social} {Media} {Use} and {Depression}},
volume = {60},
issn = {0749-3797},
url = {https://www.sciencedirect.com/science/article/pii/S0749379720304475},
doi = {10.1016/j.amepre.2020.09.014},
abstract = {Introduction
Previous studies have demonstrated cross-sectional associations between social media use and depression, but their temporal and directional associations have not been reported.
Methods
In 2018, participants aged 18–30 years were recruited in proportion to U.S. Census characteristics, including age, sex, race, education, household income, and geographic region. Participants self-reported social media use on the basis of a list of the top 10 social media networks, which represent {\textgreater}95\% of social media use. Depression was assessed using the 9-Item Patient Health Questionnaire. A total of 9 relevant sociodemographic covariates were assessed. All measures were assessed at both baseline and 6-month follow-up.
Results
Among 990 participants who were not depressed at baseline, 95 (9.6\%) developed depression by follow-up. In multivariable analyses conducted in 2020 that controlled for all covariates and included survey weights, there was a significant linear association (p{\textless}0.001) between baseline social media use and the development of depression for each level of social media use. Compared with those in the lowest quartile, participants in the highest quartile of baseline social media use had significantly increased odds of developing depression (AOR=2.77, 95\% CI=1.38, 5.56). However, there was no association between the presence of baseline depression and increasing social media use at follow-up (OR=1.04, 95\% CI=0.78, 1.38). Results were robust to all sensitivity analyses.
Conclusions
In a national sample of young adults, baseline social media use was independently associated with the development of depression by follow-up, but baseline depression was not associated with an increase in social media use at follow-up. This pattern suggests temporal associations between social media use and depression, an important criterion for causality.},
language = {en},
number = {2},
urldate = {2021-04-26},
journal = {American Journal of Preventive Medicine},
author = {Primack, Brian A. and Shensa, Ariel and Sidani, Jaime E. and Escobar-Viera, César G. and Fine, Michael J.},
month = feb,
year = {2021},
pages = {179--188},
}

@inproceedings{sadeque_measuring_2018,
address = {New York, NY, USA},
series = {{WSDM} '18},
title = {Measuring the {Latency} of {Depression} {Detection} in {Social} {Media}},
isbn = {978-1-4503-5581-0},
url = {https://doi.org/10.1145/3159652.3159725},
doi = {10.1145/3159652.3159725},
abstract = {Detecting depression is a key public health challenge, as almost 12\% of all disabilities can be attributed to depression. Computational models for depression detection must prove not only that can they detect depression, but that they can do it early enough for an intervention to be plausible. However, current evaluations of depression detection are poor at measuring model latency. We identify several issues with the currently popular ERDE metric, and propose a latency-weighted F1 metric that addresses these concerns. We then apply this evaluation to several models from the recent eRisk 2017 shared task on depression detection, and show how our proposed measure can better capture system differences.},
urldate = {2021-04-26},
booktitle = {Proceedings of the {Eleventh} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
publisher = {Association for Computing Machinery},
author = {Sadeque, Farig and Xu, Dongfang and Bethard, Steven},
month = feb,
year = {2018},
keywords = {depression, latency, neural networks, social media},
pages = {495--503},
}

@article{dhir_online_2018,
title = {Online social media fatigue and psychological wellbeing—{A} study of compulsive use, fear of missing out, fatigue, anxiety and depression},
volume = {40},
issn = {0268-4012},
url = {https://www.sciencedirect.com/science/article/pii/S0268401217310629},
doi = {10.1016/j.ijinfomgt.2018.01.012},
abstract = {The constant development of online social media features and related services has constantly attracted and increased the number of social media users. But, at the same time, a myriad of users have deviated themselves, temporarily or permanently, from social media use due to social media fatigue. Scholars have investigated different antecedents and consequences of social media fatigue. However, empirical relationships between psychosocial wellbeing and social media fatigue are currently not known. To bridge this gap, the current study utilises the stressor-strain-outcome framework (SSO) to examine whether psychosocial wellbeing measures, such as compulsive media use and fear of missing out, trigger fatigue and, furthermore, whether social media fatigue results in anxiety and depression. The study utilised repeated cross-sectional methodology whereby two waves of data (N = 1554, 1144) were collected to test the research model with adolescent social media users in India. The study findings suggest that compulsive media use significantly triggered social media fatigue, which later result in elevated anxiety and depression. Fear of missing out indirectly predicted social media fatigue through mediation of compulsive social media use. The theoretical and practical implications, limitations of the present study and agenda for future studies are presented and discussed.},
language = {en},
urldate = {2021-04-26},
journal = {International Journal of Information Management},
author = {Dhir, Amandeep and Yossatorn, Yossiri and Kaur, Puneet and Chen, Sufen},
month = jun,
year = {2018},
keywords = {Adolescents, Anxiety, Compulsive media use, Depression, Fear of missing out, Repeated cross-sectional survey, Social media fatigue},
pages = {141--152},
}

@inproceedings{aldarwish_predicting_2017,
title = {Predicting {Depression} {Levels} {Using} {Social} {Media} {Posts}},
doi = {10.1109/ISADS.2017.41},
abstract = {The use of Social Network Sites (SNS) is increasing nowadays especially by the younger generations. The availability of SNS allows users to express their interests, feelings and share daily routine. Many researchers prove that using user-generated content (UGC) in a correct way may help determine people's mental health levels. Mining the UGC could help to predict the mental health levels and depression. Depression is a serious medical illness, which interferes most with the ability to work, study, eat, sleep and having fun. However, from the user profile in SNS, we can collect all the information that relates to person's mood, and negativism. In this research, our aim is to investigate how SNS user's posts can help classify users according to mental health levels. We propose a system that uses SNS as a source of data and screening tool to classify the user using artificial intelligence according to the UGC on SNS. We created a model that classify the UGC using two different classifiers: Support Vector Machine (SVM), and Naïve Bayes.},
booktitle = {2017 {IEEE} 13th {International} {Symposium} on {Autonomous} {Decentralized} {System} ({ISADS})},
author = {Aldarwish, Maryam Mohammed and Ahmad, Hafiz Farooq},
month = mar,
year = {2017},
keywords = {Facebook, Mathematical model, Medical diagnostic imaging, Mood, Social Network Sites (SNS), Support Vector Machine (SVM), Support vector machines, Training, User Generated Content (UGC)},
pages = {277--280},
}

@article{hunt_no_2018,
title = {No {More} {FOMO}: {Limiting} {Social} {Media} {Decreases} {Loneliness} and {Depression}},
volume = {37},
issn = {0736-7236},
shorttitle = {No {More} {FOMO}},
url = {https://guilfordjournals.com/doi/abs/10.1521/jscp.2018.37.10.751},
doi = {10.1521/jscp.2018.37.10.751},
abstract = {Introduction: Given the breadth of correlational research linking social media use to worse well-being, we undertook an experimental study to investigate the potential causal role that social media plays in this relationship.Method: After a week of baseline monitoring, 143 undergraduates at the University of Pennsylvania were randomly assigned to either limit Facebook, Instagram and Snapchat use to 10 minutes, per platform, per day, or to use social media as usual for three weeks.Results: The limited use group showed significant reductions in loneliness and depression over three weeks compared to the control group. Both groups showed significant decreases in anxiety and fear of missing out over baseline, suggesting a benefit of increased self-monitoring.Discussion: Our findings strongly suggest that limiting social media use to approximately 30 minutes per day may lead to significant improvement in well-being.},
number = {10},
urldate = {2021-04-26},
journal = {Journal of Social and Clinical Psychology},
author = {Hunt, Melissa G. and Marx, Rachel and Lipson, Courtney and Young, Jordyn},
month = nov,
year = {2018},
note = {Publisher: Guilford Publications Inc.},
pages = {751--768},
}

@misc{noauthor_jupyter_nodate,
title = {Jupyter {Notebook} {Viewer}},
url = {https://nbviewer.jupyter.org/github/jakevdp/WhirlwindTourOfPython/blob/master/Index.ipynb},
urldate = {2021-04-25},
}

@misc{noauthor_python_nodate,
title = {Python {Data} {Science} {Handbook} {\textbar} {Python} {Data} {Science} {Handbook}},
url = {https://jakevdp.github.io/PythonDataScienceHandbook/},
urldate = {2021-04-25},
}

@article{pollard_eicu_2018,
title = {The {eICU} {Collaborative} {Research} {Database}, a freely available multi-center database for critical care research},
volume = {5},
copyright = {2018 The Author(s)},
issn = {2052-4463},
url = {https://www.nature.com/articles/sdata2018178},
doi = {10.1038/sdata.2018.178},
abstract = {Critical care patients are monitored closely through the course of their illness. As a result of this monitoring, large amounts of data are routinely collected for these patients. Philips Healthcare has developed a telehealth system, the eICU Program, which leverages these data to support management of critically ill patients. Here we describe the eICU Collaborative Research Database, a multi-center intensive care unit (ICU)database with high granularity data for over 200,000 admissions to ICUs monitored by eICU Programs across the United States. The database is deidentified, and includes vital sign measurements, care plan documentation, severity of illness measures, diagnosis information, treatment information, and more. Data are publicly available after registration, including completion of a training course in research with human subjects and signing of a data use agreement mandating responsible handling of the data and adhering to the principle of collaborative research. The freely available nature of the data will support a number of applications including the development of machine learning algorithms, decision support tools, and clinical research.},
language = {en},
number = {1},
urldate = {2020-11-15},
journal = {Scientific Data},
author = {Pollard, Tom J. and Johnson, Alistair E. W. and Raffa, Jesse D. and Celi, Leo A. and Mark, Roger G. and Badawi, Omar},
month = sep,
year = {2018},
note = {Number: 1
Publisher: Nature Publishing Group},
pages = {180178},
}

@article{wenli_zhang_comprehensive_2020,
title = {A {Comprehensive} {Analysis} of {Triggers} and {Risk} {Factors} for {Asthma} {Based} on {Machine} {Learning} and {Large} {Heterogeneous} {Data} {Sources}},
volume = {44},
issn = {02767783},
url = {https://search.ebscohost.com/login.aspx?direct=true&AuthType=shib,ip&db=bsh&AN=141995175&site=ehost-live&custid=s8875136},
doi = {10.25300/MISQ/2020/15106},
abstract = {Asthma is a common chronic health condition affecting millions of people in the United States. While asthma cannot be cured, it can be managed if we identify and understand triggers and risk factors that cause asthma exacerbations. However, this is challenging because these triggers and risk factors are complex and interconnected, and there are limitations to current mainstream approaches for identifying them. The recent availability of massive amounts of heterogeneous data has opened up new possibilities for asthma triggers and risk factors analyses. In this study, we introduce a data-driven framework, adapt and integrate multiple advanced machine learning techniques, and perform an empirical analysis to (1) derive characteristics of selfreported asthma patients from social media, (2) enable integration and repurposing of highly heterogeneous and commonly available datasets, and (3) uncover the sequential patterns of asthma triggers and risk factors, and their relative importance, both of which are difficult to achieve via retrospective cohort-based studies. Our methods and results can provide guidance for developing asthma management plans and interventions for specific subpopulations and, eventually, have the potential to reduce the societal burden of asthma.},
number = {1},
urldate = {2021-04-09},
journal = {MIS Quarterly},
author = {{Wenli Zhang} and Ram, Sudha},
month = mar,
year = {2020},
note = {Publisher: MIS Quarterly},
keywords = {Asthma risk factors, Chronic disease management, Chronic disease treatment, Design science, Machine learning, Random forest (Algorithms), asthma triggers/risk factors, convolutional neural networks, design science, distant supervision, geometric inference, machine learning, random forest, sequential pattern mining},
pages = {305--349},
}

@article{becker_icu_1996,
title = {{ICU} {SCORING} {SYSTEMS} {ALLOW} {PREDICTION} {OF} {PATIENT} {OUTCOMES} {AND} {COMPARISON} {OF} {ICU} {PERFORMANCE}},
volume = {12},
issn = {0749-0704, 1557-8232},
url = {https://www.criticalcare.theclinics.com/article/S0749-0704(05)70258-X/abstract},
doi = {10.1016/S0749-0704(05)70258-X},
abstract = {The debate about prognostic systems in critical illness has evolved from a general
question of relevance in the field of critical care medicine to the present and more
useful question of their potential specific roles in critical care. Over the past
20 years, substantial resources were committed to the development of scoring systems
that would provide objective prognostic estimates for critically ill patients. A common
goal was to produce systems flexible enough to predict outcome among heterogeneous
groups of patients who share the misfortune of being critically ill.},
language = {English},
number = {3},
urldate = {2021-04-09},
journal = {Critical Care Clinics},
author = {Becker, Richard B. and Zimmerman, Jack E.},
month = jul,
year = {1996},
pmid = {8839586},
note = {Publisher: Elsevier},
pages = {503--514},
}

@article{pirracchio_mortality_2015,
title = {Mortality prediction in intensive care units with the {Super} {ICU} {Learner} {Algorithm} ({SICULA}): a population-based study},
volume = {3},
issn = {2213-2600},
shorttitle = {Mortality prediction in intensive care units with the {Super} {ICU} {Learner} {Algorithm} ({SICULA})},
url = {https://www.sciencedirect.com/science/article/pii/S2213260014702395},
doi = {10.1016/S2213-2600(14)70239-5},
abstract = {Background
Improved mortality prediction for patients in intensive care units is a big challenge. Many severity scores have been proposed, but findings of validation studies have shown that they are not adequately calibrated. The Super ICU Learner Algorithm (SICULA), an ensemble machine learning technique that uses multiple learning algorithms to obtain better prediction performance, does at least as well as the best member of its library. We aimed to assess whether the Super Learner could provide a new mortality prediction algorithm for patients in intensive care units, and to assess its performance compared with other scoring systems.
Methods
From January, 2001, to December, 2008, we used the Multiparameter Intelligent Monitoring in Intensive Care II (MIMIC-II) database (version 26) including all patients admitted to an intensive care unit at the Beth Israel Deaconess Medical Centre, Boston, MA, USA. We assessed the calibration, discrimination, and risk classification of predicted hospital mortality based on Super Learner compared with SAPS-II, APACHE-II, and SOFA. We calculated performance measures with cross-validation to avoid making biased assessments. Our proposed score was then externally validated on a dataset of 200 randomly selected patients admitted at the intensive care unit of Hôpital Européen Georges-Pompidou, Paris, France, between Sept 1, 2013, and June, 30, 2014. The primary outcome was hospital mortality. The explanatory variables were the same as those included in the SAPS II score.
Findings
24 508 patients were included, with median SAPS-II of 38 (IQR 27–51) and median SOFA of 5 (IQR 2–8). 3002 of 24 508 (12\%) patients died in the Beth Israel Deaconess Medical Centre. We produced two sets of predictions based on the Super Learner; the first based on the 17 variables as they appear in the SAPS-II score (SL1), and the second, on the original, untransformed variables (SL2). The two versions yielded average predicted probabilities of death of 0·12 (IQR 0·02–0·16) and 0·13 (0·01–0·19), whereas the corresponding value for SOFA was 0·12 (0·05–0·15) and for SAPS-II 0·30 (0·08–0·48). The cross-validated area under the receiver operating characteristic curve (AUROC) for SAPS-II was 0·78 (95\% CI 0·77–0·78) and 0·71 (0·70–0·72) for SOFA. Super Learner had an AUROC of 0·85 (0·84–0·85) when the explanatory variables were categorised as in SAPS-II, and of 0·88 (0·87–0·89) when the same explanatory variables were included without any transformation. Additionally, Super Learner showed better calibration properties than previous score systems. On the external validation dataset, the AUROC was 0·94 (0·90–0·98) and calibration properties were good.
Interpretation
Compared with conventional severity scores, Super Learner offers improved performance for predicting hospital mortality in patients in intensive care units. A user-friendly implementation is available online and should be useful for clinicians seeking to validate our score.
Funding
Fulbright Foundation, Assistance Publique–Hôpitaux de Paris, Doris Duke Clinical Scientist Development Award, and the NIH.},
language = {en},
number = {1},
urldate = {2021-04-08},
journal = {The Lancet Respiratory Medicine},
author = {Pirracchio, Romain and Petersen, Maya L and Carone, Marco and Rigon, Matthieu Resche and Chevret, Sylvie and van der Laan, Mark J},
month = jan,
year = {2015},
pages = {42--52},
}

@article{dillon_how_2008,
title = {How {Near}-{Misses} {Influence} {Decision} {Making} {Under} {Risk}: {A} {Missed} {Opportunity} for {Learning}},
volume = {54},
issn = {0025-1909},
shorttitle = {How {Near}-{Misses} {Influence} {Decision} {Making} {Under} {Risk}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1080.0869},
doi = {10.1287/mnsc.1080.0869},
abstract = {Although organizations appear to learn from obvious failures, we argue that it is harder for them to learn from “near-misses”—events in which chance played a role in averting failure. In this paper, we formalize the concept of near-misses and hypothesize that organizations and managers fail to learn from near-misses because they evaluate such events as successes and thus feel safer about the situation. We distinguish perceived (“felt”) risk from calculated statistical risk and propose that lower levels of perceived risk encourage people with near-miss information to make riskier subsequent decisions compared to people without near-miss information. In our first study, we confirm the tendency to evaluate near-misses as successes by having participants rate a project manager whose decisions result in either (a) mission success, (b) near-miss, or (c) failure. Participants (both students and NASA employees and contractors) give similar ratings to managers whose decisions produced near-misses and to managers whose decisions resulted in successes, and both ratings are significantly different from ratings of managers who experienced failures. We suggest that the failure to hold managers accountable for near-misses is a foregone learning opportunity for both the manager and the organization. In our second set of studies, we confirm that near-miss information leads people to choose a riskier alternative because of a lower perceived risk following near-miss events. We explore several alternative explanations for these findings, including the role of Bayesian updating in processing near-miss data. Ultimately, the analysis suggests that managers and organizations are reducing their perception of the risk, although not necessarily updating (lowering) the statistical probability of the failure event. We speculate that this divergence arises because perceived risk is the product of associative processing, whereas statistical risk arises from rule-based processing.},
number = {8},
urldate = {2021-04-08},
journal = {Management Science},
author = {Dillon, Robin L. and Tinsley, Catherine H.},
month = jun,
year = {2008},
note = {Publisher: INFORMS},
pages = {1425--1440},
}

@article{tinsley_how_2011,
title = {How to {Avoid} {Catastrophe}},
issn = {0017-8012},
url = {https://hbr.org/2011/04/how-to-avoid-catastrophe},
abstract = {Failures happen. But if you pay attention to near misses, you can predict and prevent crises.},
urldate = {2021-04-08},
journal = {Harvard Business Review},
author = {Tinsley, Catherine H. and Dillon, Robin L. and Madsen, Peter M.},
month = apr,
year = {2011},
note = {Section: Strategic planning},
keywords = {Crisis management, Organizational culture, Psychology, Strategic planning, Strategy},
}

@article{chen_data_2013,
title = {Data {Model} {Development} for {Fire} {Related} {Extreme} {Events}: {An} {Activity} {Theory} {Approach}},
volume = {37},
issn = {0276-7783},
shorttitle = {Data {Model} {Development} for {Fire} {Related} {Extreme} {Events}},
url = {https://www.jstor.org/stable/43825940},
abstract = {Post-analyses of major extreme events reveal that information sharing is critical for effective emergency response. The lack of consistent data standards for current emergency management practice, however, hinders efficient critical information flow among incident responders. In this paper, we adopt a third-generation activity theory guided approach to develop a data model that can be used in the response to fire-related extreme events. This data model prescribes the core data standards to reduce information interoperability barriers. The model is validated through a three-step approach including a request for comment (RFC) process, case application, and prototype system test. This study contributes to the literature in the area of interoperability and data modeling; it also informs practice in emergency response system design.},
number = {1},
urldate = {2021-04-08},
journal = {MIS Quarterly},
author = {Chen, Rui and Sharman, Raj and Rao, H. Raghav and Upadhyaya, Shambhu J.},
year = {2013},
note = {Publisher: Management Information Systems Research Center, University of Minnesota},
pages = {125--147},
}

@article{le_distributed_2014,
title = {Distributed {Representations} of {Sentences} and {Documents}},
url = {http://arxiv.org/abs/1405.4053},
abstract = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
urldate = {2016-08-31},
journal = {arXiv:1405.4053 [cs]},
author = {Le, Quoc V. and Mikolov, Tomas},
month = may,
year = {2014},
note = {arXiv: 1405.4053},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Learning, Computer Science - Machine Learning, paper vesion},
}

@article{park_disaster_2015,
title = {Disaster {Experience} and {Hospital} {Information} {Systems}: {An} {Examination} of {Perceived} {Information} {Assurance}, {Risk}, {Resilience}, and {HIS} {Usefulness}},
shorttitle = {Disaster {Experience} and {Hospital} {Information} {Systems}},
doi = {10.25300/MISQ/2015/39.2.03},
abstract = {This paper examines how an individual's disaster experience affects his or her perceptions of sociotechnical safety factors (risk, information assurance, resilience) and perceived usefulness of hospital information systems (HIS). This paper consists of two studies focusing on different aspects: a quasi-field experiment conducted with employees in three hospitals affected by a severe snowstorm (labeled a federal disaster) (N = 103), where we compare the perceptual factors in the context of the disaster experience (with versus without recall), and a comparative study between a first sample group (with disaster experience) and a second, contrast sample group (with no disaster experience) of hospital employees (N= 179) from two similar hospitals. The results show that the disaster experience changes the relationships among the perceptual factors that affect perceived usefulness. Individuals tend to perceive negative factors (such as risk) as having greater effects when they actually have direct experience in a disaster situation than in a normal situation. Positive factors (such as information assurance and resilience) have a lesser impact among individuals who have disaster experience (with versus without recall).},
journal = {MIS Q.},
author = {Park, Insu and Sharman, R. and Rao, H.},
year = {2015},
}

@misc{noauthor_american_nodate,
title = {American {Epilepsy} {Society} {Seizure} {Prediction} {Challenge}},
url = {https://kaggle.com/c/seizure-prediction},
abstract = {Predict seizures in intracranial EEG recordings},
language = {en},
urldate = {2019-08-28},
}

@article{yang_design_2011,
title = {Design {Principles} of {Integrated} {Information} {Platform} for {Emergency} {Responses}: {The} {Case} of 2008 {Beijing} {Olympic} {Games}},
volume = {23},
issn = {1047-7047},
shorttitle = {Design {Principles} of {Integrated} {Information} {Platform} for {Emergency} {Responses}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.1110.0387},
doi = {10.1287/isre.1110.0387},
abstract = {This paper investigates the challenges faced in designing an integrated information platform for emergency response management and uses the Beijing Olympic Games as a case study. The research methods are grounded in action research, participatory design, and situation-awareness oriented design. The completion of a more than two-year industrial secondment and six-month field studies ensured that a full understanding of user requirements had been obtained. A service-centered architecture was proposed to satisfy these user requirements. The proposed architecture consists mainly of information gathering, database management, and decision support services. The decision support services include situational overview, instant risk assessment, emergency response preplan, and disaster development prediction. Abstracting from the experience obtained while building this system, we outline a set of design principles in the general domain of information systems (IS) development for emergency management. These design principles form a contribution to the information systems literature because they provide guidance to developers who are aiming to support emergency response and the development of such systems that have not yet been adequately met by any existing types of IS. We are proud that the information platform developed was deployed in the real world and used in the 2008 Beijing Olympic Games.},
number = {3-part-1},
urldate = {2021-04-08},
journal = {Information Systems Research},
author = {Yang, Lili and Su, Guofeng and Yuan, Hongyong},
month = nov,
year = {2011},
note = {Publisher: INFORMS},
pages = {761--786},
}

@article{beydoun_disaster_2018,
title = {Disaster {Management} and {Information} {Systems}: {Insights} to {Emerging} {Challenges}},
volume = {20},
issn = {1572-9419},
shorttitle = {Disaster {Management} and {Information} {Systems}},
url = {https://doi.org/10.1007/s10796-018-9871-6},
doi = {10.1007/s10796-018-9871-6},
language = {en},
number = {4},
urldate = {2021-04-08},
journal = {Information Systems Frontiers},
author = {Beydoun, Ghassan and Dascalu, Sergiu and Dominey-Howes, Dale and Sheehan, Andrew},
month = aug,
year = {2018},
pages = {649--652},
}

@misc{noauthor_call_nodate,
title = {Call for {Papers} {\textbar} {Information} {Systems} {Research}},
url = {https://pubsonline.informs.org/page/isre/calls-for-papers},
abstract = {Available calls for papers to the Informations Systems Research journal.},
language = {en},
urldate = {2021-04-08},
}

@inproceedings{vieweg_microblogging_2010,
address = {New York, NY, USA},
series = {{CHI} '10},
title = {Microblogging {During} {Two} {Natural} {Hazards} {Events}: {What} {Twitter} {May} {Contribute} to {Situational} {Awareness}},
isbn = {978-1-60558-929-9},
shorttitle = {Microblogging {During} {Two} {Natural} {Hazards} {Events}},
url = {http://doi.acm.org/10.1145/1753326.1753486},
doi = {10.1145/1753326.1753486},
abstract = {We analyze microblog posts generated during two recent, concurrent emergency events in North America via Twitter, a popular microblogging service. We focus on communications broadcast by people who were "on the ground" during the Oklahoma Grassfires of April 2009 and the Red River Floods that occurred in March and April 2009, and identify information that may contribute to enhancing situational awareness (SA). This work aims to inform next steps for extracting useful, relevant information during emergencies using information extraction (IE) techniques.},
booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
publisher = {ACM},
author = {Vieweg, Sarah and Hughes, Amanda L. and Starbird, Kate and Palen, Leysia},
year = {2010},
keywords = {computer-mediated communication, crisis informatics, disaster, emergency, hazards, microblogging, research ideas, situational awareness},
pages = {1079--1088},
}

@article{xiao_tell_2020,
title = {Tell {Me} {About} {Yourself}: {Using} an {AI}-{Powered} {Chatbot} to {Conduct} {Conversational} {Surveys} with {Open}-ended {Questions}},
volume = {27},
issn = {1073-0516},
shorttitle = {Tell {Me} {About} {Yourself}},
url = {https://doi.org/10.1145/3381804},
doi = {10.1145/3381804},
abstract = {The rise of increasingly more powerful chatbots offers a new way to collect information through conversational surveys, where a chatbot asks open-ended questions, interprets a user’s free-text responses, and probes answers whenever needed. To investigate the effectiveness and limitations of such a chatbot in conducting surveys, we conducted a field study involving about 600 participants. In this study with mostly open-ended questions, half of the participants took a typical online survey on Qualtrics and the other half interacted with an AI-powered chatbot to complete a conversational survey. Our detailed analysis of over 5,200 free-text responses revealed that the chatbot drove a significantly higher level of participant engagement and elicited significantly better quality responses measured by Gricean Maxims in terms of their informativeness, relevance, specificity, and clarity. Based on our results, we discuss design implications for creating AI-powered chatbots to conduct effective surveys and beyond.},
number = {3},
urldate = {2021-03-13},
journal = {ACM Transactions on Computer-Human Interaction},
author = {Xiao, Ziang and Zhou, Michelle X. and Liao, Q. Vera and Mark, Gloria and Chi, Changyan and Chen, Wenxi and Yang, Huahai},
month = jun,
year = {2020},
keywords = {Conversational agent, chatbot, open-ended questions, read here, survey},
pages = {15:1--15:37},
}

@misc{brownlee_how_2019,
title = {How to {Choose} a {Feature} {Selection} {Method} {For} {Machine} {Learning}},
url = {https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/},
abstract = {Feature selection is the process of reducing the number of input variables when developing a predictive model. It is desirable to reduce the number of input variables to both reduce the computational cost of modeling and, in some cases, to improve the performance of the model. Statistical-based feature selection methods involve evaluating the relationship between […]},
language = {en-US},
urldate = {2021-03-08},
journal = {Machine Learning Mastery},
author = {Brownlee, Jason},
month = nov,
year = {2019},
}

@article{khaire_stability_2019,
title = {Stability of feature selection algorithm: {A} review},
issn = {1319-1578},
shorttitle = {Stability of feature selection algorithm},
url = {https://www.sciencedirect.com/science/article/pii/S1319157819304379},
doi = {10.1016/j.jksuci.2019.06.012},
abstract = {Feature selection technique is a knowledge discovery tool which provides an understanding of the problem through the analysis of the most relevant features. Feature selection aims at building better classifier by listing significant features which also helps in reducing computational overload. Due to existing high throughput technologies and their recent advancements are resulting in high dimensional data due to which feature selection is being treated as handy and mandatory in such datasets. This actually questions the interpretability and stability of traditional feature selection algorithms. The high correlation in features frequently produces multiple equally optimal signatures, which makes traditional feature selection method unstable and thus leading to instability which reduces the confidence of selected features. Stability is the robustness of the feature preferences it produces to perturbation of training samples. Stability indicates the reproducibility power of the feature selection method. High stability of the feature selection algorithm is equally important as the high classification accuracy when evaluating feature selection performance. In this paper, we provide an overview of feature selection techniques and instability of the feature selection algorithm. We also present some of the solutions which can handle the different source of instability.},
language = {en},
urldate = {2021-03-08},
journal = {Journal of King Saud University - Computer and Information Sciences},
author = {Khaire, Utkarsh Mahadeo and Dhanalakshmi, R.},
month = jun,
year = {2019},
keywords = {Feature selection, Instability, Knowledge discovery, Perturbation, Robustness, Stability},
}

@misc{admin_building_2018,
title = {Building {Recurrent} {Neural} {Networks} in {Tensorflow}},
url = {https://ataspinar.com/2018/07/05/building-recurrent-neural-networks-in-tensorflow/},
abstract = {[latexpage] Introduction In the previous blog posts we have seen how we can build Convolutional Neural Networks in Tensorflow and also how we can use Stochastic Signal Analysis techniques to classi…},
language = {nl},
urldate = {2021-01-28},
journal = {Ahmet Taspinar},
author = {{admin}},
month = jul,
year = {2018},
}

@misc{noauthor_deep_nodate,
title = {Deep {Learning} for {Signal} {Processing}: {What} {You} {Need} to {Know}},
shorttitle = {Deep {Learning} for {Signal} {Processing}},
url = {https://www.kdnuggets.com/deep-learning-for-signal-processing-what-you-need-to-know.html/},
abstract = {Signal Processing is a branch of electrical engineering that models and analyzes data representations of physical events. It is at the core of the digital world. And now, signal processing is starting to make some waves in deep learning.},
language = {en-US},
urldate = {2021-01-27},
journal = {KDnuggets},
}

@article{zeiler_visualizing_2013,
title = {Visualizing and {Understanding} {Convolutional} {Networks}},
url = {http://arxiv.org/abs/1311.2901},
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky {\textbackslash}etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
urldate = {2021-01-24},
journal = {arXiv:1311.2901 [cs]},
author = {Zeiler, Matthew D. and Fergus, Rob},
month = nov,
year = {2013},
note = {arXiv: 1311.2901
version: 3},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{noh_learning_2015,
title = {Learning {Deconvolution} {Network} for {Semantic} {Segmentation}},
url = {http://arxiv.org/abs/1505.04366},
abstract = {We propose a novel semantic segmentation algorithm by learning a deconvolution network. We learn the network on top of the convolutional layers adopted from VGG 16-layer net. The deconvolution network is composed of deconvolution and unpooling layers, which identify pixel-wise class labels and predict segmentation masks. We apply the trained network to each proposal in an input image, and construct the final semantic segmentation map by combining the results from all proposals in a simple manner. The proposed algorithm mitigates the limitations of the existing methods based on fully convolutional networks by integrating deep deconvolution network and proposal-wise prediction; our segmentation method typically identifies detailed structures and handles objects in multiple scales naturally. Our network demonstrates outstanding performance in PASCAL VOC 2012 dataset, and we achieve the best accuracy (72.5\%) among the methods trained with no external data through ensemble with the fully convolutional network.},
urldate = {2021-01-24},
journal = {arXiv:1505.04366 [cs]},
author = {Noh, Hyeonwoo and Hong, Seunghoon and Han, Bohyung},
month = may,
year = {2015},
note = {arXiv: 1505.04366},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{simonyan_very_2015,
title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
url = {http://arxiv.org/abs/1409.1556},
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
urldate = {2021-01-24},
journal = {arXiv:1409.1556 [cs]},
author = {Simonyan, Karen and Zisserman, Andrew},
month = apr,
year = {2015},
note = {arXiv: 1409.1556
version: 6},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{jaderberg_spatial_2016,
title = {Spatial {Transformer} {Networks}},
url = {http://arxiv.org/abs/1506.02025},
abstract = {Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.},
urldate = {2021-01-24},
journal = {arXiv:1506.02025 [cs]},
author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
month = feb,
year = {2016},
note = {arXiv: 1506.02025},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{karpathy_deep_2015,
title = {Deep {Visual}-{Semantic} {Alignments} for {Generating} {Image} {Descriptions}},
url = {http://arxiv.org/abs/1412.2306},
abstract = {We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions significantly outperform retrieval baselines on both full images and on a new dataset of region-level annotations.},
urldate = {2021-01-24},
journal = {arXiv:1412.2306 [cs]},
author = {Karpathy, Andrej and Fei-Fei, Li},
month = apr,
year = {2015},
note = {arXiv: 1412.2306
version: 2},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{ren_faster_2016,
title = {Faster {R}-{CNN}: {Towards} {Real}-{Time} {Object} {Detection} with {Region} {Proposal} {Networks}},
shorttitle = {Faster {R}-{CNN}},
url = {http://arxiv.org/abs/1506.01497},
abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
urldate = {2021-01-24},
journal = {arXiv:1506.01497 [cs]},
author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
month = jan,
year = {2016},
note = {arXiv: 1506.01497
version: 3},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{girshick_fast_2015,
title = {Fast {R}-{CNN}},
url = {http://arxiv.org/abs/1504.08083},
abstract = {This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn.},
urldate = {2021-01-24},
journal = {arXiv:1504.08083 [cs]},
author = {Girshick, Ross},
month = sep,
year = {2015},
note = {arXiv: 1504.08083},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{girshick_rich_2014,
title = {Rich feature hierarchies for accurate object detection and semantic segmentation},
url = {http://arxiv.org/abs/1311.2524},
abstract = {Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30\% relative to the previous best result on VOC 2012---achieving a mAP of 53.3\%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also compare R-CNN to OverFeat, a recently proposed sliding-window detector based on a similar CNN architecture. We find that R-CNN outperforms OverFeat by a large margin on the 200-class ILSVRC2013 detection dataset. Source code for the complete system is available at http://www.cs.berkeley.edu/{\textasciitilde}rbg/rcnn.},
urldate = {2021-01-24},
journal = {arXiv:1311.2524 [cs]},
author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
month = oct,
year = {2014},
note = {arXiv: 1311.2524
version: 5},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{szegedy_going_2015,
address = {Boston, MA, USA},
title = {Going deeper with convolutions},
isbn = {978-1-4673-6964-0},
url = {http://ieeexplore.ieee.org/document/7298594/},
doi = {10.1109/CVPR.2015.7298594},
abstract = {We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classiﬁcation and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classiﬁcation and detection.},
language = {en},
urldate = {2021-01-24},
booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
publisher = {IEEE},
author = {Szegedy, Christian and {Wei Liu} and {Yangqing Jia} and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
month = jun,
year = {2015},
pages = {1--9},
}

@article{piris_customer_2021,
title = {Customer satisfaction and natural language processing},
volume = {124},
issn = {0148-2963},
url = {http://www.sciencedirect.com/science/article/pii/S0148296320308249},
doi = {10.1016/j.jbusres.2020.11.065},
abstract = {This study uses natural language processing in order to increase knowledge concerning customer satisfaction. A total of 12,000 customer returns were analyzed, 6,800 of which contained freely expressed qualitative feedback. Eight themes emerge from the analysis and bring to light the factors influencing satisfaction. It is also noted that satisfaction is not vertical or horizontal but can involve a more or less important combination of themes. This study also shows the link between the level of satisfaction and the number of themes addressed, thus challenging traditional approaches that do not seem to distinguish the discursive differences between satisfied and dissatisfied customers. Finally, this investigation lays the foundations for automatic and personalized processing of customer comments.},
language = {en},
urldate = {2021-01-15},
journal = {Journal of Business Research},
author = {Piris, Yolande and Gay, Anne-Cécile},
month = jan,
year = {2021},
keywords = {Artificial intelligence, Customer experience, Customer voice, NLP, Satisfaction},
pages = {264--271},
}

@misc{deshpande_beginners_nodate,
title = {A {Beginner}'s {Guide} {To} {Understanding} {Convolutional} {Neural} {Networks}},
url = {https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/},
abstract = {Don't worry, it's easier than it looks},
urldate = {2021-01-15},
author = {Deshpande, Adit},
}

@misc{noauthor_using_nodate,
title = {Using continuous verses discrete wavelet transform in digital applications - {Signal} {Processing} {Stack} {Exchange}},
url = {https://dsp.stackexchange.com/questions/8009/using-continuous-verses-discrete-wavelet-transform-in-digital-applications},
urldate = {2020-12-19},
}

@misc{noauthor_using_nodate-1,
title = {Using continuous verses discrete wavelet transform in digital applications},
url = {https://dsp.stackexchange.com/questions/8009/using-continuous-verses-discrete-wavelet-transform-in-digital-applications},
urldate = {2020-12-18},
journal = {Signal Processing Stack Exchange},
}

@article{lee_persona_2020,
title = {{PERSONA}: {Personality}-{Based} {Deep} {Learning} for {Detecting} {Hate} {Speech}},
abstract = {Hate speech in an online environment has detrimental impacts on the wellbeing of individuals, online communities, and social network platforms. Consequently, the automated detection of hate speech has become a significant issue for various stakeholders. While previous studies have proposed many approaches for this issue, we find an important research gap that they have neglected a plethora of studies from psychology investigating the relationship between personality and hate. To fill the gap, we adopt a text-mining approach which fully automates the process of personality inference. Based its results, we build a personality-based deep learning model for detecting online hate speech (i.e., PERSONA). We validated our model with two real-world cases. The results show that our model significantly outperforms state-of-the-art baselines including a method proposed by Google. Our study paves the way for future research by incorporating psychological aspects into the design of a deep-learning model for hate speech detection.},
language = {en},
author = {Lee, Kyuhan and Ram, Sudha},
year = {2020},
pages = {18},
}

@article{misiti_wavelet_1996,
title = {Wavelet toolbox user’s guide},
journal = {The Math Works Inc},
author = {Misiti, Michel and Misiti, Yves and Oppenheim, Georges and Poggi, Jean-Michel},
year = {1996},
}

@article{lepine_editors_2010,
title = {Editors' comments: {Developing} {Novel} {Theoretical} {Insight} from {Reviews} of {Existing} {Theory} and {Research}},
volume = {35},
issn = {0363-7425},
shorttitle = {Editors' comments},
url = {https://journals.aom.org/doi/abs/10.5465/amr.35.4.zok506},
doi = {10.5465/amr.35.4.zok506},
number = {4},
urldate = {2020-12-12},
journal = {Academy of Management Review},
author = {LePine, Jeffery A. and King, Adelaide Wilcox},
month = oct,
year = {2010},
note = {Publisher: Academy of Management},
pages = {506--509},
}

@article{rivard_editors_2014,
title = {Editor's {Comments}:  {The} {Ions} of {Theory} {Construction}},
volume = {38},
issn = {ISSN 0276-7783/ISSN 2162-9730},
shorttitle = {Editor's {Comments}},
url = {https://aisel.aisnet.org/misq/vol38/iss2/2},
number = {2},
journal = {Management Information Systems Quarterly},
author = {Rivard, Suzanne},
month = jun,
year = {2014},
pages = {iii--xiii},
}

@article{lewis_metatriangulation_1999,
title = {Metatriangulation: {Building} {Theory} from {Multiple} {Paradigms}},
volume = {24},
issn = {0363-7425},
shorttitle = {Metatriangulation},
url = {https://www.jstor.org/stable/259348},
doi = {10.2307/259348},
abstract = {Multiparadigm approaches aid exploration of particularly complex and paradoxical phenomena by helping theorists employ disparate theoretical perspectives. In this article we provide an extensive guide to multiparadigm exemplars and then link their varied approaches within a metatriangulation theory-building strategy. Our process addresses the challenges theorists face as they select a research topic, collect and analyze data, theorize, and evaluate resulting theory using multiple paradigms. A concluding discussion of the advantages, limitations, and potential applications of metatriangulation positions it within the wider realm of organization theory.},
number = {4},
urldate = {2020-12-12},
journal = {The Academy of Management Review},
author = {Lewis, Marianne W. and Grimes, Andrew J.},
year = {1999},
note = {Publisher: Academy of Management},
pages = {672--690},
}

@article{poole_using_1989,
title = {Using {Paradox} to {Build} {Management} and {Organization} {Theories}},
volume = {14},
issn = {0363-7425},
url = {https://www.jstor.org/stable/258559},
doi = {10.2307/258559},
abstract = {Most contemporary theory construction methodologies attempt to build internally consistent theories of limited scope. Relatively little attention has been paid to the opportunities offered by tensions, oppositions, and contradictions among explanations of the same phenomenon. This essay attempts to spell out a set of theory-building strategies to help researchers take advantage of theoretical tensions. Such tensions can be regarded as paradoxes of social theory, and four different modes of working with paradoxes can be distinguished: (1) accept the paradox and use it constructively; (2) clarify levels of analysis; (3) temporally separate the two levels; and (4) introduce new terms to resolve the paradox. These four modes of paradox resolution are illustrated by application to the action::structure paradox in organizational theory.},
number = {4},
urldate = {2020-12-12},
journal = {The Academy of Management Review},
author = {Poole, Marshall Scott and van de Ven, Andrew H.},
year = {1989},
note = {Publisher: Academy of Management},
pages = {562--578},
}

@article{shepherd_inductive_2011,
title = {{INDUCTIVE} {TOP}-{DOWN} {THEORIZING}: {A} {SOURCE} {OF} {NEW} {THEORIES} {OF} {ORGANIZATION}},
volume = {36},
issn = {0363-7425},
shorttitle = {{INDUCTIVE} {TOP}-{DOWN} {THEORIZING}},
url = {https://www.jstor.org/stable/41318005},
abstract = {Building on coherence theory and a pragmatist tradition, we offer an inductive model of top-down theorizing that can be a source of new theories of organization. We explain how an initial hypothesis is refined to enhance its potential contribution (consistent with abduction). But, unlike abduction, we explain how inquiry begins—how research tensions are carved out of the flux of the vast literature—and how constant comparison facilitates an abductive process.},
number = {2},
urldate = {2020-12-12},
journal = {The Academy of Management Review},
author = {SHEPHERD, DEAN A. and SUTCLIFFE, KATHLEEN M.},
year = {2011},
note = {Publisher: Academy of Management},
pages = {361--380},
}

@article{corley_building_2011,
title = {Building {Theory} about {Theory} {Building}: {What} {Constitutes} a {Theoretical} {Contribution}?},
volume = {36},
issn = {0363-7425},
shorttitle = {Building {Theory} about {Theory} {Building}},
url = {https://journals.aom.org/doi/10.5465/amr.2009.0486},
doi = {10.5465/amr.2009.0486},
abstract = {We distill existing literature on theoretical contribution into two dimensions, originality (incremental or revelatory) and utility (scientific or practical). We argue for a revision in the way scholars approach the utility dimension by calling for a view of theorizing that would enable theories with more “scope” (both scientific and practical utility). We also argue for an orientation toward “prescience” as a way of achieving scope and fulfilling our scholarly role of facilitating organizational and societal adaptiveness.},
number = {1},
urldate = {2020-12-12},
journal = {Academy of Management Review},
author = {Corley, Kevin G. and Gioia, Dennis A.},
month = jan,
year = {2011},
note = {Publisher: Academy of Management},
pages = {12--32},
}

@article{suddaby_editors_2010,
title = {Editor's {Comments}: {Construct} {Clarity} in {Theories} of {Management} and {Organization}},
volume = {35},
issn = {0363-7425},
shorttitle = {Editor's {Comments}},
url = {https://journals.aom.org/doi/abs/10.5465/amr.35.3.zok346},
doi = {10.5465/amr.35.3.zok346},
number = {3},
urldate = {2020-12-12},
journal = {Academy of Management Review},
author = {Suddaby, Roy},
month = jul,
year = {2010},
note = {Publisher: Academy of Management},
pages = {346--357},
}

@article{leidner_care_nodate,
title = {The {CARE} {Theory} of {Dignity} {Amid} {Personal} {Data} {Digitalization}},
author = {Leidner, Dorothy E. and Tona, Olgerta},
}

@article{gregory_role_2020,
title = {The {Role} of {Artificial} {Intelligence} and {Data} {Network} {Effects} for {Creating} {User} {Value}},
issn = {0363-7425},
url = {https://journals.aom.org/doi/abs/10.5465/amr.2019.0178},
doi = {10.5465/amr.2019.0178},
abstract = {Some of the world’s most profitable firms own platforms that exhibit network effects. A platform exhibits network effects if the more people that use it, the more valuable that it becomes to each user. Theorizing about the value perceived by users of a platform that exhibits network effects has traditionally focused on direct and indirect network effects. In this paper, we theorize about a third type of network effects—data network effects—that has emerged from advances in artificial intelligence (AI) and the growing availability of data. A platform exhibits data network effects if the more that the platform learns from the data it collects on users, the more valuable the platform becomes to each user. We argue that there is a positive direct relationship between the AI capability of a platform and the value perceived in the platform by its users—a relationship that is moderated by platform legitimation, data stewardship and user-centric design.},
urldate = {2020-12-12},
journal = {Academy of Management Review},
author = {Gregory, Robert Wayne and Henfridsson, Ola and Kaganer, Evgeny and Kyriakou, Harris},
month = mar,
year = {2020},
note = {Publisher: Academy of Management},
}

@book{burrus_wavelets_nodate,
title = {Wavelets and {Wavelet} {Transforms}},
language = {en},
author = {Burrus, C Sidney},
}

@book{addison_illustrated_2017,
address = {Boca Raton, FL},
edition = {Second edition},
title = {The illustrated wavelet transform handbook: introductory theory and applications in science, engineering, medicine and finance},
isbn = {978-1-4822-5132-6},
shorttitle = {The illustrated wavelet transform handbook},
abstract = {"The Illustrated Wavelet Transform Handbook: Introductory Theory and Applications in Science, Engineering, Medicine and Finance 2e provides an overview of the theory and practical applications of wavelet transform methods. It uniquely covers continuous as well as discrete transforms. The author uses several hundred illustrations, some in color, to convey mathematical concepts and the results of applications. This second edition reflects numerous recent developments across a wide range of areas, with a particular focus on finance, ECG, geophysics, and astronomy"--},
language = {en},
publisher = {CRC Press, Taylor \& Francis Group},
author = {Addison, Paul S.},
year = {2017},
keywords = {Biomedical engineering, Fourier analysis, Wavelets (Mathematics)},
}

@article{fujieda_wavelet_2018,
title = {Wavelet {Convolutional} {Neural} {Networks}},
url = {http://arxiv.org/abs/1805.08620},
abstract = {Spatial and spectral approaches are two major approaches for image processing tasks such as image classification and object recognition. Among many such algorithms, convolutional neural networks (CNNs) have recently achieved significant performance improvement in many challenging tasks. Since CNNs process images directly in the spatial domain, they are essentially spatial approaches. Given that spatial and spectral approaches are known to have different characteristics, it will be interesting to incorporate a spectral approach into CNNs. We propose a novel CNN architecture, wavelet CNNs, which combines a multiresolution analysis and CNNs into one model. Our insight is that a CNN can be viewed as a limited form of a multiresolution analysis. Based on this insight, we supplement missing parts of the multiresolution analysis via wavelet transform and integrate them as additional components in the entire architecture. Wavelet CNNs allow us to utilize spectral information which is mostly lost in conventional CNNs but useful in most image processing tasks. We evaluate the practical performance of wavelet CNNs on texture classification and image annotation. The experiments show that wavelet CNNs can achieve better accuracy in both tasks than existing models while having significantly fewer parameters than conventional CNNs.},
urldate = {2020-12-04},
journal = {arXiv:1805.08620 [cs]},
author = {Fujieda, Shin and Takayama, Kohei and Hachisuka, Toshiya},
month = may,
year = {2018},
note = {arXiv: 1805.08620},
keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{liu_multi-level_2019,
title = {Multi-level {Wavelet} {Convolutional} {Neural} {Networks}},
url = {http://arxiv.org/abs/1907.03128},
abstract = {In computer vision, convolutional networks (CNNs) often adopts pooling to enlarge receptive field which has the advantage of low computational complexity. However, pooling can cause information loss and thus is detrimental to further operations such as features extraction and analysis. Recently, dilated filter has been proposed to trade off between receptive field size and efficiency. But the accompanying gridding effect can cause a sparse sampling of input images with checkerboard patterns. To address this problem, in this paper, we propose a novel multi-level wavelet CNN (MWCNN) model to achieve better trade-off between receptive field size and computational efficiency. The core idea is to embed wavelet transform into CNN architecture to reduce the resolution of feature maps while at the same time, increasing receptive field. Specifically, MWCNN for image restoration is based on U-Net architecture, and inverse wavelet transform (IWT) is deployed to reconstruct the high resolution (HR) feature maps. The proposed MWCNN can also be viewed as an improvement of dilated filter and a generalization of average pooling, and can be applied to not only image restoration tasks, but also any CNNs requiring a pooling operation. The experimental results demonstrate effectiveness of the proposed MWCNN for tasks such as image denoising, single image super-resolution, JPEG image artifacts removal and object classification.},
urldate = {2020-12-04},
journal = {arXiv:1907.03128 [cs, eess]},
author = {Liu, Pengju and Zhang, Hongzhi and Lian, Wei and Zuo, Wangmeng},
month = jul,
year = {2019},
note = {arXiv: 1907.03128},
keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{dai_document_2015,
title = {Document {Embedding} with {Paragraph} {Vectors}},
url = {http://arxiv.org/abs/1507.07998},
abstract = {Paragraph Vectors has been recently proposed as an unsupervised method for learning distributed representations for pieces of texts. In their work, the authors showed that the method can learn an embedding of movie review texts which can be leveraged for sentiment analysis. That proof of concept, while encouraging, was rather narrow. Here we consider tasks other than sentiment analysis, provide a more thorough comparison of Paragraph Vectors to other document modelling algorithms such as Latent Dirichlet Allocation, and evaluate performance of the method as we vary the dimensionality of the learned representation. We benchmarked the models on two document similarity data sets, one from Wikipedia, one from arXiv. We observe that the Paragraph Vector method performs significantly better than other methods, and propose a simple improvement to enhance embedding quality. Somewhat surprisingly, we also show that much like word embeddings, vector operations on Paragraph Vectors can perform useful semantic results.},
urldate = {2020-12-02},
journal = {arXiv:1507.07998 [cs]},
author = {Dai, Andrew M. and Olah, Christopher and Le, Quoc V.},
month = jul,
year = {2015},
note = {arXiv: 1507.07998},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{benoit_improving_2012,
title = {Improving customer retention in financial services using kinship network information},
volume = {39},
issn = {0957-4174},
url = {http://www.sciencedirect.com/science/article/pii/S0957417412006136},
doi = {10.1016/j.eswa.2012.04.016},
abstract = {This study investigates the advantage of social network mining in a customer retention context. A company that is able to identify likely churners in an early stage can take appropriate steps to prevent these potential churners from actually churning and subsequently increase profit. Academics and practitioners are constantly trying to optimize their predictive-analytics models by searching for better predictors. The aim of this study is to investigate if, in addition to the conventional sets of variables (socio-demographics, purchase history, etc.), kinship network based variables improve the predictive power of customer retention models. Results show that the predictive power of the churn model can indeed be improved by adding the social network (SNA-) based variables. Including network structure measures (i.e. degree, betweenness centrality and density) increase predictive accuracy, but contextual network based variables turn out to have the highest impact on discriminating churners from non-churners. For the majority of the latter type of network variables, the importance in the model is even higher than the individual level counterpart variable.},
language = {en},
number = {13},
urldate = {2020-12-02},
journal = {Expert Systems with Applications},
author = {Benoit, Dries F. and Van den Poel, Dirk},
month = oct,
year = {2012},
keywords = {CRM, Financial services, Kinship network, Network based marketing, Predictive analytics, Random forests, Social network analysis (SNA)},
pages = {11435--11442},
}

@article{rai_editors_2016,
title = {Editor's {Comments}:  {Writing} a {Virtuous} {Review}},
volume = {40},
issn = {ISSN 0276-7783/ISSN 2162-9730},
shorttitle = {Editor's {Comments}},
url = {https://aisel.aisnet.org/misq/vol40/iss3/2},
number = {3},
journal = {Management Information Systems Quarterly},
author = {Rai, Arun},
month = sep,
year = {2016},
pages = {iii--x},
}

@article{rai_editors_2019,
title = {Editor's {Comments}: the first revision},
volume = {43},
issn = {0276-7783},
shorttitle = {Editor's {Comments}},
number = {3},
journal = {MIS Quarterly},
author = {Rai, Arun},
month = sep,
year = {2019},
pages = {iii--viii},
}

@misc{cdc_icd-9-cm_2011,
title = {{ICD}-9-{CM} {Official} {Guidelines} for {Coding} and {Reporting}},
url = {https://www.cdc.gov/nchs/data/icd/icd9cm_guidelines_2011.pdf},
language = {English},
author = {CDC},
month = oct,
year = {2011},
}

@book{little_machine_2019,
title = {Machine {Learning} for {Signal} {Processing}: {Data} {Science}, {Algorithms}, and {Computational} {Statistics}},
isbn = {978-0-19-102431-3},
shorttitle = {Machine {Learning} for {Signal} {Processing}},
abstract = {This book describes in detail the fundamental mathematics and algorithms of machine learning (an example of artificial intelligence) and signal processing, two of the most important and exciting technologies in the modern information economy. Taking a gradual approach, it builds up concepts in a solid, step-by-step fashion so that the ideas and algorithms can be implemented in practical software applications. Digital signal processing (DSP) is one of the 'foundational' engineering topics of the modern world, without which technologies such the mobile phone, television, CD and MP3 players, WiFi and radar, would not be possible. A relative newcomer by comparison, statistical machine learning is the theoretical backbone of exciting technologies such as automatic techniques for car registration plate recognition, speech recognition, stock market prediction, defect detection on assembly lines, robot guidance, and autonomous car navigation. Statistical machine learning exploits the analogy between intelligent information processing in biological brains and sophisticated statistical modelling and inference. DSP and statistical machine learning are of such wide importance to the knowledge economy that both have undergone rapid changes and seen radical improvements in scope and applicability. Both make use of key topics in applied mathematics such as probability and statistics, algebra, calculus, graphs and networks. Intimate formal links between the two subjects exist and because of this many overlaps exist between the two subjects that can be exploited to produce new DSP tools of surprising utility, highly suited to the contemporary world of pervasive digital sensors and high-powered, yet cheap, computing hardware. This book gives a solid mathematical foundation to, and details the key concepts and algorithms in this important topic.},
language = {en},
publisher = {Oxford University Press},
author = {Little, Max A.},
month = aug,
year = {2019},
note = {Google-Books-ID: ejGoDwAAQBAJ},
keywords = {Computers / Computer Science, Computers / Intelligence (AI) \& Semantics, Science / Physics / General, Technology \& Engineering / Signals \& Signal Processing},
}

@article{markgraf_performance_2001,
title = {Performance of the score systems {Acute} {Physiology} and {Chronic} {Health} {Evaluation} {II} and {III} at an interdisciplinary intensive care unit, after customization},
volume = {5},
issn = {1364-8535},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC29054/},
abstract = {Background:
Mortality predictions calculated using scoring scales are often not accurate in populations other than those in which the scales were developed because of differences in case-mix. The present study investigates the effect of first-level customization, using a logistic regression technique, on discrimination and calibration of the Acute Physiology and Chronic Health Evaluation (APACHE) II and III scales.

Method:
Probabilities of hospital death for patients were estimated by applying APACHE II and III and comparing these with observed outcomes. Using the split sample technique, a customized model to predict outcome was developed by logistic regression. The overall goodness-of-fit of the original and the customized models was assessed.

Results:
Of 3383 consecutive intensive care unit (ICU) admissions over 3 years, 2795 patients could be analyzed, and were split randomly into development and validation samples. The discriminative powers of APACHE II and III were unchanged by customization (areas under the receiver operating characteristic [ROC] curve 0.82 and 0.85, respectively). Hosmer-Lemeshow goodness-of-fit tests showed good calibration for APACHE II, but insufficient calibration for APACHE III. Customization improved calibration for both models, with a good fit for APACHE III as well. However, fit was different for various subgroups.

Conclusions:
The overall goodness-of-fit of APACHE III mortality prediction was improved significantly by customization, but uniformity of fit in different subgroups was not achieved. Therefore, application of the customized model provides no advantage, because differences in case-mix still limit comparisons of quality of care.},
number = {1},
urldate = {2020-11-20},
journal = {Critical Care},
author = {Markgraf, Rainer and Deutschinoff, Gerd and Pientka, Ludger and Scholten, Theo and Lorenz, Cristoph},
year = {2001},
pmid = {11178223},
pmcid = {PMC29054},
pages = {31--36},
}

@article{knaus_apache_1985,
title = {{APACHE} {II}: a severity of disease classification system},
volume = {13},
issn = {0090-3493},
shorttitle = {{APACHE} {II}},
abstract = {This paper presents the form and validation results of APACHE II, a severity of disease classification system. APACHE II uses a point score based upon initial values of 12 routine physiologic measurements, age, and previous health status to provide a general measure of severity of disease. An increasing score (range 0 to 71) was closely correlated with the subsequent risk of hospital death for 5815 intensive care admissions from 13 hospitals. This relationship was also found for many common diseases. When APACHE II scores are combined with an accurate description of disease, they can prognostically stratify acutely ill patients and assist investigators comparing the success of new or differing forms of therapy. This scoring index can be used to evaluate the use of hospital resources and compare the efficacy of intensive care in different hospitals or over time.},
language = {eng},
number = {10},
journal = {Critical Care Medicine},
author = {Knaus, W. A. and Draper, E. A. and Wagner, D. P. and Zimmerman, J. E.},
month = oct,
year = {1985},
pmid = {3928249},
keywords = {Acute Disease, Adult, Age Factors, Aged, Chronic Disease, Coronary Artery Bypass, Costs and Cost Analysis, Critical Care, Diagnosis-Related Groups, Disease, Humans, Middle Aged, Patient Admission, Prognosis, Risk, Surgical Procedures, Operative},
pages = {818--829},
}

@misc{noauthor_critical_nodate,
title = {Critical {Care} - {ClinCalc}.com},
url = {https://clincalc.com/CriticalCare/},
urldate = {2020-11-20},
}

@article{le_gall_new_1993,
title = {A new {Simplified} {Acute} {Physiology} {Score} ({SAPS} {II}) based on a {European}/{North} {American} multicenter study},
volume = {270},
issn = {0098-7484},
doi = {10.1001/jama.270.24.2957},
abstract = {OBJECTIVE: To develop and validate a new Simplified Acute Physiology Score, the SAPS II, from a large sample of surgical and medical patients, and to provide a method to convert the score to a probability of hospital mortality.
DESIGN AND SETTING: The SAPS II and the probability of hospital mortality were developed and validated using data from consecutive admissions to 137 adult medical and/or surgical intensive care units in 12 countries.
PATIENTS: The 13,152 patients were randomly divided into developmental (65\%) and validation (35\%) samples. Patients younger than 18 years, burn patients, coronary care patients, and cardiac surgery patients were excluded.
OUTCOME MEASURE: Vital status at hospital discharge.
RESULTS: The SAPS II includes only 17 variables: 12 physiology variables, age, type of admission (scheduled surgical, unscheduled surgical, or medical), and three underlying disease variables (acquired immunodeficiency syndrome, metastatic cancer, and hematologic malignancy). Goodness-of-fit tests indicated that the model performed well in the developmental sample and validated well in an independent sample of patients (P = .883 and P = .104 in the developmental and validation samples, respectively). The area under the receiver operating characteristic curve was 0.88 in the developmental sample and 0.86 in the validation sample.
CONCLUSION: The SAPS II, based on a large international sample of patients, provides an estimate of the risk of death without having to specify a primary diagnosis. This is a starting point for future evaluation of the efficiency of intensive care units.},
language = {eng},
number = {24},
journal = {JAMA},
author = {Le Gall, J. R. and Lemeshow, S. and Saulnier, F.},
month = dec,
year = {1993},
pmid = {8254858},
keywords = {Adult, Aged, Female, Hospital Mortality, Humans, Intensive Care Units, Male, Middle Aged, Probability, Severity of Illness Index},
pages = {2957--2963},
}

@article{halpern_critical_2010,
title = {Critical care medicine in the {United} {States} 2000-2005: an analysis of bed numbers, occupancy rates, payer mix, and costs},
volume = {38},
issn = {1530-0293},
shorttitle = {Critical care medicine in the {United} {States} 2000-2005},
doi = {10.1097/CCM.0b013e3181b090d0},
abstract = {OBJECTIVES: To analyze the evolving role, patterns of use, and costs of critical care medicine in the United States from 2000 to 2005.
DESIGN: Retrospective study of data from the Hospital Cost Report Information System (Centers for Medicare and Medicaid Services, Baltimore, Maryland).
SETTING: Nonfederal, acute care hospitals with critical care medicine beds in the United States.
SUBJECTS: None.
INTERVENTIONS: None.
MEASUREMENTS AND MAIN RESULTS: We analyzed hospital and critical care medicine beds, bed types, days, occupancy rates, payer mix (Medicare and Medicaid), and costs. Critical care medicine costs were compared with national cost indexes. Between 2000 and 2005, the total number of U.S. hospitals with critical care medicine beds decreased by 12.2\% (from 3,586 to 3,150). Although the number of hospital beds decreased by 4.2\% (from 655,785 to 628,409), both hospital days and occupancy rates increased by 5.1\% (from 145.1 to 152.5 million) and 13.7\% (from 59\% to 67\%), respectively. Critical care medicine beds increased by 6.5\% (from 88,252 to 93,955), days by 10.6\% (from 21.0 to 23.2 million), and occupancy rates by 4.5\% (from 65\% to 68\%). The majority (90\%) of critical care medicine beds were classified as intensive care, premature/neonatal, and coronary care unit beds. The percentage of critical care medicine days used by Medicare decreased by 3.8\% (from 37.9\% to 36.5\%) compared with an increase of 15.5\% (from 14.5\% to 16.8\%) by Medicaid. From 2000 to 2005, critical care medicine costs per day increased by 30.4\% (from \$2698 to \$3518). Although annual critical care medicine costs increased by 44.2\% (from \$56.6 to \$81.7 billion), the proportion of hospital costs and national health expenditures allocated to critical care medicine decreased by 1.6\% and 1.8\%, respectively. However, the proportion of the gross domestic product used by critical care medicine increased by 13.7\%. In 2005, critical care medicine costs represented 13.4\% of hospital costs, 4.1\% of national health expenditures, and 0.66\% of the gross domestic product.
CONCLUSIONS: Critical care medicine continues to grow in a shrinking U.S. hospital system. The critical care medicine payer mix is evolving, with Medicaid increasing in its percentage of critical care medicine use. Critical care medicine is more cost controlled than other healthcare indexes, but is still using an increasing percentage of the gross domestic product. Our updated and comprehensive critical care medicine use and cost analysis provides a contemporary benchmark for the strategic planning of critical care medicine services within the U.S. healthcare system.},
language = {eng},
number = {1},
journal = {Critical Care Medicine},
author = {Halpern, Neil A. and Pastores, Stephen M.},
month = jan,
year = {2010},
pmid = {19730257},
keywords = {Academic Medical Centers, Bed Occupancy, Cost Savings, Cost-Benefit Analysis, Critical Care, Emergency Medicine, Female, Health Care Surveys, Hospital Bed Capacity, Hospital Costs, Humans, Inpatients, Insurance, Health, Reimbursement, Male, Medicaid, Medicare, New York City, Patient Admission, Quality of Health Care, Retrospective Studies, United States},
pages = {65--71},
}

@article{rapoport_explaining_1990,
title = {Explaining {Variability} of {Cost} {Using} a {Severity}-of-{Illness} {Measure} for {ICU} {Patients}},
volume = {28},
issn = {0025-7079},
url = {https://journals.lww.com/lww-medicalcare/Abstract/1990/04000/Explaining_Variability_of_Cost_Using_a.5.aspx},
abstract = {Factors related to hospital resource use by intensive care unit (ICU) patients, including severity of illness at admission and intensity of therapy during the first 24 ICU hours were explored in this study. Analysis was based on 2,749 patients admitted to the general medical-surgical ICU at Baystate Medical Center, Springfield, Massachusetts, between February 1,1983 and January 10, 1985. Resource use was indexed by hospital length of stay (LOS) adjusted for differences between ICU and other hospital days. Severity of illness was measured by the Mortality Prediction Model (MPM0), a validated predictor of outcome but not previously used to analyze resource consumption. Intensity of therapy was measured using the Therapeutic Intervention Scoring System (TISS). The 10\% of patients with longest ICU stays were significantly different from the other 90\% with respect to previous ICU use, MPM probability, and TISS score. Variability in resource use was analyzed using four diagnosis-related groups (DRGs) accounting for large numbers of ICU patients. The relationship between severity of illness and resource use was nonlinear: as severity increased from low levels, resource use increased at a decreasing rate, reached a plateau, and eventually declined. Within each DRG, MPM0 explained a statistically significant percentage of the variability in resource use.
    © Lippincott-Raven Publishers.},
language = {en-US},
number = {4},
urldate = {2020-11-20},
journal = {Medical Care},
author = {Rapoport, John and Teres, Daniel and Lemeshow, Stanley and Avrunin, Jill Spitz and Haber, Russell},
month = apr,
year = {1990},
pages = {338--348},
}

@article{wu_icu_2002,
title = {{ICU} incident reporting systems},
volume = {17},
issn = {0883-9441},
url = {http://www.sciencedirect.com/science/article/pii/S088394410270004X},
doi = {10.1053/jcrc.2002.35100},
abstract = {Intensive care is one of the largest and most expensive components of American health care. Studies suggest that errors and resulting adverse events are common in intensive care units (ICUs). The incidence may be as high as 2 errors per patient per day; 1 in 5 ICU patients may sustain a serious adverse event, and virtually all are exposed to serious risk for harm. Theories of error developed in aviation and other high-risk industries suggest that errors are likely to occur in all complex systems. Reporting of incidents, including both adverse events and near misses, is an essential component for improving safety. Voluntary, confidential reporting is likely to be more important than mandatory reporting. There have been a few efforts to apply such systems in medicine. In intensive care, the Australian Incident Monitoring System (AIMS)-ICU has been the most prominent.We have designed a Web-based ICU Safety Reporting System (ICUSRS). The goal is to identify high-risk situations and working conditions, to help change systems, and reduce the risk for error. The analysis and feedback of reports will inform the design of interventions to improve patient safety. The effort is aided substantially by collaboration with the 30 participating ICUs and important stakeholders including the Society of Critical Care Medicine, the American Society for Health-care Risk Management, the Food and Drug Administration Center for Devices and Radiological Health, the Foundation for Accountability, and the Leapfrog Group. A demonstration and evaluation of the system is underway, funded by the Agency for Healthcare Re-search and Quality. Copyright 2002, Elsevier Science (USA). All rights reserved.},
language = {en},
number = {2},
urldate = {2020-11-20},
journal = {Journal of Critical Care},
author = {Wu, Albert W. and Pronovost, Peter and Morlock, Laura},
month = jun,
year = {2002},
pages = {86--94},
}

@article{pronovost_building_2002,
title = {Building safety into {ICU} care},
volume = {17},
issn = {0883-9441},
doi = {10.1053/jcrc.2002.34363},
abstract = {The Institute of Medicine's (IOMs) report, "To Err is Human," recently addressed patient safety in the United States, alerting the nation to the need for improved systems of health care. Seven main findings were addressed in this report, we focus on 3: (1) patient safety is a nationwide problem, (2) health care workers are not to blame, and (3) safety and harm are products of care systems. This article discusses systems in intensive care units (ICUs) and how these systems affect patient safety. We use a case example to outline the complex chain of medical and administrative system failures that can result in an adverse event. Then we discuss evidence linking ICU organizational characteristics with patient safety, focusing on how safer systems in ICUs can directly improve patient care.},
language = {eng},
number = {2},
journal = {Journal of Critical Care},
author = {Pronovost, Peter and Wu, Albert W. and Dorman, Todd and Morlock, Laura},
month = jun,
year = {2002},
pmid = {12096370},
keywords = {Aged, Humans, Intensive Care Units, Male, Medical Staff, Hospital, Medication Errors, Medication Systems, Hospital, Models, Organizational, Nursing Staff, Hospital, Outcome Assessment, Health Care, Personnel Staffing and Scheduling, Safety Management, Systems Analysis},
pages = {78--85},
}

@article{raza_accelerating_2020,
title = {Accelerating pattern-based time series classification: a linear time and space string mining approach},
volume = {62},
issn = {0219-3116},
shorttitle = {Accelerating pattern-based time series classification},
url = {https://doi.org/10.1007/s10115-019-01378-7},
doi = {10.1007/s10115-019-01378-7},
abstract = {Subsequences-based time series classification algorithms provide interpretable and generally more accurate classification models compared to the nearest neighbor approach, albeit at a considerably higher computational cost. A number of discretized time series-based algorithms have been proposed to reduce the computational complexity of these algorithms; however, the asymptotic time complexity of the proposed algorithms is also cubic or higher-order polynomial. We present a remarkably fast and resource-efficient time series classification approach which employs a linear time and space string mining algorithm for extracting frequent patterns from discretized time series data. Compared to other subsequence or pattern-based classification algorithms, the proposed approach only requires a few parameters, which can be chosen arbitrarily and do not require any fine-tuning for different datasets. The time series data are discretized using symbolic aggregate approximation, and frequent patterns are extracted using a string mining algorithm. An independence test is used to select the most discriminative frequent patterns, which are subsequently used to create a transformed version of the time series data. Finally, a classification model can be trained using any off-the-shelf algorithm. Extensive empirical evaluations demonstrate the competitive classification accuracy of our approach compared to other state-of-the-art approaches. The experiments also show that our approach is at least one to two orders of magnitude faster than the existing pattern-based methods due to the extremely fast frequent pattern extraction, which is the most computationally intensive process in pattern-based time series classification approaches.},
language = {en},
number = {3},
urldate = {2020-11-19},
journal = {Knowledge and Information Systems},
author = {Raza, Atif and Kramer, Stefan},
month = mar,
year = {2020},
pages = {1113--1141},
}

@misc{kim_predicting_2019,
title = {Predicting {Mortality} in the {ICU}},
url = {https://towardsdatascience.com/predicting-mortality-in-the-icu-2e4832cc94d2},
abstract = {Applying Modern Machine Learning Methods to SAPS I Data},
language = {en},
urldate = {2020-11-18},
journal = {Medium},
author = {Kim, Isaac},
month = sep,
year = {2019},
}

@inproceedings{nguyen_discovery_2003,
address = {Berlin, Heidelberg},
series = {Lecture {Notes} in {Computer} {Science}},
title = {Discovery of {Trends} and {States} in {Irregular} {Medical} {Temporal} {Data}},
isbn = {978-3-540-39644-4},
doi = {10.1007/978-3-540-39644-4_40},
abstract = {Temporal abstraction has been known as a powerful approach of data abstraction by converting temporal data into interval with abstracted values including trends and states. Most temporal abstraction methods, however, has been developed for regular temporal data, and they cannot be used when temporal data are collected irregularly. In this paper we introduced a temporal abstraction approach to irregular temporal data inspired from a real-life application of a large database in hepatitis domain.},
language = {en},
booktitle = {Discovery {Science}},
publisher = {Springer},
author = {Nguyen, Trong Dung and Kawasaki, Saori and Ho, Tu Bao},
editor = {Grieser, Gunter and Tanaka, Yuzuru and Yamamoto, Akihiro},
year = {2003},
keywords = {Abstraction Method, Change Test, Data Mining System, Interferon Therapy, Temporal Abstraction},
pages = {410--417},
}

@misc{noauthor_jais_nodate,
title = {{JAIS} style for authors},
}

@article{lehman_physiological_2015,
title = {A {Physiological} {Time} {Series} {Dynamics}-{Based} {Approach} to {Patient} {Monitoring} and {Outcome} {Prediction}},
volume = {19},
issn = {2168-2194, 2168-2208},
url = {http://ieeexplore.ieee.org/document/6846269/},
doi = {10.1109/JBHI.2014.2330827},
abstract = {Cardiovascular variables such as heart rate (HR) and blood pressure (BP) are regulated by an underlying control system, and therefore the time series of these vital signs exhibit rich dynamical patterns of interaction in response to external perturbations (e.g., drug administration) as well as pathological states (e.g., onset of sepsis and hypotension). A question of interest is whether “similar” dynamical patterns can be identiﬁed across a heterogeneous patient cohort, and be used for prognosis of patients’ health and progress. In this work, we used a switching vector autoregressive (SVAR) framework to systematically learn and identify a collection of vital sign time series dynamics, which are possibly recurrent within the same patient and may be shared across the entire cohort. We show that these dynamical behaviors can be used to characterize the physiological “state” of a patient. We validate our technique using simulated time series of the cardiovascular system, and human recordings of HR and BP time series from an orthostatic stress study with known postural states. Using the HR and BP dynamics of an intensive care unit (ICU) cohort of over 450 patients from the MIMIC II database, we demonstrate that the discovered cardiovascular dynamics are signiﬁcantly associated with hospital mortality (dynamic modes 3 and 9, p = 0.001, p = 0.006 from logistic regression after adjusting for the APACHE scores). Combining the dynamics of BP time series and SAPS-I or APACHE-III provided a more accurate assessment of patient survival/mortality in the hospital than using SAPS-I and APACHE-III alone (p = 0.005 and p = 0.045). Our results suggest that the discovered dynamics of vital sign time series may contain additional prognostic value beyond that of the baseline acuity measures, and can potentially be used as an independent predictor of outcomes in the ICU.},
language = {en},
number = {3},
urldate = {2020-11-16},
journal = {IEEE Journal of Biomedical and Health Informatics},
author = {Lehman, Li-wei H. and Adams, Ryan P. and Mayaud, Louis and Moody, George B. and Malhotra, Atul and Mark, Roger G. and Nemati, Shamim},
month = may,
year = {2015},
keywords = {Adult, Algorithms, Blood Pressure, Databases, Factual, Female, Health Status Indicators, Heart Rate, Hospital Mortality, Humans, Intensive Care Units, Male, Medical Informatics, Models, Statistical, Monitoring, Physiologic, Prognosis, Reproducibility of Results, Tilt-Table Test},
pages = {1068--1076},
}

@article{celi_eicu_2001,
title = {The {eICU}: {It}’s not just telemedicine},
volume = {29},
issn = {0090-3493},
shorttitle = {The {eICU}},
url = {https://journals.lww.com/ccmjournal/Fulltext/2001/08001/The_eICU__It_s_not_just_telemedicine.7.aspx?casa_token=Gk2V2BCz8-sAAAAA:Klr7NU4QK8-hbl062O3zrHJ2lkBPorFJj-N7Ghf7JYsyQH7pn1hME6qK2REElkPd7HzS45bDIfVYb4K-396YuzXWRTM},
abstract = {Intensive care units (ICUs) are major sites for medical errors and adverse events. Suboptimal outcomes reflect a widespread failure to implement care delivery systems that successfully address the complexity of modern ICUs. Whereas other industries have used information technologies to fundamentally improve operating efficiency and enhance safety, medicine has been slow to implement such strategies. Most ICUs do not even track performance; fewer still have the capability to examine clinical data and use this information to guide quality improvement initiatives. This article describes a technology-enabled care model (electronic ICU, or eICU) that represents a new paradigm for delivery of critical care services. A major component of the model is the use of telemedicine to leverage clinical expertise and facilitate a round-the-clock proactive care by intensivist-led teams of ICU caregivers. Novel data presentation formats, computerized decision support, and smart alarms are used to enhance efficiency, increase effectiveness, and standardize clinical and operating processes. In addition, the technology infrastructure facilitates performance improvement by providing an automated means to measure outcomes, track performance, and monitor resource utilization. The program is designed to support the multidisciplinary intensivist-led team model and incorporates comprehensive ICU re-engineering efforts to change practice behavior. Although this model can transform ICUs into centers of excellence, success will hinge on hospitals accepting the underlying value proposition and physicians being willing to change established practices.},
language = {en-US},
number = {8},
urldate = {2020-11-15},
journal = {Critical Care Medicine},
author = {Celi, Leo Anthony and Hassan, Erkan and Marquardt, Cynthia and Breslow, Michael and Rosenfeld, Brian},
month = aug,
year = {2001},
pages = {N183},
}

@article{kuzniewicz_variation_2008,
title = {Variation in {ICU} risk-adjusted mortality: impact of methods of assessment and potential confounders},
volume = {133},
issn = {0012-3692},
shorttitle = {Variation in {ICU} risk-adjusted mortality},
doi = {10.1378/chest.07-3061},
abstract = {BACKGROUND: Federal and state agencies are considering ICU performance assessment and public reporting; however, an accurate method for measuring performance must be selected. In this study, we determine whether a substantial variation in ICU mortality performance still exists in modern ICUs, and compare the predictive accuracy, reliability, and data burden of existing ICU risk-adjustment models.
METHODS: A retrospective chart review of 11,300 ICU patients from 35 California hospitals from 2001 to 2004 was performed. We calculated standardized mortality ratios (SMRs) for each hospital using the mortality probability model III (MPM(0) III), the simplified acute physiology score (SAPS) II, and the acute physiology and chronic health evaluation (APACHE) IV risk-adjustment models. We compared discrimination, calibration, data reliability, and abstraction time for the models.
RESULTS: Regardless of the model used, there was a large variation in SMRs among the ICUs studied. The discrimination and calibration were adequate for all risk-adjustment models. APACHE IV had the best discrimination (area under the receiver operating characteristic curve [AUC], 0.892) compared to MPM(0) III (AUC, 0.809), and SAPS II (AUC, 0.873; p {\textless} 0.001). The models differed substantially in data abstraction times, as follows: MPM(0)III, 11.1 min (95\% confidence interval [CI], 8.7 to 13.4); SAPS II, 19.6 min (95\% CI, 17.0 to 22.2); and APACHE IV, 37.3 min (95\% CI, 28.0 to 46.6).
CONCLUSIONS: We found substantial variation in the ICU risk-adjusted mortality rates that persisted regardless of the risk-adjustment model. With unlimited resources, the APACHE IV model offers the best predictive accuracy. If constrained by cost and manual data collection, the MPM(0) III model offers a viable alternative without a substantial loss in accuracy.},
language = {eng},
number = {6},
journal = {Chest},
author = {Kuzniewicz, Michael W. and Vasilevskis, Eduard E. and Lane, Rondall and Dean, Mitzi L. and Trivedi, Nisha G. and Rennie, Deborah J. and Clay, Ted and Kotler, Pamela L. and Dudley, R. Adams},
month = jun,
year = {2008},
pmid = {18403657},
keywords = {APACHE, Aged, California, Confounding Factors, Epidemiologic, Female, Hospital Mortality, Humans, Intensive Care Units, Male, Medical Records, Middle Aged, Models, Theoretical, Multicenter Studies as Topic, Quality Assurance, Health Care, Retrospective Studies, Risk Assessment},
pages = {1319--1327},
}

@misc{noauthor_simplified_nodate,
title = {Simplified {Acute} {Physiology} {Score} ({SAPS} {II}) {Calculator} - {ClinCalc}.com},
url = {https://clincalc.com/IcuMortality/SAPSII.aspx},
urldate = {2020-11-15},
}

@article{vasilevskis_mortality_2009,
title = {Mortality {Probability} {Model} {III} and {Simplified} {Acute} {Physiology} {Score} {II}},
volume = {136},
issn = {0012-3692},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3198495/},
doi = {10.1378/chest.08-2591},
abstract = {Background:
To develop and compare ICU length-of-stay (LOS) risk-adjustment models using three commonly used mortality or LOS prediction models.

Methods:
Between 2001 and 2004, we performed a retrospective, observational study of 11,295 ICU patients from 35 hospitals in the California Intensive Care Outcomes Project. We compared the accuracy of the following three LOS models: a recalibrated acute physiology and chronic health evaluation (APACHE) IV-LOS model; and models developed using risk factors in the mortality probability model III at zero hours (MPM0) and the simplified acute physiology score (SAPS) II mortality prediction model. We evaluated models by calculating the following: (1) grouped coefficients of determination; (2) differences between observed and predicted LOS across subgroups; and (3) intraclass correlations of observed/expected LOS ratios between models.

Results:
The grouped coefficients of determination were APACHE IV with coefficients recalibrated to the LOS values of the study cohort (APACHE IVrecal) [R2 = 0.422], mortality probability model III at zero hours (MPM0 III) [R2 = 0.279], and simplified acute physiology score (SAPS II) [R2 = 0.008]. For each decile of predicted ICU LOS, the mean predicted LOS vs the observed LOS was significantly different (p ≤ 0.05) for three, two, and six deciles using APACHE IVrecal, MPM0 III, and SAPS II, respectively. Plots of the predicted vs the observed LOS ratios of the hospitals revealed a threefold variation in LOS among hospitals with high model correlations.

Conclusions:
APACHE IV and MPM0 III were more accurate than SAPS II for the prediction of ICU LOS. APACHE IV is the most accurate and best calibrated model. Although it is less accurate, MPM0 III may be a reasonable option if the data collection burden or the treatment effect bias is a consideration.},
number = {1},
urldate = {2020-11-15},
journal = {Chest},
author = {Vasilevskis, Eduard E. and Kuzniewicz, Michael W. and Cason, Brian A. and Lane, Rondall K. and Dean, Mitzi L. and Clay, Ted and Rennie, Deborah J. and Vittinghoff, Eric and Dudley, R. Adams},
month = jul,
year = {2009},
pmid = {19363210},
pmcid = {PMC3198495},
pages = {89--101},
}

@article{bouch_severity_2008,
title = {Severity scoring systems in the critically ill},
volume = {8},
issn = {1743-1816},
url = {https://academic.oup.com/bjaed/article/8/5/181/268370},
doi = {10.1093/bjaceaccp/mkn033},
abstract = {Scoring systems for use in intensive care unit (ICU) patients have been introduced and developed over the last 30 years. They allow an assessment of the severit},
language = {en},
number = {5},
urldate = {2020-11-15},
journal = {Continuing Education in Anaesthesia Critical Care \& Pain},
author = {Bouch, D. Christopher and Thompson, Jonathan P.},
month = oct,
year = {2008},
note = {Publisher: Oxford Academic},
pages = {181--185},
}

@article{nemati_interpretable_2018,
title = {An {Interpretable} {Machine} {Learning} {Model} for {Accurate} {Prediction} of {Sepsis} in the {ICU}},
volume = {46},
issn = {0090-3493},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5851825/},
doi = {10.1097/CCM.0000000000002936},
abstract = {OBJECTIVE
Sepsis is among the leading causes of morbidity, mortality, and cost overruns in critically ill patients. Early intervention with antibiotics improves survival in septic patients. However, no clinically validated system exists for real-time prediction of sepsis onset. We aimed to develop and validate an Artificial Intelligence Sepsis Expert (AISE) algorithm for early prediction of sepsis.

DESIGN
Observational cohort study.

SETTING
Academic medical center from January 2013 to December 2015.

PATIENTS
Over 31,000 admissions to the intensive care units (ICUs) at two Emory University hospitals (development cohort), in addition to over 52,000 ICU patients from the publicly available MIMIC-III ICU database (validation cohort). Patients who met the Third International Consensus Definitions for Sepsis (sepsis-3) prior to or within 4 hours of their ICU admission were excluded, resulting in roughly 27,000 and 42,000 patients within our development and validation cohorts, respectively.

INTERVENTIONS
None

MEASUREMENTS and MAIN RESULTS
High-resolution vital signs time series and Electronic Medical Record (EMR) data were extracted. A set of 65 features (variables) were calculated on hourly basis and passed to the AISE algorithm to predict onset of sepsis in the proceeding T hours (where T = 12, 8, 6 or 4). AISE was used to predict onset of sepsis in the proceeding T hours, and to produce a list of the most significant contributing factors. For the 12-hour, 8-hour, 6-hour, and 4-hour ahead prediction of sepsis, AISE achieved area under the receiver operating characteristic (AUROC) in the range of 0.83–0.85. Performance of the AISE on the development and validation cohorts were indistinguishable.

CONCLUSION
Using data available in the ICU in real-time, AISE can accurately predict the onset of sepsis in an ICU patient 4 to 12 hours prior to clinical recognition. A prospective study is necessary to determine the clinical utility of the proposed sepsis prediction model.},
number = {4},
urldate = {2020-11-15},
journal = {Critical care medicine},
author = {Nemati, Shamim and Holder, Andre and Razmi, Fereshteh and Stanley, Matthew D. and Clifford, Gari D. and Buchman, Timothy G.},
month = apr,
year = {2018},
pmid = {29286945},
pmcid = {PMC5851825},
pages = {547--553},
}

@article{lemeshow_mortality_1994,
title = {Mortality probability models for patients in the intensive care unit for 48 or 72 hours: {A} prospective, multicenter study},
volume = {22},
issn = {0090-3493},
shorttitle = {Mortality probability models for patients in the intensive care unit for 48 or 72 hours},
url = {https://journals.lww.com/ccmjournal/Abstract/1994/09000/Mortality_probability_models_for_patients_in_the.3.aspx},
abstract = {Objective 
    To develop models in the Mortality Probability Model (MPM II) system to estimate the probability of hospital mortality at 48 and 72 hrs in the intensive care unit (ICU), and to test whether the 24-hr Mortality Probability Model (MPM24), developed for use at 24 hrs in the ICU, can be used on a daily basis beyond 24 hrs.
    Design 
    A prospective, multicenter study to develop and validate models, using a cohort of consecutive admissions.
    Setting 
    Six adult medical and surgical ICUs in Massachusetts and New York adjusted to reflect 137 ICUs in 12 countries.
    Patients 
    Consecutive admissions (n = 6,290) to the Massachusetts/New York ICUs were studied. Of these patients, 3,023 and 2,233 patients remained in the ICU and had complete data at 48 and 72 hrs, respectively. Patients {\textless}18 yrs of age, burn patients, coronary care patients, and cardiac surgical patients were excluded.
    Outcome Measure 
    Vital status at the time of hospital discharge.
    Results 
    The models consist of five variables measured at the time of ICU admission and eight variables ascertained at 24-hr intervals. The 24-hr model demonstrated poor calibration and discrimination at 48 and 72 hrs. The newly developed 48− and 72-hr models—MPM48 and MPM72—contain the same 13 variables and coefficients as the MPM24. The models differ only in their constant terms, which increase in a manner that reflects the increasing probability of mortality with increasing length of stay in the ICU. These constant terms were adjusted by a factor determined from the relationship between the data from the six Massachusetts and New York ICUs and a more extensive data set, from which the ICU admission Mortality Probability Model (MPM0) and MPM24 were developed. This latter data set was assembled from ICUs in 12 countries. The MPM48 and MPM72 calibrated and discriminated well, based on goodness-of-fit tests and area under the receiver operating characteristic curve.
    Conclusions 
    Models developed for use among ICU patients at one time period are not transferable without modification to other time periods. The MPM48 and MPM72 calibrated well to their respective time periods, and they are intended for use at specific points in time. The increasing constant terms and associated increase in the probability of hospital mortality exemplify a common clinical adage that if a patient's clinical profile stays the same, he or she is actually getting worse. (Crit Care Med 1994; 22:1351–1358)},
language = {en-US},
number = {9},
urldate = {2020-11-15},
journal = {Critical Care Medicine},
author = {Lemeshow, Stanley and Klar, Janelle and Teres, Daniel and Avrunin, Jill Spitz and Gehlbach, Stephen H. and Rapoport, John and Rué, Montse},
month = sep,
year = {1994},
pages = {1351--1358},
}

@article{barnato_value_2004,
title = {Value and role of intensive care unit outcome prediction models in end-of-life decision making},
volume = {20},
issn = {0749-0704, 1557-8232},
url = {https://www.criticalcare.theclinics.com/article/S0749-0704(04)00005-3/abstract},
doi = {10.1016/j.ccc.2004.03.002},
abstract = {In 1999, one out of every five Americans died in the hospital using intensive care,
and terminal admissions associated with intensive care unit (ICU) admission consumed
80\% of all terminal hospitalization costs [1]. Most of these ICU decedents are over
age 65. Indeed, the proportion of fee-for-service Medicare beneficiaries with one
or more ICU admissions in the last year of life increased from 30.5\% in 1985 to 35\%
in 1999 [2]. High levels of ICU use at the end of life attract policy attention because
of the concern that this care is futile and, hence, wasteful. Yet, these high levels
of use are identified retrospectively. The challenge is to predict prospectively which
patients will not survive despite ICU care, and for whom averting or interrupting
an ICU stay is an acceptable goal. Many mortality prediction models currently exist;
how are we to measure the value of these models for informing the utility of ICU care?
First, we would expect the prediction tool to be highly reliable. Second, it would
have to be available in a timely fashion to inform the decision both to initiate and
to continue intensive care. Third, it would have to offer predictions about the outcomes
in which patients are most interested. Fourth, it would have to influence clinician
behavior. Finally, it would have to help patients and families receive care that is
consistent with their preferences.},
language = {English},
number = {3},
urldate = {2020-11-15},
journal = {Critical Care Clinics},
author = {Barnato, Amber E. and Angus, Derek C.},
month = jul,
year = {2004},
pmid = {15183207},
note = {Publisher: Elsevier},
pages = {345--362},
}

@article{power_why_2014,
title = {Why try to predict {ICU} outcomes?},
volume = {20},
issn = {1070-5295},
url = {https://journals.lww.com/co-criticalcare/Abstract/2014/10000/Why_try_to_predict_ICU_outcomes_.13.aspx},
doi = {10.1097/MCC.0000000000000136},
abstract = {Purpose of review 
    To describe why the prediction of ICU outcomes is essential to underpin critical care quality improvement programmes.
    Recent findings 
    Recent literature demonstrates that risk-adjusted mortality is a widely used and well-accepted quality indicator for benchmarking ICU performance. Ongoing research continues to address the best ways to present the results of benchmarking through either direct comparison among institutions (e.g., by funnel plots) or indirect comparison against the risk predictions from a risk model (e.g., by process control charts). There is also ongoing research and debate regarding event-based outcomes (e.g., hospital mortality) versus time-based outcomes (e.g., 30-day mortality). Beyond benchmarking, ICU outcome prediction models have a role in risk adjustment and risk stratification in randomized controlled trials, and adjusting for confounding in nonrandomized, observational research. Recent examples include comparing risk-adjusted outcomes according to ‘capacity strain’ on the ICU and extending propensity matching methods to evaluate outcomes of patients managed with a pulmonary artery catheter, among others. Risk models may have a role in communicating risk, but their utility for individual patient decision-making is limited.
    Summary 
    Risk-adjusted mortality has strong support from the critical care community as a quality indicator for benchmarking ICU performance but is dependent on up-to-date, accurate risk models. ICU outcome prediction can also contribute to both randomized and nonrandomized research and potentially contribute to individual patient management, although generic risk models should not be used to guide individual treatment decisions.},
language = {en-US},
number = {5},
urldate = {2020-11-15},
journal = {Current Opinion in Critical Care},
author = {Power, G. Sarah and Harrison, David A.},
month = oct,
year = {2014},
pages = {544--549},
}

@article{zimmerman_history_2014,
title = {A history of outcome prediction in the {ICU}},
volume = {20},
issn = {1070-5295},
url = {https://journals.lww.com/co-criticalcare/Abstract/2014/10000/A_history_of_outcome_prediction_in_the_ICU.14.aspx},
doi = {10.1097/MCC.0000000000000138},
abstract = {Purpose of review 
    There are few first-hand accounts that describe the history of outcome prediction in critical care. This review summarizes the authors’ personal perspectives about the development and evolution of Acute Physiology and Chronic Health Evaluation over the past 35 years.
    Recent findings 
    We emphasize what we have learned in the past and more recently our perspectives about the current status of outcome prediction, and speculate about the future of outcome prediction.
    Summary 
    There is increasing evidence that superior accuracy in outcome prediction requires complex modeling with detailed adjustment for diagnosis and physiologic abnormalities. Thus, an automated electronic system is recommended for gathering data and generating predictions. Support, either public or private, is required to assist users and to update and improve models. Current outcome prediction models have increasingly focused on benchmarks for resource use, a trend that seems likely to increase in the future.},
language = {en-US},
number = {5},
urldate = {2020-11-15},
journal = {Current Opinion in Critical Care},
author = {Zimmerman, Jack E. and Kramer, Andrew A.},
month = oct,
year = {2014},
pages = {550--556},
}

@misc{noauthor_icu_nodate,
title = {{ICU} {Outcomes}},
url = {https://healthpolicy.ucsf.edu/icu-outcomes},
language = {en},
urldate = {2020-11-14},
journal = {Philip R. Lee Institute for Health Policy Studies},
}

@article{rusu_progressive_2016,
title = {Progressive {Neural} {Networks}},
url = {http://arxiv.org/abs/1606.04671},
abstract = {Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting--remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy.},
urldate = {2020-11-14},
journal = {arXiv:1606.04671 [cs]},
author = {Rusu, Andrei A. and Rabinowitz, Neil C. and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
month = sep,
year = {2016},
note = {arXiv: 1606.04671},
keywords = {Computer Science - Machine Learning},
}

@article{desautels_prediction_2016,
title = {Prediction of {Sepsis} in the {Intensive} {Care} {Unit} {With} {Minimal} {Electronic} {Health} {Record} {Data}: {A} {Machine} {Learning} {Approach}},
volume = {4},
issn = {2291-9694},
shorttitle = {Prediction of {Sepsis} in the {Intensive} {Care} {Unit} {With} {Minimal} {Electronic} {Health} {Record} {Data}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5065680/},
doi = {10.2196/medinform.5909},
abstract = {Background
Sepsis is one of the leading causes of mortality in hospitalized patients. Despite this fact, a reliable means of predicting sepsis onset remains elusive. Early and accurate sepsis onset predictions could allow more aggressive and targeted therapy while maintaining antimicrobial stewardship. Existing detection methods suffer from low performance and often require time-consuming laboratory test results.

Objective
To study and validate a sepsis prediction method, InSight, for the new Sepsis-3 definitions in retrospective data, make predictions using a minimal set of variables from within the electronic health record data, compare the performance of this approach with existing scoring systems, and investigate the effects of data sparsity on InSight performance.

Methods
We apply InSight, a machine learning classification system that uses multivariable combinations of easily obtained patient data (vitals, peripheral capillary oxygen saturation, Glasgow Coma Score, and age), to predict sepsis using the retrospective Multiparameter Intelligent Monitoring in Intensive Care (MIMIC)-III dataset, restricted to intensive care unit (ICU) patients aged 15 years or more. Following the Sepsis-3 definitions of the sepsis syndrome, we compare the classification performance of InSight versus quick sequential organ failure assessment (qSOFA), modified early warning score (MEWS), systemic inflammatory response syndrome (SIRS), simplified acute physiology score (SAPS) II, and sequential organ failure assessment (SOFA) to determine whether or not patients will become septic at a fixed period of time before onset. We also test the robustness of the InSight system to random deletion of individual input observations.

Results
In a test dataset with 11.3\% sepsis prevalence, InSight produced superior classification performance compared with the alternative scores as measured by area under the receiver operating characteristic curves (AUROC) and area under precision-recall curves (APR). In detection of sepsis onset, InSight attains AUROC = 0.880 (SD 0.006) at onset time and APR = 0.595 (SD 0.016), both of which are superior to the performance attained by SIRS (AUROC: 0.609; APR: 0.160), qSOFA (AUROC: 0.772; APR: 0.277), and MEWS (AUROC: 0.803; APR: 0.327) computed concurrently, as well as SAPS II (AUROC: 0.700; APR: 0.225) and SOFA (AUROC: 0.725; APR: 0.284) computed at admission (P{\textless}.001 for all comparisons). Similar results are observed for 1-4 hours preceding sepsis onset. In experiments where approximately 60\% of input data are deleted at random, InSight attains an AUROC of 0.781 (SD 0.013) and APR of 0.401 (SD 0.015) at sepsis onset time. Even with 60\% of data missing, InSight remains superior to the corresponding SIRS scores (AUROC and APR, P{\textless}.001), qSOFA scores (P=.0095; P{\textless}.001) and superior to SOFA and SAPS II computed at admission (AUROC and APR, P{\textless}.001), where all of these comparison scores (except InSight) are computed without data deletion.

Conclusions
Despite using little more than vitals, InSight is an effective tool for predicting sepsis onset and performs well even with randomly missing data.},
number = {3},
urldate = {2019-09-04},
journal = {JMIR Medical Informatics},
author = {Desautels, Thomas and Calvert, Jacob and Hoffman, Jana and Jay, Melissa and Kerem, Yaniv and Shieh, Lisa and Shimabukuro, David and Chettipally, Uli and Feldman, Mitchell D and Barton, Chris and Wales, David J and Das, Ritankar},
month = sep,
year = {2016},
pmid = {27694098},
pmcid = {PMC5065680},
}

@inproceedings{korosi_mooc_2020,
address = {Singapore},
series = {Communications in {Computer} and {Information} {Science}},
title = {{MOOC} {Performance} {Prediction} by {Deep} {Learning} from {Raw} {Clickstream} {Data}},
isbn = {9789811566349},
doi = {10.1007/978-981-15-6634-9_43},
abstract = {Student performance prediction is a challenging problem in online education. One of the key issues relating to the quality Massive Open Online Courses (MOOC) teaching is the issue of how to foretell student performance in the future during the initial phases of education. While the fame of MOOCs has been rapidly increasing, there is a growing interest in scalable automated support technologies for student learning. Researchers have implemented numerous different Machine Learning algorithms in order to find suitable solutions to this problem. The main concept was to manually design features through cumulating daily, weekly or monthly user log data and use standard Machine Learners, like SVM, LOGREG or MLP. Deep learning algorithms could give us new opportunities, as we can apply them directly on raw input data, and we could spare the most time-consuming process of feature engineering. Based on our extensive literature survey, recent deep learning publications on MOOC sequences are based on cumulated data, i.e. on fine-engineered features. The main contribution of this paper is using raw log-line-level data as our input without any feature engineering and Recurrent Neural Networks (RNN) to predict student performance at the end of the MOOC course. We used the Stanford Lagunita’s dataset, consisting of log-level data of 130000 students and compared the RNN model based on raw data to standard classifiers using hand-crafted commulated features. The experimental results presented in this paper indicate the RNN’s dominance given its dependably superior performance as compared with the standard method. As far as we know, this will be the first work to use deep learning to predict student performance from raw log-line level students’ clickstream sequences in an online course.},
language = {en},
booktitle = {Advances in {Computing} and {Data} {Sciences}},
publisher = {Springer},
author = {Kőrösi, Gábor and Farkas, Richard},
editor = {Singh, Mayank and Gupta, P. K. and Tyagi, Vipin and Flusser, Jan and Ören, Tuncer and Valentino, Gianluca},
year = {2020},
keywords = {Clickstream sequence analysis, MOOC, RNN, read here},
pages = {474--485},
}

@article{mccoy_reducing_2017,
title = {Reducing patient mortality, length of stay and readmissions through machine learning-based sepsis prediction in the emergency department, intensive care unit and hospital floor units},
volume = {6},
copyright = {© Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://www.bmj.com/company/products-services/rights-and-licensing/ . This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/},
issn = {2399-6641},
url = {https://bmjopenquality.bmj.com/content/6/2/e000158},
doi = {10.1136/bmjoq-2017-000158},
abstract = {Introduction Sepsis management is a challenge for hospitals nationwide, as severe sepsis carries high mortality rates and costs the US healthcare system billions of dollars each year. It has been shown that early intervention for patients with severe sepsis and septic shock is associated with higher rates of survival. The Cape Regional Medical Center (CRMC) aimed to improve sepsis-related patient outcomes through a revised sepsis management approach.
Methods In collaboration with Dascena, CRMC formed a quality improvement team to implement a machine learning-based sepsis prediction algorithm to identify patients with sepsis earlier. Previously, CRMC assessed all patients for sepsis using twice-daily systemic inflammatory response syndrome screenings, but desired improvements. The quality improvement team worked to implement a machine learning-based algorithm, collect and incorporate feedback, and tailor the system to current hospital workflow.
Results Relative to the pre-implementation period, the post-implementation period sepsis-related in-hospital mortality rate decreased by 60.24\%, sepsis-related hospital length of stay decreased by 9.55\% and sepsis-related 30-day readmission rate decreased by 50.14\%.
Conclusion The machine learning-based sepsis prediction algorithm improved patient outcomes at CRMC.},
language = {en},
number = {2},
urldate = {2020-11-14},
journal = {BMJ Open Quality},
author = {McCoy, Andrea and Das, Ritankar},
month = oct,
year = {2017},
note = {Publisher: British Medical Journal Publishing Group
Section: BMJ Quality Improvement Report},
keywords = {PDSA, information technology, quality improvement},
pages = {e000158},
}

@article{shimabukuro_effect_2017,
title = {Effect of a machine learning-based severe sepsis prediction algorithm on patient survival and hospital length of stay: a randomised clinical trial},
volume = {4},
copyright = {© Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2017. All rights reserved. No commercial use is permitted unless otherwise expressly granted.. This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/},
issn = {2052-4439},
shorttitle = {Effect of a machine learning-based severe sepsis prediction algorithm on patient survival and hospital length of stay},
url = {https://bmjopenrespres.bmj.com/content/4/1/e000234},
doi = {10.1136/bmjresp-2017-000234},
abstract = {Introduction Several methods have been developed to electronically monitor patients for severe sepsis, but few provide predictive capabilities to enable early intervention; furthermore, no severe sepsis prediction systems have been previously validated in a randomised study. We tested the use of a machine learning-based severe sepsis prediction system for reductions in average length of stay and in-hospital mortality rate.
Methods We conducted a randomised controlled clinical trial at two medical-surgical intensive care units at the University of California, San Francisco Medical Center, evaluating the primary outcome of average length of stay, and secondary outcome of in-hospital mortality rate from December 2016 to February 2017. Adult patients (18+) admitted to participating units were eligible for this factorial, open-label study. Enrolled patients were assigned to a trial arm by a random allocation sequence. In the control group, only the current severe sepsis detector was used; in the experimental group, the machine learning algorithm (MLA) was also used. On receiving an alert, the care team evaluated the patient and initiated the severe sepsis bundle, if appropriate. Although participants were randomly assigned to a trial arm, group assignments were automatically revealed for any patients who received MLA alerts.
Results Outcomes from 75 patients in the control and 67 patients in the experimental group were analysed. Average length of stay decreased from 13.0 days in the control to 10.3 days in the experimental group (p=0.042). In-hospital mortality decreased by 12.4 percentage points when using the MLA (p=0.018), a relative reduction of 58.0\%. No adverse events were reported during this trial.
Conclusion The MLA was associated with improved patient outcomes. This is the first randomised controlled trial of a sepsis surveillance system to demonstrate statistically significant differences in length of stay and in-hospital mortality.
Trial registration NCT03015454.},
language = {en},
number = {1},
urldate = {2020-11-14},
journal = {BMJ Open Respiratory Research},
author = {Shimabukuro, David W. and Barton, Christopher W. and Feldman, Mitchell D. and Mataraso, Samson J. and Das, Ritankar},
month = nov,
year = {2017},
note = {Publisher: Archives of Disease in childhood
Section: Critical care},
keywords = {alerts, electronic health records, machine learning, patient monitoring, prediction, sepsis, severe sepsis},
pages = {e000234},
}

@article{gultepe_vital_2014,
title = {From vital signs to clinical outcomes for patients with sepsis: a machine learning basis for a clinical decision support system},
volume = {21},
issn = {1067-5027},
shorttitle = {From vital signs to clinical outcomes for patients with sepsis},
url = {https://academic.oup.com/jamia/article/21/2/315/723976},
doi = {10.1136/amiajnl-2013-001815},
abstract = {Abstract. Objective To develop a decision support system to identify patients at high risk for hyperlactatemia based upon routinely measured vital signs and lab},
language = {en},
number = {2},
urldate = {2020-11-14},
journal = {Journal of the American Medical Informatics Association},
author = {Gultepe, Eren and Green, Jeffrey P. and Nguyen, Hien and Adams, Jason and Albertson, Timothy and Tagkopoulos, Ilias},
month = mar,
year = {2014},
note = {Publisher: Oxford Academic},
pages = {315--325},
}

@article{tennila_early_2000,
title = {Early signs of critical illness polyneuropathy in {ICU} patients with systemic inflammatory response syndrome or sepsis},
volume = {26},
issn = {1432-1238},
url = {https://doi.org/10.1007/s001340000586},
doi = {10.1007/s001340000586},
abstract = {Objective: To evaluate with electromyography the incidence and the time of appearance of neuromuscular abnormality in patients with systemic inflammatory response syndrome (SIRS) and/or sepsis.},
language = {en},
number = {9},
urldate = {2020-11-14},
journal = {Intensive Care Medicine},
author = {Tennilä, A. and Salmi, T. and Pettilä, V. and Roine, R.O. and Varpula, T. and Takkunen, O.},
month = sep,
year = {2000},
pages = {1360--1363},
}

@article{subotin_method_2015,
title = {A {Method} for {Modeling} {Co}-{Occurrence} {Propensity} of {Clinical} {Codes} with {Application} to {ICD}-10-{PCS} {Auto}-{Coding}},
volume = {23},
doi = {10.1093/jamia/ocv201},
abstract = {Objective: 
Natural language processing methods for medical auto-coding, or automatic generation of medical billing codes from electronic health records, generally assign each code independently of the others. They may thus assign codes for closely related procedures or diagnoses to the same document, even when they do not tend to occur together in practice, simply because the right choice can be difficult to infer from the clinical narrative.

Methods:
We propose a method that injects awareness of the propensities for code co-occurrence into this process. First, a model is trained to estimate the conditional probability that one code is assigned by a human coder, given than another code is known to have been assigned to the same document. Then, at runtime, an iterative algorithm is used to apply this model to the output of an existing statistical auto-coder to modify the confidence scores of the codes.

Results:
We tested this method in combination with a primary auto-coder for International Statistical Classification of Diseases-10 procedure codes, achieving a 12\% relative improvement in F-score over the primary auto-coder baseline. The proposed method can be used, with appropriate features, in combination with any auto-coder that generates codes with different levels of confidence.

Conclusions:
The promising results obtained for International Statistical Classification of Diseases-10 procedure codes suggest that the proposed method may have wider applications in auto-coding.},
journal = {Journal of the American Medical Informatics Association},
author = {Subotin, Michael and Davis, Anthony},
month = oct,
year = {2015},
}

@misc{noauthor_interpreting_nodate,
title = {Interpreting the numeric results},
url = {cloud.ibm.com/docs/personality-insights},
language = {en},
urldate = {2020-11-07},
}

@misc{noauthor_personality_nodate,
title = {Personality models},
url = {https://cloud.ibm.com/docs/personality-insights?topic=personality-insights-models},
urldate = {2020-11-07},
}

@misc{noauthor_service_nodate,
title = {The service in action},
url = {https://cloud.ibm.com/docs/personality-insights?topic=personality-insights-applied},
urldate = {2020-11-06},
}

@article{botelho_developing_2019,
title = {Developing {Early} {Detectors} of {Student} {Attrition} and {Wheel} {Spinning} {Using} {Deep} {Learning}},
volume = {12},
issn = {1939-1382},
doi = {10.1109/TLT.2019.2912162},
abstract = {The increased usage of computer-based learning platforms and online tools in classrooms presents new opportunities to not only study the underlying constructs involved in the learning process, but also use this information to identify and aid struggling students. Many learning platforms, particularly those driving or supplementing instruction, are only able to provide aid to students who interact with the system. With this in mind, student persistence emerges as a prominent learning construct contributing to students success when learning new material. Conversely, high persistence is not always productive for students, where additional practice does not help the student move toward a state of mastery of the material. In this paper, we apply a transfer learning methodology using deep learning and traditional modeling techniques to study high and low representations of unproductive persistence. We focus on two prominent problems in the fields of educational data mining and learner analytics representing low persistence, characterized as student “stopout,” and unproductive high persistence, operationalized through student “wheel spinning,” in an effort to better understand the relationship between these measures of unproductive persistence (i.e., stopout and wheel spinning) and develop early detectors of these behaviors. We find that models developed to detect each within and across-assignment stopout and wheel spinning are able to learn sets of features that generalize to predict the other. We further observe how these models perform at each learning opportunity within student assignments to identify when interventions may be deployed to best aid students who are likely to exhibit unproductive persistence.},
number = {2},
journal = {IEEE Transactions on Learning Technologies},
author = {Botelho, A. F. and Varatharaj, A. and Patikorn, T. and Doherty, D. and Adjei, S. A. and Beck, J. E.},
month = apr,
year = {2019},
note = {Conference Name: IEEE Transactions on Learning Technologies},
keywords = {Deep learning, Detectors, Early detection, Education, Predictive models, Spinning, Task analysis, Wheels, across-assignment stopout, computer aided instruction, computer-based learning platforms, data analysis, data mining, deep learning, educational administrative data processing, educational courses, educational data mining, learner analytics, learning (artificial intelligence), neural nets, online tools, persistence, stopout, student assignments, student attrition, student persistence, student wheel spinning, students success, transfer learning, transfer learning methodology, wheel spinning, within-assignment stopout},
pages = {158--170},
}

@article{xu_multimodal_2019,
title = {Multimodal {Machine} {Learning} for {Automated} {ICD} {Coding}},
url = {http://arxiv.org/abs/1810.13348},
abstract = {This study presents a multimodal machine learning model to predict ICD-10 diagnostic codes. We developed separate machine learning models that can handle data from different modalities, including unstructured text, semi-structured text and structured tabular data. We further employed an ensemble method to integrate all modality-specific models to generate ICD-10 codes. Key evidence was also extracted to make our prediction more convincing and explainable. We used the Medical Information Mart for Intensive Care III (MIMIC -III) dataset to validate our approach. For ICD code prediction, our best-performing model (micro-F1 = 0.7633, micro-AUC = 0.9541) significantly outperforms other baseline models including TF-IDF (micro-F1 = 0.6721, micro-AUC = 0.7879) and Text-CNN model (micro-F1 = 0.6569, micro-AUC = 0.9235). For interpretability, our approach achieves a Jaccard Similarity Coefficient (JSC) of 0.1806 on text data and 0.3105 on tabular data, where well-trained physicians achieve 0.2780 and 0.5002 respectively.},
urldate = {2020-10-23},
journal = {arXiv:1810.13348 [cs, stat]},
author = {Xu, Keyang and Lam, Mike and Pang, Jingzhi and Gao, Xin and Band, Charlotte and MD, Piyush Mathur and MD, Frank Papay and MD, Ashish K. Khanna and MD, Jacek B. Cywinski and MD, Kamal Maheshwari and Xie, Pengtao and Xing, Eric},
month = aug,
year = {2019},
note = {arXiv: 1810.13348},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{xie_neural_2018,
address = {Melbourne, Australia},
title = {A {Neural} {Architecture} for {Automated} {ICD} {Coding}},
url = {https://www.aclweb.org/anthology/P18-1098},
doi = {10.18653/v1/P18-1098},
abstract = {The International Classification of Diseases (ICD) provides a hierarchy of diagnostic codes for classifying diseases. Medical coding – which assigns a subset of ICD codes to a patient visit – is a mandatory process that is crucial for patient care and billing. Manual coding is time-consuming, expensive, and error prone. In this paper, we build a neural architecture for automated coding. It takes the diagnosis descriptions (DDs) of a patient as inputs and selects the most relevant ICD codes. This architecture contains four major ingredients: (1) tree-of-sequences LSTM encoding of code descriptions (CDs), (2) adversarial learning for reconciling the different writing styles of DDs and CDs, (3) isotonic constraints for incorporating the importance order among the assigned codes, and (4) attentional matching for performing many-to-one and one-to-many mappings from DDs to CDs. We demonstrate the effectiveness of the proposed methods on a clinical datasets with 59K patient visits.},
urldate = {2020-10-19},
booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
publisher = {Association for Computational Linguistics},
author = {Xie, Pengtao and Xing, Eric},
month = jul,
year = {2018},
pages = {1066--1076},
}

@inproceedings{crossley_combining_2016,
address = {New York, NY, USA},
series = {{LAK} '16},
title = {Combining click-stream data with {NLP} tools to better understand {MOOC} completion},
isbn = {978-1-4503-4190-5},
url = {https://doi.org/10.1145/2883851.2883931},
doi = {10.1145/2883851.2883931},
abstract = {Completion rates for massive open online classes (MOOCs) are notoriously low. Identifying student patterns related to course completion may help to develop interventions that can improve retention and learning outcomes in MOOCs. Previous research predicting MOOC completion has focused on click-stream data, student demographics, and natural language processing (NLP) analyses. However, most of these analyses have not taken full advantage of the multiple types of data available. This study combines click-stream data and NLP approaches to examine if students' on-line activity and the language they produce in the online discussion forum is predictive of successful class completion. We study this analysis in the context of a subsample of 320 students who completed at least one graded assignment and produced at least 50 words in discussion forums, in a MOOC on educational data mining. The findings indicate that a mix of click-stream data and NLP indices can predict with substantial accuracy (78\%) whether students complete the MOOC. This predictive power suggests that student interaction data and language data within a MOOC can help us both to understand student retention in MOOCs and to develop automated signals of student success.},
urldate = {2020-10-14},
booktitle = {Proceedings of the {Sixth} {International} {Conference} on {Learning} {Analytics} \& {Knowledge}},
publisher = {Association for Computing Machinery},
author = {Crossley, Scott and Paquette, Luc and Dascalu, Mihai and McNamara, Danielle S. and Baker, Ryan S.},
month = apr,
year = {2016},
keywords = {MOOC, click-stream data, educational data mining, educational success, natural language processing, predictive analytics, sentiment analysis},
pages = {6--14},
}

@techreport{ho_harvardx_2014,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {{HarvardX} and {MITx}: {The} {First} {Year} of {Open} {Online} {Courses}, {Fall} 2012-{Summer} 2013},
shorttitle = {{HarvardX} and {MITx}},
url = {https://papers.ssrn.com/abstract=2381263},
abstract = {HarvardX and MITx are collaborative institutional efforts between Harvard University and MIT to enhance campus-based education, advance educational research, and increase access to online learning opportunities worldwide.  Over the year from the fall of 2012 to the summer of 2013, HarvardX and MITx launched 17 courses on edX, a jointly founded platform for delivering massive open online courses (MOOCs).  In that year, 43,196 registrants earned certificates of completion.  Another 35,937 registrants explored half or more of course content without certification.  An additional 469,702 registrants viewed less than half of the content.  And 292,852 registrants never engaged with the online content.  In total, there were 841,687 registrations from 597,692 unique users across the first year of HarvardX and MITx courses.  This report is a joint effort by institutional units at Harvard and MIT to describe the registrant and course data provided by edX in the context of the diverse efforts and intentions of HarvardX and MITx instructor teams.},
language = {en},
number = {ID 2381263},
urldate = {2020-10-14},
institution = {Social Science Research Network},
author = {Ho, Andrew and Reich, Justin and Nesterko, Sergiy and Seaton, Daniel and Mullaney, Tommy and Waldo, Jim and Chuang, Isaac},
month = jan,
year = {2014},
doi = {10.2139/ssrn.2381263},
keywords = {HarvardX, MITx, MOOC, distance education, higher education, massive open online course, online learning},
}

@article{hone_exploring_2016,
title = {Exploring the factors affecting {MOOC} retention: {A} survey study},
volume = {98},
issn = {0360-1315},
shorttitle = {Exploring the factors affecting {MOOC} retention},
url = {http://www.sciencedirect.com/science/article/pii/S0360131516300793},
doi = {10.1016/j.compedu.2016.03.016},
abstract = {Massive Open Online Courses (MOOCs) hold the potential to open up educational opportunities to a global audience. However, evidence suggests that only a small proportion of MOOC participants go on to complete their courses and relatively little is understood about the MOOC design and implementation factors that influence retention. This paper reports a survey study of 379 participants enrolled at university in Cairo who were encouraged to take a MOOC of their own choice as part of their development. 122 participants (32.2\%) went onto to complete an entire course. There were no significant differences in completion rates by gender, level of study (undergraduate or postgraduate) or MOOC platform. A post-MOOC survey of students' perceptions found that MOOC Course Content was a significant predictor of MOOC retention, with the relationship mediated by the effect of content on the Perceived Effectiveness of the course. Interaction with the instructor of the MOOC was also found to be significant predictor of MOOC retention. Overall these constructs explained 79\% of the variance in MOOC retention.},
language = {en},
urldate = {2020-10-14},
journal = {Computers \& Education},
author = {Hone, Kate S. and El Said, Ghada R.},
month = jul,
year = {2016},
keywords = {Distance education, Massive Open Online Courses (MOOCs), Telelearning},
pages = {157--168},
}

@inproceedings{imran_predicting_2019,
address = {New York, NY, USA},
series = {{ICCAI} '19},
title = {Predicting {Student} {Dropout} in a {MOOC}: {An} {Evaluation} of a {Deep} {Neural} {Network} {Model}},
isbn = {978-1-4503-6106-4},
shorttitle = {Predicting {Student} {Dropout} in a {MOOC}},
url = {https://doi.org/10.1145/3330482.3330514},
doi = {10.1145/3330482.3330514},
abstract = {Massive Open Online Courses (MOOCs) have transformed the way educational institutions deliver high-quality educational material to the onsite and distance learners across the globe. As a result, a new paradigm shifts as to how learners acquire and benefit from the wealth of knowledge provided by a MOOC at their doorstep nowadays in contrast to the brick and mortar settings is visible. Learners are therefore showing a profound interest in the MOOCs offered by top universities and industry giants. They have also attracted a vast number of students from far-flung areas of the world. The massive number of registered students in MOOCs, however, pose one major challenge, i.e., 'the dropouts'. Course planners and content providers are struggling to retain the registered students, which give rise to a new research agenda focusing on predicting and explaining student dropout and low completion rates in a MOOC. Machine learning techniques utilizing deep learning approaches can efficiently predict the potential dropouts and can raise an alert well before time. In this paper, we have focused our study on the application of feed-forward deep neural network architectures to address this problem. Our model achieves not only high accuracy, but also low false negative rate while predicting dropouts on the MOOC data. Moreover, we also provide an in-depth comparison of the proposed architectures concerning precision, recall, and F1 measure.},
urldate = {2020-10-12},
booktitle = {Proceedings of the 2019 5th {International} {Conference} on {Computing} and {Artificial} {Intelligence}},
publisher = {Association for Computing Machinery},
author = {Imran, Ali Shariq and Dalipi, Fisnik and Kastrati, Zenun},
month = apr,
year = {2019},
keywords = {ANN, Dropout prediction, MOOC, deep learning, distance learning, e-Learning, online learning},
pages = {190--195},
}

@misc{noauthor_27_nodate,
title = {27. {Reinforcement} {Learning}},
}

@misc{lee_26_nodate,
title = {26. {Life} {Long} {Learning} \& {Curriculum} {Learning}},
language = {en},
author = {Lee, Hung-yi},
}

@inproceedings{dalipi_mooc_2018,
title = {{MOOC} dropout prediction using machine learning techniques: {Review} and research challenges},
shorttitle = {{MOOC} dropout prediction using machine learning techniques},
doi = {10.1109/EDUCON.2018.8363340},
abstract = {MOOC represents an ultimate way to deliver educational content in higher education settings by providing high-quality educational material to the students throughout the world. Considering the differences between traditional learning paradigm and MOOCs, a new research agenda focusing on predicting and explaining dropout of students and low completion rates in MOOCs has emerged. However, due to different problem specifications and evaluation metrics, performing a comparative analysis of state-of-the-art machine learning architectures is a challenging task. In this paper, we provide an overview of the MOOC student dropout prediction phenomenon where machine learning techniques have been utilized. Furthermore, we highlight some solutions being used to tackle with dropout problem, provide an analysis about the challenges of prediction models, and propose some valuable insights and recommendations that might lead to developing useful and effective machine learning solutions to solve the MOOC dropout problem.},
booktitle = {2018 {IEEE} {Global} {Engineering} {Education} {Conference} ({EDUCON})},
author = {Dalipi, Fisnik and Imran, Ali Shariq and Kastrati, Zenun},
month = apr,
year = {2018},
note = {ISSN: 2165-9567},
keywords = {Computer architecture, Engineering education, Hidden Markov models, MOOC, MOOC student dropout prediction phenomenon, Machine learning, Predictive models, Support vector machines, artificial intelligence, comparative analysis, computer aided instruction, dropout prediction, educational content, educational courses, further education, high-quality educational material, higher education settings, learning (artificial intelligence), low completion rates, machine learning, machine learning techniques, research agenda, research ideas, review, traditional learning paradigm},
pages = {1007--1014},
}

@misc{lee_25_2020,
title = {25. {Meta} {Learning}},
url = {http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html},
language = {en},
author = {Lee, Hung-yi},
year = {2020},
}

@misc{lee_24_nodate,
title = {24. {Transfer} {Learning}},
language = {en},
author = {Lee, Hung-yi},
}

@misc{noauthor_23_nodate,
title = {23. {FLOW}-based generative model},
}

@article{ganin_domain-adversarial_2016,
title = {Domain-{Adversarial} {Training} of {Neural} {Networks}},
url = {http://arxiv.org/abs/1505.07818},
abstract = {We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation and stochastic gradient descent, and can thus be implemented with little effort using any of the deep learning packages. We demonstrate the success of our approach for two distinct classification problems (document sentiment analysis and image classification), where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.},
urldate = {2020-09-28},
journal = {arXiv:1505.07818 [cs, stat]},
author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario and Lempitsky, Victor},
month = may,
year = {2016},
note = {arXiv: 1505.07818},
keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{noauthor_22_nodate,
title = {22. {Generative} {Adversarial} {Network} ({GAN})},
keywords = {research ideas},
}

@article{nelson_measures_nodate,
title = {Measures of {Text} {Difficulty}:},
language = {en},
author = {Nelson, Jessica and Perfetti, Charles and Liben, David and Liben, Meredith},
pages = {58},
}

@article{yang_peer_nodate,
title = {Peer {Inﬂuence} on {Attrition} in {Massive} {Open} {Online} {Courses}},
abstract = {In this work, we investigate the role of relational bonds in keeping students engaged in online courses. Speciﬁcally, we quantify the manner in which students who demonstrate similar behavior patterns inﬂuence each other’s commitment to the course through their interaction with them either explicitly or implicitly. To this end, we design ﬁve alternative operationalizations of relationship bonds, which together allow us to infer a scaled measure of relationship between pairs of students. Using this, we construct three variables, namely number of signiﬁcant bonds, number of signiﬁcant bonds with people who have dropped out in the previous week, and number of such bonds with people who have dropped in the current week. Using a survival analysis, we are able to measure the prediction strength of these variables with respect to dropout at each time point. Results indicate that higher numbers of signiﬁcant bonds predicts lower rates of dropout; while loss of signiﬁcant bonds is associated with higher rates of dropout.},
language = {en},
author = {Yang, Diyi and Wen, Miaomiao and Rose, Carolyn},
pages = {2},
}

@article{yang_turn_nodate,
title = {“{Turn} on, {Tune} in, {Drop} out”: {Anticipating} student dropouts in {Massive} {Open} {Online} {Courses}},
abstract = {In this paper, we explore student dropout behavior in Massive Open Online Courses(MOOC). We use as a case study a recent Coursera class from which we develop a survival model that allows us to measure the inﬂuence of factors extracted from that data on student dropout rate. Speciﬁcally we explore factors related to student behavior and social positioning within discussion forums using standard social network analytic techniques. The analysis reveals several signiﬁcant predictors of dropout.},
language = {en},
author = {Yang, Diyi and Sinha, Tanmay and Adamson, David and Rose, Carolyn Penstein},
pages = {9},
}

@inproceedings{rose_social_2014,
address = {Atlanta, Georgia, USA},
title = {Social factors that contribute to attrition in {MOOCs}},
isbn = {978-1-4503-2669-8},
url = {http://dl.acm.org/citation.cfm?doid=2556325.2567879},
doi = {10.1145/2556325.2567879},
abstract = {In this paper, we explore student dropout behavior in a Massively Open Online Course (MOOC). We use a survival model to measure the impact of three social factors that make predictions about attrition along the way for students who have participated in the course discussion forum.},
language = {en},
urldate = {2020-09-26},
booktitle = {Proceedings of the first {ACM} conference on {Learning} @ scale conference - {L}@{S} '14},
publisher = {ACM Press},
author = {Rosé, Carolyn Penstein and Carlson, Ryan and Yang, Diyi and Wen, Miaomiao and Resnick, Lauren and Goldman, Pam and Sherer, Jennifer},
year = {2014},
pages = {197--198},
}

@inproceedings{yang_exploring_2015,
address = {New York, NY, USA},
series = {L@{S} '15},
title = {Exploring the {Effect} of {Confusion} in {Discussion} {Forums} of {Massive} {Open} {Online} {Courses}},
isbn = {978-1-4503-3411-2},
url = {https://doi.org/10.1145/2724660.2724677},
doi = {10.1145/2724660.2724677},
abstract = {Thousands of students enroll in Massive Open Online Courses{\textasciitilde}(MOOCs) to seek opportunities for learning and self-improvement. However, the learning process often involves struggles with confusion, which may have an adverse effect on the course participation experience, leading to dropout along the way. In this paper, we quantify that effect. We describe a classification model using discussion forum behavior and clickstream data to automatically identify posts that express confusion. We then apply survival analysis to quantify the impact of confusion on student dropout. The results demonstrate that the more confusion students express or are exposed to, the lower the probability of their retention. Receiving support and resolution of confusion helps mitigate this effect. We explore the differential effects of confusion expressed in different contexts and related to different aspects of courses. We conclude with implications for design of interventions towards improving the retention of students in MOOCs.},
urldate = {2020-09-25},
booktitle = {Proceedings of the {Second} (2015) {ACM} {Conference} on {Learning} @ {Scale}},
publisher = {Association for Computing Machinery},
author = {Yang, Diyi and Wen, Miaomiao and Howley, Iris and Kraut, Robert and Rose, Carolyn},
month = mar,
year = {2015},
keywords = {confusion, massive open online courses (mooc), read here, research ideas, survival analysis},
pages = {121--130},
}

@article{lee_deep_2020,
title = {Deep {Attentive} {Study} {Session} {Dropout} {Prediction} in {Mobile} {Learning} {Environment}},
url = {http://arxiv.org/abs/2002.11624},
abstract = {Student dropout prediction provides an opportunity to improve student engagement, which maximizes the overall effectiveness of learning experiences. However, researches on student dropout were mainly conducted on school dropout or course dropout, and study session dropout in a mobile learning environment has not been considered thoroughly. In this paper, we investigate the study session dropout prediction problem in a mobile learning environment. First, we define the concept of the study session, study session dropout and study session dropout prediction task in a mobile learning environment. Based on the definitions, we propose a novel Transformer based model for predicting study session dropout, DAS: Deep Attentive Study Session Dropout Prediction in Mobile Learning Environment. DAS has an encoder-decoder structure which is composed of stacked multi-head attention and point-wise feed-forward networks. The deep attentive computations in DAS are capable of capturing complex relations among dynamic student interactions. To the best of our knowledge, this is the first attempt to investigate study session dropout in a mobile learning environment. Empirical evaluations on a large-scale dataset show that DAS achieves the best performance with a significant improvement in area under the receiver operating characteristic curve compared to baseline models.},
urldate = {2020-09-25},
journal = {arXiv:2002.11624 [cs]},
author = {Lee, Youngnam and Shin, Dongmin and Loh, HyunBin and Lee, Jaemin and Chae, Piljae and Cho, Junghyun and Park, Seoyon and Lee, Jinhwan and Baek, Jineon and Kim, Byungsoo and Choi, Youngduck},
month = aug,
year = {2020},
note = {arXiv: 2002.11624},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning, read here},
}

@article{yang_behavior-based_2017,
title = {Behavior-{Based} {Grade} {Prediction} for {MOOCs} via {Time} {Series} {Neural} {Networks}},
issn = {1932-4553, 1941-0484},
url = {http://ieeexplore.ieee.org/document/7917237/},
doi = {10.1109/JSTSP.2017.2700227},
abstract = {We present a novel method for predicting the evolution of a student’s grade in Massive Open Online Courses (MOOCs). Performance prediction is particularly challenging in MOOC settings due to per-student assessment response sparsity and the need for personalized models. Our method overcomes these challenges by incorporating another, richer form of data collected from each student – lecture video-watching clickstreams – into the machine learning feature set, and using that to train a time series neural network that learns from both prior performance and clickstream data. Through evaluation on two MOOC datasets, we ﬁnd that our algorithm outperforms a baseline of average past performance by more than 60\% on average, and a lasso regression baseline by more than 15\%. Moreover, the gains are higher when the student has answered fewer questions, underscoring their ability to provide instructors with early detection of struggling and/or advanced students. We also show that despite these gains, when taken alone, none of the behavioral features are particularly correlated with performance, emphasizing the need to consider their combined effect and nonlinear predictors. Finally, we discuss how course instructors can use these predictive learning analytics to stage student interventions.},
language = {en},
urldate = {2020-09-25},
journal = {IEEE Journal of Selected Topics in Signal Processing},
author = {Yang, Tsung-Yen and Brinton, Christopher G. and Joe-Wong, Carlee and Chiang, Mung},
year = {2017},
keywords = {Clickstream data analysis, Electronic mail, MOOC, MOOCs, Neural networks, Prediction algorithms, Predictive models, Signal processing algorithms, Time series analysis, Videos, behavior-based student grade prediction, behavioural sciences computing, computer aided instruction, educational courses, lasso regression baseline, learning (artificial intelligence), learning analytics, lecture video-watching clickstreams, machine learning feature set, massive open online courses, neural nets, per-student assessment response sparsity, predictive learning analytics, read here, regression analysis, student performance prediction, time series, time series neural networks},
pages = {1--1},
}

@article{jeon_dropout_2020,
title = {Dropout {Prediction} over {Weeks} in {MOOCs} by {Learning} {Representations} of {Clicks} and {Videos}},
url = {http://arxiv.org/abs/2002.01955},
abstract = {This paper addresses a key challenge in MOOC dropout prediction, namely to build meaningful representations from clickstream data. While a variety of feature extraction techniques have been explored extensively for such purposes, to our knowledge, no prior works have explored modeling of educational content (e.g. video) and their correlation with the learner's behavior (e.g. clickstream) in this context. We bridge this gap by devising a method to learn representation for videos and the correlation between videos and clicks. The results indicate that modeling videos and their correlation with clicks bring statistically significant improvements in predicting dropout.},
urldate = {2020-09-25},
journal = {arXiv:2002.01955 [cs]},
author = {Jeon, Byungsoo and Park, Namyong},
month = feb,
year = {2020},
note = {arXiv: 2002.01955},
keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, read here},
}

@article{caison_analysis_2007,
title = {{ANALYSIS} {OF} {INSTITUTIONALLY} {SPECIFIC} {RETENTION} {RESEARCH}: {A} {Comparison} {Between} {Survey} and {Institutional} {Database} {Methods}},
volume = {48},
issn = {0361-0365},
shorttitle = {{ANALYSIS} {OF} {INSTITUTIONALLY} {SPECIFIC} {RETENTION} {RESEARCH}},
url = {https://www.jstor.org/stable/25704511},
abstract = {This study empirically explores the comparability of traditional survey-based retention research methodology with an alternative approach that relies on data commonly available in institutional student databases. Drawing on Tinto's [Tinto, V. (1993). Leaving College: Rethinking the Causes and Cures of Student Attrition (2nd Ed.), The University of Chicago Press, Chicago.] theory of student integration, this project utilizes an information-theoretic approach [Bumham, K.P., and Anderson, D. R. (2002). Model Selection and Inference: A Practical Information-theoretical Approach (2nd ed.), Springer-Verlag, New York, NY.], in which a set of candidate models was developed using institutional integration survey variables and variables drawn from institutional student databases. An information-theoretical approach to selecting the most parsimonious logistic regression model revealed that institutional database variables out-perform the institutional integration survey scales developed by Pascarella and Terenzini [Pascarella, E. T., and Terenzini, P. T. (1980). Journal of Higher Education 51(1): 60–75.] in predicting 1-year retention. This empirical support for the use of institutional database variables is valuable in conducting institution-specific retention research under constrained resources.},
number = {4},
urldate = {2020-09-25},
journal = {Research in Higher Education},
author = {Caison, Amy L.},
year = {2007},
note = {Publisher: Springer},
keywords = {research ideas},
pages = {435--451},
}

@article{hassan_virtual_2019,
title = {Virtual learning environment to predict withdrawal by leveraging deep learning},
volume = {34},
copyright = {© 2019 Wiley Periodicals, Inc.},
issn = {1098-111X},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22129},
doi = {10.1002/int.22129},
abstract = {The current evolution in multidisciplinary learning analytics research poses significant challenges for the exploitation of behavior analysis by fusing data streams toward advanced decision-making. The identification of students that are at risk of withdrawals in higher education is connected to numerous educational policies, to enhance their competencies and skills through timely interventions by academia. Predicting student performance is a vital decision-making problem including data from various environment modules that can be fused into a homogenous vector to ascertain decision-making. This research study exploits a temporal sequential classification problem to predict early withdrawal of students, by tapping the power of actionable smart data in the form of students' interactional activities with the online educational system, using the freely available Open University Learning Analytics data set by employing deep long short-term memory (LSTM) model. The deployed LSTM model outperforms baseline logistic regression and artificial neural networks by 10.31\% and 6.48\% respectively with 97.25\% learning accuracy, 92.79\% precision, and 85.92\% recall.},
language = {en},
number = {8},
urldate = {2020-09-19},
journal = {International Journal of Intelligent Systems},
author = {Hassan, Saeed-Ul and Waheed, Hajra and Aljohani, Naif R. and Ali, Mohsen and Ventura, Sebastián and Herrera, Francisco},
year = {2019},
note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.22129},
keywords = {classification, deep learning, long short-term memory (LSTM), students-at-risk. smart data, virtual learning environment (VLE)},
pages = {1935--1952},
}

@inproceedings{zhang_using_2010,
address = {Portugal},
title = {Using data mining to improve student retention in {HE}: a case study.},
shorttitle = {Using data mining to improve student retention in {HE}},
url = {http://eprints.mdx.ac.uk/5808/},
abstract = {Data mining combines machine learning, statistics and visualization techniques to discover and extract knowledge. One of the biggest challenges that higher education faces is to improve student retention (National Audition Office, 2007).Student retention has become an indication of academic performance and enrolment management. Our project uses data mining and natural language processing technologies to monitor student, analyze student academic behaviour and provide a basis for efficient intervention strategies. Our aim is to identify potential problems as early as possible and to follow up with intervention options to enhance student retention. In this paper we discuss how data mining can help spot students ‘at risk’, evaluate the course or module suitability, and tailor the interventions to increase student retention.},
language = {en},
urldate = {2020-09-25},
author = {Zhang, Ying and Oussena, Samia and Clark, Tony and Hyensook, Kim},
year = {2010},
}

@article{delen_comparative_2010,
title = {A comparative analysis of machine learning techniques for student retention management},
volume = {49},
issn = {0167-9236},
url = {http://www.sciencedirect.com/science/article/pii/S0167923610001041},
doi = {10.1016/j.dss.2010.06.003},
abstract = {Student retention is an essential part of many enrollment management systems. It affects university rankings, school reputation, and financial wellbeing. Student retention has become one of the most important priorities for decision makers in higher education institutions. Improving student retention starts with a thorough understanding of the reasons behind the attrition. Such an understanding is the basis for accurately predicting at-risk students and appropriately intervening to retain them. In this study, using five years of institutional data along with several data mining techniques (both individuals as well as ensembles), we developed analytical models to predict and to explain the reasons behind freshmen student attrition. The comparative analyses results showed that the ensembles performed better than individual models, while the balanced dataset produced better prediction results than the unbalanced dataset. The sensitivity analysis of the models revealed that the educational and financial variables are among the most important predictors of the phenomenon.},
language = {en},
number = {4},
urldate = {2020-09-25},
journal = {Decision Support Systems},
author = {Delen, Dursun},
month = nov,
year = {2010},
keywords = {Classification, Machine learning, Prediction, Retention management, Sensitivity analysis, Student attrition},
pages = {498--506},
}

@article{ram_using_2015,
title = {Using {Big} {Data} for {Predicting} {Freshmen} {Retention}},
url = {https://aisel.aisnet.org/icis2015/proceedings/DecisionAnalytics/13},
journal = {ICIS 2015 Proceedings},
author = {Ram, Sudha and Wang, Yun and Currim, Faiz and Currim, Sabah},
month = dec,
year = {2015},
}

@article{sun_meta-transfer_2019,
title = {Meta-{Transfer} {Learning} for {Few}-{Shot} {Learning}},
url = {http://arxiv.org/abs/1812.02391},
abstract = {Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, meta-learning typically uses shallow neural networks (SNNs), thus limiting its effectiveness. In this paper we propose a novel few-shot learning method called meta-transfer learning (MTL) which learns to adapt a deep NN for few shot learning tasks. Specifically, "meta" refers to training multiple tasks, and "transfer" is achieved by learning scaling and shifting functions of DNN weights for each task. In addition, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum for MTL. We conduct experiments using (5-class, 1-shot) and (5-class, 5-shot) recognition tasks on two challenging few-shot learning benchmarks: miniImageNet and Fewshot-CIFAR100. Extensive comparisons to related works validate that our meta-transfer learning approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.},
urldate = {2020-09-21},
journal = {arXiv:1812.02391 [cs]},
author = {Sun, Qianru and Liu, Yaoyao and Chua, Tat-Seng and Schiele, Bernt},
month = apr,
year = {2019},
note = {arXiv: 1812.02391},
keywords = {Computer Science - Computer Vision and Pattern Recognition, discussion},
}

@article{yin_dimensionality_2018,
title = {On the {Dimensionality} of {Word} {Embedding}},
url = {http://arxiv.org/abs/1812.04224},
abstract = {In this paper, we provide a theoretical understanding of word embedding and its dimensionality. Motivated by the unitary-invariance of word embedding, we propose the Pairwise Inner Product (PIP) loss, a novel metric on the dissimilarity between word embeddings. Using techniques from matrix perturbation theory, we reveal a fundamental bias-variance trade-off in dimensionality selection for word embeddings. This bias-variance trade-off sheds light on many empirical observations which were previously unexplained, for example the existence of an optimal dimensionality. Moreover, new insights and discoveries, like when and how word embeddings are robust to over-fitting, are revealed. By optimizing over the bias-variance trade-off of the PIP loss, we can explicitly answer the open question of dimensionality selection for word embedding.},
urldate = {2020-09-21},
journal = {arXiv:1812.04224 [cs, stat]},
author = {Yin, Zi and Shen, Yuanyuan},
month = dec,
year = {2018},
note = {arXiv: 1812.04224},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{wong_sequence_2018,
address = {Cham},
series = {Lecture {Notes} in {Computer} {Science}},
title = {Sequence {Based} {Course} {Recommender} for {Personalized} {Curriculum} {Planning}},
isbn = {978-3-319-93846-2},
doi = {10.1007/978-3-319-93846-2_100},
abstract = {Students in higher education need to select appropriate courses to meet graduation requirements for their degree. Selection approaches range from manual guides, on-line systems to personalized assistance from academic advisers. An automated course recommender is one approach to scale advice for large cohorts. However, existing recommenders need to be adapted to include sequence, concurrency, constraints and concept drift. In this paper, we propose the use of recent deep learning techniques such as Long Short-Term Memory (LSTM) Recurrent Neural Networks to resolve these issues in this domain.},
language = {en},
booktitle = {Artificial {Intelligence} in {Education}},
publisher = {Springer International Publishing},
author = {Wong, Chris},
editor = {Penstein Rosé, Carolyn and Martínez-Maldonado, Roberto and Hoppe, H. Ulrich and Luckin, Rose and Mavrikis, Manolis and Porayska-Pomsta, Kaska and McLaren, Bruce and du Boulay, Benedict},
year = {2018},
keywords = {Deep learning, Educational data mining, Recommender systems, Study planning},
pages = {531--534},
}

@article{liu_predicting_2018,
title = {Predicting {Learning} {Status} in {MOOCs} using {LSTM}},
url = {http://arxiv.org/abs/1808.01616},
abstract = {Real-time and open online course resources of MOOCs have attracted a large number of learners in recent years. However, many new questions were emerging about the high dropout rate of learners. For MOOCs platform, predicting the learning status of MOOCs learners in real time with high accuracy is the crucial task, and it also help improve the quality of MOOCs teaching. The prediction task in this paper is inherently a time series prediction problem, and can be treated as time series classification problem, hence this paper proposed a prediction model based on RNNLSTMs and optimization techniques which can be used to predict learners' learning status. Using datasets provided by Chinese University MOOCs as the inputs of model, the average accuracy of model's outputs was about 90\%.},
urldate = {2020-09-19},
journal = {arXiv:1808.01616 [cs]},
author = {Liu, Zhemin and Xiong, Feng and Zou, Kaifa and Wang, Hongzhi},
month = aug,
year = {2018},
note = {arXiv: 1808.01616},
keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@article{gulrajani_improved_2017,
title = {Improved {Training} of {Wasserstein} {GANs}},
url = {http://arxiv.org/abs/1704.00028},
abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
urldate = {2020-09-17},
journal = {arXiv:1704.00028 [cs, stat]},
author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
month = dec,
year = {2017},
note = {arXiv: 1704.00028},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{arjovsky_wasserstein_2017,
title = {Wasserstein {GAN}},
url = {http://arxiv.org/abs/1701.07875},
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
urldate = {2020-09-17},
journal = {arXiv:1701.07875 [cs, stat]},
author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Léon},
month = dec,
year = {2017},
note = {arXiv: 1701.07875},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kaiser_learning_2017,
title = {Learning to {Remember} {Rare} {Events}},
url = {http://arxiv.org/abs/1703.03129},
abstract = {Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. Our memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.},
urldate = {2020-09-10},
journal = {arXiv:1703.03129 [cs]},
author = {Kaiser, Łukasz and Nachum, Ofir and Roy, Aurko and Bengio, Samy},
month = mar,
year = {2017},
note = {arXiv: 1703.03129},
keywords = {Computer Science - Machine Learning, discussion},
}

@article{lample_fader_2018,
title = {Fader {Networks}: {Manipulating} {Images} by {Sliding} {Attributes}},
shorttitle = {Fader {Networks}},
url = {http://arxiv.org/abs/1706.00409},
abstract = {This paper introduces a new encoder-decoder architecture that is trained to reconstruct images by disentangling the salient information of the image and the values of attributes directly in the latent space. As a result, after training, our model can generate different realistic versions of an input image by varying the attribute values. By using continuous attribute values, we can choose how much a specific attribute is perceivable in the generated image. This property could allow for applications where users can modify an image using sliding knobs, like faders on a mixing console, to change the facial expression of a portrait, or to update the color of some objects. Compared to the state-of-the-art which mostly relies on training adversarial networks in pixel space by altering attribute values at train time, our approach results in much simpler training schemes and nicely scales to multiple attributes. We present evidence that our model can significantly change the perceived value of the attributes while preserving the naturalness of images.},
urldate = {2020-09-16},
journal = {arXiv:1706.00409 [cs]},
author = {Lample, Guillaume and Zeghidour, Neil and Usunier, Nicolas and Bordes, Antoine and Denoyer, Ludovic and Ranzato, Marc'Aurelio},
month = jan,
year = {2018},
note = {arXiv: 1706.00409},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{liu_unsupervised_2018,
title = {Unsupervised {Image}-to-{Image} {Translation} {Networks}},
url = {http://arxiv.org/abs/1703.00848},
abstract = {Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in https://github.com/mingyuliutw/unit .},
urldate = {2020-09-16},
journal = {arXiv:1703.00848 [cs]},
author = {Liu, Ming-Yu and Breuel, Thomas and Kautz, Jan},
month = jul,
year = {2018},
note = {arXiv: 1703.00848},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{liu_coupled_2016,
title = {Coupled {Generative} {Adversarial} {Networks}},
url = {http://arxiv.org/abs/1606.07536},
abstract = {We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn a joint distribution without any tuple of corresponding images. It can learn a joint distribution with just samples drawn from the marginal distributions. This is achieved by enforcing a weight-sharing constraint that limits the network capacity and favors a joint distribution solution over a product of marginal distributions one. We apply CoGAN to several joint distribution learning tasks, including learning a joint distribution of color and depth images, and learning a joint distribution of face images with different attributes. For each task it successfully learns the joint distribution without any tuple of corresponding images. We also demonstrate its applications to domain adaptation and image transformation.},
urldate = {2020-09-16},
journal = {arXiv:1606.07536 [cs]},
author = {Liu, Ming-Yu and Tuzel, Oncel},
month = sep,
year = {2016},
note = {arXiv: 1606.07536},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{isola_image--image_2018,
title = {Image-to-{Image} {Translation} with {Conditional} {Adversarial} {Networks}},
url = {http://arxiv.org/abs/1611.07004},
abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
urldate = {2020-09-16},
journal = {arXiv:1611.07004 [cs]},
author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
month = nov,
year = {2018},
note = {arXiv: 1611.07004},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{zhang_stackgan_2017,
title = {{StackGAN}: {Text} to {Photo}-realistic {Image} {Synthesis} with {Stacked} {Generative} {Adversarial} {Networks}},
shorttitle = {{StackGAN}},
url = {http://arxiv.org/abs/1612.03242},
abstract = {Synthesizing high-quality images from text descriptions is a challenging problem in computer vision and has many practical applications. Samples generated by existing text-to-image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts. In this paper, we propose Stacked Generative Adversarial Networks (StackGAN) to generate 256x256 photo-realistic images conditioned on text descriptions. We decompose the hard problem into more manageable sub-problems through a sketch-refinement process. The Stage-I GAN sketches the primitive shape and colors of the object based on the given text description, yielding Stage-I low-resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high-resolution images with photo-realistic details. It is able to rectify defects in Stage-I results and add compelling details with the refinement process. To improve the diversity of the synthesized images and stabilize the training of the conditional-GAN, we introduce a novel Conditioning Augmentation technique that encourages smoothness in the latent conditioning manifold. Extensive experiments and comparisons with state-of-the-arts on benchmark datasets demonstrate that the proposed method achieves significant improvements on generating photo-realistic images conditioned on text descriptions.},
urldate = {2020-09-16},
journal = {arXiv:1612.03242 [cs, stat]},
author = {Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Wang, Xiaogang and Huang, Xiaolei and Metaxas, Dimitris},
month = aug,
year = {2017},
note = {arXiv: 1612.03242},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
}

@article{reed_generative_2016,
title = {Generative {Adversarial} {Text} to {Image} {Synthesis}},
url = {http://arxiv.org/abs/1605.05396},
abstract = {Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neural network architectures have been developed to learn discriminative text feature representations. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to generate highly compelling images of specific categories, such as faces, album covers, and room interiors. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image model- ing, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.},
urldate = {2020-09-16},
journal = {arXiv:1605.05396 [cs]},
author = {Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
month = jun,
year = {2016},
note = {arXiv: 1605.05396},
keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@misc{zhang_zhangqianhuiadversarialnetspapers_2020,
title = {zhangqianhui/{AdversarialNetsPapers}},
url = {https://github.com/zhangqianhui/AdversarialNetsPapers},
abstract = {Awesome paper list with code about generative adversarial nets},
urldate = {2020-09-16},
author = {Zhang, Jichao},
month = sep,
year = {2020},
note = {original-date: 2016-09-24T10:16:42Z},
keywords = {adversarial-networks, deep-learning, gan, image-translation},
}

@misc{noauthor_machine_nodate,
title = {Machine {Learning} 2020},
url = {http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html},
urldate = {2020-09-16},
}

@misc{lee_21_nodate,
title = {21. {Anomaly} {Detection}},
language = {en},
author = {Lee, Hung-yi},
}

@article{peters_deep_2018,
title = {Deep contextualized word representations},
url = {http://arxiv.org/abs/1802.05365},
abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
urldate = {2019-08-01},
journal = {arXiv:1802.05365 [cs]},
author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
month = feb,
year = {2018},
note = {arXiv: 1802.05365},
keywords = {Computer Science - Computation and Language, ELMO, Embeddings from Language Model, read here},
}

@misc{noauthor_20_nodate,
title = {20. {ELMO}, {BERT}, {GPT}},
}

@misc{noauthor_19_nodate,
title = {19. {Unsupervised} {Learning}: {Deep} {Auto}-encoder},
keywords = {research ideas},
}

@incollection{noauthor_laplacian_nodate,
title = {Laplacian {Eigenmaps}: [{Alpaydin}, {Chapter} 6.12]},
}

@incollection{noauthor_locally_nodate,
title = {Locally {Linear} {Embedding} ({LLE}): [{Alpaydin}, {Chapter}  6.11]},
}

@misc{noauthor_18_nodate,
title = {18. {Unsupervised} {Learning}: neighbor embedding},
keywords = {research ideas},
}

@article{gazza_facilitating_2014,
title = {Facilitating student retention in online graduate nursing education programs: {A} review of the literature},
volume = {34},
issn = {0260-6917},
shorttitle = {Facilitating student retention in online graduate nursing education programs},
url = {http://www.sciencedirect.com/science/article/pii/S0260691714000343},
doi = {10.1016/j.nedt.2014.01.010},
abstract = {Online education, a form of distance education, provides students with opportunities to engage in lifelong learning without the restrictions of time and space. However, while this approach meets the needs of employed nursing professionals, it poses some challenges for educators. Student retention is one such challenge. Student retention rates serve as measures of program quality and are reported to accrediting bodies. Therefore, it is imperative that administrators and program faculty implement comprehensive programs to ensure student retention. This review of the literature was designed to identify strategies to improve student retention in online graduate nursing education programs. The review includes 23 articles that address models, research, and best practices supported in nursing and higher education. The findings indicate that student retention in online programs is a multidimensional problem requiring a multifaceted approach. Recommendations for facilitating retention in online nursing programs include ensuring social presence and program and course quality, and attentiveness to individual student characteristics.},
language = {en},
number = {7},
urldate = {2020-09-12},
journal = {Nurse Education Today},
author = {Gazza, Elizabeth A. and Hunker, Diane F.},
month = jul,
year = {2014},
keywords = {Education, Education, Distance, Education, Nursing, Graduate, Graduate, Internet, Nursing, Online, Student retention, Students, Nursing, United States},
pages = {1125--1129},
}

@book{allen_grade_2014,
title = {Grade {Change}: {Tracking} {Online} {Education} in the {United} {States}},
shorttitle = {Grade {Change}},
url = {https://eric.ed.gov/?id=ED602449},
abstract = {This report focuses on online courses and programs offered as a normal part of an institution's programs, as well as Massive Open Online Courses (MOOCs) typically offered for free to those outside of the institution's student body. An online course is defined as one in which at least 80 percent of the course content is delivered online. Face-to-face instruction includes courses in which zero to 29 percent of the content is delivered online; this category includes both traditional and web facilitated courses. The remaining alternative, blended (or hybrid) instruction, has between 30 and 80 percent of the course content delivered online. The definition of an online course has remained consistent for the eleven years these national reports have been conducted. These definitions were presented to the respondents at the beginning of the survey, and repeated in the body of individual questions where appropriate. While there is considerable diversity among course delivery methods used by individual instructors, the following is presented to illustrate the prototypical course classifications used in this study.},
language = {en},
urldate = {2020-09-12},
publisher = {Babson Survey Research Group},
author = {Allen, I. Elaine and Seaman, Jeff},
month = jan,
year = {2014},
note = {Publication Title: Babson Survey Research Group},
keywords = {Academic Persistence, Blended Learning, College Students, Conventional Instruction, Educational Technology, Enrollment Trends, Higher Education, Large Group Instruction, Online Courses, Self Control, Teaching Methods, Technology Uses in Education},
}

@article{ali_impact_2009,
title = {The {Impact} of {Face}-to-{Face} {Orientation} on {Online} {Retention}: {A} {Pilot} {Study}},
volume = {12},
shorttitle = {The {Impact} of {Face}-to-{Face} {Orientation} on {Online} {Retention}},
url = {https://digitalcommons.kennesaw.edu/facpubs/821},
number = {4},
journal = {Online Journal of Distance Learning Administration},
author = {Ali, Radwan and Leeds, Elke},
month = jan,
year = {2009},
}

@article{salazar_staying_2010,
title = {Staying {Connected}: {Online} {Education} {Engagement} and {Retention} using {Educational} {Technology} {Tools}},
volume = {23},
copyright = {© Copyright 2010 American Society for Clinical Laboratory Science Inc. All rights reserved.},
issn = {0894-959X, 1945-3574},
shorttitle = {Staying {Connected}},
url = {http://clsjournal.ascls.org/content/23/3_Supplement/53},
doi = {10.29074/ascls.23.3_Supplement.53},
abstract = {The objective of this article is to inform educators about the use of currently available educational technology tools to promote student retention, engagement and interaction in online courses. Educational technology tools include content management systems, podcasts, video lecture capture technology and electronic discussion boards. Successful use of educational technology tools requires planning, organization and use of effective learning strategies.},
language = {en},
number = {3 Supplement},
urldate = {2020-09-12},
journal = {American Society for Clinical Laboratory Science},
author = {Salazar, Jose},
month = jul,
year = {2010},
note = {Publisher: American Society for Clinical Laboratory Science
Section: Focus: Educational Technology},
keywords = {educational technology, engagement, online education, retention},
pages = {53--58},
}

@article{wladis_role_2014,
title = {The {Role} of {Enrollment} {Choice} in {Online} {Education}: {Course} {Selection} {Rationale} and {Course} {Difficulty} as {Factors} {Affecting} {Retention}},
volume = {18},
issn = {1939-5256},
shorttitle = {The {Role} of {Enrollment} {Choice} in {Online} {Education}},
url = {https://eric.ed.gov/?id=EJ1043163},
abstract = {There is well-documented evidence that online retention rates are lower than face-to-face retention rates. However, most past research on online retention focuses on student characteristics, with little knowledge existing on the impact of course type. This study uses a matched sample of 2,330 students at a large urban community college to analyze two key course-level factors which may be impacting online retention: the student's reason for taking the course (as an elective or a requirement) and course difficulty level. The results of this study indicate that the online modality increases dropout risk in courses that are taken as an elective or distributional requirement, particularly for lower-level courses. The findings suggest that in the online environment, the student's reason for course enrollment may be considered a risk indicator and that focused learner support targeted at particular course types may be needed to increase online persistence and retention.},
language = {en},
number = {3},
urldate = {2020-09-12},
journal = {Online Learning},
author = {Wladis, Claire and Wladis, Katherine and Hachey, Alyse C.},
month = oct,
year = {2014},
note = {Publisher: Online Learning Consortium, Inc},
keywords = {Academic Persistence, Community Colleges, Comparative Analysis, Conventional Instruction, Course Selection (Students), Difficulty Level, Elective Courses, Enrollment, Measures (Individuals), Online Courses, Regression (Statistics), Required Courses, Two Year College Students, Urban Schools, Withdrawal (Education)},
}

@book{betts_online_nodate,
title = {Online {Human} {Touch} ({OHT}) {Training} \& {Support}: {A} {Conceptual} {Framework} to {Increase} {Faculty} {Engagement}, {Connectivity}, and {Retention} in {Online} {Education}, {Part} 2},
shorttitle = {Online {Human} {Touch} ({OHT}) {Training} \& {Support}},
abstract = {Enrollment growth in online education now far exceeds overall higher education growth in the United States. As reported by Allen and Seaman (2008), the online enrollment growth rate increased 12 \% from fall 2006 to fall 2007 while the overall higher education growth rate increased only 1.2\%. In fall 2007, there were approximately 3.9 million students enrolled in at least one online course. It is predicted that online enrollments will continue to increase as a result of greater national acceptance of online education by employers, baby boomers returning to college, and a weak economy. Faculty are critical in meeting current and predicted online enrollment increases, particularly since their role extends beyond classroom instruction. Faculty play a vital role in student engagement, retention, and long-term program sustainability. Therefore, the Master of Science in Higher Education Program at Drexel University has developed and implemented the concept of Online Human Touch (OHT) training and support to proactively engage, connect, and retain online faculty. This interactive and personalized approach to working with online faculty has resulted in high retention rates and high levels of satisfaction for faculty and students. This article is the second of a two-part series that focuses on OHT in online education.},
author = {Betts, Kristen},
}

@inproceedings{krause_playful_2015,
address = {New York, NY, USA},
series = {L@{S} '15},
title = {A {Playful} {Game} {Changer}: {Fostering} {Student} {Retention} in {Online} {Education} with {Social} {Gamification}},
isbn = {978-1-4503-3411-2},
shorttitle = {A {Playful} {Game} {Changer}},
url = {https://doi.org/10.1145/2724660.2724665},
doi = {10.1145/2724660.2724665},
abstract = {Many MOOCs report high drop off rates for their students. Among the factors reportedly contributing to this picture are lack of motivation, feelings of isolation, and lack of interactivity in MOOCs. This paper investigates the potential of gamification with social game elements for increasing retention and learning success. Students in our experiment showed a significant increase of 25\% in retention period (videos watched) and 23\% higher average scores when the course interface was gamified. Social game elements amplify this effect significantly -- students in this condition showed an increase of 50\% in retention period and 40\% higher average test scores.},
urldate = {2020-09-11},
booktitle = {Proceedings of the {Second} (2015) {ACM} {Conference} on {Learning} @ {Scale}},
publisher = {Association for Computing Machinery},
author = {Krause, Markus and Mogalle, Marc and Pohl, Henning and Williams, Joseph Jay},
month = mar,
year = {2015},
keywords = {gamification, learning at scale, massive open online courses, mooc, social engagement},
pages = {95--102},
}

@article{gaytan_comparing_2015,
title = {Comparing {Faculty} and {Student} {Perceptions} {Regarding} {Factors} {That} {Affect} {Student} {Retention} in {Online} {Education}},
volume = {29},
issn = {0892-3647},
url = {https://doi.org/10.1080/08923647.2015.994365},
doi = {10.1080/08923647.2015.994365},
abstract = {This qualitative study compared faculty and student perceptions regarding factors that affect student retention in online courses in an attempt to more effectively address the problem of attrition. A grounded study method was used to interview students taking online courses, analyze their responses related to the critical factors that affect student retention, and compare them with those given by expert online faculty documented by Gaytan (2013). Among the various findings, two are considered critical: online students would like to receive more instruction from their professors and more comprehensive feedback that would allow them to engage in corrective behaviors to improve performance. Comparing faculty and student responses related to the factors that affect student retention could give online program administrators and faculty advisors a better understanding of these critical factors to be able to respond to the student retention challenge more effectively.},
number = {1},
urldate = {2020-09-12},
journal = {American Journal of Distance Education},
author = {Gaytan, Jorge},
month = jan,
year = {2015},
note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08923647.2015.994365},
pages = {56--66},
}

@misc{lee_9_nodate,
title = {9. {Unsupervised} {Learning}: {Linear} {Dimension} {Reduction}},
language = {en},
author = {Lee, Hung-yi},
}

@article{sung_learning_2018,
title = {Learning to {Compare}: {Relation} {Network} for {Few}-{Shot} {Learning}},
shorttitle = {Learning to {Compare}},
url = {http://arxiv.org/abs/1711.06025},
abstract = {We present a conceptually simple, flexible, and general framework for few-shot learning, where a classifier must learn to recognise new classes given only few examples from each. Our method, called the Relation Network (RN), is trained end-to-end from scratch. During meta-learning, it learns to learn a deep distance metric to compare a small number of images within episodes, each of which is designed to simulate the few-shot setting. Once trained, a RN is able to classify images of new classes by computing relation scores between query images and the few examples of each new class without further updating the network. Besides providing improved performance on few-shot learning, our framework is easily extended to zero-shot learning. Extensive experiments on five benchmarks demonstrate that our simple approach provides a unified and effective approach for both of these two tasks.},
urldate = {2020-08-27},
journal = {arXiv:1711.06025 [cs]},
author = {Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip H. S. and Hospedales, Timothy M.},
month = mar,
year = {2018},
note = {arXiv: 1711.06025},
keywords = {Computer Science - Computer Vision and Pattern Recognition, discussion},
}

@article{xian_zero-shot_2018,
title = {Zero-{Shot} {Learning} - {A} {Comprehensive} {Evaluation} of the {Good}, the {Bad} and the {Ugly}},
url = {http://arxiv.org/abs/1707.00600},
abstract = {Due to the importance of zero-shot learning, i.e. classifying images where there is a lack of labeled training data, the number of proposed approaches has recently increased steadily. We argue that it is time to take a step back and to analyze the status quo of the area. The purpose of this paper is three-fold. First, given the fact that there is no agreed upon zero-shot learning benchmark, we first define a new benchmark by unifying both the evaluation protocols and data splits of publicly available datasets used for this task. This is an important contribution as published results are often not comparable and sometimes even flawed due to, e.g. pre-training on zero-shot test classes. Moreover, we propose a new zero-shot learning dataset, the Animals with Attributes 2 (AWA2) dataset which we make publicly available both in terms of image features and the images themselves. Second, we compare and analyze a significant number of the state-of-the-art methods in depth, both in the classic zero-shot setting but also in the more realistic generalized zero-shot setting. Finally, we discuss in detail the limitations of the current status of the area which can be taken as a basis for advancing it.},
urldate = {2020-09-10},
journal = {arXiv:1707.00600 [cs]},
author = {Xian, Yongqin and Lampert, Christoph H. and Schiele, Bernt and Akata, Zeynep},
month = aug,
year = {2018},
note = {arXiv: 1707.00600},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{ruder_overview_2017,
title = {An overview of gradient descent optimization algorithms},
url = {http://arxiv.org/abs/1609.04747},
abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
urldate = {2020-09-10},
journal = {arXiv:1609.04747 [cs]},
author = {Ruder, Sebastian},
month = jun,
year = {2017},
note = {arXiv: 1609.04747},
keywords = {Computer Science - Machine Learning},
}

@inproceedings{snell_prototypical_2017,
address = {Long Beach Convention \& Entertainment Center, Long Beach, CA},
title = {Prototypical {Networks} for {Few}-shot {Learning}},
url = {http://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning.pdf},
urldate = {2020-09-10},
booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
publisher = {Curran Associates, Inc.},
author = {Snell, Jake and Swersky, Kevin and Zemel, Richard},
editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
year = {2017},
pages = {4077--4087},
}

@inproceedings{koch_siamese_2015,
address = {Palais , France},
title = {Siamese {Neural} {Networks} for {One}-shot {Image} {Recognition}},
volume = {2},
abstract = {The process of learning good features for machine learning applications can be very computationally expensive and may prove difﬁcult in cases where little data is available. A prototypical example of this is the one-shot learning setting, in which we must correctly make predictions given only a single example of each new class. In this paper, we explore a method for learning siamese neural networks which employ a unique structure to naturally rank similarity between inputs. Once a network has been tuned, we can then capitalize on powerful discriminative features to generalize the predictive power of the network not just to new data, but to entirely new classes from unknown distributions. Using a convolutional architecture, we are able to achieve strong results which exceed those of other deep learning models with near state-of-the-art performance on one-shot classiﬁcation tasks.},
language = {en},
author = {Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
month = jul,
year = {2015},
pages = {8},
}

@misc{noauthor_17_nodate,
title = {17. {Transformer}},
}

@misc{lee_16_nodate,
title = {16. {Recursive} {Structure}},
language = {en},
author = {Lee, Hung-yi},
}

@misc{noauthor_15_nodate,
title = {15. {Pointer} {Network}},
}

@misc{noauthor_14_nodate,
title = {14. {Seq2seq}: {Conditional} {Generation} by {RNN} \& {Attention}},
}

@misc{lee_13_nodate,
title = {13. {Network} {Compression}},
language = {en},
author = {Lee, Hung-yi},
}

@misc{lee_12_nodate,
title = {12. {Attack} and {Defense}},
language = {en},
author = {Lee, Hung-yi},
}

@misc{lee_11_nodate,
title = {11. {Explainable} {Machine} {Learning}},
language = {en},
author = {Lee, Hung-yi},
}

@book{alpaydin_introduction_2020,
address = {Cambridge, Massachusetts},
edition = {fourth edition},
title = {Introduction to {Machine} {Learning}},
isbn = {978-0-262-04379-3},
abstract = {A substantially revised fourth edition of a comprehensive textbook, including new coverage of recent advances in deep learning and neural networks.The goal of machine learning is to program computers to use example data or past experience to solve a given problem. Machine learning underlies such exciting new technologies as self-driving cars, speech recognition, and translation applications. This substantially revised fourth edition of a comprehensive, widely used machine learning textbook offers new coverage of recent advances in the field in both theory and practice, including developments in deep learning and neural networks.The book covers a broad array of topics not usually included in introductory machine learning texts, including supervised learning, Bayesian decision theory, parametric methods, semiparametric methods, nonparametric methods, multivariate analysis, hidden Markov models, reinforcement learning, kernel machines, graphical models, Bayesian estimation, and statistical testing. The fourth edition offers a new chapter on deep learning that discusses training, regularizing, and structuring deep neural networks such as convolutional and generative adversarial networks; new material in the chapter on reinforcement learning that covers the use of deep networks, the policy gradient methods, and deep reinforcement learning; new material in the chapter on multilayer perceptrons on autoencoders and the word2vec network; and discussion of a popular method of dimensionality reduction, t-SNE. New appendixes offer background material on linear algebra and optimization. End-of-chapter exercises help readers to apply concepts learned. Introduction to Machine Learning can be used in courses for advanced undergraduate and graduate students and as a reference for professionals.},
language = {English},
publisher = {The MIT Press},
author = {Alpaydin, Ethem},
month = mar,
year = {2020},
}

@misc{noauthor_10_nodate,
title = {10. {Unsupervised} {Learning}: {Word} {Embedding}},
}

@article{weston_deep_nodate,
title = {Deep {Learning} via {Semi}-{Supervised} {Embedding}},
abstract = {We show how nonlinear embedding algorithms popular for use with shallow semisupervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This provides a simple alternative to existing approaches to deep learning whilst yielding competitive error rates compared to those methods, and existing shallow semi-supervised techniques.},
language = {en},
author = {Weston, Jason and Ratle, Frederic and Collobert, Ronan},
pages = {8},
}

@misc{noauthor_8_nodate,
title = {8. {Semi}-supervised learning},
keywords = {research ideas},
}

@article{boh_submission_nodate,
title = {Submission {Deadline}: {November} 30, 2020},
language = {en},
author = {Boh, Wai Fong and Constantinides, Panos and Padmanabhan, Balaji and Viswanathan, Siva},
pages = {3},
}

@misc{noauthor_7_nodate,
title = {7. {RNN}},
}

@misc{noauthor_2_nodate,
title = {2. {Regression}, {Bias} and {Variance}},
}

@misc{noauthor_4_nodate,
title = {4. {Classification}: {Logistic} {Regression}},
}

@misc{noauthor_6_nodate,
title = {6. {CNN}},
}

@inproceedings{vinyals_matching_2016,
address = {Barcelona, Spain},
title = {Matching {Networks} for {One} {Shot} {Learning}},
url = {http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning.pdf},
urldate = {2020-08-27},
booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
publisher = {Curran Associates, Inc.},
author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and kavukcuoglu, koray and Wierstra, Daan},
editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
year = {2016},
keywords = {discussion},
pages = {3630--3638},
}

@article{zhang_metapred_2019,
title = {{MetaPred}: {Meta}-{Learning} for {Clinical} {Risk} {Prediction} with {Limited} {Patient} {Electronic} {Health} {Records}},
shorttitle = {{MetaPred}},
url = {http://arxiv.org/abs/1905.03218},
abstract = {In recent years, increasingly augmentation of health data, such as patient Electronic Health Records (EHR), are becoming readily available. This provides an unprecedented opportunity for knowledge discovery and data mining algorithms to dig insights from them, which can, later on, be helpful to the improvement of the quality of care delivery. Predictive modeling of clinical risk, including in-hospital mortality, hospital readmission, chronic disease onset, condition exacerbation, etc., from patient EHR, is one of the health data analytic problems that attract most of the interests. The reason is not only because the problem is important in clinical settings, but also there are challenges working with EHR such as sparsity, irregularity, temporality, etc. Different from applications in other domains such as computer vision and natural language processing, the labeled data samples in medicine (patients) are relatively limited, which creates lots of troubles for effective predictive model learning, especially for complicated models such as deep learning. In this paper, we propose MetaPred, a meta-learning for clinical risk prediction from longitudinal patient EHRs. In particular, in order to predict the target risk where there are limited data samples, we train a meta-learner from a set of related risk prediction tasks which learns how a good predictor is learned. The meta-learned can then be directly used in target risk prediction, and the limited available samples can be used for further fine-tuning the model performance. The effectiveness of MetaPred is tested on a real patient EHR repository from Oregon Health \& Science University. We are able to demonstrate that with CNN and RNN as base predictors, MetaPred can achieve much better performance for predicting target risk with low resources comparing with the predictor trained on the limited samples available for this risk.},
urldate = {2020-08-27},
journal = {arXiv:1905.03218 [cs, stat]},
author = {Zhang, Xi Sheryl and Tang, Fengyi and Dodge, Hiroko and Zhou, Jiayu and Wang, Fei},
month = may,
year = {2019},
note = {arXiv: 1905.03218},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, discussion, research ideas},
}

@inproceedings{mahajan_meta-dermdiagnosis_2020,
title = {Meta-{DermDiagnosis}: {Few}-{Shot} {Skin} {Disease} {Identification} using {Meta}-{Learning}},
shorttitle = {Meta-{DermDiagnosis}},
doi = {10.1109/CVPRW50498.2020.00373},
abstract = {Annotated images for diagnosis of rare or novel diseases are likely to remain scarce due to small affected patient population and limited clinical expertise to annotate images. Deep networks employed for image based diagnosis need to be robust enough to quickly adapt to novel diseases with few annotated images. Further, in case of the frequently occurring long-tailed class distributions in skin lesion and other disease classification datasets, conventional training approaches lead to poor generalization on classes at the tail end of the distribution due to biased class priors. This paper focuses on the problems of disease identification and quick model adaptation in such data-scarce and long-tailed class distribution scenarios by exploiting recent advances in meta-learning. This involves training a neural network on few-shot image classification tasks based on an initial set of class labels / head classes of the distribution, prior to adapting the model for classification on a set of unseen / tail classes. We named the proposed method Meta-DermDiagnosis because it utilizes meta-learning based few-shot learning techniques such as the gradient based Reptile and distance metric based Prototypical networks for identification of diseases in skin lesion datasets. We evaluate the effectiveness of our approach on publicly available skin lesion datasets, namely the ISIC 2018, Derm7pt and SD-198 datasets and obtain significant performance improvement over pretrained models with just a few annotated examples. Further, we incorporate Group Equivariant convolutions (G-convolutions) for the Meta-DermDiagnosis network to improve disease identification performance as these images generally do not have any prevailing global orientation / canonical structure and G-convolutions make the network equivariant to any discrete transformations like rotation, reflection and translation.},
booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
author = {Mahajan, Kushagra and Sharma, Monika and Vig, Lovekesh},
month = jun,
year = {2020},
note = {ISSN: 2160-7516},
keywords = {Adaptation models, Biomedical imaging, Diseases, Lesions, Skin, Task analysis, Training},
pages = {3142--3151},
}

@misc{noauthor_5_nodate,
title = {5. {Deep} {Learning}},
}

@book{bishop_pattern_2006,
address = {New York},
series = {Information science and statistics},
title = {Pattern recognition and machine learning},
isbn = {978-0-387-31073-2},
language = {en},
publisher = {Springer},
author = {Bishop, Christopher M.},
year = {2006},
keywords = {Machine learning, Pattern perception},
}

@article{block_social_2020,
title = {Social network-based distancing strategies to flatten the {COVID} 19 curve in a post-lockdown world},
url = {http://arxiv.org/abs/2004.07052},
abstract = {Social distancing and isolation have been introduced widely to counter the COVID-19 pandemic. However, more moderate contact reduction policies become desirable owing to adverse social, psychological, and economic consequences of a complete or near-complete lockdown. Adopting a social network approach, we evaluate the effectiveness of three targeted distancing strategies designed to 'keep the curve flat' and aid compliance in a post-lockdown world. These are limiting interaction to a few repeated contacts, seeking similarity across contacts, and strengthening communities via triadic strategies. We simulate stochastic infection curves that incorporate core elements from infection models, ideal-type social network models, and statistical relational event models. We demonstrate that strategic reduction of contact can strongly increase the efficiency of social distancing measures, introducing the possibility of allowing some social contact while keeping risks low. This approach provides nuanced insights to policy makers for effective social distancing that can mitigate negative consequences of social isolation.},
urldate = {2020-08-10},
journal = {arXiv:2004.07052 [physics, q-bio, stat]},
author = {Block, Per and Hoffman, Marion and Raabe, Isabel J. and Dowd, Jennifer Beam and Rahal, Charles and Kashyap, Ridhi and Mills, Melinda C.},
month = may,
year = {2020},
note = {arXiv: 2004.07052},
keywords = {Physics - Physics and Society, Quantitative Biology - Populations and Evolution, Statistics - Other Statistics},
}

@inproceedings{wang_structural_2016,
address = {New York, NY, USA},
series = {{KDD} '16},
title = {Structural {Deep} {Network} {Embedding}},
isbn = {978-1-4503-4232-2},
url = {http://doi.acm.org/10.1145/2939672.2939753},
doi = {10.1145/2939672.2939753},
abstract = {Network embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.},
urldate = {2019-12-09},
booktitle = {Proceedings of the {22Nd} {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
publisher = {ACM},
author = {Wang, Daixin and Cui, Peng and Zhu, Wenwu},
year = {2016},
note = {event-place: San Francisco, California, USA},
keywords = {deep learning, network analysis, network embedding},
pages = {1225--1234},
}

@article{belkin_laplacian_2003,
title = {Laplacian {Eigenmaps} for {Dimensionality} {Reduction} and {Data} {Representation}},
volume = {15},
issn = {0899-7667},
url = {https://doi.org/10.1162/089976603321780317},
doi = {10.1162/089976603321780317},
abstract = {One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.},
number = {6},
urldate = {2019-05-31},
journal = {Neural Computation},
author = {Belkin, Mikhail and Niyogi, Partha},
month = jun,
year = {2003},
pages = {1373--1396},
}

@misc{lee_3_nodate,
title = {3. {Gradient} {Descent}},
language = {en},
author = {Lee, Hung-yi},
}

@misc{lee_1_nodate,
title = {1. {Machine} {Learning} {Introduction}},
language = {en},
author = {Lee, Hung-yi},
}

@inproceedings{ravi_optimization_2017,
title = {Optimization as a {Model} for {Few}-{Shot} {Learning}},
abstract = {Though deep neural networks have shown great success in the large data domain, they generally perform poorly on few-shot learning tasks, where a model has to quickly generalize after seeing very few examples from each class. The general belief is that gradient-based optimization in high capacity models requires many iterative steps over many examples to perform well. Here, we propose an LSTM-based meta-learner model to learn the exact optimization algorithm used to train another learner neural network in the few-shot regime. The parametrization of our model allows it to learn appropriate parameter updates specifically for the scenario where a set amount of updates will be made, while also learning a general initialization of the learner network that allows for quick convergence of training. We demonstrate that this meta-learning model is competitive with deep metric-learning techniques for few-shot learning.},
booktitle = {{ICLR}},
author = {Ravi, S. and Larochelle, H.},
year = {2017},
}

@article{gu_meta-learning_2018,
title = {Meta-{Learning} for {Low}-{Resource} {Neural} {Machine} {Translation}},
url = {http://arxiv.org/abs/1808.08437},
abstract = {In this paper, we propose to extend the recently introduced model-agnostic meta-learning algorithm (MAML) for low-resource neural machine translation (NMT). We frame low-resource translation as a meta-learning problem, and we learn to adapt to low-resource languages based on multilingual high-resource language tasks. We use the universal lexical representation{\textasciitilde}{\textbackslash}citep\{gu2018universal\} to overcome the input-output mismatch across different languages. We evaluate the proposed meta-learning strategy using eighteen European languages (Bg, Cs, Da, De, El, Es, Et, Fr, Hu, It, Lt, Nl, Pl, Pt, Sk, Sl, Sv and Ru) as source tasks and five diverse languages (Ro, Lv, Fi, Tr and Ko) as target tasks. We show that the proposed approach significantly outperforms the multilingual, transfer learning based approach{\textasciitilde}{\textbackslash}citep\{zoph2016transfer\} and enables us to train a competitive NMT system with only a fraction of training examples. For instance, the proposed approach can achieve as high as 22.04 BLEU on Romanian-English WMT'16 by seeing only 16,000 translated words ({\textasciitilde}600 parallel sentences).},
urldate = {2020-08-21},
journal = {arXiv:1808.08437 [cs]},
author = {Gu, Jiatao and Wang, Yong and Chen, Yun and Cho, Kyunghyun and Li, Victor O. K.},
month = aug,
year = {2018},
note = {arXiv: 1808.08437},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{andrychowicz_learning_2016,
title = {Learning to learn by gradient descent by gradient descent},
url = {http://arxiv.org/abs/1606.04474},
abstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},
urldate = {2020-08-20},
journal = {arXiv:1606.04474 [cs]},
author = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and Shillingford, Brendan and de Freitas, Nando},
month = nov,
year = {2016},
note = {arXiv: 1606.04474},
keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@misc{noauthor_cord-19_nodate,
title = {{CORD}-19 {Non}-{Pharmaceutical} {Interventions}},
url = {https://kaggle.com/davidmezzetti/cord-19-non-pharmaceutical-interventions},
abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from multiple data sources},
language = {en},
urldate = {2020-08-14},
}

@article{wellenius_impacts_2020,
title = {Impacts of {State}-{Level} {Policies} on {Social} {Distancing} in the {United} {States} {Using} {Aggregated} {Mobility} {Data} during the {COVID}-19 {Pandemic}},
url = {http://arxiv.org/abs/2004.10172},
abstract = {Social distancing has emerged as the primary mitigation strategy to combat the COVID-19 pandemic in the United States. However, large-scale evaluation of the public's response to social distancing campaigns has been lacking. We used anonymized and aggregated mobility data from Google Location History users to estimate the impact of social distancing recommendations on bulk mobility among users who have opted into this service. We found that state-of-emergency declarations resulted in approximately a 10\% reduction in time spent away from places of residence. Implementation of one or more social distancing policies resulted in an additional 25\% reduction in mobility the following week. Subsequent shelter-in-place mandates provided an additional 29\% reduction. Our findings provide evidence that state-wide mandates are effective in promoting social distancing within this study group.},
urldate = {2020-08-14},
journal = {arXiv:2004.10172 [q-bio]},
author = {Wellenius, Gregory A. and Vispute, Swapnil and Espinosa, Valeria and Fabrikant, Alex and Tsai, Thomas C. and Hennessy, Jonathan and Williams, Brian and Gadepalli, Krishna and Boulanger, Adam and Pearce, Adam and Kamath, Chaitanya and Schlosberg, Arran and Bendebury, Catherine and Stanton, Charlotte and Bavadekar, Shailesh and Pluntke, Christopher and Desfontaines, Damien and Jacobson, Benjamin and Armstrong, Zan and Gipson, Bryant and Wilson, Royce and Widdowson, Andrew and Chou, Katherine and Oplinger, Andrew and Shekel, Tomer and Jha, Ashish K. and Gabrilovich, Evgeniy},
month = apr,
year = {2020},
note = {arXiv: 2004.10172},
keywords = {Quantitative Biology - Populations and Evolution},
}

@article{alamo_open_2020,
title = {Open {Data} {Resources} for {Fighting} {COVID}-19},
url = {http://arxiv.org/abs/2004.06111},
abstract = {We provide an insight into the open data resources pertinent to the study of the spread of Covid-19 pandemic and its control. We identify the variables required to analyze fundamental aspects like seasonal behaviour, regional mortality rates, and effectiveness of government measures. Open data resources, along with data-driven methodologies, provide many opportunities to improve the response of the different administrations to the virus. We describe the present limitations and difficulties encountered in most of the open-data resources. To facilitate the access to the main open-data portals and resources, we identify the most relevant institutions, at a world scale, providing Covid-19 information and/or auxiliary variables (demographics, mobility, etc.). We also describe several open resources to access Covid-19 data-sets at a country-wide level (i.e. China, Italy, Spain, France, Germany, U.S., etc.). In an attempt to facilitate the rapid response to the study of the seasonal behaviour of Covid-19, we enumerate the main open resources in terms of weather and climate variables. CONCO-Team: The authors of this paper belong to the CONtrol COvid-19 Team, which is composed of different researches from universities of Spain, Italy, France, Germany, United Kingdom and Argentina. The main goal of CONCO-Team is to develop data-driven methods for the better understanding and control of the pandemic.},
urldate = {2020-08-14},
journal = {arXiv:2004.06111 [q-bio, stat]},
author = {Alamo, Teodoro and Reina, Daniel G. and Mammarella, Martina and Abella, Alberto},
month = may,
year = {2020},
note = {arXiv: 2004.06111},
keywords = {Quantitative Biology - Other Quantitative Biology, Statistics - Machine Learning},
}

@article{killeen_county-level_2020,
title = {A {County}-level {Dataset} for {Informing} the {United} {States}' {Response} to {COVID}-19},
url = {http://arxiv.org/abs/2004.00756},
abstract = {As the coronavirus disease 2019 (COVID-19) becomes a global pandemic, policy makers must enact interventions to stop its spread. Data driven approaches might supply information to support the implementation of mitigation and suppression strategies. To facilitate research in this direction, we present a machine-readable dataset that aggregates relevant data from governmental, journalistic, and academic sources on the county level. In addition to county-level time-series data from the JHU CSSE COVID-19 Dashboard, our dataset contains more than 300 variables that summarize population estimates, demographics, ethnicity, housing, education, employment and in come, climate, transit scores, and healthcare system-related metrics. Furthermore, we present aggregated out-of-home activity information for various points of interest for each county, including grocery stores and hospitals, summarizing data from SafeGraph. By collecting these data, as well as providing tools to read them, we hope to aid researchers investigating how the disease spreads and which communities are best able to accommodate stay-at-home mitigation efforts. Our dataset and associated code are available at https://github.com/JieYingWu/COVID-19\_US\_County-level\_Summaries.},
urldate = {2020-08-14},
journal = {arXiv:2004.00756 [physics, q-bio]},
author = {Killeen, Benjamin D. and Wu, Jie Ying and Shah, Kinjal and Zapaishchykova, Anna and Nikutta, Philipp and Tamhane, Aniruddha and Chakraborty, Shreya and Wei, Jinchi and Gao, Tiger and Thies, Mareike and Unberath, Mathias},
month = apr,
year = {2020},
note = {arXiv: 2004.00756},
keywords = {Computer Science - Computers and Society, Computer Science - Databases, Physics - Physics and Society, Quantitative Biology - Populations and Evolution},
}

@article{chen_tracking_2020,
title = {Tracking {Social} {Media} {Discourse} {About} the {COVID}-19 {Pandemic}: {Development} of a {Public} {Coronavirus} {Twitter} {Data} {Set}},
volume = {6},
issn = {2369-2960},
shorttitle = {Tracking {Social} {Media} {Discourse} {About} the {COVID}-19 {Pandemic}},
url = {http://arxiv.org/abs/2003.07372},
doi = {10.2196/19273},
abstract = {At the time of this writing, the novel coronavirus (COVID-19) pandemic outbreak has already put tremendous strain on many countries' citizens, resources and economies around the world. Social distancing measures, travel bans, self-quarantines, and business closures are changing the very fabric of societies worldwide. With people forced out of public spaces, much conversation about these phenomena now occurs online, e.g., on social media platforms like Twitter. In this paper, we describe a multilingual coronavirus (COVID-19) Twitter dataset that we have been continuously collecting since January 22, 2020. We are making our dataset available to the research community (https://github.com/echen102/COVID-19-TweetIDs). It is our hope that our contribution will enable the study of online conversation dynamics in the context of a planetary-scale epidemic outbreak of unprecedented proportions and implications. This dataset could also help track scientific coronavirus misinformation and unverified rumors, or enable the understanding of fear and panic -- and undoubtedly more. Ultimately, this dataset may contribute towards enabling informed solutions and prescribing targeted policy interventions to fight this global crisis.},
number = {2},
urldate = {2020-08-14},
journal = {JMIR Public Health and Surveillance},
author = {Chen, Emily and Lerman, Kristina and Ferrara, Emilio},
month = may,
year = {2020},
note = {arXiv: 2003.07372},
keywords = {Computer Science - Social and Information Networks, Quantitative Biology - Populations and Evolution},
pages = {e19273},
}

@misc{noauthor_deep_nodate,
title = {Deep {Reinforcement} {Learning} {Course}},
url = {https://simoninithomas.github.io/Deep_reinforcement_learning_Course/},
urldate = {2020-08-13},
}

@article{nichol_first-order_2018,
title = {On {First}-{Order} {Meta}-{Learning} {Algorithms}},
url = {http://arxiv.org/abs/1803.02999},
abstract = {This paper considers meta-learning problems, where there is a distribution of tasks, and we would like to obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution. We analyze a family of algorithms for learning a parameter initialization that can be fine-tuned quickly on a new task, using only first-order derivatives for the meta-learning updates. This family includes and generalizes first-order MAML, an approximation to MAML obtained by ignoring second-order derivatives. It also includes Reptile, a new algorithm that we introduce here, which works by repeatedly sampling a task, training on it, and moving the initialization towards the trained weights on that task. We expand on the results from Finn et al. showing that first-order meta-learning algorithms perform well on some well-established benchmarks for few-shot classification, and we provide theoretical analysis aimed at understanding why these algorithms work.},
urldate = {2020-08-13},
journal = {arXiv:1803.02999 [cs]},
author = {Nichol, Alex and Achiam, Joshua and Schulman, John},
month = oct,
year = {2018},
note = {arXiv: 1803.02999},
keywords = {Computer Science - Machine Learning},
}

@article{finn_model-agnostic_2017,
title = {Model-{Agnostic} {Meta}-{Learning} for {Fast} {Adaptation} of {Deep} {Networks}},
url = {http://arxiv.org/abs/1703.03400},
abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
urldate = {2020-08-13},
journal = {arXiv:1703.03400 [cs]},
author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
month = jul,
year = {2017},
note = {arXiv: 1703.03400},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{pan_urban_2019,
address = {New York, NY, USA},
series = {{KDD} '19},
title = {Urban {Traffic} {Prediction} from {Spatio}-{Temporal} {Data} {Using} {Deep} {Meta} {Learning}},
isbn = {978-1-4503-6201-6},
url = {https://doi.org/10.1145/3292500.3330884},
doi = {10.1145/3292500.3330884},
abstract = {Predicting urban traffic is of great importance to intelligent transportation systems and public safety, yet is very challenging because of two aspects: 1) complex spatio-temporal correlations of urban traffic, including spatial correlations between locations along with temporal correlations among timestamps; 2) diversity of such spatio-temporal correlations, which vary from location to location and depend on the surrounding geographical information, e.g., points of interests and road networks. To tackle these challenges, we proposed a deep-meta-learning based model, entitled ST-MetaNet, to collectively predict traffic in all location at once. ST-MetaNet employs a sequence-to-sequence architecture, consisting of an encoder to learn historical information and a decoder to make predictions step by step. In specific, the encoder and decoder have the same network structure, consisting of a recurrent neural network to encode the traffic, a meta graph attention network to capture diverse spatial correlations, and a meta recurrent neural network to consider diverse temporal correlations. Extensive experiments were conducted based on two real-world datasets to illustrate the effectiveness of ST-MetaNet beyond several state-of-the-art methods.},
urldate = {2020-08-13},
booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
publisher = {Association for Computing Machinery},
author = {Pan, Zheyi and Liang, Yuxuan and Wang, Weifeng and Yu, Yong and Zheng, Yu and Zhang, Junbo},
month = jul,
year = {2019},
keywords = {discussion, meta learning, neural network, spatio-temporal data, urban traffic},
pages = {1720--1730},
}

@inproceedings{huang_label_2017,
address = {Cambridge, United Kingdom},
title = {Label {Informed} {Attributed} {Network} {Embedding}},
isbn = {978-1-4503-4675-7},
url = {http://dl.acm.org/citation.cfm?doid=3018661.3018667},
doi = {10.1145/3018661.3018667},
abstract = {Attributed network embedding aims to seek low-dimensional vector representations for nodes in a network, such that original network topological structure and node attribute proximity can be preserved in the vectors. These learned representations have been demonstrated to be helpful in many learning tasks such as network clustering and link prediction. While existing algorithms follow an unsupervised manner, nodes in many real-world attributed networks are often associated with abundant label information, which is potentially valuable in seeking more eﬀective joint vector representations. In this paper, we investigate how labels can be modeled and incorporated to improve attributed network embedding. This is a challenging task since label information could be noisy and incomplete. In addition, labels are completely distinct with the geometrical structure and node attributes. The bewildering combination of heterogeneous information makes the joint vector representation learning more diﬃcult. To address these issues, we propose a novel Label informed Attributed Network Embedding (LANE) framework. It can smoothly incorporate label information into the attributed network embedding while preserving their correlations. Experiments on real-world datasets demonstrate that the proposed framework achieves signiﬁcantly better performance compared with the state-of-the-art embedding algorithms.},
language = {en},
urldate = {2020-01-10},
booktitle = {Proceedings of the {Tenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining} - {WSDM} '17},
publisher = {ACM Press},
author = {Huang, Xiao and Li, Jundong and Hu, Xia},
year = {2017},
pages = {731--739},
}

@article{decroos_actions_2019,
title = {Actions {Speak} {Louder} {Than} {Goals}: {Valuing} {Player} {Actions} in {Soccer}},
shorttitle = {Actions {Speak} {Louder} {Than} {Goals}},
url = {http://arxiv.org/abs/1802.07127},
doi = {10.1145/3292500.3330758},
abstract = {Assessing the impact of the individual actions performed by soccer players during games is a crucial aspect of the player recruitment process. Unfortunately, most traditional metrics fall short in addressing this task as they either focus on rare actions like shots and goals alone or fail to account for the context in which the actions occurred. This paper introduces (1) a new language for describing individual player actions on the pitch and (2) a framework for valuing any type of player action based on its impact on the game outcome while accounting for the context in which the action happened. By aggregating soccer players' action values, their total offensive and defensive contributions to their team can be quantified. We show how our approach considers relevant contextual information that traditional player evaluation metrics ignore and present a number of use cases related to scouting and playing style characterization in the 2016/2017 and 2017/2018 seasons in Europe's top competitions.},
urldate = {2020-08-03},
journal = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
author = {Decroos, Tom and Bransen, Lotte and Van Haaren, Jan and Davis, Jesse},
month = jul,
year = {2019},
note = {arXiv: 1802.07127},
keywords = {Statistics - Applications, Statistics - Machine Learning, discussion, research ideas},
pages = {1851--1861},
}

@article{bayham_impact_2020,
title = {The {Impact} of {School} {Closure} for {COVID}-19 on the {US} {Healthcare} {Workforce} and the {Net} {Mortality} {Effects}},
copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
url = {https://www.medrxiv.org/content/10.1101/2020.03.09.20033415v2},
doi = {10.1101/2020.03.09.20033415},
abstract = {{\textless}p{\textgreater}Background COVID-19 is leading to the implementation of social distancing policies around the world and in the United States, including school closures. The evidence that mandatory school closures reduce cases and ultimately mortality mostly comes from experience with influenza or from models that do not include the impact of school closure on the healthcare labor supply or the role of the healthcare labor force in reducing the per infection mortality from the pathogen. There is considerable uncertainty of the incremental effect of school closures on transmission and lives saved from school closures. The likely, but uncertain, benefits from school closure need to be weighed against uncertain, and seldom quantified, costs of healthcare worker absenteeism associated with additional child care obligations. Methods We analyze data from the US Current Population Survey to measure the potential child care obligations for US healthcare workers that will need to be addressed if school closures are employed as a social distancing measure. We account for the occupation within the healthcare sector, state, and household structure to identify the segments of the healthcare labor force that are most exposed to child care obligations from school closures. We use these estimates to identify the critical level for the importance of healthcare labor supply in increasing a patient9s COVID-19 survival probability that would undo the benefits of school closures and ultimately increase cumulative mortality. Findings The US healthcare sector has some of the highest child care obligations in the United States. 29\% of healthcare provider households must provide care for children 3-12. Assuming non-working adults or a sibling 13 years old or older can provide child care, leaves 15\% of healthcare provider households in need of childcare during a school closure, while 7\% of healthcare households are single-parent households. We document the substantial variation within the healthcare system. For example, 35\% of medical assistants and 31\% of nursing, psychiatric, and home health aide households have child care obligations, while only 24\% of emergency medical personnel have childcare obligations. Child care obligations can vary between states by over 10 percentage points. A 15\% decline in the healthcare labor force, combined with reasonable parameters for COVID-19 such as a 15\% case reduction from school closings and 2\% baseline mortality rate implies that a 15\% loss in the healthcare labor force must decrease the survival probability per percent healthcare worker lost by 17.6\% for a school closure to increase cumulative mortality. This means that the per infection mortality rate cannot increase from 2\% to 2.35\% when the healthcare workforce declines by 15\%; otherwise, school closures will lead to a greater number of deaths than they prevent. For school closures to unambiguously provide a net reduction in COVID-19 mortality with these parameters, the school closures must reduce cases by over 25\%. Conclusion School closures come with many tradeoffs. Setting aside economic costs, school closures implemented to reduce COVID-19 spread create unintended childcare obligations, which are particularly large in healthcare occupations. Detailed data are provided to help public health officials make informed decisions about the tradeoffs associated with closing schools. The results suggest that it is unclear if the potential contagion prevention from school closures justifies the potential loss of healthcare workers from the standpoint of reducing cummulative mortality.{\textless}/p{\textgreater}},
language = {en},
urldate = {2020-08-10},
journal = {medRxiv},
author = {Bayham, Jude and Fenichel, Eli P.},
month = mar,
year = {2020},
note = {Publisher: Cold Spring Harbor Laboratory Press},
pages = {2020.03.09.20033415},
}

@article{giorgi_cultural_2020,
title = {Cultural {Differences} in {Tweeting} about {Drinking} {Across} the {US}},
volume = {17},
copyright = {http://creativecommons.org/licenses/by/3.0/},
url = {https://www.mdpi.com/1660-4601/17/4/1125},
doi = {10.3390/ijerph17041125},
abstract = {Excessive alcohol use in the US contributes to over 88,000 deaths per year and costs over \$250 billion annually. While previous studies have shown that excessive alcohol use can be detected from general patterns of social media engagement, we characterized how drinking-specific language varies across regions and cultures in the US. From a database of 38 billion public tweets, we selected those mentioning \&ldquo;drunk\&rdquo;, found the words and phrases distinctive of drinking posts, and then clustered these into topics and sets of semantically related words. We identified geolocated \&ldquo;drunk\&rdquo; tweets and correlated their language with the prevalence of self-reported excessive alcohol consumption (Behavioral Risk Factor Surveillance System; BRFSS). We then identified linguistic markers associated with excessive drinking in different regions and cultural communities as identified by the American Community Project. \&ldquo;Drunk\&rdquo; tweet frequency (of the 3.3 million geolocated \&ldquo;drunk\&rdquo; tweets) correlated with excessive alcohol consumption at both the county and state levels (r = 0.26 and 0.45, respectively, p \&lt; 0.01). Topic analyses revealed that excessive alcohol consumption was most correlated with references to drinking with friends (r = 0.20), family (r = 0.15), and driving under the influence (r = 0.14). Using the American Community Project classification, we found a number of cultural markers of drinking: religious communities had a high frequency of anti-drunk driving tweets, Hispanic centers discussed family members drinking, and college towns discussed sexual behavior. This study shows that Twitter can be used to explore the specific sociocultural contexts in which excessive alcohol use occurs within particular regions and communities. These findings can inform more targeted public health messaging and help to better understand cultural determinants of substance abuse.},
language = {en},
number = {4},
urldate = {2020-02-14},
journal = {International Journal of Environmental Research and Public Health},
author = {Giorgi, Salvatore and Yaden, David B. and Eichstaedt, Johannes C. and Ashford, Robert D. and Buffone, Anneke E. K. and Schwartz, H. Andrew and Ungar, Lyle H. and Curtis, Brenda},
month = jan,
year = {2020},
keywords = {American Communities Project, Twitter, excessive drinking, natural language processing, social media},
pages = {1125},
}

@article{su_network_nodate,
title = {Network embedding in biomedical data science},
url = {https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bby117/5228144},
doi = {10.1093/bib/bby117},
abstract = {Abstract.  Owning to the rapid development of computer technologies, an increasing number of relational data have been emerging in modern biomedical research. M},
language = {en},
urldate = {2019-12-18},
journal = {Briefings in Bioinformatics},
author = {Su, Chang and Tong, Jie and Zhu, Yongjun and Cui, Peng and Wang, Fei},
}

@article{tang_line:_2015,
title = {{LINE}: {Large}-scale {Information} {Network} {Embedding}},
shorttitle = {{LINE}},
url = {http://arxiv.org/abs/1503.03578},
doi = {10.1145/2736277.2741093},
abstract = {This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the "LINE," which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online.},
urldate = {2019-12-09},
journal = {Proceedings of the 24th International Conference on World Wide Web - WWW '15},
author = {Tang, Jian and Qu, Meng and Wang, Mingzhe and Zhang, Ming and Yan, Jun and Mei, Qiaozhu},
year = {2015},
note = {arXiv: 1503.03578},
keywords = {Computer Science - Machine Learning},
pages = {1067--1077},
}

@article{li_approach_2003,
title = {An {Approach} for {Measuring} {Semantic} {Similarity} {Between} {Words} {Using} {Multiple} {Information} {Sources}},
volume = {15},
issn = {1041-4347},
url = {https://doi.org/10.1109/TKDE.2003.1209005},
doi = {10.1109/TKDE.2003.1209005},
abstract = {Semantic similarity between words is becoming a generic problem for many applications of computational linguistics and artificial intelligence. This paper explores the determination of semantic similarity by a number of information sources, which consist of structural semantic information from a lexical taxonomy and information content from a corpus. To investigate how information sources could be used effectively, a variety of strategies for using various possible information sources are implemented. A new measure is then proposed which combines information sources nonlinearly. Experimental evaluation against a benchmark set of human similarity ratings demonstrates that the proposed measure significantly outperforms traditional similarity measures.},
number = {4},
urldate = {2019-11-14},
journal = {IEEE Trans. on Knowl. and Data Eng.},
author = {Li, Yuhua and Bandar, Zuhair A. and McLean, David},
month = jul,
year = {2003},
keywords = {Semantic similarity, corpus statistics., information content, lexical database},
pages = {871--882},
}

@article{maaten_dimensionality_2009,
title = {Dimensionality {Reduction}: {A} {Comparative} {Review}},
volume = {66},
url = {http://www.math.chalmers.se/Stat/Grundutb/GU/MSA220/S18/DimRed2.pdf},
abstract = {In recent years, a variety of nonlinear dimensionality reduction techniques have been proposed that aim to address the limitations of traditional techniques such as PCA and classical scaling. The paper presents a review and systematic comparison of these techniques. The performances of the nonlinear techniques are investigated on artificial and natural tasks. The results of the experiments reveal that nonlinear techniques perform well on selected artificial tasks, but that this strong performance does not necessarily extend to real-world tasks. The paper explains these results by identifying weaknesses of current nonlinear techniques, and suggests how the performance of nonlinear dimensionality reduction techniques may be improved.},
number = {10},
journal = {Journal of Machine Learning Research},
author = {Maaten, Laurens van der and Postma, Eric and Herik, Jaap van den},
year = {2009},
pages = {13},
}

@article{wongkoblap_researching_2017,
title = {Researching {Mental} {Health} {Disorders} in the {Era} of {Social} {Media}: {Systematic} {Review}},
volume = {19},
copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work (},
shorttitle = {Researching {Mental} {Health} {Disorders} in the {Era} of {Social} {Media}},
url = {https://www.jmir.org/2017/6/e228/},
doi = {10.2196/jmir.7215},
abstract = {Background: Mental illness is quickly becoming one of the most prevalent public health problems worldwide. Social network platforms, where users can express their emotions, feelings, and thoughts, are a valuable source of data for researching mental health, and techniques based on machine learning are increasingly used for this purpose. Objective: The objective of this review was to explore the scope and limits of cutting-edge techniques that researchers are using for predictive analytics in mental health and to review associated issues, such as ethical concerns, in this area of research. Methods: We performed a systematic literature review in March 2017, using keywords to search articles on data mining of social network data in the context of common mental health disorders, published between 2010 and March 8, 2017 in medical and computer science journals. Results: The initial search returned a total of 5386 articles. Following a careful analysis of the titles, abstracts, and main texts, we selected 48 articles for review. We coded the articles according to key characteristics, techniques used for data collection, data preprocessing, feature extraction, feature selection, model construction, and model verification. The most common analytical method was text analysis, with several studies using different flavors of image analysis and social interaction graph analysis. Conclusions: Despite an increasing number of studies investigating mental health issues using social network data, some common problems persist. Assembling large, high-quality datasets of social media users with mental disorder is problematic, not only due to biases associated with the collection methods, but also with regard to managing consent and selecting appropriate analytics techniques.  [J Med Internet Res 2017;19(6):e228]},
language = {en},
number = {6},
urldate = {2019-10-28},
journal = {Journal of Medical Internet Research},
author = {Wongkoblap, Akkapon and Vadillo, Miguel A. and Curcin, Vasa},
year = {2017},
pages = {e228},
}

@article{leis_detecting_2019,
title = {Detecting {Signs} of {Depression} in {Tweets} in {Spanish}: {Behavioral} and {Linguistic} {Analysis}},
volume = {21},
copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work (},
shorttitle = {Detecting {Signs} of {Depression} in {Tweets} in {Spanish}},
url = {https://www.jmir.org/2019/6/e14199/},
doi = {10.2196/14199},
abstract = {Background: Mental disorders have become a major concern in public health, and they are one of the main causes of the overall disease burden worldwide. Social media platforms allow us to observe the activities, thoughts, and feelings of people’s daily lives, including those of patients suffering from mental disorders. There are studies that have analyzed the influence of mental disorders, including depression, in the behavior of social media users, but they have been usually focused on messages written in English. Objective: The study aimed to identify the linguistic features of tweets in Spanish and the behavioral patterns of Twitter users who generate them, which could suggest signs of depression. Methods: This study was developed in 2 steps. In the first step, the selection of users and the compilation of tweets were performed. A total of 3 datasets of tweets were created, a depressive users dataset (made up of the timeline of 90 users who explicitly mentioned that they suffer from depression), a depressive tweets dataset (a manual selection of tweets from the previous users, which included expressions indicative of depression), and a control dataset (made up of the timeline of 450 randomly selected users). In the second step, the comparison and analysis of the 3 datasets of tweets were carried out. Results: In comparison with the control dataset, the depressive users are less active in posting tweets, doing it more frequently between 23:00 and 6:00 (P{\textless}.001). The percentage of nouns used by the control dataset almost doubles that of the depressive users (P{\textless}.001). By contrast, the use of verbs is more common in the depressive users dataset (P{\textless}.001). The first-person singular pronoun was by far the most used in the depressive users dataset (80\%), and the first- and the second-person plural pronouns were the least frequent (0.4\% in both cases), this distribution being different from that of the control dataset (P{\textless}.001). Emotions related to sadness, anger, and disgust were more common in the depressive users and depressive tweets datasets, with significant differences when comparing these datasets with the control dataset (P{\textless}.001). As for negation words, they were detected in 34\% and 46\% of tweets in among depressive users and in depressive tweets, respectively, which are significantly different from the control dataset (P{\textless}.001). Negative polarity was more frequent in the depressive users (54\%) and depressive tweets (65\%) datasets than in the control dataset (43.5\%; P{\textless}.001). Conclusions: Twitter users who are potentially suffering from depression modify the general characteristics of their language and the way they interact on social media. On the basis of these changes, these users can be monitored and supported, thus introducing new opportunities for studying depression and providing additional health care services to people with this disorder.  [J Med Internet Res 2019;21(6):e14199]},
language = {en},
number = {6},
urldate = {2019-10-28},
journal = {Journal of Medical Internet Research},
author = {Leis, Angela and Ronzano, Francesco and Mayer, Miguel A. and Furlong, Laura I. and Sanz, Ferran},
year = {2019},
pages = {e14199},
}

@article{gottlieb_method_2013,
title = {A method for inferring medical diagnoses from patient similarities},
volume = {11},
issn = {1741-7015},
url = {https://doi.org/10.1186/1741-7015-11-194},
doi = {10.1186/1741-7015-11-194},
abstract = {Clinical decision support systems assist physicians in interpreting complex patient data. However, they typically operate on a per-patient basis and do not exploit the extensive latent medical knowledge in electronic health records (EHRs). The emergence of large EHR systems offers the opportunity to integrate population information actively into these tools.},
number = {1},
urldate = {2019-08-28},
journal = {BMC Medicine},
author = {Gottlieb, Assaf and Stein, Gideon Y. and Ruppin, Eytan and Altman, Russ B. and Sharan, Roded},
month = sep,
year = {2013},
pages = {194},
}

@article{girardi_using_2016,
title = {Using concept hierarchies to improve calculation of patient similarity},
volume = {63},
issn = {1532-0464},
url = {http://www.sciencedirect.com/science/article/pii/S1532046416300752},
doi = {10.1016/j.jbi.2016.07.021},
abstract = {Objective
We introduce a new distance measure that is better suited than traditional methods at detecting similarities in patient records by referring to a concept hierarchy.
Materials and methods
The new distance measure improves on distance measures for categorical values by taking the path distance between concepts in a hierarchy into account. We evaluate and compare the new measure on a data set of 836 patients.
Results
The new measure shows marked improvements over the standard measures, both qualitatively and quantitatively. Using the new measure for clustering patient data reveals structure that is otherwise not visible. Statistical comparisons of distances within patient groups with similar diagnoses shows that the new measure is significantly better at detecting these similarities than the standard measures.
Conclusion
The new distance measure is an improvement over the current standard whenever a hierarchical arrangement of categorical values is available.},
urldate = {2019-08-28},
journal = {Journal of Biomedical Informatics},
author = {Girardi, Dominic and Wartner, Sandra and Halmerbauer, Gerhard and Ehrenmüller, Margit and Kosorus, Hilda and Dreiseitl, Stephan},
month = oct,
year = {2016},
keywords = {Distance measure using concept hierarchy, ICD-10 taxonomy, Patient similarity calculation},
pages = {66--73},
}

@article{maaten_visualizing_2008,
title = {Visualizing {Data} using t-{SNE}},
volume = {9},
issn = {ISSN 1533-7928},
url = {http://www.jmlr.org/papers/v9/vandermaaten08a.html},
number = {Nov},
urldate = {2019-10-23},
journal = {Journal of Machine Learning Research},
author = {Maaten, Laurens van der and Hinton, Geoffrey},
year = {2008},
pages = {2579--2605},
}

@article{mcinnes_umap:_2018,
title = {{UMAP}: {Uniform} {Manifold} {Approximation} and {Projection} for {Dimension} {Reduction}},
shorttitle = {{UMAP}},
url = {http://arxiv.org/abs/1802.03426},
abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
urldate = {2019-10-15},
journal = {arXiv:1802.03426 [cs, stat]},
author = {McInnes, Leland and Healy, John and Melville, James},
month = feb,
year = {2018},
note = {arXiv: 1802.03426},
keywords = {Computer Science - Computational Geometry, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{nguyen_deepr:_2016,
title = {Deepr: {A} {Convolutional} {Net} for {Medical} {Records}},
shorttitle = {Deepr},
url = {http://arxiv.org/abs/1607.07519},
abstract = {Feature engineering remains a major bottleneck when creating predictive systems from electronic medical records. At present, an important missing element is detecting predictive regular clinical motifs from irregular episodic records. We present Deepr (short for Deep record), a new end-to-end deep learning system that learns to extract features from medical records and predicts future risk automatically. Deepr transforms a record into a sequence of discrete elements separated by coded time gaps and hospital transfers. On top of the sequence is a convolutional neural net that detects and combines predictive local clinical motifs to stratify the risk. Deepr permits transparent inspection and visualization of its inner working. We validate Deepr on hospital data to predict unplanned readmission after discharge. Deepr achieves superior accuracy compared to traditional techniques, detects meaningful clinical motifs, and uncovers the underlying structure of the disease and intervention space.},
urldate = {2019-09-18},
journal = {arXiv:1607.07519 [cs, stat]},
author = {Nguyen, Phuoc and Tran, Truyen and Wickramasinghe, Nilmini and Venkatesh, Svetha},
month = jul,
year = {2016},
note = {arXiv: 1607.07519},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{seymour_assessment_2016,
title = {Assessment of {Clinical} {Criteria} for {Sepsis}: {For} the {Third} {International} {Consensus} {Definitions} for {Sepsis} and {Septic} {Shock} ({Sepsis}-3)},
volume = {315},
issn = {0098-7484},
shorttitle = {Assessment of {Clinical} {Criteria} for {Sepsis}},
url = {https://jamanetwork.com/journals/jama/fullarticle/2492875},
doi = {10.1001/jama.2016.0288},
abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}The Third International Consensus Definitions Task Force defined sepsis as “life-threatening organ dysfunction due to a dysregulated host response to infection.” The performance of clinical criteria for this sepsis definition is unknown.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To evaluate the validity of clinical criteria to identify patients with suspected infection who are at risk of sepsis.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Settings, and Population{\textless}/h3{\textgreater}{\textless}p{\textgreater}Among 1.3 million electronic health record encounters from January 1, 2010, to December 31, 2012, at 12 hospitals in southwestern Pennsylvania, we identified those with suspected infection in whom to compare criteria. Confirmatory analyses were performed in 4 data sets of 706 399 out-of-hospital and hospital encounters at 165 US and non-US hospitals ranging from January 1, 2008, until December 31, 2013.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Exposures{\textless}/h3{\textgreater}{\textless}p{\textgreater}Sequential [Sepsis-related] Organ Failure Assessment (SOFA) score, systemic inflammatory response syndrome (SIRS) criteria, Logistic Organ Dysfunction System (LODS) score, and a new model derived using multivariable logistic regression in a split sample, the quick Sequential [Sepsis-related] Organ Failure Assessment (qSOFA) score (range, 0-3 points, with 1 point each for systolic hypotension [≤100 mm Hg], tachypnea [≥22/min], or altered mentation).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}For construct validity, pairwise agreement was assessed. For predictive validity, the discrimination for outcomes (primary: in-hospital mortality; secondary: in-hospital mortality or intensive care unit [ICU] length of stay ≥3 days) more common in sepsis than uncomplicated infection was determined. Results were expressed as the fold change in outcome over deciles of baseline risk of death and area under the receiver operating characteristic curve (AUROC).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}In the primary cohort, 148 907 encounters had suspected infection (n = 74 453 derivation; n = 74 454 validation), of whom 6347 (4\%) died. Among ICU encounters in the validation cohort (n = 7932 with suspected infection, of whom 1289 [16\%] died), the predictive validity for in-hospital mortality was lower for SIRS (AUROC = 0.64; 95\% CI, 0.62-0.66) and qSOFA (AUROC = 0.66; 95\% CI, 0.64-0.68) vs SOFA (AUROC = 0.74; 95\% CI, 0.73-0.76;\textit{P} \&lt; .001 for both) or LODS (AUROC = 0.75; 95\% CI, 0.73-0.76;\textit{P} \&lt; .001 for both). Among non-ICU encounters in the validation cohort (n = 66 522 with suspected infection, of whom 1886 [3\%] died), qSOFA had predictive validity (AUROC = 0.81; 95\% CI, 0.80-0.82) that was greater than SOFA (AUROC = 0.79; 95\% CI, 0.78-0.80;\textit{P} \&lt; .001) and SIRS (AUROC = 0.76; 95\% CI, 0.75-0.77;\textit{P} \&lt; .001). Relative to qSOFA scores lower than 2, encounters with qSOFA scores of 2 or higher had a 3- to 14-fold increase in hospital mortality across baseline risk deciles. Findings were similar in external data sets and for the secondary outcome.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Among ICU encounters with suspected infection, the predictive validity for in-hospital mortality of SOFA was not significantly different than the more complex LODS but was statistically greater than SIRS and qSOFA, supporting its use in clinical criteria for sepsis. Among encounters with suspected infection outside of the ICU, the predictive validity for in-hospital mortality of qSOFA was statistically greater than SOFA and SIRS, supporting its use as a prompt to consider possible sepsis.{\textless}/p{\textgreater}},
language = {en},
number = {8},
urldate = {2019-09-04},
journal = {JAMA},
author = {Seymour, Christopher W. and Liu, Vincent X. and Iwashyna, Theodore J. and Brunkhorst, Frank M. and Rea, Thomas D. and Scherag, André and Rubenfeld, Gordon and Kahn, Jeremy M. and Shankar-Hari, Manu and Singer, Mervyn and Deutschman, Clifford S. and Escobar, Gabriel J. and Angus, Derek C.},
month = feb,
year = {2016},
pages = {762--774},
}

@article{singer_third_2016,
title = {The {Third} {International} {Consensus} {Definitions} for {Sepsis} and {Septic} {Shock} ({Sepsis}-3)},
volume = {315},
issn = {0098-7484},
url = {https://jamanetwork.com/journals/jama/fullarticle/2492881},
doi = {10.1001/jama.2016.0287},
abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Definitions of sepsis and septic shock were last revised in 2001. Considerable advances have since been made into the pathobiology (changes in organ function, morphology, cell biology, biochemistry, immunology, and circulation), management, and epidemiology of sepsis, suggesting the need for reexamination.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To evaluate and, as needed, update definitions for sepsis and septic shock.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Process{\textless}/h3{\textgreater}{\textless}p{\textgreater}A task force (n = 19) with expertise in sepsis pathobiology, clinical trials, and epidemiology was convened by the Society of Critical Care Medicine and the European Society of Intensive Care Medicine. Definitions and clinical criteria were generated through meetings, Delphi processes, analysis of electronic health record databases, and voting, followed by circulation to international professional societies, requesting peer review and endorsement (by 31 societies listed in the Acknowledgment).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Key Findings From Evidence Synthesis{\textless}/h3{\textgreater}{\textless}p{\textgreater}Limitations of previous definitions included an excessive focus on inflammation, the misleading model that sepsis follows a continuum through severe sepsis to shock, and inadequate specificity and sensitivity of the systemic inflammatory response syndrome (SIRS) criteria. Multiple definitions and terminologies are currently in use for sepsis, septic shock, and organ dysfunction, leading to discrepancies in reported incidence and observed mortality. The task force concluded the term\textit{severe sepsis}was redundant.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Recommendations{\textless}/h3{\textgreater}{\textless}p{\textgreater}Sepsis should be defined as life-threatening organ dysfunction caused by a dysregulated host response to infection. For clinical operationalization, organ dysfunction can be represented by an increase in the Sequential [Sepsis-related] Organ Failure Assessment (SOFA) score of 2 points or more, which is associated with an in-hospital mortality greater than 10\%. Septic shock should be defined as a subset of sepsis in which particularly profound circulatory, cellular, and metabolic abnormalities are associated with a greater risk of mortality than with sepsis alone. Patients with septic shock can be clinically identified by a vasopressor requirement to maintain a mean arterial pressure of 65 mm Hg or greater and serum lactate level greater than 2 mmol/L (\&gt;18 mg/dL) in the absence of hypovolemia. This combination is associated with hospital mortality rates greater than 40\%. In out-of-hospital, emergency department, or general hospital ward settings, adult patients with suspected infection can be rapidly identified as being more likely to have poor outcomes typical of sepsis if they have at least 2 of the following clinical criteria that together constitute a new bedside clinical score termed quickSOFA (qSOFA): respiratory rate of 22/min or greater, altered mentation, or systolic blood pressure of 100 mm Hg or less.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}These updated definitions and clinical criteria should replace previous definitions, offer greater consistency for epidemiologic studies and clinical trials, and facilitate earlier recognition and more timely management of patients with sepsis or at risk of developing sepsis.{\textless}/p{\textgreater}},
language = {en},
number = {8},
urldate = {2019-09-04},
journal = {JAMA},
author = {Singer, Mervyn and Deutschman, Clifford S. and Seymour, Christopher Warren and Shankar-Hari, Manu and Annane, Djillali and Bauer, Michael and Bellomo, Rinaldo and Bernard, Gordon R. and Chiche, Jean-Daniel and Coopersmith, Craig M. and Hotchkiss, Richard S. and Levy, Mitchell M. and Marshall, John C. and Martin, Greg S. and Opal, Steven M. and Rubenfeld, Gordon D. and Poll, Tom van der and Vincent, Jean-Louis and Angus, Derek C.},
month = feb,
year = {2016},
pages = {801--810},
}

@techreport{gao_words_2018,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {Words {Matter}: {The} {Role} of {Texts} in {Online} {Credit} {Markets}},
shorttitle = {Words {Matter}},
url = {https://papers.ssrn.com/abstract=2446114},
abstract = {We use debt crowdfunding data to examine how borrowers’ writing style is associated with lender and borrower behavior. Controlling for credit and auction characteristics, lenders bid more aggressively, are more likely to fund, and charge lower rates to borrowers whose writing is more readable, more positive, and contains fewer deception cues. Consistent with information garnered from writing driving the relation, controlling for credit and auction characteristics, borrowers whose writing is more readable, more positive, and has fewer deception cues are less likely to default. Investors, however, fail to fully account for the information contained in borrowers’ writing—especially deception cues.},
language = {en},
number = {ID 2446114},
urldate = {2019-08-29},
institution = {Social Science Research Network},
author = {Gao, Qiang and Lin, Mingfeng and Sias, Richard W.},
month = sep,
year = {2018},
keywords = {crowdfunding, deception detection, machine learning, peer-to-peer lending, predictive analysis, readability analysis, sentiment analysis, subjectivity analysis, texts},
}

@techreport{lin_survival_2019,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {The {Survival} of {Noise} {Traders}: {Evidence} from {Peer}-to-{Peer} {Lending}},
shorttitle = {The {Survival} of {Noise} {Traders}},
url = {https://papers.ssrn.com/abstract=3185608},
abstract = {Using detailed transaction data from a natural experiment on a peer-to-peer lending market, we present the first direct evidence that, when faced with identical information sets, sophisticated institutional investors exploit less sophisticated retail investors. Consistent with traditional economic theory, our results suggest that the relative role of less sophisticated "noise traders" will decline over time and they will eventually become unimportant. Our results also demonstrate, however, that this does not occur quickly—it would take more than four centuries of exploitation by institutional investors for less sophisticated retail traders’ fraction of market wealth to fall from 50\% to 10\%.},
language = {en},
number = {ID 3185608},
urldate = {2019-08-29},
institution = {Social Science Research Network},
author = {Lin, Mingfeng and Sias, Richard W. and Wei, Zaiyan},
month = apr,
year = {2019},
keywords = {FinTech, Institutional Investors, Noise Traders, Peer-to-Peer Lending, Retail Investors},
}

@article{lin_judging_2012,
title = {Judging {Borrowers} by the {Company} {They} {Keep}: {Friendship} {Networks} and {Information} {Asymmetry} in {Online} {Peer}-to-{Peer} {Lending}},
volume = {59},
issn = {0025-1909},
shorttitle = {Judging {Borrowers} by the {Company} {They} {Keep}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1120.1560},
doi = {10.1287/mnsc.1120.1560},
abstract = {We study the online market for peer-to-peer (P2P) lending, in which individuals bid on unsecured microloans sought by other individual borrowers. Using a large sample of consummated and failed listings from the largest online P2P lending marketplace, Prosper.com, we find that the online friendships of borrowers act as signals of credit quality. Friendships increase the probability of successful funding, lower interest rates on funded loans, and are associated with lower ex post default rates. The economic effects of friendships show a striking gradation based on the roles and identities of the friends. We discuss the implications of our findings for the disintermediation of financial markets and the design of decentralized electronic markets.This paper was accepted by Sandra Slaughter, information systems.},
number = {1},
urldate = {2019-08-29},
journal = {Management Science},
author = {Lin, Mingfeng and Prabhala, Nagpurnanand R. and Viswanathan, Siva},
month = sep,
year = {2012},
pages = {17--35},
}

@article{lin_home_2015,
title = {Home {Bias} in {Online} {Investments}: {An} {Empirical} {Study} of an {Online} {Crowdfunding} {Market}},
volume = {62},
issn = {0025-1909},
shorttitle = {Home {Bias} in {Online} {Investments}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2015.2206},
doi = {10.1287/mnsc.2015.2206},
abstract = {An extensive literature in economics and finance has documented home bias, the tendency that transactions are more likely to occur between parties in the same geographical area rather than outside. Using data from a large online crowdfunding marketplace and employing a quasi-experimental design, we find evidence that home bias still exists in this virtual marketplace for financial products. Furthermore, through a series of empirical tests, we show that rationality-based explanations cannot fully explain such behavior and that behavioral reasons at least partially drive this remarkable phenomenon. As crowdfunding becomes an alternative and increasingly appealing channel for financing, a better understanding of home bias in this new context provides important managerial, practical, and policy implications.This paper was accepted by Lee Fleming, entrepreneurship and innovation.},
number = {5},
urldate = {2019-08-29},
journal = {Management Science},
author = {Lin, Mingfeng and Viswanathan, Siva},
month = sep,
year = {2015},
pages = {1393--1414},
}

@article{wei_market_2016,
title = {Market {Mechanisms} in {Online} {Peer}-to-{Peer} {Lending}},
volume = {63},
issn = {0025-1909},
url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2016.2531},
doi = {10.1287/mnsc.2016.2531},
abstract = {Online peer-to-peer lending (P2P lending) has emerged as an appealing new channel of financing in recent years. A fundamental but largely unanswered question in this nascent industry is the choice of market mechanisms, i.e., how the supply and demand of funds are matched, and the terms (price) at which transactions will occur. Two of the most popular mechanisms are auctions (where the “crowd” determines the price of the transaction through an auction process) and posted prices (where the platform determines the price). While P2P lending platforms typically use one or the other, there is little systematic research on the implications of such choices for market participants, transaction outcomes, and social welfare. We address this question both theoretically and empirically. We first develop a game-theoretic model that yields empirically testable hypotheses, taking into account the incentive of the platform. We then test these hypotheses by exploiting a regime change from auctions to posted prices on one of the largest P2P lending platforms. Consistent with our hypotheses, we find that under platform-mandated posted prices, loans are funded with higher probability, but the preset interest rates are higher than borrowers’ starting interest rates and contract interest rates in auctions. More important, all else equal, loans funded under posted prices are more likely to default, thereby undermining lenders’ returns on investment and their surplus. Although platform-mandated posted prices may be faster in originating loans, auctions that rely on the crowd to discover prices are not necessarily inferior in terms of overall social welfare.This paper was accepted by Chris Forman, information systems.},
number = {12},
urldate = {2019-08-29},
journal = {Management Science},
author = {Wei, Zaiyan and Lin, Mingfeng},
month = sep,
year = {2016},
pages = {4236--4257},
}

@article{burtch_role_2018,
title = {The {Role} of {Provision} {Points} in {Online} {Crowdfunding}},
volume = {35},
issn = {0742-1222},
url = {https://doi.org/10.1080/07421222.2018.1440764},
doi = {10.1080/07421222.2018.1440764},
abstract = {Extending recent work on market mechanisms in new fintech offerings, we explore the implications of a key mechanism in online crowdfunding-the use of a provision point. Under a provision point mechanism (otherwise known as all-or-nothing or fixed fundraising scheme), the fundraiser, typically an entrepreneur, only receives funds pledged toward his or her campaign if a preregistered fundraising target is met, rather than keeping everything that is raised. Provision points may weaken contributors' reliance on prior capital accumulation for judging a project's potential for success, by eliminating their concerns about a partial fundraising outcome and by signaling the project or entrepreneur's quality. Yet, provision points may also induce attention to prior capital accumulation, because the materialization of one person's contribution depends explicitly on sufficient contributions from others (a network effect). We assess this tension empirically, leveraging proprietary data from a leading crowdfunding platform that allows entrepreneurs to opt into a provision point. We consider the effects of prior capital accumulation on visitors' conversion and contribution decisions, and the moderating influence of a provision point. We find that provision points weaken the association between prior capital accumulation and visitor contribution, implying a reduction in potential herd behavior.},
number = {1},
urldate = {2019-08-29},
journal = {Journal of Management Information Systems},
author = {Burtch, Gordon and Hong, Yili and Liu, De},
month = jan,
year = {2018},
keywords = {crowdfunding, fintech, fundraising, market mechanisms, mechanism design, provision point mechanism, social proof},
pages = {117--144},
}

@article{perry_supervised_2014,
title = {Supervised embedding of textual predictors with applications in clinical diagnostics for pediatric cardiology},
volume = {21},
issn = {1067-5027},
url = {https://academic.oup.com/jamia/article/21/e1/e136/790657},
doi = {10.1136/amiajnl-2013-001792},
abstract = {Abstract.  Objective Electronic health records possess critical predictive information for machine-learning-based diagnostic aids. However, many traditional mac},
language = {en},
number = {e1},
urldate = {2019-05-30},
journal = {Journal of the American Medical Informatics Association},
author = {Perry, Thomas Ernest and Zha, Hongyuan and Zhou, Ke and Frias, Patricio and Zeng, Dadan and Braunstein, Mark},
month = feb,
year = {2014},
pages = {e136--e142},
}

@article{bahdanau_neural_2014,
title = {Neural {Machine} {Translation} by {Jointly} {Learning} to {Align} and {Translate}},
url = {https://arxiv.org/abs/1409.0473v7},
abstract = {Neural machine translation is a recently proposed approach to machine
translation. Unlike the traditional statistical machine translation, the neural
machine translation aims at building a single neural network that can be
jointly tuned to maximize the translation performance. The models proposed
recently for neural machine translation often belong to a family of
encoder-decoders and consists of an encoder that encodes a source sentence into
a fixed-length vector from which a decoder generates a translation. In this
paper, we conjecture that the use of a fixed-length vector is a bottleneck in
improving the performance of this basic encoder-decoder architecture, and
propose to extend this by allowing a model to automatically (soft-)search for
parts of a source sentence that are relevant to predicting a target word,
without having to form these parts as a hard segment explicitly. With this new
approach, we achieve a translation performance comparable to the existing
state-of-the-art phrase-based system on the task of English-to-French
translation. Furthermore, qualitative analysis reveals that the
(soft-)alignments found by the model agree well with our intuition.},
language = {en},
urldate = {2019-08-01},
author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
month = sep,
year = {2014},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, read here},
}

@article{xu_show_2015,
title = {Show, {Attend} and {Tell}: {Neural} {Image} {Caption} {Generation} with {Visual} {Attention}},
shorttitle = {Show, {Attend} and {Tell}},
url = {http://arxiv.org/abs/1502.03044},
abstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.},
urldate = {2019-02-06},
journal = {arXiv:1502.03044 [cs]},
author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
month = feb,
year = {2015},
note = {arXiv: 1502.03044},
keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@inproceedings{luong_effective_2015,
address = {Lisbon, Portugal},
title = {Effective {Approaches} to {Attention}-based {Neural} {Machine} {Translation}},
url = {http://aclweb.org/anthology/D15-1166},
urldate = {2019-02-01},
booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
publisher = {Association for Computational Linguistics},
author = {Luong, Thang and Pham, Hieu and Manning, Christopher D.},
month = sep,
year = {2015},
pages = {1412--1421},
}

@inproceedings{pennington_glove:_2014,
address = {Doha, Qatar},
title = {Glove: {Global} {Vectors} for {Word} {Representation}},
shorttitle = {Glove},
url = {http://www.aclweb.org/anthology/D14-1162},
urldate = {2019-01-08},
booktitle = {Proceedings of the 2014 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
publisher = {Association for Computational Linguistics},
author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
month = oct,
year = {2014},
keywords = {read here},
pages = {1532--1543},
}

@techreport{jiang_not_2019,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {Not {Just} a {Name}: {The} {Moderating} {Effect} of {Identity} {Disclosure} on {Herding}},
shorttitle = {Not {Just} a {Name}},
url = {https://papers.ssrn.com/abstract=3136144},
abstract = {Extending recent research on online herding phenomenon, this research note explores the role of online identity in shaping peer influence in online crowdfunding markets. Drawing on theories from social psychology literature, we argue that a subsequent lender forms different perceptions of credibility towards preceding peers based on their online identities, and then uses such perceptions to moderate her herding momentum towards them. We collect data from a leading debt-based crowdfunding platform and classify lenders’ online identities (i.e., usernames) into three categories—anonymous, pseudonymous, and real-sounding—based on their anonymity states. A cross-classified multilevel model is developed to explain the variation in individual lending amounts, while controlling for unobserved heterogeneity at the project and the lender levels. The results show that the anonymity state of online identity has a significant moderating effect on herding. Subsequent lenders demonstrate the strongest herding magnitude toward preceding peers who use anonymous usernames, followed by those with pseudonymous and real-sounding ones. This finding, which we attribute to lenders’ perception of high expertise toward a high anonymity state, challenges a conventional wisdom that considers anonymity a negative factor for source credibility. Our work contributes to literatures on herding behavior and the impact of anonymity in online environments.},
language = {en},
number = {ID 3136144},
urldate = {2019-08-29},
institution = {Social Science Research Network},
author = {Jiang, Yang and Ho, Yi-Chun (Chad) and Yan, Xiangbin and Tan, Yong},
month = apr,
year = {2019},
keywords = {anonymity, crowdfunding, herding, hierarchical Bayes, multilevel models, peer influence},
}

@article{crosetto_its_2018,
title = {It's never too late: {Funding} dynamics and self pledges in reward-based crowdfunding},
volume = {47},
issn = {0048-7333},
shorttitle = {It's never too late},
url = {http://www.sciencedirect.com/science/article/pii/S0048733318301112},
doi = {10.1016/j.respol.2018.04.020},
abstract = {Crowdfunding recently emerged as an alternative funding channel for entrepreneurs. We use pledge-level data from Startnext, the biggest German platform, to gain insights on funding dynamics and pledgers’ motivations. We find that the majority of projects that eventually succeed are not on a successful track at 75\% of their funding period. These late successes are boosted by information cascades during the final 25\% of the funding duration. We conclude – in contrast with earlier literature – that project success is only partially path-dependent. While early pledges do anticipate project success, a lack of them does not necessarily mean that projects will fail. Interviews and questionnaire responses indicate that projects’ communication efforts play a role in making severely under track projects succeed eventually. Moreover, our dataset uniquely allows us to quantify the extent of self funding. Self pledges account for about 10\% of all initial pledges and 9\% of all pledges that secure funding. Nonetheless, the late surges at severely under track projects are mostly driven by external funders. Furthermore, we find no evidence of subsequent herding triggered by self pledges.},
number = {8},
urldate = {2019-08-29},
journal = {Research Policy},
author = {Crosetto, Paolo and Regner, Tobias},
month = oct,
year = {2018},
keywords = {Crowdfunding, Donations, Entrepreneurial finance, Innovation, Pre-selling, Self funding},
pages = {1463--1477},
}

@article{guler_classification_2005,
title = {Classification of {EMG} {Signals} {Using} {PCA} and {FFT}},
volume = {29},
issn = {1573-689X},
url = {https://doi.org/10.1007/s10916-005-5184-7},
doi = {10.1007/s10916-005-5184-7},
abstract = {In this study, the fast Fourier transform (FFT) analysis was applied to EMG signals recorded from ulnar nerves of 59 patients to interpret data. The data of the patients were diagnosed by the neurologists as 19 patients were normal, 20 patients had neuropathy and 20 patients had myopathy. The amount of FFT coefficients had been reduced by using principal components analysis (PCA). This would facilitate calculation and storage of EMG data. PCA coefficients were applied to multilayer perceptron (MLP) and support vector machine (SVM) and both classified systems of performance values were computed. Consequently, the results show that SVM has high anticipation level in the diagnosis of neuromuscular disorders. It is proved that its test performance is high compared with MLP.},
language = {en},
number = {3},
urldate = {2019-08-28},
journal = {Journal of Medical Systems},
author = {Güler, Nihal Fatma and Koçer, Sabri},
month = jun,
year = {2005},
keywords = {backpropagation (BP), fast Fourier transform (FFT), multilayer perceptron (MLP), principal components analysis (PCA), support vector machine (SVM)},
pages = {241--250},
}

@inproceedings{sandirasegaram_comparative_2005,
title = {Comparative analysis of feature extraction ({2D} {FFT} and wavelet) and classification ({Lp} metric distances, {MLP} {NN}, and {HNeT}) algorithms for {SAR} imagery},
volume = {5808},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5808/0000/Comparative-analysis-of-feature-extraction-2D-FFT-and-wavelet-and/10.1117/12.597305.short},
doi = {10.1117/12.597305},
abstract = {The performance of several combinations of feature extraction and target classification algorithms is analyzed for Synthetic Aperture Radar (SAR) imagery using the standard Moving and Stationary Target Acquisition and Recognition (MSTAR) evaluation method. For feature extraction, 2D Fast Fourier Transform (FFT) is used to extract Fourier coefficients (frequency information) while 2D wavelet decomposition is used to extract wavelet coefficients (time-frequency information), from which subsets of characteristic in-class "invariant" coefficients are developed. Confusion matrices and Receiver Operating Characteristic (ROC) curves are used to evaluate and compare combinations of these characteristic coefficients with several classification methods, including Lp metric distances, a Multi Layer Perceptron (MLP) Neural Network (NN) and AND Corporation's Holographic Neural Technology (HNeT) classifier. The evaluation method examines the trade-off between correct detection rate and false alarm rate for each combination of feature-classifier systems. It also measures correct classification, misclassification and rejection rates for a 90\% detection rate. Our analysis demonstrates the importance of feature and classifier selection in accurately classifying new target images.},
urldate = {2019-08-28},
booktitle = {Algorithms for {Synthetic} {Aperture} {Radar} {Imagery} {XII}},
publisher = {International Society for Optics and Photonics},
author = {Sandirasegaram, Nicholas and English, Ryan},
month = may,
year = {2005},
pages = {314--325},
}

@article{chan_wavelet_2008,
title = {Wavelet {Distance} {Measure} for {Person} {Identification} {Using} {Electrocardiograms}},
volume = {57},
issn = {0018-9456},
doi = {10.1109/TIM.2007.909996},
abstract = {In this paper, the authors present an evaluation of a new biometric based on electrocardiogram (ECG) waveforms. ECG data were collected from 50 subjects during three data-recording sessions on different days using a simple user interface, where subjects held two electrodes on the pads of their thumbs using their thumb and index fingers. Data from session 1 were used to establish an enrolled database, and data from the remaining two sessions were used as test cases. Classification was performed using three different quantitative measures: percent residual difference, correlation coefficient, and a novel distance measure based on wavelet transform. The wavelet distance measure has a classification accuracy of 89\%, outperforming the other methods by nearly 10\%. This ECG person-identification modality would be a useful supplement for conventional biometrics, such as fingerprint and palm recognition systems.},
number = {2},
journal = {IEEE Transactions on Instrumentation and Measurement},
author = {Chan, A. D. C. and Hamdy, M. M. and Badre, A. and Badee, V.},
month = feb,
year = {2008},
keywords = {Biometric, Biometrics, Databases, ECG waveforms, Electrocardiography, Electrodes, Fingerprint recognition, Fingers, Performance evaluation, Testing, Thumb, User interfaces, biometrics, biometrics (access control), electrocardiogram, electrocardiogram (ECG), electrocardiography, intra subject variability, intrasubject variability, medical signal processing, person identification, user interface, user interfaces, wavelet transform, wavelet transforms, wavelets},
pages = {248--253},
}

@article{philip_de_chazal_automatic_2004,
title = {Automatic classification of heartbeats using {ECG} morphology and heartbeat interval features},
volume = {51},
issn = {0018-9294},
doi = {10.1109/TBME.2004.827359},
abstract = {A method for the automatic processing of the electrocardiogram (ECG) for the classification of heartbeats is presented. The method allocates manually detected heartbeats to one of the five beat classes recommended by ANSI/AAMI EC57:1998 standard, i.e., normal beat, ventricular ectopic beat (VEB), supraventricular ectopic beat (SVEB), fusion of a normal and a VEB, or unknown beat type. Data was obtained from the 44 nonpacemaker recordings of the MIT-BIH arrhythmia database. The data was split into two datasets with each dataset containing approximately 50 000 beats from 22 recordings. The first dataset was used to select a classifier configuration from candidate configurations. Twelve configurations processing feature sets derived from two ECG leads were compared. Feature sets were based on ECG morphology, heartbeat intervals, and RR-intervals. All configurations adopted a statistical classifier model utilizing supervised learning. The second dataset was used to provide an independent performance assessment of the selected configuration. This assessment resulted in a sensitivity of 75.9\%, a positive predictivity of 38.5\%, and a false positive rate of 4.7\% for the SVEB class. For the VEB class, the sensitivity was 77.7\%, the positive predictivity was 81.9\%, and the false positive rate was 1.2\%. These results are an improvement on previously reported results for automated heartbeat classification systems.},
number = {7},
journal = {IEEE Transactions on Biomedical Engineering},
author = {{Philip de Chazal} and O'Dwyer, M. and Reilly, R. B.},
month = jul,
year = {2004},
keywords = {ANSI standards, Algorithms, Arrhythmias, Cardiac, Artificial Intelligence, Cluster Analysis, Diagnosis, Computer-Assisted, ECG morphology, Electrocardiography, European Union, False Positive Reactions, Fibrillation, Heart Rate, Heart rate variability, Humans, Linear discriminant analysis, MIT-BIH arrhythmia database, Medical treatment, Morphology, Pattern Recognition, Automated, Reproducibility of Results, Rhythm, Sensitivity and Specificity, Signal Processing, Computer-Assisted, Spatial databases, Supervised learning, United States, automated heartbeat classification systems, electrocardiogram processing, electrocardiography, heartbeat interval features, medical signal processing, nonpacemaker recordings, normal beat, signal classification, statistical classifier model, supraventricular ectopic beat, ventricular ectopic beat},
pages = {1196--1206},
}

@misc{ataspinar_machine_2018,
title = {Machine {Learning} with {Signal} {Processing} {Techniques}},
url = {http://ataspinar.com/2018/04/04/machine-learning-with-signal-processing-techniques/},
abstract = {[latexpage] Introduction Stochastic Signal Analysis is a field of science concerned with the processing, modification and analysis of (stochastic) signals. Anyone with a background in Physics or En…},
language = {nl},
urldate = {2019-08-28},
journal = {Ahmet Taspinar},
author = {{ataspinar}},
month = apr,
year = {2018},
}

@misc{admin_guide_2018,
title = {A guide for using the {Wavelet} {Transform} in {Machine} {Learning}},
url = {http://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/},
abstract = {[latexpage] 1. Introduction In a previous blog-post we have seen how we can use Signal Processing techniques for the classification of time-series and signals. A very short summary of that post is:…},
language = {nl},
urldate = {2019-08-28},
journal = {Ahmet Taspinar},
author = {{admin}},
month = dec,
year = {2018},
}

@inproceedings{lund_movie_2018,
title = {Movie {Recommendations} {Using} the {Deep} {Learning} {Approach}},
doi = {10.1109/IRI.2018.00015},
abstract = {Recommendation systems are an important part of suggesting items especially in streaming services. For streaming movie services like Netflix, recommendation systems are essential for helping users find new movies to enjoy. In this paper, we propose a deep learning approach based on autoencoders to produce a collaborative filtering system which predicts movie ratings for a user based on a large database of ratings from other users. Using the MovieLens dataset, we explore the use of deep learning to predict users' ratings on new movies, thereby enabling movie recommendations. To verify the novelty and accuracy of our deep learning approach, we compare our approach to standard collaborative filtering techniques: k-nearest-neighbor and matrix-factorization. The experimental results show that our recommendation system outperforms a user-based neighborhood baseline both in terms of root mean squared error on predicted ratings and in a survey in which users judge between recommendations from both systems.},
booktitle = {2018 {IEEE} {International} {Conference} on {Information} {Reuse} and {Integration} ({IRI})},
author = {Lund, J. and Ng, Y.},
month = jul,
year = {2018},
keywords = {Collaboration, Computational modeling, Computer architecture, Machine learning, Matrix decomposition, Motion pictures, MovieLens dataset, Netflix, Neural networks, autoencoders, collaborative filtering, collaborative filtering system, deep learning, deep learning approach, k-nearest-neighbor, matrix decomposition, matrix-factorization, mean square error methods, movie ratings, movie recommendation, movie recommendations, movie services, nearest neighbour methods, recommendation system, recommender systems, root mean squared error, streaming services, user-based neighborhood},
pages = {47--54},
}

@inproceedings{covington_deep_2016,
address = {New York, NY, USA},
title = {Deep {Neural} {Networks} for {YouTube} {Recommendations}},
booktitle = {Proceedings of the 10th {ACM} {Conference} on {Recommender} {Systems}},
author = {Covington, Paul and Adams, Jay and Sargin, Emre},
year = {2016},
}

@misc{noauthor_word-embedding_nodate,
title = {From {Word}-embedding {To} {BERT}},
url = {https://zhuanlan.zhihu.com/p/49271699},
urldate = {2019-08-26},
}

@article{yang_xlnet:_2019,
title = {{XLNet}: {Generalized} {Autoregressive} {Pretraining} for {Language} {Understanding}},
shorttitle = {{XLNet}},
url = {http://arxiv.org/abs/1906.08237},
abstract = {With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, XLNet outperforms BERT on 20 tasks, often by a large margin, and achieves state-of-the-art results on 18 tasks including question answering, natural language inference, sentiment analysis, and document ranking.},
urldate = {2019-08-26},
journal = {arXiv:1906.08237 [cs]},
author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
month = jun,
year = {2019},
note = {arXiv: 1906.08237},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{yonker_friending_2015,
title = {“{Friending}” {Teens}: {Systematic} {Review} of {Social} {Media} in {Adolescent} and {Young} {Adult} {Health} {Care}},
volume = {17},
copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work (},
shorttitle = {“{Friending}” {Teens}},
url = {https://www.jmir.org/2015/1/e4/},
doi = {10.2196/jmir.3692},
abstract = {Background: Social media has emerged as a potentially powerful medium for communication with adolescents and young adults around their health choices. Objective: The goal of this systematic review is to identify research on the use of social media for interacting with adolescents and young adults in order to achieve positive health outcomes. Methods: A MEDLINE/PubMed electronic database search was performed between January 1, 2002 and October 1, 2013, using terms to identify peer-reviewed research in which social media and other Web 2.0 technologies were an important feature. We used a systematic approach to retrieve papers and extract relevant data. Results: We identified 288 studies involving social media, of which 87 met criteria for inclusion; 75 studies were purely observational and 12 were interventional. The ways in which social media was leveraged by these studies included (1) observing adolescent and young adult behavior (n=77), (2) providing health information (n=13), (3) engaging the adolescent and young adult community (n=17), and (4) recruiting research participants (n=23). Common health topics addressed included high-risk sexual behaviors (n=23), alcohol, tobacco, and other drug use (n=19), Internet safety (n=8), mental health issues (n=18), medical conditions (n=11), or other specified issues (n=12). Several studies used more than one social media platform and addressed more than one health-related topic. Conclusions: Social media technologies offer an exciting new means for engaging and communicating with adolescents and young adults; it has been successfully used to engage this age group, identify behaviors, and provide appropriate intervention and education. Nevertheless, the majority of studies to date have been preliminary and limited in their methodologies, and mostly center around evaluating how adolescents and young adults use social media and the resulting implications on their health. Although these explorations are essential, further exploration and development of these strategies into building effective interventions is necessary.  [J Med Internet Res 2015;17(1):e4]},
language = {en},
number = {1},
urldate = {2019-08-13},
journal = {Journal of Medical Internet Research},
author = {Yonker, Lael M. and Zan, Shiyi and Scirica, Christina V. and Jethwani, Kamal and Kinane, T. Bernard},
year = {2015},
pages = {e4},
}

@misc{andreassen_relationship_nodate,
title = {The relationship between addictive use of social media and video games and symptoms of psychiatric disorders: {A} large-scale cross-sectional study.},
shorttitle = {The relationship between addictive use of social media and video games and symptoms of psychiatric disorders},
url = {/fulltext/2016-13379-006.html},
abstract = {PsycNET},
language = {en},
urldate = {2019-08-13},
journal = {Psychology of Addictive Behaviors},
author = {Andreassen, Cecilie Schou},
doi = {10.1037/adb0000160},
}

@article{moreno_feeling_2011,
title = {Feeling bad on {Facebook}: depression disclosures by college students on a social networking site},
volume = {28},
copyright = {© 2011 Wiley‐Liss, Inc.},
issn = {1520-6394},
shorttitle = {Feeling bad on {Facebook}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/da.20805},
doi = {10.1002/da.20805},
abstract = {Background: Depression is common and frequently undiagnosed among college students. Social networking sites are popular among college students and can include displayed depression references. The purpose of this study was to evaluate college students' Facebook disclosures that met DSM criteria for a depression symptom or a major depressive episode (MDE). Methods: We selected public Facebook profiles from sophomore and junior undergraduates and evaluated personally written text: “status updates.” We applied DSM criteria to 1-year status updates from each profile to determine prevalence of displayed depression symptoms and MDE criteria. Negative binomial regression analysis was used to model the association between depression disclosures and demographics or Facebook use characteristics. Results: Two hundred profiles were evaluated, and profile owners were 43.5\% female with a mean age of 20 years. Overall, 25\% of profiles displayed depressive symptoms and 2.5\% met criteria for MDE. Profile owners were more likely to reference depression, if they averaged at least one online response from their friends to a status update disclosing depressive symptoms (exp(B) = 2.1, P{\textless}.001), or if they used Facebook more frequently (P{\textless}.001). Conclusion: College students commonly display symptoms consistent with depression on Facebook. Our findings suggest that those who receive online reinforcement from their friends are more likely to discuss their depressive symptoms publicly on Facebook. Given the frequency of depression symptom displays on public profiles, social networking sites could be an innovative avenue for combating stigma surrounding mental health conditions or for identifying students at risk for depression. Depression and Anxiety, 2011. © 2011 Wiley-Liss, Inc.},
language = {en},
number = {6},
urldate = {2019-08-13},
journal = {Depression and Anxiety},
author = {Moreno, Megan A. and Jelenchick, Lauren A. and Egan, Katie G. and Cox, Elizabeth and Young, Henry and Gannon, Kerry E. and Becker, Tara},
year = {2011},
keywords = {adolescent medicine, internet, mental health, self disclosure, social networks},
pages = {447--455},
}

@article{primack_use_2017,
title = {Use of multiple social media platforms and symptoms of depression and anxiety: {A} nationally-representative study among {U}.{S}. young adults},
volume = {69},
issn = {0747-5632},
shorttitle = {Use of multiple social media platforms and symptoms of depression and anxiety},
url = {http://www.sciencedirect.com/science/article/pii/S0747563216307543},
doi = {10.1016/j.chb.2016.11.013},
abstract = {Introduction
While increased time spent on social media (TSSM) has been associated with depression and anxiety, the independent role of using multiple social media (SM) platforms is unclear.
Methods
We surveyed a nationally-representative sample of 1787 U.S. young adults ages 19–32. Depression and anxiety symptoms were measured using the Patient-Reported Outcomes Measurement Information System (PROMIS). We assessed use of multiple SM platforms with an adapted Pew Internet Research scale. We used ordered logistic regression models to assess associations between use of multiple SM platforms and mental health outcomes while controlling for eight covariates, including overall TSSM.
Results
Compared to those who used 0–2 social media platforms, participants who used 7–11 social media platforms had substantially higher odds of having increased levels of both depression (Adjusted Odds Ratio [AOR] = 3.0, 95\% CI = 1.9–4.8) and anxiety symptoms (AOR = 3.2, 95\% CI = 2.0–5.1). Associations were linear (p {\textless} 0.001 for all) and robust to all sensitivity analyses.
Conclusions
Use of multiple SM platforms is independently associated with symptoms of depression and anxiety, even when controlling for overall TSSM. These associations are strong enough that it may be valuable for clinicians to ask individuals with depression and anxiety about multiple platform use and to counsel regarding this potential contributing factor.},
urldate = {2019-08-13},
journal = {Computers in Human Behavior},
author = {Primack, Brian A. and Shensa, Ariel and Escobar-Viera, César G. and Barrett, Erica L. and Sidani, Jaime E. and Colditz, Jason B. and James, A. Everette},
month = apr,
year = {2017},
keywords = {Anxiety, Depression, Facebook, Multitasking, Social media, Twitter},
pages = {1--9},
}

@article{shaw_defense_2002,
title = {In {Defense} of the {Internet}: {The} {Relationship} between {Internet} {Communication} and {Depression}, {Loneliness}, {Self}-{Esteem}, and {Perceived} {Social} {Support}},
volume = {5},
issn = {1094-9313},
shorttitle = {In {Defense} of the {Internet}},
url = {https://www.liebertpub.com/doi/abs/10.1089/109493102753770552},
doi = {10.1089/109493102753770552},
abstract = {As more people connect to the Internet, researchers are beginning to examine the effects of Internet use on users' psychological health. Due in part to a study released by Kraut and colleagues in 1998,          which concluded that Internet use is positively correlated with depression, loneliness, and stress, public opinion about the Internet has been decidedly negative. In contrast, the present study was designed          to test the hypothesis that Internet usage can affect users beneficially. Participants engaged in five chat sessions with an anonymous partner. At three different intervals they were administered scales          measuring depression, loneliness, self-esteem, and social support. Changes in their scores were tracked over time. Internet use was found to decrease loneliness and depression significantly, while perceived          social support and self-esteem increased significantly.},
number = {2},
urldate = {2019-08-13},
journal = {CyberPsychology \& Behavior},
author = {Shaw, Lindsay H. and Gant, Larry M.},
month = apr,
year = {2002},
pages = {157--171},
}

@article{woods_sleepyteens:_2016,
title = {\#{Sleepyteens}: {Social} media use in adolescence is associated with poor sleep quality, anxiety, depression and low self-esteem},
volume = {51},
issn = {0140-1971},
shorttitle = {\#{Sleepyteens}},
url = {http://www.sciencedirect.com/science/article/pii/S0140197116300343},
doi = {10.1016/j.adolescence.2016.05.008},
abstract = {This study examined how social media use related to sleep quality, self-esteem, anxiety and depression in 467 Scottish adolescents. We measured overall social media use, nighttime-specific social media use, emotional investment in social media, sleep quality, self-esteem and levels of anxiety and depression. Adolescents who used social media more – both overall and at night – and those who were more emotionally invested in social media experienced poorer sleep quality, lower self-esteem and higher levels of anxiety and depression. Nighttime-specific social media use predicted poorer sleep quality after controlling for anxiety, depression and self-esteem. These findings contribute to the growing body of evidence that social media use is related to various aspects of wellbeing in adolescents. In addition, our results indicate that nighttime-specific social media use and emotional investment in social media are two important factors that merit further investigation in relation to adolescent sleep and wellbeing.},
urldate = {2019-08-13},
journal = {Journal of Adolescence},
author = {Woods, Heather Cleland and Scott, Holly},
month = aug,
year = {2016},
keywords = {Adolescence, Anxiety, Depression, Self-esteem, Sleep, Social media},
pages = {41--49},
}

@article{okeeffe_impact_2011,
title = {The {Impact} of {Social} {Media} on {Children}, {Adolescents}, and {Families}},
volume = {127},
copyright = {Copyright © 2011 by the American Academy of Pediatrics},
issn = {0031-4005, 1098-4275},
url = {https://pediatrics.aappublications.org/content/127/4/800},
doi = {10.1542/peds.2011-0054},
abstract = {Using social media Web sites is among the most common activity of today's children and adolescents. Any Web site that allows social interaction is considered a social media site, including social networking sites such as Facebook, MySpace, and Twitter; gaming sites and virtual worlds such as Club Penguin, Second Life, and the Sims; video sites such as YouTube; and blogs. Such sites offer today's youth a portal for entertainment and communication and have grown exponentially in recent years. For this reason, it is important that parents become aware of the nature of social media sites, given that not all of them are healthy environments for children and adolescents. Pediatricians are in a unique position to help families understand these sites and to encourage healthy use and urge parents to monitor for potential problems with cyberbullying, “Facebook depression,” sexting, and exposure to inappropriate content.},
language = {en},
number = {4},
urldate = {2019-08-13},
journal = {Pediatrics},
author = {O'Keeffe, Gwenn Schurgin and Clarke-Pearson, Kathleen and Media, Council on Communications and},
month = apr,
year = {2011},
pmid = {21444588},
keywords = {COPPA, Facebook depression, Internet, adolescents, advertising, bullying, children, cyberbullying, digital footprint, online harassment, sexting, social media, social networking},
pages = {800--804},
}

@article{jelenchick_facebook_2013,
title = {“{Facebook} {Depression}?” {Social} {Networking} {Site} {Use} and {Depression} in {Older} {Adolescents}},
volume = {52},
issn = {1054-139X},
shorttitle = {“{Facebook} {Depression}?},
url = {http://www.sciencedirect.com/science/article/pii/S1054139X12002091},
doi = {10.1016/j.jadohealth.2012.05.008},
abstract = {Purpose
To evaluate the association between social networking site (SNS) use and depression in older adolescents using an experience sample method (ESM) approach.
Methods
Older adolescent university students completed an online survey containing the Patient Health Questionnaire-9 depression screen (PHQ) and a weeklong ESM data collection period to assess SNS use.
Results
Participants (N = 190) included in the study were 58\% female and 91\% Caucasian. The mean age was 18.9 years (standard deviation = .8). Most used SNSs for either {\textless}30 minutes (n = 100, 53\%) or between 30 minutes and 2 hours (n = 74, 39\%); a minority of participants reported daily use of SNS {\textgreater}2 hours (n = 16, 8\%). The mean PHQ score was 5.4 (standard deviation = 4.2). No associations were seen between SNS use and either any depression (p = .519) or moderate to severe depression (p = .470).
Conclusions
We did not find evidence supporting a relationship between SNS use and clinical depression. Counseling patients or parents regarding the risk of “Facebook Depression” may be premature.},
number = {1},
urldate = {2019-08-13},
journal = {Journal of Adolescent Health},
author = {Jelenchick, Lauren A. and Eickhoff, Jens C. and Moreno, Megan A.},
month = jan,
year = {2013},
keywords = {Depression, Internet use, Media, Mental health, Social networking sites},
pages = {128--130},
}

@article{yang_gis_2015,
title = {{GIS} analysis of depression among {Twitter} users},
volume = {60},
issn = {0143-6228},
url = {http://www.sciencedirect.com/science/article/pii/S0143622814002537},
doi = {10.1016/j.apgeog.2014.10.016},
abstract = {Depression is a common chronic disorder. It often goes undetected due to limited diagnosis methods and brings serious results to public and personal health. Former research detected geographic pattern for depression using questionnaires or self-reported measures of mental health, this may induce same-source bias. Recent studies use social media for depression detection but none of them examines the geographic patterns. In this paper, we apply GIS methods to social media data to provide new perspectives for public health research. We design a procedure to automatically detect depressed users in Twitter and analyze their spatial patterns using GIS technology. This method can improve diagnosis techniques for depression. It is faster at collecting data and more promptly at analyzing and providing results. Also, this method can be expanded to detect other major events in real-time, such as disease outbreaks and earthquakes.},
urldate = {2019-08-13},
journal = {Applied Geography},
author = {Yang, Wei and Mu, Lan},
month = jun,
year = {2015},
keywords = {Clustering, Depression, GIS, Social media, Tweets},
pages = {217--223},
}

@inproceedings{resnik_beyond_2015,
title = {Beyond {LDA}: {Exploring} {Supervised} {Topic} {Modeling} for {Depression}-{Related} {Language} in {Twitter}},
shorttitle = {Beyond {LDA}},
doi = {10.3115/v1/W15-1212},
abstract = {Topic models can yield insight into how depressed and non-depressed individuals use language differently. In this paper, we explore the use of supervised topic models in the analysis of linguistic signal for detecting depression, providing promising results using several models.},
booktitle = {{CLPsych}@{HLT}-{NAACL}},
author = {Resnik, Philip and Armstrong, William and Claudino, Leonardo Max Batista and Nguyen, Thang and Nguyen, Viet-An and Boyd-Graber, Jordan L.},
year = {2015},
keywords = {Sensor, Supervised learning, Topic model},
}

@article{reavley_use_2014,
title = {Use of {Twitter} to monitor attitudes toward depression and schizophrenia: an exploratory study},
volume = {2},
issn = {2167-8359},
shorttitle = {Use of {Twitter} to monitor attitudes toward depression and schizophrenia},
url = {https://peerj.com/articles/647},
doi = {10.7717/peerj.647},
abstract = {Introduction. The paper reports on an exploratory study of the usefulness of Twitter for unobtrusive assessment of stigmatizing attitudes in the community.Materials and Methods. Tweets with the hashtags \#depression or \#schizophrenia posted on Twitter during a 7-day period were collected. Tweets were categorised based on their content and user information and also on the extent to which they indicated a stigmatising attitude towards depression or schizophrenia (stigmatising, personal experience of stigma, supportive, neutral, or anti-stigma). Tweets that indicated stigmatising attitudes or personal experiences of stigma were further grouped into the following subthemes: social distance, dangerousness, snap out of it, personal weakness, inaccurate beliefs, mocking or trivializing, and self-stigma.Results and Discussion. Tweets on depression mostly related to resources for consumers (34\%), or advertised services or products for individuals with depression (20\%). The majority of schizophrenia tweets aimed to increase awareness of schizophrenia (29\%) or reported on research findings (22\%). Tweets on depression were largely supportive (65\%) or neutral (27\%). A number of tweets were specifically anti-stigma (7\%). Less than 1\% of tweets reflected stigmatising attitudes (0.7\%) or personal experience of stigma (0.1\%). More than one third of the tweets which reflected stigmatising attitudes were mocking or trivialising towards individuals with depression (37\%). The attitude that individuals with depression should “snap out of it” was evident in 30\% of the stigmatising tweets. The majority of tweets relating to schizophrenia were categorised as supportive (42\%) or neutral (43\%). Almost 10\% of tweets were explicitly anti-stigma. The percentage of tweets showing stigmatising attitudes was 5\%, while less than 1\% of tweets described personal experiences of stigmatising attitudes towards individuals with schizophrenia. Of the tweets that indicated stigmatising attitudes, most reflected inaccurate beliefs about schizophrenia being multiple personality disorder (52\%) or mocked or trivialised individuals with schizophrenia (33\%).Conclusions. The study supports the use of analysis of Twitter content to unobtrusively measure attitudes towards mental illness, both supportive and stigmatising. The results of the study may be useful in assisting mental health promotion and advocacy organisations to provide information about resources and support, raise awareness and counter common stigmatising attitudes.},
language = {en},
urldate = {2019-08-13},
journal = {PeerJ},
author = {Reavley, Nicola J. and Pilkington, Pamela D.},
month = oct,
year = {2014},
pages = {e647},
}

@inproceedings{coppersmith_clpsych_2015,
address = {Denver, Colorado},
title = {{CLPsych} 2015 {Shared} {Task}: {Depression} and {PTSD} on {Twitter}},
shorttitle = {{CLPsych} 2015 {Shared} {Task}},
url = {https://www.aclweb.org/anthology/W15-1204},
doi = {10.3115/v1/W15-1204},
urldate = {2019-08-13},
booktitle = {Proceedings of the 2nd {Workshop} on {Computational} {Linguistics} and {Clinical} {Psychology}: {From} {Linguistic} {Signal} to {Clinical} {Reality}},
publisher = {Association for Computational Linguistics},
author = {Coppersmith, Glen and Dredze, Mark and Harman, Craig and Hollingshead, Kristy and Mitchell, Margaret},
month = jun,
year = {2015},
pages = {31--39},
}

@inproceedings{tsugawa_recognizing_2015,
address = {New York, NY, USA},
series = {{CHI} '15},
title = {Recognizing {Depression} from {Twitter} {Activity}},
isbn = {978-1-4503-3145-6},
url = {http://doi.acm.org/10.1145/2702123.2702280},
doi = {10.1145/2702123.2702280},
abstract = {In this paper, we extensively evaluate the effectiveness of using a user's social media activities for estimating degree of depression. As ground truth data, we use the results of a web-based questionnaire for measuring degree of depression of Twitter users. We extract several features from the activity histories of Twitter users. By leveraging these features, we construct models for estimating the presence of active depression. Through experiments, we show that (1) features obtained from user activities can be used to predict depression of users with an accuracy of 69\%, (2) topics of tweets estimated with a topic model are useful features, (3) approximately two months of observation data are necessary for recognizing depression, and longer observation periods do not contribute to improving the accuracy of estimation for current depression; sometimes, longer periods worsen the accuracy.},
urldate = {2019-08-13},
booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
publisher = {ACM},
author = {Tsugawa, Sho and Kikuchi, Yusuke and Kishino, Fumio and Nakajima, Kosuke and Itoh, Yuichi and Ohsaki, Hiroyuki},
year = {2015},
note = {event-place: Seoul, Republic of Korea},
keywords = {depression, machine learning, social media, twitter},
pages = {3187--3196},
}

@article{perry_supervised_2012,
title = {Supervised {Laplacian} {Eigenmaps} with {Applications} in {Clinical} {Diagnostics} for {Pediatric} {Cardiology}},
url = {http://arxiv.org/abs/1207.7035},
abstract = {Electronic health records contain rich textual data which possess critical predictive information for machine-learning based diagnostic aids. However many traditional machine learning methods fail to simultaneously integrate both vector space data and text. We present a supervised method using Laplacian eigenmaps to augment existing machine-learning methods with low-dimensional representations of textual predictors which preserve the local similarities. The proposed implementation performs alternating optimization using gradient descent. For the evaluation we applied our method to over 2,000 patient records from a large single-center pediatric cardiology practice to predict if patients were diagnosed with cardiac disease. Our method was compared with latent semantic indexing, latent Dirichlet allocation, and local Fisher discriminant analysis. The results were assessed using AUC, MCC, specificity, and sensitivity. Results indicate supervised Laplacian eigenmaps was the highest performing method in our study, achieving 0.782 and 0.374 for AUC and MCC respectively. SLE showed an increase in 8.16\% in AUC and 20.6\% in MCC over the baseline which excluded textual data and a 2.69\% and 5.35\% increase in AUC and MCC respectively over unsupervised Laplacian eigenmaps. This method allows many existing machine learning predictors to effectively and efficiently utilize the potential of textual predictors.},
urldate = {2019-08-07},
journal = {arXiv:1207.7035 [cs]},
author = {Perry, Thomas and Zha, Hongyuan and Frias, Patricio and Zeng, Dadan and Braunstein, Mark},
month = jul,
year = {2012},
note = {arXiv: 1207.7035},
keywords = {Computer Science - Machine Learning},
}

@article{huang_clinicalbert:_2019,
title = {{ClinicalBERT}: {Modeling} {Clinical} {Notes} and {Predicting} {Hospital} {Readmission}},
shorttitle = {{ClinicalBERT}},
url = {http://arxiv.org/abs/1904.05342},
abstract = {Clinical notes contain information about patients that goes beyond structured data like lab values and medications. However, clinical notes have been underused relative to structured data, because notes are high-dimensional and sparse. This work develops and evaluates representations of clinical notes using bidirectional transformers (ClinicalBERT). ClinicalBERT uncovers high-quality relationships between medical concepts as judged by humans. ClinicalBert outperforms baselines on 30-day hospital readmission prediction using both discharge summaries and the first few days of notes in the intensive care unit. Code and model parameters are available.},
urldate = {2019-07-31},
journal = {arXiv:1904.05342 [cs]},
author = {Huang, Kexin and Altosaar, Jaan and Ranganath, Rajesh},
month = apr,
year = {2019},
note = {arXiv: 1904.05342},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{allam_neural_2019,
title = {Neural networks versus {Logistic} regression for 30 days all-cause readmission prediction},
volume = {9},
copyright = {2019 The Author(s)},
issn = {2045-2322},
url = {https://www.nature.com/articles/s41598-019-45685-z},
doi = {10.1038/s41598-019-45685-z},
abstract = {Heart failure (HF) is one of the leading causes of hospital admissions in the US. Readmission within 30 days after a HF hospitalization is both a recognized indicator for disease progression and a source of considerable financial burden to the healthcare system. Consequently, the identification of patients at risk for readmission is a key step in improving disease management and patient outcome. In this work, we used a large administrative claims dataset to (1) explore the systematic application of neural network-based models versus logistic regression for predicting 30 days all-cause readmission after discharge from a HF admission, and (2) to examine the additive value of patients’ hospitalization timelines on prediction performance. Based on data from 272,778 (49\% female) patients with a mean (SD) age of 73 years (14) and 343,328 HF admissions (67\% of total admissions), we trained and tested our predictive readmission models following a stratified 5-fold cross-validation scheme. Among the deep learning approaches, a recurrent neural network (RNN) combined with conditional random fields (CRF) model (RNNCRF) achieved the best performance in readmission prediction with 0.642 AUC (95\% CI, 0.640–0.645). Other models, such as those based on RNN, convolutional neural networks and CRF alone had lower performance, with a non-timeline based model (MLP) performing worst. A competitive model based on logistic regression with LASSO achieved a performance of 0.643 AUC (95\% CI, 0.640–0.646). We conclude that data from patient timelines improve 30 day readmission prediction, that a logistic regression with LASSO has equal performance to the best neural network model and that the use of administrative data result in competitive performance compared to published approaches based on richer clinical datasets.},
language = {En},
number = {1},
urldate = {2019-08-01},
journal = {Scientific Reports},
author = {Allam, Ahmed and Nagy, Mate and Thoma, George and Krauthammer, Michael},
month = jun,
year = {2019},
pages = {9277},
}

@article{choi_graph_2019,
title = {Graph {Convolutional} {Transformer}: {Learning} the {Graphical} {Structure} of {Electronic} {Health} {Records}},
shorttitle = {Graph {Convolutional} {Transformer}},
url = {http://arxiv.org/abs/1906.04716},
abstract = {Effective modeling of electronic health records (EHR) is rapidly becoming an important topic in both academia and industry. A recent study showed that utilizing the graphical structure underlying EHR data (e.g. relationship between diagnoses and treatments) improves the performance of prediction tasks such as heart failure diagnosis prediction. However, EHR data do not always contain complete structure information. Moreover, when it comes to claims data, structure information is completely unavailable to begin with. Under such circumstances, can we still do better than just treating EHR data as a flat-structured bag-of-features? In this paper, we study the possibility of utilizing the implicit structure of EHR by using the Transformer for prediction tasks on EHR data. Specifically, we argue that the Transformer is a suitable model to learn the hidden EHR structure, and propose the Graph Convolutional Transformer, which uses data statistics to guide the structure learning process. Our model empirically demonstrated superior prediction performance to previous approaches on both synthetic data and publicly available EHR data on encounter-based prediction tasks such as graph reconstruction and readmission prediction, indicating that it can serve as an effective general-purpose representation learning algorithm for EHR data.},
urldate = {2019-08-01},
journal = {arXiv:1906.04716 [cs, stat]},
author = {Choi, Edward and Xu, Zhen and Li, Yujia and Dusenberry, Michael W. and Flores, Gerardo and Xue, Yuan and Dai, Andrew M.},
month = jun,
year = {2019},
note = {arXiv: 1906.04716},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ba_layer_2016,
title = {Layer {Normalization}},
url = {http://arxiv.org/abs/1607.06450},
abstract = {Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.},
urldate = {2019-08-06},
journal = {arXiv:1607.06450 [cs, stat]},
author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
month = jul,
year = {2016},
note = {arXiv: 1607.06450},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{howard_universal_2018,
title = {Universal {Language} {Model} {Fine}-tuning for {Text} {Classification}},
url = {http://arxiv.org/abs/1801.06146},
abstract = {Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24\% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.},
urldate = {2019-08-03},
journal = {arXiv:1801.06146 [cs, stat]},
author = {Howard, Jeremy and Ruder, Sebastian},
month = jan,
year = {2018},
note = {arXiv: 1801.06146},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{bell_detecting_2018,
address = {Brussels, Belgium},
title = {Detecting {Diabetes} {Risk} from {Social} {Media} {Activity}},
url = {https://www.aclweb.org/anthology/W18-5601},
doi = {10.18653/v1/W18-5601},
abstract = {This work is the first to explore the detection of individuals' risk of type 2 diabetes mellitus (T2DM) directly from their social media (Twitter) activity. Our approach extends a deep learning architecture with several contributions: following previous observations that language use differs by gender, it captures and uses gender information through domain adaptation; it captures recency of posts under the hypothesis that more recent posts are more representative of an individual's current risk status; and, lastly, it demonstrates that in this scenario where activity factors are sparsely represented in the data, a bag-of-word neural network model using custom dictionaries of food and activity words performs better than other neural sequence models. Our best model, which incorporates all these contributions, achieves a risk-detection F1 of 41.9, considerably higher than the baseline rate (36.9).},
urldate = {2019-08-03},
booktitle = {Proceedings of the {Ninth} {International} {Workshop} on {Health} {Text} {Mining} and {Information} {Analysis}},
publisher = {Association for Computational Linguistics},
author = {Bell, Dane and Laparra, Egoitz and Kousik, Aditya and Ishihara, Terron and Surdeanu, Mihai and Kobourov, Stephen},
month = oct,
year = {2018},
keywords = {research ideas},
pages = {1--11},
}

@article{choi_mime:_2018,
title = {{MiME}: {Multilevel} {Medical} {Embedding} of {Electronic} {Health} {Records} for {Predictive} {Healthcare}},
shorttitle = {{MiME}},
url = {http://arxiv.org/abs/1810.09593},
abstract = {Deep learning models exhibit state-of-the-art performance for many predictive healthcare tasks using electronic health records (EHR) data, but these models typically require training data volume that exceeds the capacity of most healthcare systems. External resources such as medical ontologies are used to bridge the data volume constraint, but this approach is often not directly applicable or useful because of inconsistencies with terminology. To solve the data insufficiency challenge, we leverage the inherent multilevel structure of EHR data and, in particular, the encoded relationships among medical codes. We propose Multilevel Medical Embedding (MiME) which learns the multilevel embedding of EHR data while jointly performing auxiliary prediction tasks that rely on this inherent EHR structure without the need for external labels. We conducted two prediction tasks, heart failure prediction and sequential disease prediction, where MiME outperformed baseline methods in diverse evaluation settings. In particular, MiME consistently outperformed all baselines when predicting heart failure on datasets of different volumes, especially demonstrating the greatest performance improvement (15\% relative gain in PR-AUC over the best baseline) on the smallest dataset, demonstrating its ability to effectively model the multilevel structure of EHR data.},
urldate = {2019-08-01},
journal = {arXiv:1810.09593 [cs, stat]},
author = {Choi, Edward and Xiao, Cao and Stewart, Walter F. and Sun, Jimeng},
month = oct,
year = {2018},
note = {arXiv: 1810.09593},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{radford_improving_2018,
title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
author = {Radford, Alec},
year = {2018},
keywords = {Benchmark (computing), Body of uterus, Commonsense knowledge (artificial intelligence), Commonsense reasoning, Discriminative model, Document classification, Language model, Machine learning, Natural language understanding, Question answering, Semantic similarity, Text corpus, Textual entailment, Tracer, Transformers, Unsupervised learning, cell transformation},
}

@article{he_deep_2015,
title = {Deep {Residual} {Learning} for {Image} {Recognition}},
url = {http://arxiv.org/abs/1512.03385},
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
urldate = {2019-08-01},
journal = {arXiv:1512.03385 [cs]},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
month = dec,
year = {2015},
note = {arXiv: 1512.03385},
keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{wang_predicting_2018,
title = {Predicting {Hospital} {Readmission} via {Cost}-{Sensitive} {Deep} {Learning}},
volume = {15},
issn = {1545-5963},
doi = {10.1109/TCBB.2018.2827029},
abstract = {With increased use of electronic medical records (EMRs), data mining on medical data has great potential to improve the quality of hospital treatment and increase the survival rate of patients. Early readmission prediction enables early intervention, which is essential to preventing serious or life-threatening events, and act as a substantial contributor to reduce healthcare costs. Existing works on predicting readmission often focus on certain vital signs and diseases by extracting statistical features. They also fail to consider skewness of class labels in medical data and different costs of misclassification errors. In this paper, we recur to the merits of convolutional neural networks (CNN) to automatically learn features from time series of vital sign, and categorical feature embedding to effectively encode feature vectors with heterogeneous clinical features, such as demographics, hospitalization history, vital signs, and laboratory tests. Then, both learnt features via CNN and statistical features via feature embedding are fed into a multilayer perceptron (MLP) for prediction. We use a cost-sensitive formulation to train MLP during prediction to tackle the imbalance and skewness challenge. We validate the proposed approach on two real medical datasets from Barnes-Jewish Hospital, and all data is taken from historical EMR databases and reflects the kinds of data that would realistically be available at the clinical prediction system in hospitals. We find that early prediction of readmission is possible and when compared with state-of-the-art existing methods used by hospitals, our methods perform significantly better. For example, using the general hospital wards data for 30-day readmission prediction, the area under the curve (AUC) for the proposed model was 0.70, significantly higher than all the baseline methods. Based on these results, a system is being deployed in hospital settings with the proposed forecasting algorithms to support treatment.},
number = {6},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
author = {Wang, H. and Cui, Z. and Chen, Y. and Avidan, M. and Abdallah, A. B. and Kronzer, A.},
month = nov,
year = {2018},
pages = {1968--1978},
}

@inproceedings{rafiq_deep_2019,
series = {Lecture {Notes} in {Computer} {Science}},
title = {Deep {Learning} {Architectures} for {Vector} {Representations} of {Patients} and {Exploring} {Predictors} of 30-{Day} {Hospital} {Readmissions} in {Patients} with {Multiple} {Chronic} {Conditions}},
isbn = {978-3-030-12738-1},
abstract = {This empirical study of a complex group of patients with multiple chronic concurrent conditions (diabetes, cardiovascular and kidney diseases) explores the use of deep learning architectures to identify patient segments and contributing factors to 30-day hospital readmissions. We implemented Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) on sequential Electronic Health Records data at the Danderyd Hospital in Stockholm, Sweden. Three distinct sub-types of patient groups were identified: chronic obstructive pulmonary disease, kidney transplant, and paroxysmal ventricular tachycardia. The CNN learned about vector representations of patients, but the RNN was better able to identify and quantify key contributors to readmission such as myocardial infarction and echocardiography. We suggest that vector representations of patients with deep learning should precede predictive modeling of complex patients. The approach also has potential implications for supporting care delivery, care design and clinical decision-making.},
language = {en},
booktitle = {Artificial {Intelligence} in {Health}},
publisher = {Springer International Publishing},
author = {Rafiq, Muhammad and Keel, George and Mazzocato, Pamela and Spaak, Jonas and Savage, Carl and Guttmann, Christian},
editor = {Koch, Fernando and Koster, Andrew and Riaño, David and Montagna, Sara and Schumacher, Michael and ten Teije, Annette and Guttmann, Christian and Reichert, Manfred and Bichindaritz, Isabelle and Herrero, Pau and Lenz, Richard and López, Beatriz and Marling, Cindy and Martin, Clare and Montani, Stefania and Wiratunga, Nirmalie},
year = {2019},
keywords = {30-day hospital readmissions, Deep learning, Multiple Chronic Conditions},
pages = {228--244},
}

@article{vaswani_attention_2017,
title = {Attention {Is} {All} {You} {Need}},
url = {https://arxiv.org/abs/1706.03762v5},
abstract = {The dominant sequence transduction models are based on complex recurrent or
convolutional neural networks in an encoder-decoder configuration. The best
performing models also connect the encoder and decoder through an attention
mechanism. We propose a new simple network architecture, the Transformer, based
solely on attention mechanisms, dispensing with recurrence and convolutions
entirely. Experiments on two machine translation tasks show these models to be
superior in quality while being more parallelizable and requiring significantly
less time to train. Our model achieves 28.4 BLEU on the WMT 2014
English-to-German translation task, improving over the existing best results,
including ensembles by over 2 BLEU. On the WMT 2014 English-to-French
translation task, our model establishes a new single-model state-of-the-art
BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction
of the training costs of the best models from the literature. We show that the
Transformer generalizes well to other tasks by applying it successfully to
English constituency parsing both with large and limited training data.},
language = {en},
urldate = {2019-08-01},
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
month = jun,
year = {2017},
keywords = {read here},
}

@article{bengio_neural_2003,
title = {A {Neural} {Probabilistic} {Language} {Model}},
volume = {3},
issn = {1532-4435},
url = {http://dl.acm.org/citation.cfm?id=944919.944966},
abstract = {A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.},
urldate = {2019-08-01},
journal = {J. Mach. Learn. Res.},
author = {Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal and Janvin, Christian},
month = mar,
year = {2003},
keywords = {read here},
pages = {1137--1155},
}

@article{xie_data_2017,
title = {Data {Noising} as {Smoothing} in {Neural} {Network} {Language} {Models}},
url = {http://arxiv.org/abs/1703.02573},
abstract = {Data noising is an effective technique for regularizing neural network models. While noising is widely adopted in application domains such as vision and speech, commonly used noising primitives have not been developed for discrete sequence-level settings such as language modeling. In this paper, we derive a connection between input noising in neural network language models and smoothing in \$n\$-gram models. Using this connection, we draw upon ideas from smoothing to develop effective noising schemes. We demonstrate performance gains when applying the proposed schemes to language modeling and machine translation. Finally, we provide empirical analysis validating the relationship between noising and smoothing.},
urldate = {2019-08-01},
journal = {arXiv:1703.02573 [cs]},
author = {Xie, Ziang and Wang, Sida I. and Li, Jiwei and Lévy, Daniel and Nie, Aiming and Jurafsky, Dan and Ng, Andrew Y.},
month = mar,
year = {2017},
note = {arXiv: 1703.02573},
keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{xiao_readmission_2018,
title = {Readmission prediction via deep contextual embedding of clinical concepts},
volume = {13},
issn = {1932-6203},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0195024},
doi = {10.1371/journal.pone.0195024},
abstract = {Objective Hospital readmission costs a lot of money every year. Many hospital readmissions are avoidable, and excessive hospital readmissions could also be harmful to the patients. Accurate prediction of hospital readmission can effectively help reduce the readmission risk. However, the complex relationship between readmission and potential risk factors makes readmission prediction a difficult task. The main goal of this paper is to explore deep learning models to distill such complex relationships and make accurate predictions. Materials and methods We propose CONTENT, a deep model that predicts hospital readmissions via learning interpretable patient representations by capturing both local and global contexts from patient Electronic Health Records (EHR) through a hybrid Topic Recurrent Neural Network (TopicRNN) model. The experiment was conducted using the EHR of a real world Congestive Heart Failure (CHF) cohort of 5,393 patients. Results The proposed model outperforms state-of-the-art methods in readmission prediction (e.g. 0.6103 ± 0.0130 vs. second best 0.5998 ± 0.0124 in terms of ROC-AUC). The derived patient representations were further utilized for patient phenotyping. The learned phenotypes provide more precise understanding of readmission risks. Discussion Embedding both local and global context in patient representation not only improves prediction performance, but also brings interpretable insights of understanding readmission risks for heterogeneous chronic clinical conditions. Conclusion This is the first of its kind model that integrates the power of both conventional deep neural network and the probabilistic generative models for highly interpretable deep patient representation learning. Experimental results and case studies demonstrate the improved performance and interpretability of the model.},
language = {en},
number = {4},
urldate = {2019-07-16},
journal = {PLOS ONE},
author = {Xiao, Cao and Ma, Tengfei and Dieng, Adji B. and Blei, David M. and Wang, Fei},
month = apr,
year = {2018},
keywords = {Cardiac transplantation, Distillation, Heart failure, Hospitals, Language, Medicare, Neural networks, Surgical and invasive medical procedures},
pages = {e0195024},
}

@article{casucci_estimating_2018,
title = {Estimating the causal effects of chronic disease combinations on 30-day hospital readmissions based on observational {Medicaid} data},
volume = {25},
issn = {1067-5027},
url = {https://academic.oup.com/jamia/article/25/6/670/4677331},
doi = {10.1093/jamia/ocx141},
abstract = {AbstractObjective.  Demonstrate how observational causal inference methods can generate insights into the impact of chronic disease combinations on patients’ 30},
language = {en},
number = {6},
urldate = {2019-07-10},
journal = {Journal of the American Medical Informatics Association},
author = {Casucci, Sabrina and Lin, Li and Hewner, Sharon and Nikolaev, Alexander},
month = jun,
year = {2018},
pages = {670--678},
}

@article{futoma_improved_2017,
title = {An {Improved} {Multi}-{Output} {Gaussian} {Process} {RNN} with {Real}-{Time} {Validation} for {Early} {Sepsis} {Detection}},
url = {http://arxiv.org/abs/1708.05894},
abstract = {Sepsis is a poorly understood and potentially life-threatening complication that can occur as a result of infection. Early detection and treatment improves patient outcomes, and as such it poses an important challenge in medicine. In this work, we develop a flexible classifier that leverages streaming lab results, vitals, and medications to predict sepsis before it occurs. We model patient clinical time series with multi-output Gaussian processes, maintaining uncertainty about the physiological state of a patient while also imputing missing values. The mean function takes into account the effects of medications administered on the trajectories of the physiological variables. Latent function values from the Gaussian process are then fed into a deep recurrent neural network to classify patient encounters as septic or not, and the overall model is trained end-to-end using back-propagation. We train and validate our model on a large dataset of 18 months of heterogeneous inpatient stays from the Duke University Health System, and develop a new "real-time" validation scheme for simulating the performance of our model as it will actually be used. Our proposed method substantially outperforms clinical baselines, and improves on a previous related model for detecting sepsis. Our model's predictions will be displayed in a real-time analytics dashboard to be used by a sepsis rapid response team to help detect and improve treatment of sepsis.},
urldate = {2019-06-21},
journal = {arXiv:1708.05894 [stat]},
author = {Futoma, Joseph and Hariharan, Sanjay and Sendak, Mark and Brajer, Nathan and Clement, Meredith and Bedoya, Armando and O'Brien, Cara and Heller, Katherine},
month = aug,
year = {2017},
note = {arXiv: 1708.05894},
keywords = {Statistics - Applications, Statistics - Machine Learning, Statistics - Methodology},
}

@article{kam_learning_2017,
title = {Learning representations for the early detection of sepsis with deep neural networks},
volume = {89},
issn = {0010-4825},
url = {http://www.sciencedirect.com/science/article/pii/S0010482517302743},
doi = {10.1016/j.compbiomed.2017.08.015},
abstract = {Background
Sepsis is one of the leading causes of death in intensive care unit patients. Early detection of sepsis is vital because mortality increases as the sepsis stage worsens.
Objective
This study aimed to develop detection models for the early stage of sepsis using deep learning methodologies, and to compare the feasibility and performance of the new deep learning methodology with those of the regression method with conventional temporal feature extraction.
Method
Study group selection adhered to the InSight model. The results of the deep learning-based models and the InSight model were compared.
Results
With deep feedforward networks, the area under the ROC curve (AUC) of the models were 0.887 and 0.915 for the InSight and the new feature sets, respectively. For the model with the combined feature set, the AUC was the same as that of the basic feature set (0.915). For the long short-term memory model, only the basic feature set was applied and the AUC improved to 0.929 compared with the existing 0.887 of the InSight model.
Conclusions
The contributions of this paper can be summarized in three ways: (i) improved performance without feature extraction using domain knowledge, (ii) verification of feature extraction capability of deep neural networks through comparison with reference features, and (iii) improved performance with feedforward neural networks using long short-term memory, a neural network architecture that can learn sequential patterns.},
urldate = {2019-06-21},
journal = {Computers in Biology and Medicine},
author = {Kam, Hye Jin and Kim, Ha Young},
month = oct,
year = {2017},
keywords = {Clinical decision support system, Deep learning, Early detection, Feature extraction, LSTM, Multivariate time-series, Sepsis},
pages = {248--255},
}

@article{wiedemann_coding_2007,
title = {Coding {Sepsis} and {SIRS}},
volume = {78},
url = {http://library.ahima.org/doc?oid=70222},
abstract = {,},
language = {en},
number = {4},
urldate = {2019-07-05},
journal = {Journal of AHIMA},
author = {Wiedemann, Lou Ann},
month = apr,
year = {2007},
pages = {76--78},
}

@article{futoma_comparison_2015,
title = {A comparison of models for predicting early hospital readmissions},
volume = {56},
issn = {1532-0464},
url = {http://www.sciencedirect.com/science/article/pii/S1532046415000969},
doi = {10.1016/j.jbi.2015.05.016},
abstract = {Risk sharing arrangements between hospitals and payers together with penalties imposed by the Centers for Medicare and Medicaid (CMS) are driving an interest in decreasing early readmissions. There are a number of published risk models predicting 30day readmissions for particular patient populations, however they often exhibit poor predictive performance and would be unsuitable for use in a clinical setting. In this work we describe and compare several predictive models, some of which have never been applied to this task and which outperform the regression methods that are typically applied in the healthcare literature. In addition, we apply methods from deep learning to the five conditions CMS is using to penalize hospitals, and offer a simple framework for determining which conditions are most cost effective to target.},
urldate = {2019-06-25},
journal = {Journal of Biomedical Informatics},
author = {Futoma, Joseph and Morris, Jonathan and Lucas, Joseph},
month = aug,
year = {2015},
keywords = {Deep learning, Early readmission, Electronic Health Records, Penalized methods, Predictive models, Random forest},
pages = {229--238},
}

@techreport{cdc_hospital_nodate,
title = {Hospital {Toolkit} for {Adult} {Sepsis} {Surveillance}},
url = {https://www.cdc.gov/sepsis/pdfs/Sepsis-Surveillance-Toolkit-Aug-2018_508.pdf},
author = {CDC},
}

@techreport{nih_science_nodate,
title = {Science {Education}: {Sepsis}},
url = {https://www.nigms.nih.gov/education/Pages/factsheet_sepsis.aspx},
institution = {National Institute of General Medical Sciences},
author = {NIH},
}

@misc{cdc_sepsis:_2019,
title = {Sepsis: {Data} and {Reports}},
url = {https://www.cdc.gov/sepsis/datareports/index.html},
abstract = {Check out the most recent sepsis reports on incidence, prevalence, and mortality.},
language = {en-us},
urldate = {2019-06-27},
journal = {Centers for Disease Control and Prevention},
author = {CDC},
month = jan,
year = {2019},
}

@techreport{acep_expert_panel_on_sepsis_evidence-driven_nodate,
title = {An evidence-driven tool to guide the early recognition and treatment of sepsis and septic shock},
url = {http://www.acep.org/patient-care/dart/},
language = {en},
urldate = {2019-06-27},
author = {ACEP Expert Panel on Sepsis},
}

@misc{cdc_you_2019,
title = {Do you know about the life-threatening condition called sepsis?},
url = {https://www.cdc.gov/sepsis/index.html},
abstract = {Protect yourself and your family by learning more about sepsis and how you can prevent it},
language = {en-us},
urldate = {2019-06-27},
journal = {Centers for Disease Control and Prevention},
author = {CDC},
month = jan,
year = {2019},
}

@inproceedings{bonilla_multi-task_2007,
address = {USA},
series = {{NIPS}'07},
title = {Multi-task {Gaussian} {Process} {Prediction}},
isbn = {978-1-60560-352-0},
url = {http://dl.acm.org/citation.cfm?id=2981562.2981582},
abstract = {In this paper we investigate multi-task learning in the context of Gaussian Processes (GP). We propose a model that learns a shared covariance function on input-dependent features and a "free-form" covariance matrix over tasks. This allows for good flexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training. We show that under the assumption of noise-free observations and a block design, predictions for a given task only depend on its target values and therefore a cancellation of inter-task transfer occurs. We evaluate the benefits of our model on two practical applications: a compiler performance prediction problem and an exam score prediction task. Additionally, we make use of GP approximations and properties of our model in order to provide scalability to large data sets.},
urldate = {2019-06-27},
booktitle = {Proceedings of the 20th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
publisher = {Curran Associates Inc.},
author = {Bonilla, Edwin V. and Chai, Kian Ming A. and Williams, Christopher K. I.},
year = {2007},
note = {event-place: Vancouver, British Columbia, Canada},
pages = {153--160},
}

@inproceedings{futoma_learning_2017,
series = {{ICML}'17},
title = {Learning to {Detect} {Sepsis} with a {Multitask} {Gaussian} {Process} {RNN} {Classifier}},
url = {http://dl.acm.org/citation.cfm?id=3305381.3305503},
abstract = {We present a scalable end-to-end classifier that uses streaming physiological and medication data to accurately predict the onset of sepsis, a life-threatening complication from infections that has high mortality and morbidity. Our proposed framework models the multivariate trajectories of continuous-valued physiological time series using multitask Gaussian processes, seamlessly accounting for the high uncertainty, frequent missingness, and irregular sampling rates typically associated with real clinical data. The Gaussian process is directly connected to a black-box classifier that predicts whether a patient will become septic, chosen in our case to be a recurrent neural network to account for the extreme variability in the length of patient encounters. We show how to scale the computations associated with the Gaussian process in a manner so that the entire system can be discriminatively trained end-to-end using backpropagation. In a large cohort of heterogeneous inpatient encounters at our university health system we find that it outperforms several baselines at predicting sepsis, and yields 19.4\% and 55.5\% improved areas under the Receiver Operating Characteristic and Precision Recall curves as compared to the NEWS score currently used by our hospital.},
urldate = {2019-06-27},
booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning} - {Volume} 70},
publisher = {JMLR.org},
author = {Futoma, Joseph and Hariharan, Sanjay and Heller, Katherine},
year = {2017},
note = {event-place: Sydney, NSW, Australia},
pages = {1174--1182},
}

@article{kipf_semi-supervised_2016,
title = {Semi-{Supervised} {Classification} with {Graph} {Convolutional} {Networks}},
url = {http://arxiv.org/abs/1609.02907},
abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
urldate = {2019-06-17},
journal = {arXiv:1609.02907 [cs, stat]},
author = {Kipf, Thomas N. and Welling, Max},
month = sep,
year = {2016},
note = {arXiv: 1609.02907},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, research ideas},
}

@article{tenenbaum_global_2000,
title = {A {Global} {Geometric} {Framework} for {Nonlinear} {Dimensionality} {Reduction}},
volume = {290},
issn = {0036-8075, 1095-9203},
url = {https://science.sciencemag.org/content/290/5500/2319},
doi = {10.1126/science.290.5500.2319},
abstract = {Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs—30,000 auditory nerve fibers or 106 optic nerve fibers—a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.},
language = {en},
number = {5500},
urldate = {2019-06-17},
journal = {Science},
author = {Tenenbaum, Joshua B. and Silva, Vin de and Langford, John C.},
month = dec,
year = {2000},
pmid = {11125149},
keywords = {research ideas},
pages = {2319--2323},
}

@article{bardhan_predictive_2014,
title = {Predictive {Analytics} for {Readmission} of {Patients} with {Congestive} {Heart} {Failure}},
volume = {26},
issn = {1047-7047},
url = {https://pubsonline.informs.org/doi/abs/10.1287/isre.2014.0553},
doi = {10.1287/isre.2014.0553},
abstract = {Mitigating preventable readmissions, where patients are readmitted for the same primary diagnosis within 30 days, poses a significant challenge to the delivery of high-quality healthcare. Toward this end, we develop a novel, predictive analytics model, termed as the beta geometric Erlang-2 (BG/EG) hurdle model, which predicts the propensity, frequency, and timing of readmissions of patients diagnosed with congestive heart failure (CHF). This unified model enables us to answer three key questions related to the use of predictive analytics methods for patient readmissions: whether a readmission will occur, how often readmissions will occur, and when a readmission will occur. We test our model using a unique data set that tracks patient demographic, clinical, and administrative data across 67 hospitals in North Texas over a four-year period. We show that our model provides superior predictive performance compared to extant models such as the logit, BG/NBD hurdle, and EG hurdle models. Our model also allows us to study the association between hospital usage of health information technologies (IT) and readmission risk. We find that health IT usage, patient demographics, visit characteristics, payer type, and hospital characteristics, are significantly associated with patient readmission risk. We also observe that implementation of cardiology information systems is associated with a reduction in the propensity and frequency of future readmissions, whereas administrative IT systems are correlated with a lower frequency of future readmissions. Our results indicate that patient profiles derived from our model can serve as building blocks for a predictive analytics system to identify CHF patients with high readmission risk.},
number = {1},
urldate = {2019-06-25},
journal = {Information Systems Research},
author = {Bardhan, Indranil and Oh, Jeong-ha (Cath) and Zheng, Zhiqiang (Eric) and Kirksey, Kirk},
month = nov,
year = {2014},
pages = {19--39},
}

@article{amarasingham_automated_2010,
title = {An automated model to identify heart failure patients at risk for 30-day readmission or death using electronic medical record data},
volume = {48},
issn = {1537-1948},
doi = {10.1097/MLR.0b013e3181ef60d9},
abstract = {BACKGROUND: A real-time electronic predictive model that identifies hospitalized heart failure (HF) patients at high risk for readmission or death may be valuable to clinicians and hospitals who care for these patients.
METHODS: An automated predictive model for 30-day readmission and death was derived and validated from clinical and nonclinical risk factors present on admission in 1372 HF hospitalizations to a major urban hospital between January 2007 and August 2008. Data were extracted from an electronic medical record. The performance of the electronic model was compared with mortality and readmission models developed by the Center for Medicaid and Medicare Services (CMS models) and a HF mortality model derived from the Acute Decompensated Heart Failure Registry (ADHERE model).
RESULTS: The 30-day mortality and readmission rates were 3.1\% and 24.1\% respectively. The electronic model demonstrated good discrimination for 30 day mortality (C statistic 0.86) and readmission (C statistic 0.72) and performed as well, or better than, the ADHERE model and CMS models for both outcomes (C statistic ranges: 0.72-0.73 and 0.56-0.66 for mortality and readmissions respectively; P {\textless} 0.05 in all comparisons). Markers of social instability and lower socioeconomic status improved readmission prediction in the electronic model (C statistic 0.72 vs. 0.61, P {\textless} 0.05).
CONCLUSIONS: Clinical and social factors available within hours of hospital presentation and extractable from an EMR predicted mortality and readmission at 30 days. Incorporating complex social factors increased the model's accuracy, suggesting that such factors could enhance risk adjustment models designed to compare hospital readmission rates.},
language = {eng},
number = {11},
journal = {Medical Care},
author = {Amarasingham, Ruben and Moore, Billy J. and Tabak, Ying P. and Drazner, Mark H. and Clark, Christopher A. and Zhang, Song and Reed, W. Gary and Swanson, Timothy S. and Ma, Ying and Halm, Ethan A.},
month = nov,
year = {2010},
pmid = {20940649},
keywords = {Adult, Aged, Aged, 80 and over, Electronic Health Records, Female, Heart Failure, Humans, Male, Middle Aged, Outcome Assessment (Health Care), Patient Readmission, Predictive Value of Tests, Prognosis, Risk Assessment, Risk Factors, Severity of Illness Index, Socioeconomic Factors, Survival Rate, United States, Urban Population},
pages = {981--988},
}

@article{nachimuthu_early_2012,
title = {Early {Detection} of {Sepsis} in the {Emergency} {Department} using {Dynamic} {Bayesian} {Networks}},
volume = {2012},
issn = {1942-597X},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3540576/},
abstract = {Sepsis is a systemic inflammatory state due to an infection, and is associated with very high mortality and morbidity. Early diagnosis and prompt antibiotic and supportive therapy is associated with improved outcomes. Our objective was to detect the presence of sepsis soon after the patient visits the emergency department. We used Dynamic Bayesian Networks, a temporal probabilistic technique to model a system whose state changes over time. We built, trained and tested the model using data of 3,100 patients admitted to the emergency department, and measured the accuracy of detecting sepsis using data collected within the first 3 hours, 6 hours, 12 hours and 24 hours after admission. The area under the curve was 0.911, 0.915, 0.937 and 0.944 respectively. We describe the data, data preparation techniques, model, results, various statistical measures and the limitations of our experiments. We also briefly discuss techniques to improve accuracy, and the generalizability of our methods to other diseases.},
urldate = {2019-06-21},
journal = {AMIA Annual Symposium Proceedings},
author = {Nachimuthu, Senthil K. and Haug, Peter J.},
month = nov,
year = {2012},
pmid = {23304338},
pmcid = {PMC3540576},
pages = {653--662},
}

@article{johansson_learning_2016,
title = {Learning {Representations} for {Counterfactual} {Inference}},
url = {http://arxiv.org/abs/1605.03661},
abstract = {Observational studies are rising in importance due to the widespread accumulation of data in fields such as healthcare, education, employment and ecology. We consider the task of answering counterfactual questions such as, "Would this patient have lower blood sugar had she received a different medication?". We propose a new algorithmic framework for counterfactual inference which brings together ideas from domain adaptation and representation learning. In addition to a theoretical justification, we perform an empirical comparison with previous approaches to causal inference from observational data. Our deep learning algorithm significantly outperforms the previous state-of-the-art.},
urldate = {2019-06-21},
journal = {arXiv:1605.03661 [cs, stat]},
author = {Johansson, Fredrik D. and Shalit, Uri and Sontag, David},
month = may,
year = {2016},
note = {arXiv: 1605.03661},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, research ideas},
}

@article{mower_learning_2018,
title = {Learning predictive models of drug side-effect relationships from distributed representations of literature-derived semantic predications},
volume = {25},
issn = {1527-974X},
doi = {10.1093/jamia/ocy077},
abstract = {Objective: The aim of this work is to leverage relational information extracted from biomedical literature using a novel synthesis of unsupervised pretraining, representational composition, and supervised machine learning for drug safety monitoring.
Methods: Using ≈80 million concept-relationship-concept triples extracted from the literature using the SemRep Natural Language Processing system, distributed vector representations (embeddings) were generated for concepts as functions of their relationships utilizing two unsupervised representational approaches. Embeddings for drugs and side effects of interest from two widely used reference standards were then composed to generate embeddings of drug/side-effect pairs, which were used as input for supervised machine learning. This methodology was developed and evaluated using cross-validation strategies and compared to contemporary approaches. To qualitatively assess generalization, models trained on the Observational Medical Outcomes Partnership (OMOP) drug/side-effect reference set were evaluated against a list of ≈1100 drugs from an online database.
Results: The employed method improved performance over previous approaches. Cross-validation results advance the state of the art (AUC 0.96; F1 0.90 and AUC 0.95; F1 0.84 across the two sets), outperforming methods utilizing literature and/or spontaneous reporting system data. Examination of predictions for unseen drug/side-effect pairs indicates the ability of these methods to generalize, with over tenfold label support enrichment in the top 100 predictions versus the bottom 100 predictions.
Discussion and Conclusion: Our methods can assist the pharmacovigilance process using information from the biomedical literature. Unsupervised pretraining generates a rich relationship-based representational foundation for machine learning techniques to classify drugs in the context of a putative side effect, given known examples.},
language = {eng},
number = {10},
journal = {Journal of the American Medical Informatics Association: JAMIA},
author = {Mower, Justin and Subramanian, Devika and Cohen, Trevor},
month = oct,
year = {2018},
pmid = {30010902},
pmcid = {PMC6454491},
pages = {1339--1350},
}

@article{li_classifying_2019,
title = {Classifying relations in clinical narratives using segment graph convolutional and recurrent neural networks ({Seg}-{GCRNs})},
volume = {26},
url = {https://academic.oup.com/jamia/article/26/3/262/5263777},
doi = {10.1093/jamia/ocy157},
abstract = {Abstract.  We propose to use segment graph convolutional and recurrent neural networks (Seg-GCRNs), which use only word embedding and sentence syntactic depende},
language = {en},
number = {3},
urldate = {2019-06-13},
journal = {Journal of the American Medical Informatics Association},
author = {Li, Yifu and Jin, Ran and Luo, Yuan},
month = mar,
year = {2019},
pages = {262--268},
}

@inproceedings{pianesi_multimodal_2008,
address = {New York, NY, USA},
series = {{ICMI} '08},
title = {Multimodal {Recognition} of {Personality} {Traits} in {Social} {Interactions}},
isbn = {978-1-60558-198-9},
url = {http://doi.acm.org/10.1145/1452392.1452404},
doi = {10.1145/1452392.1452404},
abstract = {This paper targets the automatic detection of personality traits in a meeting environment by means of audio and visual features; information about the relational context is captured by means of acoustic features designed to that purpose. Two personality traits are considered: Extraversion (from the Big Five) and the Locus of Control. The classification task is applied to thin slices of behaviour, in the form of 1-minute sequences. SVM were used to test the performances of several training and testing instance setups, including a restricted set of audio features obtained through feature selection. The outcomes improve considerably over existing results, provide evidence about the feasibility of the multimodal analysis of personality, the role of social context, and pave the way to further studies addressing different features setups and/or targeting different personality traits.},
urldate = {2019-06-10},
booktitle = {Proceedings of the 10th {International} {Conference} on {Multimodal} {Interfaces}},
publisher = {ACM},
author = {Pianesi, Fabio and Mana, Nadia and Cappelletti, Alessandro and Lepri, Bruno and Zancanaro, Massimo},
year = {2008},
note = {event-place: Chania, Crete, Greece},
keywords = {NLP, group interaction, intelligent environments, personality modeling, support vector machines},
pages = {53--60},
}

@inproceedings{danescu-niculescu-mizil_mark_2011,
address = {New York, NY, USA},
series = {{WWW} '11},
title = {Mark {My} {Words}!: {Linguistic} {Style} {Accommodation} in {Social} {Media}},
isbn = {978-1-4503-0632-4},
shorttitle = {Mark {My} {Words}!},
url = {http://doi.acm.org/10.1145/1963405.1963509},
doi = {10.1145/1963405.1963509},
abstract = {The psycholinguistic theory of communication accommodation accounts for the general observation that participants in conversations tend to converge to one another's communicative behavior: they coordinate in a variety of dimensions including choice of words, syntax, utterance length, pitch and gestures. In its almost forty years of existence, this theory has been empirically supported exclusively through small-scale or controlled laboratory studies. Here we address this phenomenon in the context of Twitter conversations. Undoubtedly, this setting is unlike any other in which accommodation was observed and, thus, challenging to the theory. Its novelty comes not only from its size, but also from the non real-time nature of conversations, from the 140 character length restriction, from the wide variety of social relation types, and from a design that was initially not geared towards conversation at all. Given such constraints, it is not clear a priori whether accommodation is robust enough to occur given the constraints of this new environment. To investigate this, we develop a probabilistic framework that can model accommodation and measure its effects. We apply it to a large Twitter conversational dataset specifically developed for this task. This is the first time the hypothesis of linguistic style accommodation has been examined (and verified) in a large scale, real world setting. Furthermore, when investigating concepts such as stylistic influence and symmetry of accommodation, we discover a complexity of the phenomenon which was never observed before. We also explore the potential relation between stylistic influence and network features commonly associated with social status.},
urldate = {2019-06-10},
booktitle = {Proceedings of the 20th {International} {Conference} on {World} {Wide} {Web}},
publisher = {ACM},
author = {Danescu-Niculescu-Mizil, Cristian and Gamon, Michael and Dumais, Susan},
year = {2011},
note = {event-place: Hyderabad, India},
keywords = {NLP, linguistic convergence, linguistic style accommodation, social media, twitter conversations},
pages = {745--754},
}

@article{vinciarelli_survey_2014,
title = {A {Survey} of {Personality} {Computing}},
volume = {5},
issn = {1949-3045},
doi = {10.1109/TAFFC.2014.2330816},
abstract = {Personality is a psychological construct aimed at explaining the wide variety of human behaviors in terms of a few, stable and measurable individual characteristics. In this respect, any technology involving understanding, prediction and synthesis of human behavior is likely to benefit from Personality Computing approaches, i.e. from technologies capable of dealing with human personality. This paper is a survey of such technologies and it aims at providing not only a solid knowledge base about the state-of-the-art, but also a conceptual model underlying the three main problems addressed in the literature, namely Automatic Personality Recognition (inference of the true personality of an individual from behavioral evidence), Automatic Personality Perception (inference of personality others attribute to an individual based on her observable behavior) and Automatic Personality Synthesis (generation of artificial personalities via embodied agents). Furthermore, the article highlights the issues still open in the field and identifies potential application areas.},
number = {3},
journal = {IEEE Transactions on Affective Computing},
author = {Vinciarelli, A. and Mohammadi, G.},
month = jul,
year = {2014},
keywords = {Biological system modeling, Communities, Computational modeling, Correlation, Lenses, NLP, Observers, Personality, Psychology, artificial personality generation, automatic personality perception, automatic personality recognition, automatic personality synthesis, behavioral evidence, behavioural sciences computing, embodied agents, human behavior prediction, human behavior synthesis, human behavior understanding, inference mechanisms, multi-agent systems, personality computing, personality inference, personality synthesis, psychology, true personality inference},
pages = {273--291},
}

@article{mairesse_using_2007,
title = {Using {Linguistic} {Cues} for the {Automatic} {Recognition} of {Personality} in {Conversation} and {Text}},
volume = {30},
copyright = {Copyright (c)},
issn = {1076-9757},
url = {https://www.jair.org/index.php/jair/article/view/10520},
doi = {10.1613/jair.2349},
language = {en},
urldate = {2019-06-10},
journal = {Journal of Artificial Intelligence Research},
author = {Mairesse, F. and Walker, M. A. and Mehl, M. R. and Moore, R. K.},
month = nov,
year = {2007},
keywords = {NLP},
pages = {457--500},
}

@article{schwartz_personality_2013,
title = {Personality, {Gender}, and {Age} in the {Language} of {Social} {Media}: {The} {Open}-{Vocabulary} {Approach}},
volume = {8},
issn = {1932-6203},
shorttitle = {Personality, {Gender}, and {Age} in the {Language} of {Social} {Media}},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0073791},
doi = {10.1371/journal.pone.0073791},
abstract = {We analyzed 700 million words, phrases, and topic instances collected from the Facebook messages of 75,000 volunteers, who also took standard personality tests, and found striking variations in language with personality, gender, and age. In our open-vocabulary technique, the data itself drives a comprehensive exploration of language that distinguishes people, finding connections that are not captured with traditional closed-vocabulary word-category analyses. Our analyses shed new light on psychosocial processes yielding results that are face valid (e.g., subjects living in high elevations talk about the mountains), tie in with other research (e.g., neurotic people disproportionately use the phrase ‘sick of’ and the word ‘depressed’), suggest new hypotheses (e.g., an active life implies emotional stability), and give detailed insights (males use the possessive ‘my’ when mentioning their ‘wife’ or ‘girlfriend’ more often than females use ‘my’ with ‘husband’ or 'boyfriend’). To date, this represents the largest study, by an order of magnitude, of language and personality.},
language = {en},
number = {9},
urldate = {2019-06-10},
journal = {PLOS ONE},
author = {Schwartz, H. Andrew and Eichstaedt, Johannes C. and Kern, Margaret L. and Dziurzynski, Lukasz and Ramones, Stephanie M. and Agrawal, Megha and Shah, Achal and Kosinski, Michal and Stillwell, David and Seligman, Martin E. P. and Ungar, Lyle H.},
month = sep,
year = {2013},
keywords = {Emotions, Facebook, Forecasting, Language, Personality, Psycholinguistics, Semantics, Social media},
pages = {e73791},
}

@article{noauthor_using_2015,
title = {Using part-of-speech sequences frequencies in a text to predict author personality: {A} corpus study},
volume = {8},
issn = {0974-6846, 0974-5645},
shorttitle = {Using part-of-speech sequences frequencies in a text to predict author personality},
language = {английский},
number = {S9},
journal = {Indian Journal of Science and Technology},
year = {2015},
keywords = {NLP},
pages = {93--97},
}

@inproceedings{argamon_lexical_2005,
title = {Lexical {Predictors} {Of} {Personality} {Type}},
abstract = {We are currently pursuing methods for "author profiling" in which various aspects  of the author's identity might be identified from a text, without necessarily having a  corpus of documents from the same individual. A key component of such an identity  profile is personality; this paper addresses distinguishing high from low neuroticism  and extraversion in authors of informal text. We consider four different sets of lexical  features for this task: a standard function word list, conjunctive phrases, modality indicators,  and appraisal adjectives and modifiers. SMO, a support vector machine learner,  was used to learn linear separators for the high and low classes in each of the two tasks.},
booktitle = {In {Proceedings} of the {Joint} {Annual} {Meeting} of the {Interface} and the {Classification} {Society} of {North} {America}},
author = {Argamon, Shlomo and Dhawle, Sushant and Koppel, Moshe and Pennebaker, James W.},
year = {2005},
keywords = {NLP},
}

@article{hartzler_leveraging_2016,
title = {Leveraging cues from person-generated health data for peer matching in online communities},
volume = {23},
issn = {1527-974X},
doi = {10.1093/jamia/ocv175},
abstract = {OBJECTIVE: Online health communities offer a diverse peer support base, yet users can struggle to identify suitable peer mentors as these communities grow. To facilitate mentoring connections, we designed a peer-matching system that automatically profiles and recommends peer mentors to mentees based on person-generated health data (PGHD). This study examined the profile characteristics that mentees value when choosing a peer mentor.
MATERIALS AND METHODS: Through a mixed-methods user study, in which cancer patients and caregivers evaluated peer mentor recommendations, we examined the relative importance of four possible profile elements: health interests, language style, demographics, and sample posts. Playing the role of mentees, the study participants ranked mentors, then rated both the likelihood that they would hypothetically contact each mentor and the helpfulness of each profile element in helping the make that decision. We analyzed the participants' ratings with linear regression and qualitatively analyzed participants' feedback for emerging themes about choosing mentors and improving profile design.
RESULTS: Of the four profile elements, only sample posts were a significant predictor for the likelihood of a mentee contacting a mentor. Communication cues embedded in posts were critical for helping the participants choose a compatible mentor. Qualitative themes offer insight into the interpersonal characteristics that mentees sought in peer mentors, including being knowledgeable, sociable, and articulate. Additionally, the participants emphasized the need for streamlined profiles that minimize the time required to choose a mentor.
CONCLUSION: Peer-matching systems in online health communities offer a promising approach for leveraging PGHD to connect patients. Our findings point to interpersonal communication cues embedded in PGHD that could prove critical for building mentoring relationships among the growing membership of online health communities.},
language = {eng},
number = {3},
journal = {Journal of the American Medical Informatics Association: JAMIA},
author = {Hartzler, Andrea L. and Taylor, Megan N. and Park, Albert and Griffiths, Troy and Backonja, Uba and McDonald, David W. and Wahbeh, Sam and Brown, Cory and Pratt, Wanda},
year = {2016},
pmid = {26911825},
pmcid = {PMC4901377},
keywords = {Adult, Female, Humans, Internet, Male, Mentoring, Mentors, Middle Aged, Peer Group, Self-Help Groups, Social Support, data display, human-computer interaction, online health communities, peer mentoring, peer support, user interfaces},
pages = {496--507},
}

@article{zhao_new_2016,
title = {A new visual navigation system for exploring biomedical {Open} {Educational} {Resource} ({OER}) videos},
volume = {23},
issn = {1527-974X},
doi = {10.1093/jamia/ocv123},
abstract = {OBJECTIVE: Biomedical videos as open educational resources (OERs) are increasingly proliferating on the Internet. Unfortunately, seeking personally valuable content from among the vast corpus of quality yet diverse OER videos is nontrivial due to limitations of today's keyword- and content-based video retrieval techniques. To address this need, this study introduces a novel visual navigation system that facilitates users' information seeking from biomedical OER videos in mass quantity by interactively offering visual and textual navigational clues that are both semantically revealing and user-friendly.
MATERIALS AND METHODS: The authors collected and processed around 25 000 YouTube videos, which collectively last for a total length of about 4000 h, in the broad field of biomedical sciences for our experiment. For each video, its semantic clues are first extracted automatically through computationally analyzing audio and visual signals, as well as text either accompanying or embedded in the video. These extracted clues are subsequently stored in a metadata database and indexed by a high-performance text search engine. During the online retrieval stage, the system renders video search results as dynamic web pages using a JavaScript library that allows users to interactively and intuitively explore video content both efficiently and effectively.ResultsThe authors produced a prototype implementation of the proposed system, which is publicly accessible athttps://patentq.njit.edu/oer To examine the overall advantage of the proposed system for exploring biomedical OER videos, the authors further conducted a user study of a modest scale. The study results encouragingly demonstrate the functional effectiveness and user-friendliness of the new system for facilitating information seeking from and content exploration among massive biomedical OER videos.
CONCLUSION: Using the proposed tool, users can efficiently and effectively find videos of interest, precisely locate video segments delivering personally valuable information, as well as intuitively and conveniently preview essential content of a single or a collection of videos.},
language = {eng},
number = {e1},
journal = {Journal of the American Medical Informatics Association: JAMIA},
author = {Zhao, Baoquan and Xu, Songhua and Lin, Shujin and Luo, Xiaonan and Duan, Lian},
month = apr,
year = {2016},
pmid = {26335986},
pmcid = {PMC4954619},
keywords = {Audiovisual Aids, Education, Medical, Humans, Information Storage and Retrieval, Internet, Video Recording, biomedical videos, information retrieval and browsing, open education resources (OERs), video search, visual navigation},
pages = {e34--41},
}

@article{lu_spell_2019,
title = {Spell checker for consumer language ({CSpell})},
volume = {26},
url = {https://academic.oup.com/jamia/article/26/3/211/5298352},
doi = {10.1093/jamia/ocy171},
abstract = {AbstractObjective.  Automated understanding of consumer health inquiries might be hindered by misspellings. To detect and correct various types of spelling erro},
language = {en},
number = {3},
urldate = {2019-05-30},
journal = {Journal of the American Medical Informatics Association},
author = {Lu, Chris J. and Aronson, Alan R. and Shooshan, Sonya E. and Demner-Fushman, Dina},
month = mar,
year = {2019},
pages = {211--218},
}

@article{nikfarjam_pharmacovigilance_2015,
title = {Pharmacovigilance from social media: mining adverse drug reaction mentions using sequence labeling with word embedding cluster features},
volume = {22},
issn = {1067-5027},
shorttitle = {Pharmacovigilance from social media},
url = {https://academic.oup.com/jamia/article/22/3/671/776531},
doi = {10.1093/jamia/ocu041},
abstract = {Abstract.  Objective Social media is becoming increasingly popular as a platform for sharing personal health-related information. This information can be utiliz},
language = {en},
number = {3},
urldate = {2019-05-30},
journal = {Journal of the American Medical Informatics Association},
author = {Nikfarjam, Azadeh and Sarker, Abeed and O’Connor, Karen and Ginn, Rachel and Gonzalez, Graciela},
month = may,
year = {2015},
pages = {671--681},
}

@article{acevedo_functional_2018,
title = {The functional highly sensitive brain: a review of the brain circuits underlying sensory processing sensitivity and seemingly related disorders},
volume = {373},
issn = {0962-8436},
shorttitle = {The functional highly sensitive brain},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5832686/},
doi = {10.1098/rstb.2017.0161},
abstract = {During the past decade, research on the biological basis of sensory processing sensitivity (SPS)—a genetically based trait associated with greater sensitivity and responsivity to environmental and social stimuli—has burgeoned. As researchers try to characterize this trait, it is still unclear how SPS is distinct from seemingly related clinical disorders that have overlapping symptoms, such as sensitivity to the environment and hyper-responsiveness to incoming stimuli. Thus, in this review, we compare the neural regions implicated in SPS with those found in fMRI studies of—Autism Spectrum Disorder (ASD), Schizophrenia (SZ) and Post-Traumatic Stress Disorder (PTSD) to elucidate the neural markers and cardinal features of SPS versus these seemingly related clinical disorders. We propose that SPS is a stable trait that is characterized by greater empathy, awareness, responsivity and depth of processing to salient stimuli. We conclude that SPS is distinct from ASD, SZ and PTSD in that in response to social and emotional stimuli, SPS differentially engages brain regions involved in reward processing, memory, physiological homeostasis, self-other processing, empathy and awareness. We suggest that this serves species survival via deep integration and memory for environmental and social information that may subserve well-being and cooperation., This article is part of the theme issue ‘Diverse perspectives on diversity: multi-disciplinary approaches to taxonomies of individual differences’.},
number = {1744},
urldate = {2019-05-24},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
author = {Acevedo, Bianca and Aron, Elaine and Pospos, Sarah and Jessen, Dana},
month = apr,
year = {2018},
pmid = {29483346},
pmcid = {PMC5832686},
}

@article{acevedo_highly_2014,
title = {The highly sensitive brain: an {fMRI} study of sensory processing sensitivity and response to others' emotions},
volume = {4},
issn = {2162-3279},
shorttitle = {The highly sensitive brain},
doi = {10.1002/brb3.242},
abstract = {BACKGROUND: Theory and research suggest that sensory processing sensitivity (SPS), found in roughly 20\% of humans and over 100 other species, is a trait associated with greater sensitivity and responsiveness to the environment and to social stimuli. Self-report studies have shown that high-SPS individuals are strongly affected by others' moods, but no previous study has examined neural systems engaged in response to others' emotions.
METHODS: This study examined the neural correlates of SPS (measured by the standard short-form Highly Sensitive Person [HSP] scale) among 18 participants (10 females) while viewing photos of their romantic partners and of strangers displaying positive, negative, or neutral facial expressions. One year apart, 13 of the 18 participants were scanned twice.
RESULTS: Across all conditions, HSP scores were associated with increased brain activation of regions involved in attention and action planning (in the cingulate and premotor area [PMA]). For happy and sad photo conditions, SPS was associated with activation of brain regions involved in awareness, integration of sensory information, empathy, and action planning (e.g., cingulate, insula, inferior frontal gyrus [IFG], middle temporal gyrus [MTG], and PMA).
CONCLUSIONS: As predicted, for partner images and for happy facial photos, HSP scores were associated with stronger activation of brain regions involved in awareness, empathy, and self-other processing. These results provide evidence that awareness and responsiveness are fundamental features of SPS, and show how the brain may mediate these traits.},
language = {eng},
number = {4},
journal = {Brain and Behavior},
author = {Acevedo, Bianca P. and Aron, Elaine N. and Aron, Arthur and Sangster, Matthew-Donald and Collins, Nancy and Brown, Lucy L.},
month = jul,
year = {2014},
pmid = {25161824},
pmcid = {PMC4086365},
keywords = {Adult, Affect, Attention, Brain, Brain Mapping, Emotion, Emotions, Empathy, Facial Expression, Female, Humans, Interpersonal Relations, Magnetic Resonance Imaging, Male, Photic Stimulation, Social Perception, Surveys and Questionnaires, empathy, highly sensitive person, magnetic resonance imaging, mirror neurons, sensory processing sensitivity},
pages = {580--594},
}

@article{aron_sensory_2012,
title = {Sensory processing sensitivity: a review in the light of the evolution of biological responsivity},
volume = {16},
issn = {1532-7957},
shorttitle = {Sensory processing sensitivity},
doi = {10.1177/1088868311434213},
abstract = {This article reviews the literature on sensory processing sensitivity (SPS) in light of growing evidence from evolutionary biology that many personality differences in nonhuman species involve being more or less responsive, reactive, flexible, or sensitive to the environment. After briefly defining SPS, it first discusses how biologists studying animal personality have conceptualized this general environmental sensitivity. Second, it reviews relevant previous human personality/temperament work, focusing on crossover interactions (where a trait generates positive or negative outcomes depending on the environment), and traits relevant to specific hypothesized aspects of SPS: inhibition of behavior, sensitivity to stimuli, depth of processing, and emotional/physiological reactivity. Third, it reviews support for the overall SPS model, focusing on development of the Highly Sensitive Person (HSP) Scale as a measure of SPS then on neuroimaging and genetic studies using the scale, all of which bears on the extent to which SPS in humans corresponds to biological responsivity.},
language = {eng},
number = {3},
journal = {Personality and Social Psychology Review: An Official Journal of the Society for Personality and Social Psychology, Inc},
author = {Aron, Elaine N. and Aron, Arthur and Jagiellowicz, Jadzia},
month = aug,
year = {2012},
pmid = {22291044},
keywords = {Animals, Biological Evolution, Emotions, Humans, Inhibition (Psychology), Nervous System Physiological Phenomena, Physical Stimulation, Sensation},
pages = {262--282},
}

@article{aron_temperament_2010,
title = {Temperament trait of sensory processing sensitivity moderates cultural differences in neural response},
volume = {5},
issn = {1749-5024},
doi = {10.1093/scan/nsq028},
abstract = {This study focused on a possible temperament-by-culture interaction. Specifically, it explored whether a basic temperament/personality trait (sensory processing sensitivity; SPS), perhaps having a genetic component, might moderate a previously established cultural difference in neural responses when making context-dependent vs context-independent judgments of simple visual stimuli. SPS has been hypothesized to underlie what has been called inhibitedness or reactivity in infants, introversion in adults, and reactivity or responsivness in diverse animal species. Some biologists view the trait as one of two innate strategies-observing carefully before acting vs being first to act. Thus the central characteristic of SPS is hypothesized to be a deep processing of information. Here, 10 European-Americans and 10 East Asians underwent functional magnetic resonance imaging while performing simple visuospatial tasks emphasizing judgments that were either context independent (typically easier for Americans) or context dependent (typically easier for Asians). As reported elsewhere, each group exhibited greater activation for the culturally non-preferred task in frontal and parietal regions associated with greater effort in attention and working memory. However, further analyses, reported here for the first time, provided preliminary support for moderation by SPS. Consistent with the careful-processing theory, high-SPS individuals showed little cultural difference; low-SPS, strong culture differences.},
language = {eng},
number = {2-3},
journal = {Social Cognitive and Affective Neuroscience},
author = {Aron, Arthur and Ketay, Sarah and Hedden, Trey and Aron, Elaine N. and Rose Markus, Hazel and Gabrieli, John D. E.},
month = jun,
year = {2010},
pmid = {20388694},
pmcid = {PMC2894664},
keywords = {Adolescent, Adult, Asian Continental Ancestry Group, Brain, Brain Mapping, Culture, Emotions, European Continental Ancestry Group, Female, Humans, Magnetic Resonance Imaging, Male, Memory, Short-Term, Nervous System Physiological Phenomena, Neuropsychological Tests, Perception, Personality, Psychomotor Performance, Sensation, Surveys and Questionnaires, Temperament, Young Adult},
pages = {219--226},
}

@article{aron_sensory-processing_1997,
title = {Sensory-processing sensitivity and its relation to introversion and emotionality},
volume = {73},
issn = {1939-1315(Electronic),0022-3514(Print)},
doi = {10.1037/0022-3514.73.2.345},
abstract = {Over a series of 7 studies that used diverse samples and measures, this research identified a unidimensional core variable of high sensory-processing sensitivity and demonstrated its partial independence from social introversion and emotionality, variables with which it had been confused or subsumed in most previous theorizing by personality researchers. Additional findings were that there appear to be 2 distinct clusters of highly sensitive individuals (a smaller group with an unhappy childhood and related variables, and a larger group similar to nonhighly sensitive individuals except for their sensitivity) and that sensitivity moderates, at least for men, the relation of parental environment to reporting having had an unhappy childhood. This research also demonstrated adequate reliability and content, convergent, and discriminant validity for a 27-item Highly Sensitive Person Scale. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
number = {2},
journal = {Journal of Personality and Social Psychology},
author = {Aron, Elaine N. and Aron, Arthur},
year = {1997},
keywords = {Emotionality (Personality), Introversion, Perception, Social Interaction, Thresholds},
pages = {345--368},
}

@article{aron_experimental_1997,
title = {The {Experimental} {Generation} of {Interpersonal} {Closeness}: {A} {Procedure} and {Some} {Preliminary} {Findings}},
volume = {23},
issn = {0146-1672},
shorttitle = {The {Experimental} {Generation} of {Interpersonal} {Closeness}},
url = {https://doi.org/10.1177/0146167297234003},
doi = {10.1177/0146167297234003},
abstract = {A practical methodology is presented for creating closeness in an experimental context. Whether or not an individual is in a relationship, particular pairings of individuals in the relationship, and circumstances of relationship development become manipulated variables. Over a 45-min period subject pairs carry out self-disclosure and relationship-building tasks that gradually escalate in intensity. Study 1 found greater postinteraction closeness with these tasks versus comparable small-talk tasks. Studies 2 and 3 found no significant closeness effects, inspite of adequate power, for (a) whether pairs were matched for nondisagreement on important attitudes, (b) whether pairs were led to expect mutual liking, or (c) whether getting close was made an explicit goal. These studies also illustrated applications for addressing theoretical issues, yielding provocative tentative findings relating to attachment style and introversion/extraversion.},
language = {en},
number = {4},
urldate = {2019-05-24},
journal = {Personality and Social Psychology Bulletin},
author = {Aron, Arthur and Melinat, Edward and Aron, Elaine N. and Vallone, Robert Darrin and Bator, Renee J.},
month = apr,
year = {1997},
pages = {363--377},
}

@inproceedings{choi_multi-layer_2016,
address = {New York, NY, USA},
series = {{KDD} '16},
title = {Multi-layer {Representation} {Learning} for {Medical} {Concepts}},
isbn = {978-1-4503-4232-2},
url = {http://doi.acm.org/10.1145/2939672.2939823},
doi = {10.1145/2939672.2939823},
abstract = {Proper representations of medical concepts such as diagnosis, medication, procedure codes and visits from Electronic Health Records (EHR) has broad applications in healthcare analytics. Patient EHR data consists of a sequence of visits over time, where each visit includes multiple medical concepts, e.g., diagnosis, procedure, and medication codes. This hierarchical structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within a visit. In this work, we propose Med2Vec, which not only learns the representations for both medical codes and visits from large EHR datasets with over million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts. In the experiments, Med2Vec shows significant improvement in prediction accuracy in clinical applications compared to baselines such as Skip-gram, GloVe, and stacked autoencoder, while providing clinically meaningful interpretation.},
urldate = {2019-01-09},
booktitle = {Proceedings of the {22Nd} {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
publisher = {ACM},
author = {Choi, Edward and Bahadori, Mohammad Taha and Searles, Elizabeth and Coffey, Catherine and Thompson, Michael and Bost, James and Tejedor-Sojo, Javier and Sun, Jimeng},
year = {2016},
keywords = {healthcare analytics, medical concepts, neural networks, representation learning, research ideas},
pages = {1495--1504},
}

@article{needham_graph_nodate,
title = {Graph {Algorithms}},
language = {en},
author = {Needham, Mark and Hodler, Amy E},
pages = {257},
}

@inproceedings{choi_gram:_2017,
address = {New York, NY, USA},
series = {{KDD} '17},
title = {{GRAM}: {Graph}-based {Attention} {Model} for {Healthcare} {Representation} {Learning}},
isbn = {978-1-4503-4887-4},
shorttitle = {{GRAM}},
url = {http://doi.acm.org/10.1145/3097983.3098126},
doi = {10.1145/3097983.3098126},
abstract = {Deep learning methods exhibit promising performance for predictive modeling in healthcare, but two important challenges remain: - Data insufficiency: Often in healthcare predictive modeling, the sample size is insufficient for deep learning methods to achieve satisfactory results. Interpretation: The representations learned by deep learning methods should align with medical knowledge. To address these challenges, we propose GRaph-based Attention Model (GRAM) that supplements electronic health records (EHR) with hierarchical information inherent to medical ontologies. Based on the data volume and the ontology structure, GRAM represents a medical concept as a combination of its ancestors in the ontology via an attention mechanism. We compared predictive performance (i.e. accuracy, data needs, interpretability) of GRAM to various methods including the recurrent neural network (RNN) in two sequential diagnoses prediction tasks and one heart failure prediction task. Compared to the basic RNN, GRAM achieved 10\% higher accuracy for predicting diseases rarely observed in the training data and 3\% improved area under the ROC curve for predicting heart failure using an order of magnitude less training data. Additionally, unlike other methods, the medical concept representations learned by GRAM are well aligned with the medical ontology. Finally, GRAM exhibits intuitive attention behaviors by adaptively generalizing to higher level concepts when facing data insufficiency at the lower level concepts.},
urldate = {2019-04-18},
booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
publisher = {ACM},
author = {Choi, Edward and Bahadori, Mohammad Taha and Song, Le and Stewart, Walter F. and Sun, Jimeng},
year = {2017},
note = {event-place: Halifax, NS, Canada},
keywords = {attention model, electronic health records, graph, predictive healthcare, read here},
pages = {787--795},
}

@article{grover_node2vec:_2016,
title = {node2vec: {Scalable} {Feature} {Learning} for {Networks}},
shorttitle = {node2vec},
url = {http://arxiv.org/abs/1607.00653},
abstract = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.},
urldate = {2019-04-14},
journal = {arXiv:1607.00653 [cs, stat]},
author = {Grover, Aditya and Leskovec, Jure},
month = jul,
year = {2016},
note = {arXiv: 1607.00653},
keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning, read here},
}

@article{turner_word2vec_2017,
title = {{Word2Vec} inversion and traditional text classifiers for phenotyping lupus},
volume = {17},
issn = {1472-6947},
doi = {10.1186/s12911-017-0518-1},
abstract = {BACKGROUND: Identifying patients with certain clinical criteria based on manual chart review of doctors' notes is a daunting task given the massive amounts of text notes in the electronic health records (EHR). This task can be automated using text classifiers based on Natural Language Processing (NLP) techniques along with pattern recognition machine learning (ML) algorithms. The aim of this research is to evaluate the performance of traditional classifiers for identifying patients with Systemic Lupus Erythematosus (SLE) in comparison with a newer Bayesian word vector method.
METHODS: We obtained clinical notes for patients with SLE diagnosis along with controls from the Rheumatology Clinic (662 total patients). Sparse bag-of-words (BOWs) and Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs) matrices were produced using NLP pipelines. These matrices were subjected to several different NLP classifiers: neural networks, random forests, naïve Bayes, support vector machines, and Word2Vec inversion, a Bayesian inversion method. Performance was measured by calculating accuracy and area under the Receiver Operating Characteristic (ROC) curve (AUC) of a cross-validated (CV) set and a separate testing set.
RESULTS: We calculated the accuracy of the ICD-9 billing codes as a baseline to be 90.00\% with an AUC of 0.900, the shallow neural network with CUIs to be 92.10\% with an AUC of 0.970, the random forest with BOWs to be 95.25\% with an AUC of 0.994, the random forest with CUIs to be 95.00\% with an AUC of 0.979, and the Word2Vec inversion to be 90.03\% with an AUC of 0.905.
CONCLUSIONS: Our results suggest that a shallow neural network with CUIs and random forests with both CUIs and BOWs are the best classifiers for this lupus phenotyping task. The Word2Vec inversion method failed to significantly beat the ICD-9 code classification, but yielded promising results. This method does not require explicit features and is more adaptable to non-binary classification tasks. The Word2Vec inversion is hypothesized to become more powerful with access to more data. Therefore, currently, the shallow neural networks and random forests are the desirable classifiers.},
language = {eng},
number = {1},
journal = {BMC medical informatics and decision making},
author = {Turner, Clayton A. and Jacobs, Alexander D. and Marques, Cassios K. and Oates, James C. and Kamen, Diane L. and Anderson, Paul E. and Obeid, Jihad S.},
month = aug,
year = {2017},
pmid = {28830409},
pmcid = {PMC5568290},
keywords = {Algorithms, Artificial Intelligence, Bayes Theorem, Datasets as Topic, Electronic Health Records, Humans, International Classification of Diseases, Lupus Erythematosus, Systemic, Machine Learning, Machine learning, Natural Language Processing, Natural language processing, Neural Networks (Computer), Systemic lupus erythematosus, Unified Medical Language System},
pages = {126},
}

@article{gehrmann_comparing_2017,
title = {Comparing {Rule}-{Based} and {Deep} {Learning} {Models} for {Patient} {Phenotyping}},
url = {http://arxiv.org/abs/1703.08705},
abstract = {Objective: We investigate whether deep learning techniques for natural language processing (NLP) can be used efficiently for patient phenotyping. Patient phenotyping is a classification task for determining whether a patient has a medical condition, and is a crucial part of secondary analysis of healthcare data. We assess the performance of deep learning algorithms and compare them with classical NLP approaches. Materials and Methods: We compare convolutional neural networks (CNNs), n-gram models, and approaches based on cTAKES that extract pre-defined medical concepts from clinical notes and use them to predict patient phenotypes. The performance is tested on 10 different phenotyping tasks using 1,610 discharge summaries extracted from the MIMIC-III database. Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The average F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our model having an F1-score up to 37 points higher than alternative approaches. We additionally assess the interpretability of our model by presenting a method that extracts the most salient phrases for a particular prediction. Conclusion: We show that NLP methods based on deep learning improve the performance of patient phenotyping. Our CNN-based algorithm automatically learns the phrases associated with each patient phenotype. As such, it reduces the annotation complexity for clinical domain experts, who are normally required to develop task-specific annotation rules and identify relevant phrases. Our method performs well in terms of both performance and interpretability, which indicates that deep learning is an effective approach to patient phenotyping based on clinicians' notes.},
urldate = {2019-04-11},
journal = {arXiv:1703.08705 [cs, stat]},
author = {Gehrmann, Sebastian and Dernoncourt, Franck and Li, Yeran and Carlson, Eric T. and Wu, Joy T. and Welt, Jonathan and Foote Jr., John and Moseley, Edward T. and Grant, David W. and Tyler, Patrick D. and Celi, Leo Anthony},
month = mar,
year = {2017},
note = {arXiv: 1703.08705},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{miotto_deep_2016,
title = {Deep {Patient}: {An} {Unsupervised} {Representation} to {Predict} the {Future} of {Patients} from the {Electronic} {Health} {Records}},
volume = {6},
copyright = {2016 Nature Publishing Group},
issn = {2045-2322},
shorttitle = {Deep {Patient}},
url = {https://www.nature.com/articles/srep26094},
doi = {10.1038/srep26094},
abstract = {Secondary use of electronic health records (EHRs) promises to advance clinical research and better inform clinical decision making. Challenges in summarizing and representing patient data prevent widespread practice of predictive modeling using EHRs. Here we present a novel unsupervised deep feature learning method to derive a general-purpose patient representation from EHR data that facilitates clinical predictive modeling. In particular, a three-layer stack of denoising autoencoders was used to capture hierarchical regularities and dependencies in the aggregated EHRs of about 700,000 patients from the Mount Sinai data warehouse. The result is a representation we name “deep patient”. We evaluated this representation as broadly predictive of health states by assessing the probability of patients to develop various diseases. We performed evaluation using 76,214 test patients comprising 78 diseases from diverse clinical domains and temporal windows. Our results significantly outperformed those achieved using representations based on raw EHR data and alternative feature learning strategies. Prediction performance for severe diabetes, schizophrenia, and various cancers were among the top performing. These findings indicate that deep learning applied to EHRs can derive patient representations that offer improved clinical predictions, and could provide a machine learning framework for augmenting clinical decision systems.},
language = {en},
urldate = {2019-04-11},
journal = {Scientific Reports},
author = {Miotto, Riccardo and Li, Li and Kidd, Brian A. and Dudley, Joel T.},
month = may,
year = {2016},
keywords = {research ideas},
pages = {26094},
}

@article{yin_systematic_2019,
title = {A systematic literature review of machine learning in online personal health data},
issn = {1527-974X},
doi = {10.1093/jamia/ocz009},
abstract = {OBJECTIVE: User-generated content (UGC) in online environments provides opportunities to learn an individual's health status outside of clinical settings. However, the nature of UGC brings challenges in both data collecting and processing. The purpose of this study is to systematically review the effectiveness of applying machine learning (ML) methodologies to UGC for personal health investigations.
MATERIALS AND METHODS: We searched PubMed, Web of Science, IEEE Library, ACM library, AAAI library, and the ACL anthology. We focused on research articles that were published in English and in peer-reviewed journals or conference proceedings between 2010 and 2018. Publications that applied ML to UGC with a focus on personal health were identified for further systematic review.
RESULTS: We identified 103 eligible studies which we summarized with respect to 5 research categories, 3 data collection strategies, 3 gold standard dataset creation methods, and 4 types of features applied in ML models. Popular off-the-shelf ML models were logistic regression (n = 22), support vector machines (n = 18), naive Bayes (n = 17), ensemble learning (n = 12), and deep learning (n = 11). The most investigated problems were mental health (n = 39) and cancer (n = 15). Common health-related aspects extracted from UGC were treatment experience, sentiments and emotions, coping strategies, and social support.
CONCLUSIONS: The systematic review indicated that ML can be effectively applied to UGC in facilitating the description and inference of personal health. Future research needs to focus on mitigating bias introduced when building study cohorts, creating features from free text, improving clinical creditability of UGC, and model interpretability.},
language = {eng},
journal = {Journal of the American Medical Informatics Association: JAMIA},
author = {Yin, Zhijun and Sulieman, Lina M. and Malin, Bradley A.},
month = mar,
year = {2019},
pmid = {30908576},
keywords = {machine learning, online environment, online health community, patient portal, personal health, read here, research ideas, social media, systematic review},
}

@article{yang_heterogeneous_2018,
title = {Heterogeneous network embedding for identifying symptom candidate genes},
volume = {25},
issn = {1527-974X},
doi = {10.1093/jamia/ocy117},
abstract = {Objective: Investigating the molecular mechanisms of symptoms is a vital task in precision medicine to refine disease taxonomy and improve the personalized management of chronic diseases. Although there are abundant experimental studies and computational efforts to obtain the candidate genes of diseases, the identification of symptom genes is rarely addressed. We curated a high-quality benchmark dataset of symptom-gene associations and proposed a heterogeneous network embedding for identifying symptom genes.
Methods: We proposed a heterogeneous network embedding representation algorithm, which constructed a heterogeneous symptom-related network that integrated symptom-related associations and applied an embedding representation algorithm to obtain the low-dimensional vector representation of nodes. By measuring the relevance between symptoms and genes via calculating the similarities of their vectors, the candidate genes of given symptoms can be obtained.
Results: A benchmark dataset of 18 270 symptom-gene associations between 505 symptoms and 4549 genes was curated. We compared our method to baseline algorithms (FSGER and PRINCE). The experimental results indicated our algorithm achieved a significant improvement over the state-of-the-art method, with precision and recall improved by 66.80\% (0.844 vs 0.506) and 53.96\% (0.311 vs 0.202), respectively, for TOP@3 and association precision improved by 37.71\% (0.723 vs 0.525) over the PRINCE.
Conclusions: The experimental validation of the algorithms and the literature validation of typical symptoms indicated our method achieved excellent performance. Hence, we curated a prediction dataset of 17 479 symptom-candidate genes. The benchmark and prediction datasets have the potential to promote investigations of the molecular mechanisms of symptoms and provide candidate genes for validation in experimental settings.},
language = {eng},
number = {11},
journal = {Journal of the American Medical Informatics Association: JAMIA},
author = {Yang, Kuo and Wang, Ning and Liu, Guangming and Wang, Ruyu and Yu, Jian and Zhang, Runshun and Chen, Jianxin and Zhou, Xuezhong},
month = nov,
year = {2018},
pmid = {30357378},
keywords = {read here},
pages = {1452--1459},
}

@article{lasko_computational_2013,
title = {Computational {Phenotype} {Discovery} {Using} {Unsupervised} {Feature} {Learning} over {Noisy}, {Sparse}, and {Irregular} {Clinical} {Data}},
volume = {8},
issn = {1932-6203},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0066341},
doi = {10.1371/journal.pone.0066341},
abstract = {Inferring precise phenotypic patterns from population-scale clinical data is a core computational task in the development of precision, personalized medicine. The traditional approach uses supervised learning, in which an expert designates which patterns to look for (by specifying the learning task and the class labels), and where to look for them (by specifying the input variables). While appropriate for individual tasks, this approach scales poorly and misses the patterns that we don’t think to look for. Unsupervised feature learning overcomes these limitations by identifying patterns (or features) that collectively form a compact and expressive representation of the source data, with no need for expert input or labeled examples. Its rising popularity is driven by new deep learning methods, which have produced high-profile successes on difficult standardized problems of object recognition in images. Here we introduce its use for phenotype discovery in clinical data. This use is challenging because the largest source of clinical data – Electronic Medical Records – typically contains noisy, sparse, and irregularly timed observations, rendering them poor substrates for deep learning methods. Our approach couples dirty clinical data to deep learning architecture via longitudinal probability densities inferred using Gaussian process regression. From episodic, longitudinal sequences of serum uric acid measurements in 4368 individuals we produced continuous phenotypic features that suggest multiple population subtypes, and that accurately distinguished (0.97 AUC) the uric-acid signatures of gout vs. acute leukemia despite not being optimized for the task. The unsupervised features were as accurate as gold-standard features engineered by an expert with complete knowledge of the domain, the classification task, and the class labels. Our findings demonstrate the potential for achieving computational phenotype discovery at population scale. We expect such data-driven phenotypes to expose unknown disease variants and subtypes and to provide rich targets for genetic association studies.},
language = {en},
number = {6},
urldate = {2019-01-13},
journal = {PLOS ONE},
author = {Lasko, Thomas A. and Denny, Joshua C. and Levy, Mia A.},
month = jun,
year = {2013},
keywords = {Cancer treatment, Covariance, Engineers, Gout, Learning, Leukemias, Probability density, Uric acid},
pages = {e66341},
}

@article{xiao_opportunities_2018,
title = {Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review},
volume = {25},
issn = {1527-974X},
shorttitle = {Opportunities and challenges in developing deep learning models using electronic health records data},
doi = {10.1093/jamia/ocy068},
abstract = {Objective: To conduct a systematic review of deep learning models for electronic health record (EHR) data, and illustrate various deep learning architectures for analyzing different data sources and their target applications. We also highlight ongoing research and identify open challenges in building deep learning models of EHRs.
Design/method: We searched PubMed and Google Scholar for papers on deep learning studies using EHR data published between January 1, 2010, and January 31, 2018. We summarize them according to these axes: types of analytics tasks, types of deep learning model architectures, special challenges arising from health data and tasks and their potential solutions, as well as evaluation strategies.
Results: We surveyed and analyzed multiple aspects of the 98 articles we found and identified the following analytics tasks: disease detection/classification, sequential prediction of clinical events, concept embedding, data augmentation, and EHR data privacy. We then studied how deep architectures were applied to these tasks. We also discussed some special challenges arising from modeling EHR data and reviewed a few popular approaches. Finally, we summarized how performance evaluations were conducted for each task.
Discussion: Despite the early success in using deep learning for health analytics applications, there still exist a number of issues to be addressed. We discuss them in detail including data and label availability, the interpretability and transparency of the model, and ease of deployment.},
language = {eng},
number = {10},
journal = {Journal of the American Medical Informatics Association: JAMIA},
author = {Xiao, Cao and Choi, Edward and Sun, Jimeng},
month = oct,
year = {2018},
pmid = {29893864},
pmcid = {PMC6188527},
keywords = {read here},
pages = {1419--1428},
}

@phdthesis{chen_neural_2018,
title = {Neural reading comprehension and beyond},
url = {https://searchworks.stanford.edu/view/12857441},
abstract = {Teaching machines to understand human language documents is one of the most elusive and long-standing challenges in Artificial Intelligence. This thesis tackles the problem of reading comprehension: how to build computer systems to read a passage of text and answer comprehension questions. On the one hand, we think that reading comprehension is an important task for evaluating how well computer systems understand human language. On the other hand, if we can build high-performing reading comprehension systems, they would be a crucial technology for applications such as question answering and dialogue systems. In this thesis, we focus on neural reading comprehension: a class of reading comprehension models built on top of deep neural networks. Compared to traditional sparse, hand-designed feature-based models, these end-to-end neural models have proven to be more effective in learning rich linguistic phenomena and improved performance on all the modern reading comprehension benchmarks by a large margin. This thesis consists of two parts. In the first part, we aim to cover the essence of neural reading comprehension and present our efforts at building effective neural reading comprehension models, and more importantly, understanding what neural reading comprehension models have actually learned, and what depth of language understanding is needed to solve current tasks. We also summarize recent advances and discuss future directions and open questions in this field. In the second part of this thesis, we investigate how we can build practical applications based on the recent success of neural reading comprehension. In particular, we pioneered two new research directions: 1) how we can combine information retrieval techniques with neural reading comprehension to tackle large-scale open-domain question answering; and 2) how we can build conversational question answering systems from current single-turn, span-based reading comprehension models. We implemented these ideas in the DrQA and CoQA projects and we demonstrate the effectiveness of these approaches. We believe that they hold great promise for future language technologies.},
language = {English},
school = {Stanford University},
author = {Chen, Danqi},
year = {2018},
}

@inproceedings{grbovic_real-time_2018,
address = {New York, NY, USA},
series = {{KDD} '18},
title = {Real-time {Personalization} {Using} {Embeddings} for {Search} {Ranking} at {Airbnb}},
isbn = {978-1-4503-5552-0},
url = {http://doi.acm.org/10.1145/3219819.3219885},
doi = {10.1145/3219819.3219885},
abstract = {Search Ranking and Recommendations are fundamental problems of crucial interest to major Internet companies, including web search engines, content publishing websites and marketplaces. However, despite sharing some common characteristics a one-size-fits-all solution does not exist in this space. Given a large difference in content that needs to be ranked, personalized and recommended, each marketplace has a somewhat unique challenge. Correspondingly, at Airbnb, a short-term rental marketplace, search and recommendation problems are quite unique, being a two-sided marketplace in which one needs to optimize for host and guest preferences, in a world where a user rarely consumes the same item twice and one listing can accept only one guest for a certain set of dates. In this paper we describe Listing and User Embedding techniques we developed and deployed for purposes of Real-time Personalization in Search Ranking and Similar Listing Recommendations, two channels that drive 99\% of conversions. The embedding models were specifically tailored for Airbnb marketplace, and are able to capture guest's short-term and long-term interests, delivering effective home listing recommendations. We conducted rigorous offline testing of the embedding models, followed by successful online tests before fully deploying them into production.},
urldate = {2019-02-28},
booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
publisher = {ACM},
author = {Grbovic, Mihajlo and Cheng, Haibin},
year = {2018},
note = {event-place: London, United Kingdom},
keywords = {personalization, search ranking, user modeling},
pages = {311--320},
}

@article{hochreiter_long_1997,
title = {Long {Short}-{Term} {Memory}},
volume = {9},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
number = {8},
urldate = {2019-01-28},
journal = {Neural Computation},
author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
month = nov,
year = {1997},
pages = {1735--1780},
}

@article{choi_learning_2016,
title = {Learning {Low}-{Dimensional} {Representations} of {Medical} {Concepts}},
volume = {2016},
issn = {2153-4063},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001761/},
abstract = {We show how to learn low-dimensional representations (embeddings) of a wide range of concepts in medicine, including diseases (e.g., ICD9 codes), medications, procedures, and laboratory tests. We expect that these embeddings will be useful across medical informatics for tasks such as cohort selection and patient summarization. These embeddings are learned using a technique called neural language modeling from the natural language processing community. However, rather than learning the embeddings solely from text, we show how to learn the embeddings from claims data, which is widely available both to providers and to payers. We also show that with a simple algorithmic adjustment, it is possible to learn medical concept embeddings in a privacy preserving manner from co-occurrence counts derived from clinical narratives. Finally, we establish a methodological framework, arising from standard medical ontologies such as UMLS, NDF-RT, and CCS, to further investigate the embeddings and precisely characterize their quantitative properties.},
urldate = {2019-01-09},
journal = {AMIA Summits on Translational Science Proceedings},
author = {Choi, Youngduck and Chiu, Chill Yi-I and Sontag, David},
month = jul,
year = {2016},
pmid = {27570647},
pmcid = {PMC5001761},
pages = {41--50},
}

@article{che_distilling_2015,
title = {Distilling {Knowledge} from {Deep} {Networks} with {Applications} to {Healthcare} {Domain}},
url = {http://arxiv.org/abs/1512.03542},
abstract = {Exponential growth in Electronic Healthcare Records (EHR) has resulted in new opportunities and urgent needs for discovery of meaningful data-driven representations and patterns of diseases in Computational Phenotyping research. Deep Learning models have shown superior performance for robust prediction in computational phenotyping tasks, but suffer from the issue of model interpretability which is crucial for clinicians involved in decision-making. In this paper, we introduce a novel knowledge-distillation approach called Interpretable Mimic Learning, to learn interpretable phenotype features for making robust prediction while mimicking the performance of deep learning models. Our framework uses Gradient Boosting Trees to learn interpretable features from deep learning models such as Stacked Denoising Autoencoder and Long Short-Term Memory. Exhaustive experiments on a real-world clinical time-series dataset show that our method obtains similar or better performance than the deep learning models, and it provides interpretable phenotypes for clinical decision making.},
urldate = {2019-01-09},
journal = {arXiv:1512.03542 [cs, stat]},
author = {Che, Zhengping and Purushotham, Sanjay and Khemani, Robinder and Liu, Yan},
month = dec,
year = {2015},
note = {arXiv: 1512.03542},
keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{mikolov_efficient_2013,
title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
url = {https://arxiv.org/abs/1301.3781},
language = {en},
urldate = {2018-12-18},
author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
month = jan,
year = {2013},
keywords = {research ideas},
}

@article{lipton_learning_2015,
title = {Learning to {Diagnose} with {LSTM} {Recurrent} {Neural} {Networks}},
url = {http://arxiv.org/abs/1511.03677},
abstract = {Clinical medical data, especially in the intensive care unit (ICU), consist of multivariate time series of observations. For each patient visit (or episode), sensor data and lab test results are recorded in the patient's Electronic Health Record (EHR). While potentially containing a wealth of insights, the data is difficult to mine effectively, owing to varying length, irregular sampling and missing data. Recurrent Neural Networks (RNNs), particularly those using Long Short-Term Memory (LSTM) hidden units, are powerful and increasingly popular models for learning from sequence data. They effectively model varying length sequences and capture long range dependencies. We present the first study to empirically evaluate the ability of LSTMs to recognize patterns in multivariate time series of clinical measurements. Specifically, we consider multilabel classification of diagnoses, training a model to classify 128 diagnoses given 13 frequently but irregularly sampled clinical measurements. First, we establish the effectiveness of a simple LSTM network for modeling clinical data. Then we demonstrate a straightforward and effective training strategy in which we replicate targets at each sequence step. Trained only on raw time series, our models outperform several strong baselines, including a multilayer perceptron trained on hand-engineered features.},
urldate = {2019-01-09},
journal = {arXiv:1511.03677 [cs]},
author = {Lipton, Zachary C. and Kale, David C. and Elkan, Charles and Wetzel, Randall},
month = nov,
year = {2015},
note = {arXiv: 1511.03677},
keywords = {Computer Science - Machine Learning},
}

@article{choi_medical_2016,
title = {Medical {Concept} {Representation} {Learning} from {Electronic} {Health} {Records} and its {Application} on {Heart} {Failure} {Prediction}},
url = {http://arxiv.org/abs/1602.03686},
abstract = {Objective: To transform heterogeneous clinical data from electronic health records into clinically meaningful constructed features using data driven method that rely, in part, on temporal relations among data. Materials and Methods: The clinically meaningful representations of medical concepts and patients are the key for health analytic applications. Most of existing approaches directly construct features mapped to raw data (e.g., ICD or CPT codes), or utilize some ontology mapping such as SNOMED codes. However, none of the existing approaches leverage EHR data directly for learning such concept representation. We propose a new way to represent heterogeneous medical concepts (e.g., diagnoses, medications and procedures) based on co-occurrence patterns in longitudinal electronic health records. The intuition behind the method is to map medical concepts that are co-occuring closely in time to similar concept vectors so that their distance will be small. We also derive a simple method to construct patient vectors from the related medical concept vectors. Results: For qualitative evaluation, we study similar medical concepts across diagnosis, medication and procedure. In quantitative evaluation, our proposed representation significantly improves the predictive modeling performance for onset of heart failure (HF), where classification methods (e.g. logistic regression, neural network, support vector machine and K-nearest neighbors) achieve up to 23\% improvement in area under the ROC curve (AUC) using this proposed representation. Conclusion: We proposed an effective method for patient and medical concept representation learning. The resulting representation can map relevant concepts together and also improves predictive modeling performance.},
urldate = {2019-01-09},
journal = {arXiv:1602.03686 [cs]},
author = {Choi, Edward and Schuetz, Andy and Stewart, Walter F. and Sun, Jimeng},
month = feb,
year = {2016},
note = {arXiv: 1602.03686},
keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{choi_doctor_2015,
title = {Doctor {AI}: {Predicting} {Clinical} {Events} via {Recurrent} {Neural} {Networks}},
shorttitle = {Doctor {AI}},
url = {http://arxiv.org/abs/1511.05942},
abstract = {Leveraging large historical data in electronic health record (EHR), we developed Doctor AI, a generic predictive model that covers observed medical conditions and medication uses. Doctor AI is a temporal model using recurrent neural networks (RNN) and was developed and applied to longitudinal time stamped EHR data from 260K patients over 8 years. Encounter records (e.g. diagnosis codes, medication codes or procedure codes) were input to RNN to predict (all) the diagnosis and medication categories for a subsequent visit. Doctor AI assesses the history of patients to make multilabel predictions (one label for each diagnosis or medication category). Based on separate blind test set evaluation, Doctor AI can perform differential diagnosis with up to 79\% recall@30, significantly higher than several baselines. Moreover, we demonstrate great generalizability of Doctor AI by adapting the resulting models from one institution to another without losing substantial accuracy.},
urldate = {2019-01-09},
journal = {arXiv:1511.05942 [cs]},
author = {Choi, Edward and Bahadori, Mohammad Taha and Schuetz, Andy and Stewart, Walter F. and Sun, Jimeng},
month = nov,
year = {2015},
note = {arXiv: 1511.05942},
keywords = {Computer Science - Machine Learning},
}

@misc{karam_using_2017,
title = {Using {Word2vec} for {Music} {Recommendations}},
url = {https://towardsdatascience.com/using-word2vec-for-music-recommendations-bb9649ac2484},
abstract = {How we use neural networks to transform billions of streams into better recommendations.},
urldate = {2018-12-21},
journal = {Towards Data Science},
author = {Karam, Ramzi},
month = dec,
year = {2017},
}

@misc{sun_return_2015,
title = {Return of {Frustratingly} {Easy} {Domain} {Adaptation}},
url = {https://arxiv.org/abs/1511.05547},
language = {en},
urldate = {2018-12-18},
author = {Sun, Baochen and Feng, Jiashi and Saenko, Kate},
month = nov,
year = {2015},
}

@article{mikolov_distributed_2013,
title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
url = {https://arxiv.org/abs/1310.4546},
language = {en},
urldate = {2018-12-18},
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
month = oct,
year = {2013},
}

@article{grbovic_scalable_2016,
title = {Scalable {Semantic} {Matching} of {Queries} to {Ads} in {Sponsored} {Search} {Advertising}},
url = {http://arxiv.org/abs/1607.01869},
doi = {10.1145/2911451.2911538.},
abstract = {Sponsored search represents a major source of revenue for web search engines. This popular advertising model brings a unique possibility for advertisers to target users' immediate intent communicated through a search query, usually by displaying their ads alongside organic search results for queries deemed relevant to their products or services. However, due to a large number of unique queries it is challenging for advertisers to identify all such relevant queries. For this reason search engines often provide a service of advanced matching, which automatically finds additional relevant queries for advertisers to bid on. We present a novel advanced matching approach based on the idea of semantic embeddings of queries and ads. The embeddings were learned using a large data set of user search sessions, consisting of search queries, clicked ads and search links, while utilizing contextual information such as dwell time and skipped ads. To address the large-scale nature of our problem, both in terms of data and vocabulary size, we propose a novel distributed algorithm for training of the embeddings. Finally, we present an approach for overcoming a cold-start problem associated with new ads and queries. We report results of editorial evaluation and online tests on actual search traffic. The results show that our approach significantly outperforms baselines in terms of relevance, coverage, and incremental revenue. Lastly, we open-source learned query embeddings to be used by researchers in computational advertising and related fields.},
urldate = {2018-12-21},
journal = {Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval - SIGIR '16},
author = {Grbovic, Mihajlo and Djuric, Nemanja and Radosavljevic, Vladan and Silvestri, Fabrizio and Baeza-Yates, Ricardo and Feng, Andrew and Ordentlich, Erik and Yang, Lee and Owens, Gavin},
year = {2016},
note = {arXiv: 1607.01869},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
pages = {375--384},
}

@article{grbovic_e-commerce_2015,
title = {E-commerce in {Your} {Inbox}: {Product} {Recommendations} at {Scale}},
shorttitle = {E-commerce in {Your} {Inbox}},
url = {http://arxiv.org/abs/1606.07154},
doi = {10.1145/2783258.2788627.},
abstract = {In recent years online advertising has become increasingly ubiquitous and effective. Advertisements shown to visitors fund sites and apps that publish digital content, manage social networks, and operate e-mail services. Given such large variety of internet resources, determining an appropriate type of advertising for a given platform has become critical to financial success. Native advertisements, namely ads that are similar in look and feel to content, have had great success in news and social feeds. However, to date there has not been a winning formula for ads in e-mail clients. In this paper we describe a system that leverages user purchase history determined from e-mail receipts to deliver highly personalized product ads to Yahoo Mail users. We propose to use a novel neural language-based algorithm specifically tailored for delivering effective product recommendations, which was evaluated against baselines that included showing popular products and products predicted based on co-occurrence. We conducted rigorous offline testing using a large-scale product purchase data set, covering purchases of more than 29 million users from 172 e-commerce websites. Ads in the form of product recommendations were successfully tested on online traffic, where we observed a steady 9\% lift in click-through rates over other ad formats in mail, as well as comparable lift in conversion rates. Following successful tests, the system was launched into production during the holiday season of 2014.},
urldate = {2018-12-21},
journal = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '15},
author = {Grbovic, Mihajlo and Radosavljevic, Vladan and Djuric, Nemanja and Bhamidipati, Narayan and Savla, Jaikit and Bhagwan, Varun and Sharp, Doug},
year = {2015},
note = {arXiv: 1606.07154},
keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Social and Information Networks, H.2.8},
pages = {1809--1818},
}

@misc{grbovic_listing_2018,
title = {Listing {Embeddings} in {Search} {Ranking}},
url = {https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e},
abstract = {Listing Embeddings for Similar Listing Recommendations and Real-time Personalization in Search Ranking},
urldate = {2018-12-21},
journal = {Airbnb Engineering \& Data Science},
author = {Grbovic, Mihajlo},
month = mar,
year = {2018},
}

@misc{noauthor_applying_nodate,
title = {Applying word2vec to {Recommenders} and {Advertising} · {Chris} {McCormick}},
url = {http://mccormickml.com/2018/06/15/applying-word2vec-to-recommenders-and-advertising/},
urldate = {2018-12-21},
keywords = {research ideas},
}

@article{pineda_deep_2018,
title = {Deep learning facilitates rapid cohort identification using human and veterinary clinical narratives},
copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
url = {https://www.biorxiv.org/content/early/2018/10/04/429720},
doi = {10.1101/429720},
abstract = {Background: In public health research, there is currently a need to close the gap between care delivery and cohort identification. We need dedicated tagging staff to allocate a considerable amount of effort to assigning clinical codes after reading patient summaries. Machine learning automation can facilitate the classification of these clinical narratives, but sufficient availability of electronic medical records is still a bottleneck. Veterinary medical records represent a largely untapped data source that could be used to benefit both human and non-human patients. Very few approaches utilizing veterinary data sources currently exist. Methods: In this retrospective cross-sectional and chart review study, we trained separate long short-term memory (LSTM) Recurrent Neural Networks (RNNs) on 52,722 human records and 89,591 veterinary records, tested the models' efficacy in a standard train-test split setup, and probed the portability of these models across species domains. We trained versions of our models using first the free-text clinical narratives, and then only using extracted clinically relevant terms from MetaMap Lite, a natural language processing tool intended for this purpose. Findings: We show that our LSTM approach correctly classifies across top-level codes in the veterinary records (F1 score =0.83), and identifies top-level neoplasia records in veterinary records (F1 score = 0.93). The model trained with veterinary data can be ported over to identify neoplasia records in the human records (F1 score = 0.70). Interpretation: Our findings suggest that free-text clinical narratives can be used to learn classification models that allow the rapid identification of patient cohorts. Ultimately, this effort can lead to new insights that can address emerging public health concerns. Digitization of health information will continue to be a reality in both human and veterinary data; our approach serves as first proof-of-concept regarding how these two domains can learn from, and inform, one another.},
language = {en},
urldate = {2018-10-13},
journal = {bioRxiv},
author = {Pineda, Arturo Lopez and Walk, Oliver J. Bear Don't and Venkataraman, Guhan R. and Zehnder, Ashley M. and Ayyar, Sandeep and Page, Rodney L. and Bustamante, Carlos D. and Rivas, Manuel A.},
month = oct,
year = {2018},
keywords = {research ideas},
pages = {429720},
}

@inproceedings{gu_optimizing_2018,
address = {San Francisco, CA, USA},
title = {Optimizing {Corpus} {Creation} for {Training} {Word} {Embedding} in {Low} {Resource} {Domains}: {A} {Case} {Study} in {Autism} {Spectrum} {Disorder} ({ASD})},
url = {https://symposium2018.zerista.com/event/member/508386},
abstract = {Automating the extraction of behavioral criteria indicative of Autism Spectrum Disorder (ASD) in electronic health records (EHRs) can contribute significantly to the effort to monitor the condition. Word embedding algorithms such as Word2Vec can encode semantic meanings of words in vectors and assist in automated vocabulary discovery from EHRs. However, text available for training word embeddings for ASD is miniscule compared to the billions of tokens typically used. We evaluate the importance of corpus specificity versus size and hypothesize that for specific domains small corpora can generate excellent word embeddings. We custom-built 6 ASD-themed corpora (N=4482), using ASD EHRs and abstracts from PubMed (N=39K) and PsychInfo (N=69K) and evaluated them. We were able to generate the most useful 200-dimension embeddings based on the small ASD EHR data. Due to diversity in its vocabulary, the abstract-based embeddings generated fewer related terms and saw minimal improvement when the size of the corpus increased significantly.

Learning Objective 1: Create an appropriate corpus for training word embeddings in the medical domain with small amount of data, by considering the relationship between vocabulary diversity and corpus size.

Learning Objective 2: Understand the practical trade-offs between using pre-trained general domain word embeddings or domain-specfic embedding trained on a small corpus.},
urldate = {2018-12-08},
booktitle = {Phenotype and {Event} {Prediction}},
author = {Gu, Yang},
month = nov,
year = {2018},
}

@book{pearlson_managing_2015,
edition = {6 edition},
title = {Managing and {Using} {Information} {Systems}: {A} {Strategic} {Approach}, 6th {Edition}},
shorttitle = {Managing and {Using} {Information} {Systems}},
abstract = {Managing and Using Information Systems: A Strategic Approach, Sixth Edition, conveys the insights and knowledge MBA students need to become knowledgeable and active participants in information systems decisions. This text is written to help managers begin to form and point of view of how information systems will help, hinder and create opportunities for their organizations. It is intended to provide a solid foundation of basic concepts relevant to using and managing information.},
language = {English},
publisher = {Wiley},
author = {Pearlson, Keri E. and Saunders, Carol S. and Galletta, Dennis F.},
month = dec,
year = {2015},
}

@phdthesis{zhang_natural_2018,
address = {Tucson, AZ},
title = {{NATURAL} {LANGUAGE} {PROCESSING} {AND} {MACHINE} {LEARNING} {FOR} {CHRONIC} {DISEASE} {MANAGEMENT} {AND} {PREVENTION}: {FOCUS} {ON} {ASTHMA}},
shorttitle = {{CHRONIC} {DISEASE} {MANAGEMENT} {AND} {PREVENTION}: {FOCUS} {ON} {ASTHMA}},
language = {en},
school = {University of Arizona},
author = {Zhang, Wenli},
month = jul,
year = {2018},
}

@article{liu_go_2018,
title = {Go to {YouTube} and {See} {Me} {Tomorrow}: {The} {Role} of {Social} {Media} in {Managing} {Chronic} {Conditions}},
shorttitle = {Go to {YouTube} and {See} {Me} {Tomorrow}},
url = {https://papers.ssrn.com/abstract=3061149},
abstract = {Video sharing social media sites, such as YouTube, that host videos providing information on the pathogenesis, diagnosis, treatments, and prevention of various conditions can be an effective way to understand medical knowledge and in managing chronic conditions through patient self-care. However, due to the heterogeneity of the content quality and content helpfulness on visual social media, healthcare providers and government agencies have expressed concerns about the quality and reliability of such information. There have been relatively few studies that have identified interventions to increase the ease with which patients can find helpful health information. We propose an interdisciplinary lens that synthesizes deep learning methods with themes emphasized in Information Systems (IS) research and research on healthcare informatics. Using a bidirectional long short-term memory (BLSTM) method, we extract medical terminology from videos. We annotate videos using inputs from domain experts and build a logistic regression based classifier to categorize videos based on whether they encode a high degree of medical knowledge or not. We identify distinct types of user engagement with videos on YouTube using a principal components analysis (PCA) approach: user dissonance, popularity based engagement, and relevance based engagement. We find that medical knowledge encoded in videos matters to patient engagement; however, popularity-based indicators of engagement indicate that videos that score high on medical knowledge encoded in videos, are actually less popular than those that are not. We conduct robustness checks using a convolutional neural network (CNN) to detect the presence of medical objects in a video. We find that medical terminology embedded in textual data is more salient to an assessment of medical knowledge encoded in a video, rather than image analytics. Our results suggest that healthcare practitioners and policymakers need a nuanced understanding of how users engage with medical knowledge in video format, which has implications for the role of videos and visual social media in bridging the health literacy gap and in enabling self-care of chronic conditions.},
language = {en},
urldate = {2018-11-25},
author = {Liu, Xiao and Zhang, Bin and Susarla, Anjana and Padman, Rema},
month = may,
year = {2018},
keywords = {Bidirectional Long Short-term Memory (BLSTM), Convolutional Neural Network (CNN), chronic diseases, deep learning, healthcare informatics, patient self-care, visual social media},
}

@article{xie_mining_2018,
title = {Mining e-cigarette adverse events in social media using {Bi}-{LSTM} recurrent neural network with word embedding representation},
volume = {25},
issn = {1067-5027},
url = {https://academic.oup.com/jamia/article/25/1/72/3826532},
doi = {10.1093/jamia/ocx045},
abstract = {AbstractObjective.  Recent years have seen increased worldwide popularity of e-cigarette use. However, the risks of e-cigarettes are underexamined. Most e-cigar},
language = {en},
number = {1},
urldate = {2018-11-16},
journal = {Journal of the American Medical Informatics Association},
author = {Xie, Jiaheng and Liu, Xiao and Dajun Zeng, Daniel},
month = jan,
year = {2018},
pages = {72--80},
}

@article{baldwin_how_2013,
title = {How {Noisy} {Social} {Media} {Text}, {How} {Diffrnt} {Social} {Media} {Sources}?},
abstract = {While various claims have been made about text in social media text being noisy, but there has never been a systematic study to investigate just how linguistically noisy or otherwise it is over a range of social media sources. We explore this question empirically over popular social media text types, in the form of YouTube comments, Twitter posts, web user forum posts, blog posts and Wikipedia, which we compare to a reference corpus of edited English text. We first extract out various descriptive statistics from each data type (incl. the distribution of languages, average sentence length and proportion of outof-vocabulary words), and then investigate the proportion of grammatical sentences in each, based on a linguistically-motivated parser. We also investigate the relative similarity between different data types.},
author = {Baldwin, Timothy and Cook, Paul and Lui, Marco and Mackinlay, Andrew and Wang, Li},
year = {2013},
}

@article{weston_multi-class_1998,
title = {Multi-class support vector machines},
volume = {Technical Report CSD-TR-98-04},
author = {Weston, Jason and Chris, Watkins},
month = may,
year = {1998},
}

@book{james_introduction_2013,
address = {New York},
series = {Springer texts in statistics},
title = {An introduction to statistical learning: with applications in {R}},
isbn = {978-1-4614-7137-0},
shorttitle = {An introduction to statistical learning},
language = {en},
number = {103},
publisher = {Springer},
editor = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
year = {2013},
note = {OCLC: ocn828488009},
keywords = {Mathematical models, Mathematical statistics, Problems, exercises, etc, R (Computer program language), Statistics},
}

@book{han_data_2011,
title = {Data {Mining}: {Concepts} and {Techniques}},
isbn = {978-0-12-381480-7},
shorttitle = {Data {Mining}},
abstract = {Data Mining: Concepts and Techniques provides the concepts and techniques in processing gathered data or information, which will be used in various applications. Specifically, it explains data mining and the tools used in discovering knowledge from the collected data. This book is referred as the knowledge discovery from data (KDD). It focuses on the feasibility, usefulness, effectiveness, and scalability of techniques of large data sets. After describing data mining, this edition explains the methods of knowing, preprocessing, processing, and warehousing data. It then presents information about data warehouses, online analytical processing (OLAP), and data cube technology. Then, the methods involved in mining frequent patterns, associations, and correlations for large data sets are described. The book details the methods for data classification and introduces the concepts and methods for data clustering. The remaining chapters discuss the outlier detection and the trends, applications, and research frontiers in data mining. This book is intended for Computer Science students, application developers, business professionals, and researchers who seek information on data mining. Presents dozens of algorithms and implementation examples, all in pseudo-code and suitable for use in real-world, large-scale data mining projectsAddresses advanced topics such as mining object-relational databases, spatial databases, multimedia databases, time-series databases, text databases, the World Wide Web, and applications in several fieldsProvides a comprehensive, practical look at the concepts and techniques you need to get the most out of your data},
language = {en},
publisher = {Elsevier},
author = {Han, Jiawei and Pei, Jian and Kamber, Micheline},
month = jun,
year = {2011},
note = {Google-Books-ID: pQws07tdpjoC},
keywords = {Computers / Databases / Data Mining, Computers / Databases / General, Computers / Intelligence (AI) \& Semantics},
}

@book{bird_natural_2009,
title = {Natural {Language} {Processing} with {Python}: {Analyzing} {Text} with the {Natural} {Language} {Toolkit}},
isbn = {978-0-596-55571-9},
shorttitle = {Natural {Language} {Processing} with {Python}},
abstract = {This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication.Packed with examples and exercises, Natural Language Processing with Python will help you:Extract information from unstructured text, either to guess the topic or identify "named entities"Analyze linguistic structure in text, including parsing and semantic analysisAccess popular linguistic databases, including WordNet and treebanksIntegrate techniques drawn from fields as diverse as linguistics and artificial intelligenceThis book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages -- or if you're simply curious to have a programmer's perspective on how human language works -- you'll find Natural Language Processing with Python both fascinating and immensely useful.},
language = {en},
publisher = {"O'Reilly Media, Inc."},
author = {Bird, Steven and Klein, Ewan and Loper, Edward},
month = jun,
year = {2009},
note = {Google-Books-ID: KGIbfiiP1i4C},
keywords = {Computers / General, Computers / Programming Languages / General, Computers / Programming Languages / JavaScript, Computers / Programming Languages / Python, Computers / Software Development \& Engineering / General},
}

@book{manning_introduction_2008,
title = {Introduction to {Information} {Retrieval}},
isbn = {978-1-139-47210-4},
abstract = {Class-tested and coherent, this textbook teaches classical and web information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. It gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Slides and additional exercises (with solutions for lecturers) are also available through the book's supporting website to help course instructors prepare their lectures.},
language = {en},
publisher = {Cambridge University Press},
author = {Manning, Christopher D. and Raghavan, Prabhakar and Schütze, Hinrich},
month = jul,
year = {2008},
note = {Google-Books-ID: t1PoSh4uwVcC},
keywords = {Computers / Databases / General, Computers / System Administration / Storage \& Retrieval},
}

@book{jurafsky_speech_2014,
title = {Speech and {Language} {Processing}},
isbn = {978-0-13-325293-4},
abstract = {This is the eBook of the printed book and may not include any media, website access codes, or print supplements that may come packaged with the bound book.  For undergraduate or advanced undergraduate courses in Classical Natural Language Processing, Statistical Natural Language Processing, Speech Recognition, Computational Linguistics, and Human Language Processing.    An explosion of Web-based language techniques, merging of distinct fields, availability of phone-based dialogue systems, and much more make this an exciting time in speech and language processing. The first of its kind to thoroughly cover language technology – at all levels and with all modern technologies – this text takes an empirical approach to the subject, based on applying statistical and other machine-learning algorithms to large corporations. The authors cover areas that traditionally are taught in different courses, to describe a unified vision of speech and language processing. Emphasis is on practical applications and scientific evaluation. An accompanying Website contains teaching materials for instructors, with pointers to language processing resources on the Web. The Second Edition offers a significant amount of new and extended material.   Supplements:   Click on the "Resources" tab to View Downloadable Files:   Solutions   Power Point Lecture Slides - Chapters 1-5, 8-10, 12-13 and 24 Now Available!   For additional resourcse visit the author website: http://www.cs.colorado.edu/{\textasciitilde}martin/slp.html},
language = {en},
publisher = {Pearson Education},
author = {Jurafsky, Daniel and Martin, James H.},
month = dec,
year = {2014},
note = {Google-Books-ID: Cq2gBwAAQBAJ},
keywords = {Computers / Computer Vision \& Pattern Recognition},
}

@book{manning_foundations_nodate,
title = {Foundations of {Statistical} {Natural} {Language} {Processing}},
language = {en},
author = {Manning, Christopher D and Schiitze, Hinrich},
}

@book{kutner_applied_2005,
address = {Boston},
edition = {5th ed},
series = {The {McGraw}-{Hill}/{Irwin} series operations and decision sciences},
title = {Applied linear statistical models},
isbn = {978-0-07-238688-2},
language = {en},
publisher = {McGraw-Hill Irwin},
editor = {Kutner, Michael H.},
year = {2005},
keywords = {Analysis of variance, Experimental design, Linear models (Statistics), Regression analysis, Textbooks},
}

@book{tibshirani_elements_nodate,
title = {The {Elements} of {Statistical} {Learning}},
language = {en},
author = {Tibshirani, Sami and Friedman, Harry},
}

@article{xu_exploration_2016,
title = {Exploration of early-life candidate biomarkers for childhood asthma using antibody arrays},
volume = {27},
issn = {1399-3038},
doi = {10.1111/pai.12613},
abstract = {BACKGROUND: Proteomic approaches identifying biomarkers have been applied to asthma to only a very limited extent.
METHODS: With an antibody array (RayBiotech, Norcross, GA, USA), the relative intensity and rank differences of 444 proteins were compared in 24 plasma samples obtained at age 3, 11 from children with and 12 without asthma diagnoses at ages 5 and 9. Protein candidates identified by antibody array were quantitated by ELISA in an enlarged sample. Proteins found to differentiate children with and without asthma were also examined for association with known Year 1 asthma risk factors, eczema, and wheeze.
RESULTS: In the antibody array, four proteins had rank differences between asthma and non-asthma groups (FDR {\textless}0.1). By ELISA, mean log (±s.e.m.) erythropoietin (EPO) level (IU/l) was lower (0.750 ± 0.048 vs. 0.898 ± 0.035; p = 0.006) and mean (±s.e.m.) soluble GP130 (sGP130) level (ng/ml) was higher in the asthma vs. the non-asthma group (302 ± 13 vs. 270 ± 8; p = 0.041). The other 2 array proteins (galactin-3 and eotaxin-3) did not differ by ELISA by asthma. EPO related to the asthma risk factor, first year eczema, whereas sGP130 related to first year wheeze.
CONCLUSIONS: Through two independent assessments, age 3 plasma levels of EPO and sGP130 were found related to childhood asthma.},
language = {eng},
number = {7},
journal = {Pediatric Allergy and Immunology: Official Publication of the European Society of Pediatric Allergy and Immunology},
author = {Xu, Haili and Radabaugh, Timothy and Lu, Zhenqiang and Galligan, Michael and Billheimer, Dean and Vercelli, Donata and Wright, Anne L. and Monks, Terrence J. and Halonen, Marilyn and Lau, Serrine S.},
month = nov,
year = {2016},
pmid = {27434124},
pmcid = {PMC5526199},
keywords = {Antibodies, Asthma, Biomarkers, Child, Child, Preschool, Cohort Studies, Cytokine Receptor gp130, Erythropoietin, Female, Follow-Up Studies, Humans, Male, Protein Array Analysis, Respiratory Sounds, Risk Factors, biomarker, eczema, plasma, proteomics, soluble GP130},
pages = {696--701},
}

@article{toskala_asthma_2015,
title = {Asthma risk factors},
volume = {5},
issn = {2042-6984},
url = {http://onlinelibrary.wiley.com/doi/10.1002/alr.21557/abstract},
doi = {10.1002/alr.21557},
abstract = {Background

Bronchial asthma is one of the most common chronic diseases in childhood, with a current prevalence of 6\% to 9\%, but a prevalence that is increasing at an alarming rate. Asthma is a complex genetic disorder with strong environmental influence. It imposes a growing burden on our society in terms of morbidity, quality of life, and healthcare costs. Despite large-scale efforts, only a few asthma genes have been confirmed, suggesting that the genetic underpinning of asthma is highly complex.


Methods

A review of the literature was performed regarding atopic and nonatopic asthma risk factors, including environmental risk factors and genetic studies in adults and children.


Results

Several environmental risk factors have been identified to increase the risk of developing asthma such as exposure to air pollution and tobaccos smoke as well as occupational risk factors. In addition atopy, stress, and obesity all can increases the risk for asthma in genetically susceptible persons.


Conclusion

Asthma represents a dysfunctional interaction with our genes and the environment to which they are exposed, especially in fetal and early infant life. The increasing prevalence of asthma in all age groups indicate that our living environment and immunity are in imbalance with each other reacting with airway inflammation to the environmental exposures and often non-harmful proteins, such as allergens causing the current “asthma and allergy epidemic.” Because of the close relationship between asthma and chronic rhinosinusitis, it is important that otolaryngologists have a good understanding of asthma, the etiologic factors associated with disease, and its evaluation and management.},
language = {en},
number = {S1},
journal = {International Forum of Allergy \& Rhinology},
author = {Toskala, Elina and Kennedy, David W.},
month = sep,
year = {2015},
keywords = {Air pollution, Allergens, Asthma, Environment, Genetic Predisposition to Disease, Humans, Risk Factors, atopy, environmental risk factors, epigenetics, genetic risk factors, hygiene hypothesis, microbes},
pages = {S11--S16},
}

@article{subbarao_epidemiology_2009,
title = {Epidemiology of asthma: risk factors for development},
volume = {5},
issn = {1744-666X},
shorttitle = {Epidemiology of asthma},
url = {https://doi.org/10.1586/1744666X.5.1.77},
doi = {10.1586/1744666X.5.1.77},
abstract = {This comprehensive review of the recent literature was undertaken to determine the current state of knowledge of the risk factors involved in the development of asthma in order to focus investigations in a proposed new longitudinal birth cohort study. The origins of asthma appear to lie in the prenatal and early postnatal period, and renewed investigations in this period with long-term close follow-up and objective phenotypic characterization will help to unravel the role of the multiple putative environmental factors in the development of asthma. It is only after understanding these effects that one can hope to design rational prevention studies for asthma.},
number = {1},
journal = {Expert Review of Clinical Immunology},
author = {Subbarao, Padmaja and Becker, Allan and Brook, Jeffrey R. and Daley, Denise and Mandhane, Piush J. and Miller, Gregory E. and Turvey, Stuart E. and Sears, Malcolm R.},
month = jan,
year = {2009},
keywords = {Asthma, Child, Environment, Epidemiology, Phenotype, allergy, cohort study, genetics, lung function, risk factor},
pages = {77--95},
}

@article{howell_nonadherence_2008,
title = {Nonadherence to medical therapy in asthma: risk factors, barriers, and strategies for improving.},
volume = {45},
issn = {0277-0903},
shorttitle = {Nonadherence to medical therapy in asthma},
url = {http://europepmc.org/abstract/med/18972285},
doi = {10.1080/02770900802395512},
abstract = {Abstract: Asthma is a very prevalent disease in the United States, and the incidence is rising for a variety of reasons. Although progress has been made on...},
language = {eng},
number = {9},
urldate = {2018-01-23},
journal = {The Journal of asthma : official journal of the Association for the Care of Asthma},
author = {Howell, G.},
month = nov,
year = {2008},
pmid = {18972285},
keywords = {Age Factors, Anti-Asthmatic Agents, Asthma, Communication, Drug Utilization, Humans, Patient Compliance, Patient Education as Topic, Patient Satisfaction, Reminder Systems, Risk Factors, Severity of Illness Index, Sex Factors, Socioeconomic Factors, United States},
pages = {723--729},
}

@article{guibas_contributing_2015,
title = {Contributing factors to the development of childhood asthma: working toward risk minimization},
volume = {11},
issn = {1744-666X},
shorttitle = {Contributing factors to the development of childhood asthma},
url = {https://doi.org/10.1586/1744666X.2015.1035649},
doi = {10.1586/1744666X.2015.1035649},
abstract = {Asthma is the most common chronic disease in childhood, and considerable research has been undertaken to find ways to prevent its development and reduce its prevalence. For such interventions to be successful, risk factors for asthma emergence should be identified and clearly defined. Data are robust for some of them, including atopy, viral infections and exposure to airborne irritants, whereas it is less conclusive for others, such as aeroallergen exposure and bacterial infections. Several interventions for asthma prevention, including avoidance and pharmacotherapy, have been attempted. However, most of them have furnished equivocal results. Various issues hinder the establishment of risk factors for asthma development and reduce the effectiveness of interventions, including the complexity of the disease and the fluidity of the developing systems in childhood. In this review, we revisit the evidence on pediatric asthma risk factors and prevention and discuss issues that perplex this field.},
number = {6},
journal = {Expert Review of Clinical Immunology},
author = {Guibas, George V. and Megremis, Spyridon and West, Peter and Papadopoulos, Nikolaos G.},
month = jun,
year = {2015},
keywords = {Allergens, Animals, Asthma, Child, Drug Therapy, Environmental Exposure, Evidence-Based Medicine, Humans, Infection, Risk Factors, avoidance, interventions, pharmacotherapy, prevention},
pages = {721--735},
}

@article{gergen_inner_2015,
title = {Inner {City} {Asthma}},
volume = {35},
issn = {0889-8561},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4254510/},
doi = {10.1016/j.iac.2014.09.006},
abstract = {The inner city has long been recognized as an area of high asthma morbidity and mortality. A wide range of factors interact to create this environment. These factors include well-recognized asthma risk factors that are not specific to the inner city, the structure and delivery of health care, the location and function of the urban environment, and social inequities. This article will review these facets and discuss successful and unsuccessful interventions in order to understand what is needed to solve this problem.},
number = {1},
journal = {Immunology and allergy clinics of North America},
author = {Gergen, Peter J. and Togias, Alkis},
month = feb,
year = {2015},
pmid = {25459579},
pmcid = {PMC4254510},
keywords = {Asthma, Disparities, Environmental Exposure, Healthcare Disparities, Humans, Inner city, Intervention, Nitrogen Dioxide, Obesity, Poverty, Poverty Areas, Quality of Health Care, Risk Factors, Severity, Smoke, Social Class},
pages = {101--114},
}

@article{chebrolu_feature_2005,
title = {Feature deduction and ensemble design of intrusion detection systems},
volume = {24},
issn = {0167-4048},
url = {http://www.sciencedirect.com/science/article/pii/S016740480400238X},
doi = {10.1016/j.cose.2004.09.008},
abstract = {Current intrusion detection systems (IDS) examine all data features to detect intrusion or misuse patterns. Some of the features may be redundant or contribute little (if anything) to the detection process. The purpose of this study is to identify important input features in building an IDS that is computationally efficient and effective. We investigated the performance of two feature selection algorithms involving Bayesian networks (BN) and Classification and Regression Trees (CART) and an ensemble of BN and CART. Empirical results indicate that significant input feature selection is important to design an IDS that is lightweight, efficient and effective for real world detection systems. Finally, we propose an hybrid architecture for combining different feature selection algorithms for real world intrusion detection.},
number = {4},
urldate = {2018-10-29},
journal = {Computers \& Security},
author = {Chebrolu, Srilatha and Abraham, Ajith and Thomas, Johnson P.},
month = jun,
year = {2005},
keywords = {Bayesian network, Decision trees, Ensemble design, Feature reduction, Hybrid intelligent system, Intrusion detection, Markov blanket},
pages = {295--307},
}

@inproceedings{lewenberg_using_2015,
title = {Using emotions to predict user interest areas in online social networks},
doi = {10.1109/DSAA.2015.7344887},
abstract = {We examine the relation between the emotions users express on social networks and their perceived areas of interests, based on a sample of Twitter users. Our methodology relies on training machine learning models to classify the emotions expressed in tweets, according to Ekman's six high-level emotions. We then used raters, sourced from Amazon's Mechanical Turk, to examine several Twitter profiles and to determine whether the profile owner is interested in various areas, including sports, movies, technology and computing, politics, news, economics, science, arts, health and religion. We find that the propensity of a user to express various emotions correlates with their perceived degree of interest in various areas. We present several models that use the emotional distribution of a Twitter user, as reflected by their tweets, to predict whether they are interested or disinterested in a topic or to determine their degree of interest in a topic.},
booktitle = {2015 {IEEE} {International} {Conference} on {Data} {Science} and {Advanced} {Analytics} ({DSAA})},
author = {Lewenberg, Y. and Bachrach, Y. and Volkova, S.},
month = oct,
year = {2015},
keywords = {Advertising, Amazon Mechanical Turk, Ekman six high-level emotions, Electronic mail, Media, Predictive models, Tagging, Twitter, Twitter profiles, Twitter users, arts, computing, economics, emotion recognition, emotional distribution, emotions classification, health, learning (artificial intelligence), movies, news, online social networks, pattern classification, politics, psychology, raters, religion, science, social aspects of automation, social networking (online), sports, technology, training machine learning models, tweets, user degree-of-interest, user expression, user interest areas prediction},
pages = {1--10},
}

@book{wood_generalized_2006,
title = {Generalized {Additive} {Models} : {An} {Introduction} with {R}},
isbn = {978-1-4200-1040-4},
shorttitle = {Generalized {Additive} {Models}},
url = {https://www.taylorfrancis.com/books/9781420010404},
abstract = {Now in widespread use, generalized additive models (GAMs) have evolved into a standard statistical methodology of considerable flexibility. While Hastie and},
language = {en},
urldate = {2018-07-17},
publisher = {Chapman and Hall/CRC},
author = {Wood, Simon N.},
month = feb,
year = {2006},
doi = {10.1201/9781420010404},
}

@book{frank_regression_2015,
address = {New York},
edition = {2nd ed. 2015 edition},
title = {Regression {Modeling} {Strategies}: {With} {Applications} to {Linear} {Models}, {Logistic} and {Ordinal} {Regression}, and {Survival} {Analysis}},
isbn = {978-3-319-19424-0},
shorttitle = {Regression {Modeling} {Strategies}},
abstract = {This highly anticipated second edition features new chapters and sections, 225 new references, and comprehensive R software. In keeping with the previous edition, this book is about the art and science of data analysis and predictive modelling, which entails choosing and using multiple tools. Instead of presenting isolated techniques, this text emphasises problem solving strategies that address the many issues arising when developing multi-variable models using real data and not standard textbook examples. Regression Modelling Strategies presents full-scale case studies of non-trivial data-sets instead of over-simplified illustrations of each method. These case studies use freely available R functions that make the multiple imputation, model building, validation and interpretation tasks described in the book relatively easy to do. Most of the methods in this text apply to all regression models, but special emphasis is given to multiple regression using generalised least squares for longitudinal data, the binary logistic model, models for ordinal responses, parametric survival regression models and the Cox semi parametric survival model. A new emphasis is given to the robust analysis of continuous dependent variables using ordinal regression.As in the first edition, this text is intended for Masters' or PhD. level graduate students who have had a general introductory probability and statistics course and who are well versed in ordinary multiple regression and intermediate algebra. The book will also serve as a reference for data analysts and statistical methodologists, as it contains an up-to-date survey and bibliography of modern statistical modelling techniques.},
language = {English},
publisher = {Springer},
author = {Frank, E. and Harrell, Jr.},
month = aug,
year = {2015},
}

@article{marra_practical_2011,
title = {Practical variable selection for generalized additive models},
volume = {55},
issn = {0167-9473},
url = {http://www.sciencedirect.com/science/article/pii/S0167947311000491},
doi = {10.1016/j.csda.2011.02.004},
abstract = {The problem of variable selection within the class of generalized additive models, when there are many covariates to choose from but the number of predictors is still somewhat smaller than the number of observations, is considered. Two very simple but effective shrinkage methods and an extension of the nonnegative garrote estimator are introduced. The proposals avoid having to use nonparametric testing methods for which there is no general reliable distributional theory. Moreover, component selection is carried out in one single step as opposed to many selection procedures which involve an exhaustive search of all possible models. The empirical performance of the proposed methods is compared to that of some available techniques via an extensive simulation study. The results show under which conditions one method can be preferred over another, hence providing applied researchers with some practical guidelines. The procedures are also illustrated analysing data on plasma beta-carotene levels from a cross-sectional study conducted in the United States.},
number = {7},
urldate = {2018-07-17},
journal = {Computational Statistics \& Data Analysis},
author = {Marra, Giampiero and Wood, Simon N.},
month = jul,
year = {2011},
keywords = {Generalized additive model, Nonnegative garrote estimator, Penalized thin plate regression spline, Practical variable selection, Shrinkage smoother},
pages = {2372--2387},
}

@article{mallows_comments_1973,
title = {Some {Comments} on {CP}},
volume = {15},
issn = {0040-1706},
url = {http://www.jstor.org/stable/1267380},
doi = {10.2307/1267380},
abstract = {We discuss the interpretation of CP-plots and show how they can be calibrated in several ways. We comment on the practice of using the display as a basis for formal selection of a subset-regression model, and extend the range of application of the device to encompass arbitrary linear estimates of the regression coefficients, for example Ridge estimates.},
number = {4},
urldate = {2018-07-16},
journal = {Technometrics},
author = {Mallows, C. L.},
year = {1973},
pages = {661--675},
}

@inproceedings{ng_feature_2004,
address = {New York, NY, USA},
series = {{ICML} '04},
title = {Feature {Selection}, {L1} vs. {L2} {Regularization}, and {Rotational} {Invariance}},
isbn = {978-1-58113-838-2},
url = {http://doi.acm.org/10.1145/1015330.1015435},
doi = {10.1145/1015330.1015435},
abstract = {We consider supervised learning in the presence of very many irrelevant features, and study two different regularization methods for preventing overfitting. Focusing on logistic regression, we show that using L1 regularization of the parameters, the sample complexity (i.e., the number of training examples required to learn "well,") grows only logarithmically in the number of irrelevant features. This logarithmic rate matches the best known bounds for feature selection, and indicates that L1 regularized logistic regression can be effective even if there are exponentially many irrelevant features as there are training examples. We also give a lower-bound showing that any rotationally invariant algorithm---including logistic regression with L2 regularization, SVMs, and neural networks trained by backpropagation---has a worst case sample complexity that grows at least linearly in the number of irrelevant features.},
urldate = {2018-07-16},
booktitle = {Proceedings of the {Twenty}-first {International} {Conference} on {Machine} {Learning}},
publisher = {ACM},
author = {Ng, Andrew Y.},
year = {2004},
pages = {78--},
}

@article{bursac_purposeful_2008,
title = {Purposeful selection of variables in logistic regression},
volume = {3},
issn = {1751-0473},
url = {https://doi.org/10.1186/1751-0473-3-17},
doi = {10.1186/1751-0473-3-17},
abstract = {The main problem in many model-building situations is to choose from a large set of covariates those that should be included in the "best" model. A decision to keep a variable in the model might be based on the clinical or statistical significance. There are several variable selection algorithms in existence. Those methods are mechanical and as such carry some limitations. Hosmer and Lemeshow describe a purposeful selection of covariates within which an analyst makes a variable selection decision at each step of the modeling process.},
urldate = {2018-07-15},
journal = {Source Code for Biology and Medicine},
author = {Bursac, Zoran and Gauss, C. Heath and Williams, David Keith and Hosmer, David W.},
month = dec,
year = {2008},
keywords = {Recursive Feature Elimination, Risk Factor Modeling, Significant Covariates, Variable Selection Method, Variable Selection Procedure},
pages = {17},
}

@book{draper_applied_2014,
title = {Applied {Regression} {Analysis}},
isbn = {978-1-118-62568-2},
abstract = {An outstanding introduction to the fundamentals of regression analysis-updated and expanded The methods of regression analysis are the most widely used statistical tools for discovering the relationships among variables. This classic text, with its emphasis on clear, thorough presentation of concepts and applications, offers a complete, easily accessible introduction to the fundamentals of regression analysis. Assuming only a basic knowledge of elementary statistics, Applied Regression Analysis, Third Edition focuses on the fitting and checking of both linear and nonlinear regression models, using small and large data sets, with pocket calculators or computers. This Third Edition features separate chapters on multicollinearity, generalized linear models, mixture ingredients, geometry of regression, robust regression, and resampling procedures. Extensive support materials include sets of carefully designed exercises with full or partial solutions and a series of true/false questions with answers. All data sets used in both the text and the exercises can be found on the companion disk at the back of the book. For analysts, researchers, and students in university, industrial, and government courses on regression, this text is an excellent introduction to the subject and an efficient means of learning how to use a valuable analytical tool. It will also prove an invaluable reference resource for applied scientists and statisticians.},
language = {en},
publisher = {John Wiley \& Sons},
author = {Draper, Norman R. and Smith, Harry},
month = aug,
year = {2014},
note = {Google-Books-ID: uSReBAAAQBAJ},
keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
}

@article{genuer_variable_2010,
title = {Variable selection using random forests},
volume = {31},
issn = {0167-8655},
url = {http://www.sciencedirect.com/science/article/pii/S0167865510000954},
doi = {10.1016/j.patrec.2010.03.014},
abstract = {This paper proposes, focusing on random forests, the increasingly used statistical method for classification and regression problems introduced by Leo Breiman in 2001, to investigate two classical issues of variable selection. The first one is to find important variables for interpretation and the second one is more restrictive and try to design a good parsimonious prediction model. The main contribution is twofold: to provide some experimental insights about the behavior of the variable importance index based on random forests and to propose a strategy involving a ranking of explanatory variables using the random forests score of importance and a stepwise ascending variable introduction strategy.},
number = {14},
urldate = {2018-07-15},
journal = {Pattern Recognition Letters},
author = {Genuer, Robin and Poggi, Jean-Michel and Tuleau-Malot, Christine},
month = oct,
year = {2010},
keywords = {Classification, High dimensional data, Random forests, Regression, Variable importance, Variable selection},
pages = {2225--2236},
}

@article{gromping_variable_2009,
title = {Variable {Importance} {Assessment} in {Regression}: {Linear} {Regression} versus {Random} {Forest}},
volume = {63},
issn = {0003-1305},
shorttitle = {Variable {Importance} {Assessment} in {Regression}},
url = {https://doi.org/10.1198/tast.2009.08199},
doi = {10.1198/tast.2009.08199},
abstract = {Relative importance of regressor variables is an old topic that still awaits a satisfactory solution. When interest is in attributing importance in linear regression, averaging over orderings methods for decomposing R2 are among the state-of-the-art methods, although the mechanism behind their behavior is not (yet) completely understood. Random forests—a machine-learning tool for classification and regression proposed a few years ago—have an inherent procedure of producing variable importances. This article compares the two approaches (linear model on the one hand and two versions of random forests on the other hand) and finds both striking similarities and differences, some of which can be explained whereas others remain a challenge. The investigation improves understanding of the nature of variable importance in random forests. This article has supplementary material online.},
number = {4},
urldate = {2018-07-15},
journal = {The American Statistician},
author = {Grömping, Ulrike},
month = nov,
year = {2009},
keywords = {Linear model, Random forest, Variable importance},
pages = {308--319},
}

@inproceedings{roder_exploring_2015,
address = {New York, NY, USA},
series = {{WSDM} '15},
title = {Exploring the {Space} of {Topic} {Coherence} {Measures}},
isbn = {978-1-4503-3317-7},
url = {http://doi.acm.org/10.1145/2684822.2685324},
doi = {10.1145/2684822.2685324},
abstract = {Quantifying the coherence of a set of statements is a long standing problem with many potential applications that has attracted researchers from different sciences. The special case of measuring coherence of topics has been recently studied to remedy the problem that topic models give no guaranty on the interpretablity of their output. Several benchmark datasets were produced that record human judgements of the interpretability of topics. We are the first to propose a framework that allows to construct existing word based coherence measures as well as new ones by combining elementary components. We conduct a systematic search of the space of coherence measures using all publicly available topic relevance data for the evaluation. Our results show that new combinations of components outperform existing measures with respect to correlation to human ratings. nFinally, we outline how our results can be transferred to further applications in the context of text mining, information retrieval and the world wide web.},
urldate = {2018-07-13},
booktitle = {Proceedings of the {Eighth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
publisher = {ACM},
author = {Röder, Michael and Both, Andreas and Hinneburg, Alexander},
year = {2015},
keywords = {topic coherence, topic evaluation, topic model},
pages = {399--408},
}

@article{ketchen_application_1998,
title = {{THE} {APPLICATION} {OF} {CLUSTER} {ANALYSIS} {IN} {STRATEGIC} {MANAGEMENT} {RESEARCH}: {AN} {ANALYSIS} {AND} {CRITIQUE}},
volume = {17},
issn = {1097-0266},
shorttitle = {{THE} {APPLICATION} {OF} {CLUSTER} {ANALYSIS} {IN} {STRATEGIC} {MANAGEMENT} {RESEARCH}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0266%28199606%2917%3A6%3C441%3A%3AAID-SMJ819%3E3.0.CO%3B2-G},
doi = {10.1002/(SICI)1097-0266(199606)17:6<441::AID-SMJ819>3.0.CO;2-G},
language = {en},
number = {6},
urldate = {2018-07-13},
journal = {Strategic Management Journal},
author = {Ketchen, David J. and Shook, Christopher L.},
month = dec,
year = {1998},
keywords = {elbow method},
pages = {441--458},
}

@book{sparck_jones_readings_1997,
address = {San Francisco, CA, USA},
title = {Readings in {Information} {Retrieval}},
isbn = {978-1-55860-454-4},
publisher = {Morgan Kaufmann Publishers Inc.},
editor = {Sparck Jones, Karen and Willett, Peter},
year = {1997},
}

@techreport{epa_aqi_2014,
title = {{AQI} {Air} {Quality} {Index}: a guide to air quality and your health},
url = {https://www3.epa.gov/airnow/aqi_brochure_02_14.pdf},
collaborator = {{EPA}},
month = feb,
year = {2014},
keywords = {Air quality, Air quality indexes, Air quality management, Health aspects, Standards Health aspects, United States},
pages = {1--12},
}

@article{collaborating_group_isrdce_frequency_1997,
title = {Frequency of risk factors in bronchial asthma in various regions of {Italy}.},
volume = {21},
issn = {1120-9763},
abstract = {{\textless}Italian Studies of Respiration Disorders in Childhood and the Environment{\textgreater}
Many risk factors, both individual and environmental, are associated to asthma. In this paper the frequency distribution of various asthma risk factors in different geographical areas in Italy is provided. Data come from S.I.D.R.I.A.--Italian Studies on Respiratory Disorders in Childhood and the Environment--a collaborative research project which involved 18,737 children in the first two levels of primary school and 21,410 adolescents in the third class of the secondary school. The study population was distributed in ten areas in Central and North Italy with different geographic, environmental and demographic conditions. Information was provided by the parents of the children in the primary school and by both parents and adolescents in the secondary school through ad hoc questionnaires; the response rate was very high (94.4\%). Risk factors are unevenly distributed in the study areas. The prevalence of bronchitis in the first two years of life is 18.1\% in Siena but it is 31.3\% in Cremona; the frequency of moquette in the bed room range from 8.6\% in Viterbo to 29.8\% in Trento as well as the presence of a cat in the house in the first two years of life involves 7.4\% of study subjects in Roma and 21.2\% in Siena. Maternal smoking during pregnancy is quite infrequent in Empoli (8.1\%) but much more common in Milano (17.7\%). In Trento 6.3\% of the study subjects live in a house facing a busy road whilst in Milano the same proportion is 30.5\%. Reported differences can be of value in promoting and evaluating asthma prevention programs.},
language = {ita},
number = {4},
journal = {Epidemiologia E Prevenzione},
author = {Collaborating group ISRDCE},
month = dec,
year = {1997},
pmid = {9489226},
keywords = {Adolescent, Asthma, Child, Female, Humans, Italy, Male, Pregnancy, Prevalence, Rhinitis, Allergic, Perennial, Risk Factors, eczema},
pages = {243--251},
}

@article{fox_stop_1989,
title = {A {Stop} {List} for {General} {Text}},
volume = {24},
issn = {0163-5840},
url = {http://doi.acm.org/10.1145/378881.378888},
doi = {10.1145/378881.378888},
abstract = {A stop list, or negative dictionary is a device used in automatic indexing to filter out words that would make poor index terms. Traditionally stop lists are supposed to have included only the most frequently occurring words. In practice, however, stop lists have tended to include infrequently occurring words, and have not included many frequently occurring words. Infrequently occurring words seem to have been included because stop list compilers have not, for whatever reason, consulted empirical studies of word frequencies. Frequently occurring words seem to have been left out for the same reason, and also because many of them might still be important as index terms.This paper reports an exercise in generating a stop list for general text based on the Brown corpus of 1,014,000 words drawn from a broad range of literature in English. We start with a list of tokens occurring more than 300 times in the Brown corpus. From this list of 278 words, 32 are culled on the grounds that they are too important as potential index terms. Twenty-six words are then added to the list in the belief that they may occur very frequently in certain kinds of literature. Finally, 149 words are added to the list because the finite state machine based filter in which this list is intended to be used is able to filter them at almost no cost. The final product is a list of 421 stop words that should be maximally efficient and effective in filtering the most frequently occurring and semantically neutral words in general literature in English.},
number = {1-2},
journal = {SIGIR Forum},
author = {Fox, Christopher},
month = sep,
year = {1989},
pages = {19--21},
}

@book{salton_introduction_1986,
address = {New York, NY, USA},
title = {Introduction to {Modern} {Information} {Retrieval}},
isbn = {978-0-07-054484-0},
publisher = {McGraw-Hill, Inc.},
author = {Salton, Gerard and McGill, Michael J.},
year = {1986},
}

@article{mocanu_twitter_2013,
title = {The {Twitter} of {Babel}: {Mapping} {World} {Languages} through {Microblogging} {Platforms}},
volume = {8},
issn = {1932-6203},
shorttitle = {The {Twitter} of {Babel}},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061981},
doi = {10.1371/journal.pone.0061981},
abstract = {Large scale analysis and statistics of socio-technical systems that just a few short years ago would have required the use of consistent economic and human resources can nowadays be conveniently performed by mining the enormous amount of digital data produced by human activities. Although a characterization of several aspects of our societies is emerging from the data revolution, a number of questions concerning the reliability and the biases inherent to the big data “proxies” of social life are still open. Here, we survey worldwide linguistic indicators and trends through the analysis of a large-scale dataset of microblogging posts. We show that available data allow for the study of language geography at scales ranging from country-level aggregation to specific city neighborhoods. The high resolution and coverage of the data allows us to investigate different indicators such as the linguistic homogeneity of different countries, the touristic seasonal patterns within countries and the geographical distribution of different languages in multilingual regions. This work highlights the potential of geolocalized studies of open data sources to improve current analysis and develop indicators for major social phenomena in specific communities.},
language = {en},
number = {4},
urldate = {2018-05-11},
journal = {PLOS ONE},
author = {Mocanu, Delia and Baronchelli, Andrea and Perra, Nicola and Gonçalves, Bruno and Zhang, Qian and Vespignani, Alessandro},
month = apr,
year = {2013},
keywords = {Belgium, Census, Data Mining, Economic analysis, Geographic distribution, Languages, Linguistic geography, twitter},
pages = {e61981},
}

@techreport{lazer_google_2014,
address = {Rochester, NY},
type = {{SSRN} {Scholarly} {Paper}},
title = {Google {Flu} {Trends} {Still} {Appears} {Sick}: {An} {Evaluation} of the 2013-2014 {Flu} {Season}},
shorttitle = {Google {Flu} {Trends} {Still} {Appears} {Sick}},
url = {https://papers.ssrn.com/abstract=2408560},
abstract = {In response to its poor performance during the 2012-2013 flu season, Google Flu Trends (GFT) engineers announced a redesign of the GFT algorithm. Two changes were made: (1) dampening anomalous media spikes and (2) using ElasticNet, rather than regression, for estimation. This paper identifies several problems that persist in the new algorithm. First, the transparency problems identified in our earlier Science paper appear to have, if anything, become worse. Second, there are reasons to doubt whether a spike in media attention was the only, or primary, cause of GFT's errors. Finally, there is strong evidence that GFT is still not using all the information at its disposal to make accurate measurements of flu prevalence. While it is too early to give a complete evaluation of the new algorithm, these results are discouraging.},
language = {en},
number = {ID 2408560},
urldate = {2018-05-11},
institution = {Social Science Research Network},
author = {Lazer, David and Kennedy, Ryan and King, Gary and Vespignani, Alessandro},
month = mar,
year = {2014},
keywords = {Big Data, Google Flu Trends, replication, time series, transparency},
}

@article{collier_omg_2011,
title = {{OMG} {U} got flu? {Analysis} of shared health messages for bio-surveillance},
volume = {2},
issn = {2041-1480},
shorttitle = {{OMG} {U} got flu?},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3239309/},
doi = {10.1186/2041-1480-2-S5-S9},
abstract = {Background
Micro-blogging services such as Twitter offer the potential to crowdsource epidemics in real-time. However, Twitter posts (‘tweets’) are often ambiguous and reactive to media trends. In order to ground user messages in epidemic response we focused on tracking reports of self-protective behaviour such as avoiding public gatherings or increased sanitation as the basis for further risk analysis.

Results
We created guidelines for tagging self protective behaviour based on Jones and Salathé (2009)’s behaviour response survey. Applying the guidelines to a corpus of 5283 Twitter messages related to influenza like illness showed a high level of inter-annotator agreement (kappa 0.86). We employed supervised learning using unigrams, bigrams and regular expressions as features with two supervised classifiers (SVM and Naive Bayes) to classify tweets into 4 self-reported protective behaviour categories plus a self-reported diagnosis. In addition to classification performance we report moderately strong Spearman’s Rho correlation by comparing classifier output against WHO/NREVSS laboratory data for A(H1N1) in the USA during the 2009-2010 influenza season.

Conclusions
The study adds to evidence supporting a high degree of correlation between pre-diagnostic social media signals and diagnostic influenza case data, pointing the way towards low cost sensor networks. We believe that the signals we have modelled may be applicable to a wide range of diseases.},
number = {Suppl 5},
journal = {Journal of Biomedical Semantics},
author = {Collier, Nigel and Son, Nguyen Truong and Nguyen, Ngoc Mai},
month = oct,
year = {2011},
pmid = {22166368},
pmcid = {PMC3239309},
pages = {S9},
}

@article{chew_pandemics_2010,
title = {Pandemics in the {Age} of {Twitter}: {Content} {Analysis} of {Tweets} during the 2009 {H1N1} {Outbreak}},
volume = {5},
issn = {1932-6203},
shorttitle = {Pandemics in the {Age} of {Twitter}},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0014118},
doi = {10.1371/journal.pone.0014118},
abstract = {Background Surveys are popular methods to measure public perceptions in emergencies but can be costly and time consuming. We suggest and evaluate a complementary “infoveillance” approach using Twitter during the 2009 H1N1 pandemic. Our study aimed to: 1) monitor the use of the terms “H1N1” versus “swine flu” over time; 2) conduct a content analysis of “tweets”; and 3) validate Twitter as a real-time content, sentiment, and public attention trend-tracking tool. Methodology/Principal Findings Between May 1 and December 31, 2009, we archived over 2 million Twitter posts containing keywords “swine flu,” “swineflu,” and/or “H1N1.” using Infovigil, an infoveillance system. Tweets using “H1N1” increased from 8.8\% to 40.5\% (R2 = .788; p{\textless}.001), indicating a gradual adoption of World Health Organization-recommended terminology. 5,395 tweets were randomly selected from 9 days, 4 weeks apart and coded using a tri-axial coding scheme. To track tweet content and to test the feasibility of automated coding, we created database queries for keywords and correlated these results with manual coding. Content analysis indicated resource-related posts were most commonly shared (52.6\%). 4.5\% of cases were identified as misinformation. News websites were the most popular sources (23.2\%), while government and health agencies were linked only 1.5\% of the time. 7/10 automated queries correlated with manual coding. Several Twitter activity peaks coincided with major news stories. Our results correlated well with H1N1 incidence data. Conclusions This study illustrates the potential of using social media to conduct “infodemiology” studies for public health. 2009 H1N1-related tweets were primarily used to disseminate information from credible sources, but were also a source of opinions and experiences. Tweets can be used for real-time content analysis and knowledge translation research, allowing health authorities to respond to public concerns.},
language = {en},
number = {11},
urldate = {2018-05-11},
journal = {PLOS ONE},
author = {Chew, Cynthia and Eysenbach, Gunther},
month = nov,
year = {2010},
keywords = {Chi square tests, Data Mining, Graphs, H1N1, Internet, Public and occupational health, Swine influenza, twitter},
pages = {e14118},
}

@inproceedings{culotta_towards_2010,
address = {New York, NY, USA},
series = {{SOMA} '10},
title = {Towards {Detecting} {Influenza} {Epidemics} by {Analyzing} {Twitter} {Messages}},
isbn = {978-1-4503-0217-3},
url = {http://doi.acm.org/10.1145/1964858.1964874},
doi = {10.1145/1964858.1964874},
abstract = {Rapid response to a health epidemic is critical to reduce loss of life. Existing methods mostly rely on expensive surveys of hospitals across the country, typically with lag times of one to two weeks for influenza reporting, and even longer for less common diseases. In response, there have been several recently proposed solutions to estimate a population's health from Internet activity, most notably Google's Flu Trends service, which correlates search term frequency with influenza statistics reported by the Centers for Disease Control and Prevention (CDC). In this paper, we analyze messages posted on the micro-blogging site Twitter.com to determine if a similar correlation can be uncovered. We propose several methods to identify influenza-related messages and compare a number of regression models to correlate these messages with CDC statistics. Using over 500,000 messages spanning 10 weeks, we find that our best model achieves a correlation of .78 with CDC statistics by leveraging a document classifier to identify relevant messages.},
booktitle = {Proceedings of the {First} {Workshop} on {Social} {Media} {Analytics}},
publisher = {ACM},
author = {Culotta, Aron},
year = {2010},
keywords = {Data Mining, Social Media, classification, regression},
pages = {115--122},
}

@inproceedings{paul_you_2011,
address = {Barcelona, Spain},
title = {You {Are} {What} {You} {Tweet}: {Analyzing} {Twitter} for {Public} {Health}},
shorttitle = {You {Are} {What} {You} {Tweet}},
url = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/view/2880},
abstract = {Analyzing user messages in social media can measure different population characteristics, including public health measures. For example, recent work has correlated Twitter messages with influenza rates in the United States; but this has largely been the extent of mining Twitter for public health. In this work, we consider a broader range of public health applications for Twitter. We apply the recently introduced Ailment Topic Aspect Model to over one and a half million health related tweets and discover mentions of over a dozen ailments, including allergies, obesity and insomnia. We introduce extensions to incorporate prior knowledge into this model and apply it to several tasks: tracking illnesses over times (syndromic surveillance), measuring behavioral risk factors, localizing illnesses by geographic region, and analyzing symptoms and medication usage. We show quantitative correlations with public health data and qualitative evaluations of model output. Our results suggest that Twitter has broad applicability for public health research.},
booktitle = {Proceedings of the {Fifth} {International} {AAAI} {Conference} on {Weblogs} and {Social} {Media}},
publisher = {The AAAI Press, Menlo Park, California},
author = {Paul, Michael and Dredze, Mark},
month = jul,
year = {2011},
keywords = {Asthma, PCCI, Twitter, cosn2014, done, icwsm, metric-brief-0, metric-consent-0, metric-irb-0, metric-length-1, metric-n-1, metric-processing-1, metric-protocol-1, metric-sampling-1, metric-shared-0, metric-sourcesns-1, yes},
}

@inproceedings{krieck_new_2011,
title = {A new age of public health: {Identifying} disease outbreaks by analyzing tweets},
shorttitle = {A new age of public health},
abstract = {Traditional disease surveillance is a very time consuming reporting process. Cases of notifiable diseases are reported to the different levels in the national health care system before actions can be taken. But, early detection of disease activity followed by a rapid response is crucial to reduce the impact of epidemics. To address this challenge, alternative sources of information are investigated for disease surveillance. In this paper, the relevance of twitter messages outbreak detection is investigated from two directions. First, Twitter messages potentially related to disease outbreaks are retrospectively searched and analyzed. Second, incoming twitter messages are assessed with respect to their relevance for outbreak detection. The studies show that twitter messages can be – to a certain extent – highly relevant for early detecting hints to public health threats.},
booktitle = {Proceedings of {Health} {WebScience} {Workshop}, {ACM} {Web} {Science} {Conference}},
author = {Krieck, Manuela and Dreesman, Johannes and Otrusina, Lubomir and Denecke, Kerstin},
year = {2011},
}

@article{trasande_role_2005,
title = {The role of air pollution in asthma and other pediatric morbidities},
volume = {115},
issn = {0091-6749, 1097-6825},
url = {https://www.jacionline.org/article/S0091-6749(05)00306-4/fulltext},
doi = {10.1016/j.jaci.2005.01.056},
language = {English},
number = {4},
urldate = {2018-05-11},
journal = {Journal of Allergy and Clinical Immunology},
author = {Trasande, Leonardo and Thurston, George D.},
month = apr,
year = {2005},
pmid = {15805986},
keywords = {Asthma, CO, EPA, Environmental Protection Agency, NO2, NOx, Nitrogen Dioxide, O3, Ozone, PM, PM10, PM2.5, Particulate Matter, Particulate matter {\textless}10 μm in aerodynamic diameter, Particulate matter {\textless}2.5 μm in aerodynamic diameter, SO2, WTC, World Trade Center, carbon monoxide, children's environmental health, lead, nitrogen oxides, sulfur dioxide},
pages = {689--699},
}

@article{cook_assessing_2011,
title = {Assessing {Google} {Flu} {Trends} {Performance} in the {United} {States} during the 2009 {Influenza} {Virus} {A} ({H1N1}) {Pandemic}},
volume = {6},
issn = {1932-6203},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0023610},
doi = {10.1371/journal.pone.0023610},
abstract = {Background Google Flu Trends (GFT) uses anonymized, aggregated internet search activity to provide near-real time estimates of influenza activity. GFT estimates have shown a strong correlation with official influenza surveillance data. The 2009 influenza virus A (H1N1) pandemic [pH1N1] provided the first opportunity to evaluate GFT during a non-seasonal influenza outbreak. In September 2009, an updated United States GFT model was developed using data from the beginning of pH1N1. Methodology/Principal Findings We evaluated the accuracy of each U.S. GFT model by comparing weekly estimates of ILI (influenza-like illness) activity with the U.S. Outpatient Influenza-like Illness Surveillance Network (ILINet). For each GFT model we calculated the correlation and RMSE (root mean square error) between model estimates and ILINet for four time periods: pre-H1N1, Summer H1N1, Winter H1N1, and H1N1 overall (Mar 2009–Dec 2009). We also compared the number of queries, query volume, and types of queries (e.g., influenza symptoms, influenza complications) in each model. Both models' estimates were highly correlated with ILINet pre-H1N1 and over the entire surveillance period, although the original model underestimated the magnitude of ILI activity during pH1N1. The updated model was more correlated with ILINet than the original model during Summer H1N1 (r = 0.95 and 0.29, respectively). The updated model included more search query terms than the original model, with more queries directly related to influenza infection, whereas the original model contained more queries related to influenza complications. Conclusions Internet search behavior changed during pH1N1, particularly in the categories “influenza complications” and “term for influenza.” The complications associated with pH1N1, the fact that pH1N1 began in the summer rather than winter, and changes in health-seeking behavior each may have played a part. Both GFT models performed well prior to and during pH1N1, although the updated model performed better during pH1N1, especially during the summer months.},
language = {en},
number = {8},
urldate = {2018-05-11},
journal = {PLOS ONE},
author = {Cook, Samantha and Conrad, Corrie and Fowlkes, Ashley L. and Mohebbi, Matthew H.},
month = aug,
year = {2011},
keywords = {Bronchitis, H1N1, Infectious disease surveillance, Influenza, Influenza A virus, Outpatients, Pneumonia, Swine influenza},
pages = {e23610},
}

@article{ginsberg_detecting_2009,
title = {Detecting influenza epidemics using search engine query data},
volume = {457},
copyright = {2008 Nature Publishing Group},
issn = {1476-4687},
url = {https://www.nature.com/articles/nature07634},
doi = {10.1038/nature07634},
abstract = {Seasonal influenza epidemics are a major public health concern, causing tens of millions of respiratory illnesses and 250,000 to 500,000 deaths worldwide each year1. In addition to seasonal influenza, a new strain of influenza virus against which no previous immunity exists and that demonstrates human-to-human transmission could result in a pandemic with millions of fatalities2. Early detection of disease activity, when followed by a rapid response, can reduce the impact of both seasonal and pandemic influenza3,4. One way to improve early detection is to monitor health-seeking behaviour in the form of queries to online search engines, which are submitted by millions of users around the world each day. Here we present a method of analysing large numbers of Google search queries to track influenza-like illness in a population. Because the relative frequency of certain queries is highly correlated with the percentage of physician visits in which a patient presents with influenza-like symptoms, we can accurately estimate the current level of weekly influenza activity in each region of the United States, with a reporting lag of about one day. This approach may make it possible to use search queries to detect influenza epidemics in areas with a large population of web search users.},
language = {en},
number = {7232},
urldate = {2018-05-11},
journal = {Nature},
author = {Ginsberg, Jeremy and Mohebbi, Matthew H. and Patel, Rajan S. and Brammer, Lynnette and Smolinski, Mark S. and Brilliant, Larry},
month = feb,
year = {2009},
pages = {1012--1014},
}

@article{kim_use_2013,
title = {Use of {Hangeul} {Twitter} to {Track} and {Predict} {Human} {Influenza} {Infection}},
volume = {8},
issn = {1932-6203},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0069305},
doi = {10.1371/journal.pone.0069305},
abstract = {Influenza epidemics arise through the accumulation of viral genetic changes. The emergence of new virus strains coincides with a higher level of influenza-like illness (ILI), which is seen as a peak of a normal season. Monitoring the spread of an epidemic influenza in populations is a difficult and important task. Twitter is a free social networking service whose messages can improve the accuracy of forecasting models by providing early warnings of influenza outbreaks. In this study, we have examined the use of information embedded in the Hangeul Twitter stream to detect rapidly evolving public awareness or concern with respect to influenza transmission and developed regression models that can track levels of actual disease activity and predict influenza epidemics in the real world. Our prediction model using a delay mode provides not only a real-time assessment of the current influenza epidemic activity but also a significant improvement in prediction performance at the initial phase of ILI peak when prediction is of most importance.},
language = {en},
number = {7},
urldate = {2018-05-11},
journal = {PLOS ONE},
author = {Kim, Eui-Ki and Seok, Jong Hyeon and Oh, Jang Seok and Lee, Hyong Woo and Kim, Kyung Hyun},
month = jul,
year = {2013},
keywords = {Algorithms, Forecasting, Infectious disease surveillance, Influenza, Influenza viruses, Linear regression analysis, Seasons, twitter},
pages = {e69305},
}

@article{tolomeo_predictors_2009,
title = {Predictors of asthma-related pediatric emergency department visits and hospitalizations},
volume = {46},
issn = {1532-4303},
abstract = {OBJECTIVE: Asthma is a leading cause of emergency department visits and hospitalizations for children in the United States. As part of a larger study, the purpose of this analysis was to determine which variables were most effective at predicting subsequent pediatric asthma-related emergency department visits and hospitalizations.
METHODS: A retrospective, descriptive study was conducted. Subjects consisted of a convenience sample of 298 children admitted to a New England Children's Hospital in 2006 with a primary diagnosis of asthma. Data from two hospital databases were collected for 12 months before and 12 months after the 2006 admission. Basic descriptive statistics were followed by chi-square tests to determine which variables were associated with emergency department visits and hospitalizations. Logistic regression analysis was used to determine which variables were significant predictors of asthma-related emergency department visits and hospitalizations.
RESULTS: Sixty-percent of all subjects were male. Ninety subjects experienced a total of 145 emergency department visits and 54 experienced a total of 70 hospitalizations. A previous emergency department visit was a significant predictor of both subsequent emergency department visits and subsequent hospitalizations. Age was also an independent risk factor for subsequent hospitalizations. In this sample, the risk of a hospitalization increased with each year increase in age.
CONCLUSION: These findings support the importance of early identification of children with asthma so that appropriate asthma management can be instituted before an emergency department visit occurs. Furthermore, results suggest involving school-age and preadolescent children in the care of their asthma so that they can be equipped and encouraged to self-manage their own asthma.},
language = {eng},
number = {8},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Tolomeo, Concettina and Savrin, Carol and Heinzer, Marjorie and Bazzy-Asaad, Alia},
month = oct,
year = {2009},
pmid = {19863288},
keywords = {Adolescent, Asthma, Child, Child, Preschool, Emergency Service, Hospital, Female, Hospitalization, Humans, Male, New England, Retrospective Studies},
pages = {829--834},
}

@article{schatz_controller--total_2006,
title = {The controller-to-total asthma medication ratio is associated with patient-centered as well as utilization outcomes},
volume = {130},
issn = {0012-3692},
doi = {10.1378/chest.130.1.43},
abstract = {BACKGROUND: The ratio of controller medication to total asthma medications has been related to asthma utilization outcomes, but its relationship to patient-centered outcomes has not been explored.
METHODS: Surveys that included validated asthma quality-of-life, control, and symptom severity tools were completed by a random sample of 2,250 health maintenance organization members aged 18 to 56 years who had persistent asthma. Linked computerized pharmacy data provided dispensing information on beta-agonist canisters and asthma controller medication. The ratio was calculated as the number of controller medications dispensed during the year of the survey divided by the total number medications (ie, inhaled beta-agonist plus controller medications) dispensed. The relationships of the optimal ratio cutoff to patient-centered outcomes and to subsequent acute asthma exacerbations were determined.
RESULTS: Mean asthma quality-of-life, asthma control, and symptom severity scale scores were significantly (p {\textless} 0.0001) more favorable in patients with ratios of {\textgreater} or = 0.5. After adjusting for demographic characteristics, patients with ratios of {\textgreater} or = 0.5 were significantly less likely to have adverse results regarding asthma quality of life (odds ratio [OR], 0.65; 95\% confidence interval [CI], 0.52 to 0.80), asthma control (OR, 0.62; 95\% CI, 0.50 to 0.77), and symptom severity (OR, 0.53; 95\% CI, 0.43 to 0.65), and were also less likely to experience subsequent asthma hospitalizations or emergency department visits (OR, 0.44; 95\% CI, 0.26 to 0.74) than patients with lower ratios.
CONCLUSION: A higher controller medication/total asthma medication ratio is associated with better patient-centered asthma outcomes as well as with reduced emergency hospital utilization. This adds further support to the use of the medication ratio as an asthma quality-of-care measure.},
language = {eng},
number = {1},
journal = {Chest},
author = {Schatz, Michael and Zeiger, Robert S. and Vollmer, William M. and Mosen, David and Mendoza, Guillermo and Apter, Andrea J. and Stibolt, Thomas B. and Leong, Albin and Johnson, Michael S. and Cook, E. Francis},
month = jul,
year = {2006},
pmid = {16840381},
keywords = {Adrenal Cortex Hormones, Adult, Anti-Asthmatic Agents, Asthma, Female, Health Maintenance Organizations, Humans, Male, Medical Records Systems, Computerized, Middle Aged, Patient-Centered Care, ROC Curve, Severity of Illness Index, Surveys and Questionnaires},
pages = {43--50},
}

@article{pesola_predicting_2004,
title = {Predicting asthma morbidity in {Harlem} emergency department patients},
volume = {11},
issn = {1069-6563},
doi = {10.1197/j.aem.2004.03.020},
abstract = {OBJECTIVES: To determine predictors of asthma morbidity in African American patients with asthma. Proxies for asthma morbidity were emergency department (ED) visits for asthma and hospitalizations for asthma.
METHODS: This was a prospective observational study that evaluated baseline predictors of asthma morbidity in adults in an urban, predominantly African American community in New York City. Potential predictors of asthma morbidity evaluated were education, gender, employment status, current smoking status, asthma severity, duration of asthma, daily use of a peak flow meter, presence or absence of pets at home, presence or absence of a significant other, presence or absence of medical insurance, and previous hospitalization for asthma in the past year. Follow-up consisted of a repeat questionnaire obtained between nine and 15 months after the baseline questionnaire. Follow-up data collection was limited to the last three-month history of ED visits or hospitalizations before the follow-up visit. At follow-up, the baseline predictors were related to the presence or absence of ED visits for asthma or hospitalizations for asthma. All predictors were evaluated individually (crude odds ratio [OR]) and simultaneously (adjusted OR) in a logistic regression model with the dichotomous outcome variable ED visits or hospitalization.
RESULTS: Return ED visits on follow-up were more likely to occur in asthma patients hospitalized in the previous year (adjusted OR, 3.9; 95\% confidence interval [CI] = 1.7 to 9.0) and were less likely to occur in asthma patients with pets (OR, 0.4; 95\% CI = 0.2 to 0.9). Patients with moderate/severe asthma, relative to patients with mild asthma, were more likely to be seen in the ED on follow-up on initial analysis (crude OR, 2.4; 95\% CI = 1.1 to 1.5), but the adjusted OR was not significant. Follow-up hospitalizations were significantly more likely to occur only in subjects reporting daily use of a peak flow meter (OR, 6.8; 95\% CI = 1.3 to 34.5). Subjects hospitalized for asthma in the previous year were more likely to be hospitalized subsequently on initial analysis (crude OR, 2.9; 95\% CI = 1.0 to 8.1), but the adjusted OR was not significant.
CONCLUSIONS: It appears that African American patients with asthma who had previous hospitalizations for asthma within the past year or use a peak flow meter daily (a marker for more severe asthma) are more likely to visit the ED in the future or to be hospitalized for asthma, respectively. These patients need to be targeted and treated more aggressively to improve asthma care and decrease morbidity. The apparent protective effect of the presence of pets on reducing ED visits is unclear at this time, and the findings need to be replicated and evaluated further.},
language = {eng},
number = {9},
journal = {Academic Emergency Medicine: Official Journal of the Society for Academic Emergency Medicine},
author = {Pesola, Gene R. and Xu, Feng and Ahsan, Habibul and Sternfels, Pamela and Meyer, Ilan H. and Ford, Jean G.},
month = sep,
year = {2004},
pmid = {15347544},
keywords = {Adult, African Americans, Age distribution, Animals, Animals, Domestic, Asthma, Emergency Service, Hospital, Female, Hospitalization, Humans, Male, New York City, Peak Expiratory Flow Rate, Predictive Value of Tests, Prospective Studies, Severity of Illness Index, Sex Distribution, Surveys and Questionnaires},
pages = {944--950},
}

@techreport{cdc_about_2010,
title = {About the {Morbidity} and {Mortality} {Weekly} {Report} ({MMWR}) {Series}},
url = {https://www.cdc.gov/mmwr/about.html},
abstract = {Learn more about CDC’s Morbidity and Mortality Weekly Report (MMWR).},
language = {en-us},
urldate = {2018-05-11},
author = {CDC},
year = {2010},
}

@techreport{nih_guidelines_2007,
type = {Expert {Panel} {Report}},
title = {Guidelines for the {Diagnosis} and {Management} of {Asthma}},
url = {https://www.nhlbi.nih.gov/health-topics/guidelines-for-diagnosis-management-of-asthma},
language = {English},
number = {3},
institution = {National Heart, Lung, and Blood Institute},
author = {{NIH}},
year = {2007},
pages = {440},
}

@inproceedings{pang_thumbs_2002,
address = {Stroudsburg, PA, USA},
series = {{EMNLP} '02},
title = {Thumbs {Up}?: {Sentiment} {Classification} {Using} {Machine} {Learning} {Techniques}},
shorttitle = {Thumbs {Up}?},
url = {https://doi.org/10.3115/1118693.1118704},
doi = {10.3115/1118693.1118704},
abstract = {We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.},
booktitle = {Proceedings of the {ACL}-02 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} - {Volume} 10},
publisher = {Association for Computational Linguistics},
author = {Pang, Bo and Lee, Lillian and Vaithyanathan, Shivakumar},
year = {2002},
pages = {79--86},
}

@article{das_yahoo!_2007,
title = {Yahoo! for {Amazon}: {Sentiment} {Extraction} from {Small} {Talk} on the {Web}},
volume = {53},
issn = {0025-1909},
shorttitle = {Yahoo! for {Amazon}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1070.0704},
doi = {10.1287/mnsc.1070.0704},
abstract = {Extracting sentiment from text is a hard semantic problem. We develop a methodology for extracting small investor sentiment from stock message boards. The algorithm comprises different classifier algorithms coupled together by a voting scheme. Accuracy levels are similar to widely used Bayes classifiers, but false positives are lower and sentiment accuracy higher. Time series and cross-sectional aggregation of message information improves the quality of the resultant sentiment index, particularly in the presence of slang and ambiguity. Empirical applications evidence a relationship with stock values—tech-sector postings are related to stock index levels, and to volumes and volatility. The algorithms may be used to assess the impact on investor opinion of management announcements, press releases, third-party news, and regulatory changes.},
number = {9},
journal = {Management Science},
author = {Das, Sanjiv R. and Chen, Mike Y.},
month = sep,
year = {2007},
pages = {1375--1388},
}

@article{kashiwabara_airborne_2003,
title = {Airborne water droplets in mist or fog may affect nocturnal attacks in asthmatic children},
volume = {40},
issn = {0277-0903},
abstract = {Our study objectives were to evaluate whether or not airborne water droplets in mist or fog affect the occurrence of nocturnal attacks of asthmatic children using a retrospective study. This study included 971 visits by children with bronchial asthma to the emergency department at nighttime (from 18:00 to 09:00) during a 3-year period (April 1, 1998-March 31, 2001). Meteorological data were checked at a local fire station and regional meteorological observatory. We divided nighttime into five 3-hour periods to evaluate the relationship between chronological changes in the frequency of the emergency department visits of asthmatic children and of meteorological conditions. In four of five periods of nighttime, multivariate analysis showed that mist or fog, average atmospheric temperature, and barometric pressure were related to the number of emergency department visits (n=1096, r=0.165-0.263, p{\textless}0.0001). We divided the year into four seasons to eliminate differences between atmospheric temperature and barometric pressure on clear nights and on misty or foggy nights; we also found the mean number of emergency department visits was higher on misty or foggy nights than on clear nights in each seasonal period (p{\textless}0.01). In addition, average atmospheric temperature on misty or foggy nights with the emergency department visits was higher than that on misty or foggy nights without any visits (p{\textless}0.01). Asthmatic children frequently visited the emergency department on misty or foggy nights, especially during midnight to dawn periods with high atmospheric temperature. Because a higher atmospheric temperature on misty or foggy nights indicates a larger saturated amount of airborne water droplets, our results suggest that mist and fog, in particular a saturated amount of airborne water droplets, may be a stimulus for bronchoconstriction.},
language = {eng},
number = {4},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Kashiwabara, Kosuke and Itonaga, Kotaro and Moroi, Toshihiro},
month = jun,
year = {2003},
pmid = {12870836},
keywords = {Asthma, Atmosphere, Bronchoconstriction, Child, Chronobiology Phenomena, Female, Humans, Male, Retrospective Studies, Water, Weather},
pages = {405--411},
}

@inproceedings{rothe_dex:_2015,
title = {{DEX}: {Deep} {EXpectation} of {Apparent} {Age} {From} a {Single} {Image}},
shorttitle = {{DEX}},
url = {https://www.cv-foundation.org/openaccess/content_iccv_2015_workshops/w11/html/Rothe_DEX_Deep_EXpectation_ICCV_2015_paper.html},
urldate = {2018-04-28},
author = {Rothe, Rasmus and Timofte, Radu and Van Gool, Luc},
year = {2015},
pages = {10--15},
}

@book{lopez_global_2006,
address = {Washington (DC)},
title = {Global {Burden} of {Disease} and {Risk} {Factors}},
copyright = {Copyright © 2006, The International Bank for Reconstruction and Development/The World Bank Group.},
isbn = {978-0-8213-6262-4},
url = {http://www.ncbi.nlm.nih.gov/books/NBK11812/},
abstract = {Strategic health planning, the cornerstone of initiatives to facilitate the attainment of health goals in populations around the world, requires an understanding of the comparative burden of diseases and injuries, their corresponding risk factors, and the likely effects of proposed interventions. Critical to an effective assessment of risks and outcomes is a framework to integrate, validate, analyze, compare and disseminate available information to policy makers. The Global Burden of Disease (GBD) framework, the principal instrument to do so, has been widely adopted since its publication in 1990 as the preferred method for health accounting and as the standard to guide the setting of health research priorities. Features of this framework include the development of methods for assessing the reliability of data and estimating missing data for ensuring epidemiological consistency among the various estimates available for a disease, and the use of a common metric to summarize the disease burden from diagnostic categories of the International Classification of Diseases and the major risk factors that cause those health outcomes.},
language = {eng},
publisher = {World Bank},
editor = {Lopez, Alan D. and Mathers, Colin D. and Ezzati, Majid and Jamison, Dean T. and Murray, Christopher JL},
year = {2006},
pmid = {21250374},
}

@article{nicholson_respiratory_1993,
title = {Respiratory viruses and exacerbations of asthma in adults.},
volume = {307},
issn = {0959-8138, 1468-5833},
url = {https://www.bmj.com/content/307/6910/982},
doi = {10.1136/bmj.307.6910.982},
abstract = {OBJECTIVE--To study the role of respiratory viruses in exacerbations of asthma in adults. DESIGN--Longitudinal study of 138 adults with asthma. SETTING--Leicestershire Health Authority. SUBJECTS--48 men and 90 women 19-46 years of age with a mean duration of wheeze of 19.6 years. 75\% received regular treatment with bronchodilators; 89\% gave a history of eczema, hay fever, allergic rhinitis, nasal polyps, or allergies; 38\% had been admitted to hospital with asthma. MAIN OUTCOME MEASURES--Symptomatic colds and asthma exacerbations; objective exacerbations of asthma with {\textgreater} or = 50 l/min reduction in mean peak expiratory flow rate when morning and night time readings on days 1-7 after onset of symptoms were compared with rates during an asymptomatic control period; laboratory confirmed respiratory tract infections. RESULTS--Colds were reported in 80\% (223/280) of episodes with symptoms of wheeze, chest tightness, or breathlessness, and 89\% (223/250) of colds were associated with asthma symptoms. 24\% of 115 laboratory confirmed non-bacterial infections were associated with reductions in mean peak expiratory flow rate {\textgreater} or = 50 l/min through days 1-7 and 48\% had mean decreases {\textgreater} or = 25 l/min. 44\% of episodes with mean decreases in flow rate {\textgreater} or = 50 l/min were associated with laboratory confirmed infections. Infections with rhinoviruses, coronaviruses OC43 and 229E, influenza B, respiratory syncytial virus, parainfluenza virus, and chlamydia were all associated with objective evidence of an exacerbation of asthma. CONCLUSIONS--These findings show that asthma symptoms and reductions in peak flow are often associated with colds and respiratory viruses; respiratory virus infections commonly cause or are associated with exacerbations of asthma in adults.},
language = {en},
number = {6910},
urldate = {2018-04-26},
journal = {BMJ},
author = {Nicholson, K. G. and Kent, J. and Ireland, D. C.},
month = oct,
year = {1993},
pmid = {8241910},
pages = {982--986},
}

@techreport{cdc_flu_2017,
title = {Flu and {People} with {Asthma} {\textbar} {Seasonal} {Influenza} ({Flu})},
url = {https://www.cdc.gov/flu/asthma/index.htm},
abstract = {Flu and People with Asthma - CDC},
language = {en-us},
urldate = {2018-04-26},
author = {CDC},
month = aug,
year = {2017},
}

@article{price_types_2014,
title = {Types, frequency and impact of asthma triggers on patients’ lives: a quantitative study in five {European} countries},
volume = {51},
issn = {0277-0903},
shorttitle = {Types, frequency and impact of asthma triggers on patients’ lives},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3934435/},
doi = {10.3109/02770903.2013.846369},
abstract = {Objective:
To identify the types, frequency and impact of asthma triggers and the relationship to asthma control among adults with asthma in Europe.

Methods:
Adults with self-reported physician-diagnosed asthma receiving maintenance asthma treatment and self-reported exposure to known asthma triggers completed an online questionnaire; a subset completed a diary over 3–4 weeks. Information on asthma control (Asthma Control Test™ [ACT]), asthma triggers, frequency of exposure and behaviours in response or to avoid asthma triggers and the perceived impact on daily life was captured. A post-hoc analysis evaluated the impact of high trigger burden on the frequency of severe asthma exacerbations, hospitalisations and days lost at work/study.

Results:
A total of 1202 adults participated and 177 completed the diary. Asthma was uncontrolled for the majority (76\%) of participants and most (52\%) reported exposure to 6–15 asthma triggers. As trigger burden increased, behavioural changes to manage trigger exposure had a significantly increased impact on daily life (p {\textless} 0.0001) and job choice (p = 0.002). Participants reporting a high trigger burden ({\textgreater}16) were more likely to report uncontrolled asthma than those with a low trigger burden (1–5). Participants with a high trigger burden had previously experienced on average two more severe asthma attacks during a lifetime (p {\textless} 0.001), two more hospitalisations (p {\textless} 0.001) and 3.5 more missed days at work or study in the last year due to their asthma (p {\textless} 0.001) than those with a low trigger burden.

Conclusions:
Adults with asthma reporting a high trigger burden ({\textgreater}16 different triggers) experience more severe asthma attacks than those reporting lower trigger burdens.},
number = {2},
journal = {The Journal of Asthma},
author = {Price, David and Dale, Peter and Elder, Emma and Chapman, Kenneth R.},
month = mar,
year = {2014},
pmid = {24050523},
pmcid = {PMC3934435},
pages = {127--135},
}

@article{gruber_removing_2016,
title = {Removing asthma triggers and improving children's health: {The} {Asthma} {Partnership} {Demonstration} project},
volume = {116},
issn = {1534-4436},
shorttitle = {Removing asthma triggers and improving children's health},
doi = {10.1016/j.anai.2016.03.025},
abstract = {BACKGROUND: Studies have revealed the efficacy of home-based environmental interventions on reduction of asthma symptoms as a strategy for managing asthma in children. A focus on education and behavior change alone is generally too limited to reduce exposure to asthma triggers that exist because of adverse housing conditions.
OBJECTIVE: To demonstrate that housing conditions as a focus of a health intervention should be considered more widely as an effective means of addressing serious health problems such as asthma.
METHODS: Residences of 41 families of children identified with some of the highest rates of asthma-related hospital visits were assessed for the presence of asthma triggers.
RESULTS: The intervention had a positive effect on lessening the effect of the child's asthma on the family's lives and activities. Reductions in frequency of negative effects of children's asthma on sleeping, job or work around the house, and family activity plans, fewer worries or concerns about children getting enough sleep and performing normal daily activities, and fewer adverse effects of children's asthma medications were reported. Reduced use of asthma medication, medication applications, and health visits were noted. Households with return visits had 50\% lower hospital bills for childhood asthma treatment.
CONCLUSION: Home environment conditions that lead to or exacerbate asthma may be reduced or eliminated by making minor repairs and introducing reasonable cleaning regimens that address sources of asthma triggers. This can produce greater awareness on the part of families about the presence of asthma triggers and motivate future action to address the conditions associated with these triggers.},
language = {eng},
number = {5},
journal = {Annals of Allergy, Asthma \& Immunology: Official Publication of the American College of Allergy, Asthma, \& Immunology},
author = {Gruber, Kenneth J. and McKee-Huger, Beth and Richard, April and Byerly, Brett and Raczkowski, Jana L. and Wall, Thomas C.},
year = {2016},
pmid = {27153740},
keywords = {Adolescent, Asthma, Child, Child Health, Child, Preschool, Environmental Exposure, Female, Health Education, Hospital Charges, Hospitalization, Housing, Humans, Male},
pages = {408--414},
}

@article{ritz_predicting_2014,
title = {Predicting asthma control: the role of psychological triggers},
volume = {35},
issn = {1539-6304},
shorttitle = {Predicting asthma control},
doi = {10.2500/aap.2014.35.3779},
abstract = {Asthma triggers have been linked to adverse health outcomes in asthma, but little is known about their association with asthma control. Because trigger avoidance is an integral part of successful asthma management, psychological triggers in particular may be associated with suboptimal asthma control, given the difficulty of controlling them. We examined cross-sectional and longitudinal associations of perceived asthma triggers with self-report of asthma control impairment, symptoms, and spirometric lung function (forced expiratory volume in the 1st second, [FEV1]) in 179 adult primary care asthma patients. Perceived asthma triggers explained up to 42.5\% of the variance in asthma control and symptoms, but not in FEV1 alone. Allergic triggers explained up to 12.1\% of the asthma control and symptom variance, three nonallergic trigger types, air pollution/irritants, physical activity, and infection, explained up to 26.2\% over and above allergic triggers, and psychological triggers up to 9.5\% over and above all other triggers. Psychological triggers alone explained up to 33.9\% of the variance and were the only trigger class that was consistently significant in all final multiple regression models predicting control and symptoms. Psychological triggers also predicted lower asthma control 3-6 months later, although controlling for initial asthma control eliminated this association. In free reports of individually relevant triggers, only psychological triggers were associated with suboptimal asthma control. Trigger factors are important predictors of self-reported asthma control and symptoms but not actual lung function. Particular attention should be directed to psychological triggers as indicators of patients' perceptions of suboptimal asthma control.},
language = {eng},
number = {5},
journal = {Allergy and Asthma Proceedings},
author = {Ritz, Thomas and Bobb, Carol and Griffiths, Chris},
month = oct,
year = {2014},
pmid = {25295806},
keywords = {Adolescent, Adult, Age of Onset, Asthma, Child, Cross-Sectional Studies, Female, Forced Expiratory Volume, Humans, Male, Middle Aged, Prognosis, Risk Factors, Surveys and Questionnaires, Young Adult, spirometry},
pages = {390--397},
}

@article{covar_medications_2005,
title = {Medications as asthma triggers},
volume = {25},
issn = {0889-8561},
doi = {10.1016/j.iac.2004.09.009},
abstract = {Certain medications can generate asthma symptoms, with the potential to cause considerable morbidity. This article focuses on the common drugs that have the potential to cause distinct respiratory reactions in asthmatics: aspirin and other nonsteroidal anti-inflammatory drugs, beta-blockers, and angiotensin-converting enzyme inhibitors. The means by which these medications can trigger asthma vary in terms of acuity of onset, severity, and the mechanisms involved. The general and most practical approach is avoidance and cautious use of these drugs in asthmatics. However, these classes of medications can exert a major role in the management of common and serious diseases. Fortunately, controller therapy for asthma and alternative or more selective medications for the treatment of these conditions are now available.},
language = {eng},
number = {1},
journal = {Immunology and Allergy Clinics of North America},
author = {Covar, Ronina A. and Macomber, Beth A. and Szefler, Stanley J.},
month = feb,
year = {2005},
pmid = {15579370},
keywords = {Adrenergic beta-Antagonists, Angiotensin-Converting Enzyme Inhibitors, Anti-Inflammatory Agents, Non-Steroidal, Asthma, Humans, Prevalence},
pages = {169--190},
}

@article{webley_infectious_2015,
title = {Infectious asthma triggers: time to revise the hygiene hypothesis?},
volume = {23},
issn = {1878-4380},
shorttitle = {Infectious asthma triggers},
doi = {10.1016/j.tim.2015.05.006},
abstract = {The hygiene hypothesis supports an inverse relationship between respiratory infections in early-life and atopic diseases. However, a recent study supports growing evidence that early-life infection and airway microbiome composition can significantly influence asthma inception and exacerbation later in life. This reignites discussions on infection-mediated asthma phenotypes and potential therapeutics.},
language = {eng},
number = {7},
journal = {Trends in Microbiology},
author = {Webley, Wilmore C. and Aldridge, Kelly L.},
month = jul,
year = {2015},
pmid = {26070971},
keywords = {Asthma, Humans, Microbiota, Nasopharynx, Respiratory Tract Infections, hygiene hypothesis, microbiome, respiratory infection},
pages = {389--391},
}

@article{sarafino_genetic_1995,
title = {Genetic factors in the presence, severity, and triggers of asthma.},
volume = {73},
issn = {0003-9888, 1468-2044},
url = {http://adc.bmj.com/content/73/2/112},
doi = {10.1136/adc.73.2.112},
abstract = {The role of heredity in the presence of asthma, severity of the condition, and impact of 12 specific triggers of attacks was investigated. Health surveys containing questions about children's asthma characteristics were completed by 325 families with twin children across the United States. Data for 39 monozygotic twin pairs and 55 same sex dizygotic twin pairs who were between 2 and 20 years of age and had asthma present in at least one member of each pair were received and analysed. Results revealed higher concordance for the presence of asthma among monozygotic (58.97\%; n = 23) than dizygotic twins (23.64\%; n = 13). Further analyses were restricted to data from the concordant monozygotic and dizygotic twin pairs. Asthma severity (the product of attack frequency and intensity ratings) was significantly correlated for monozygotic pairs but not for dizygotic pairs, and this difference in monozygotic and dizygotic severity correlations was significant. Also, monozygotic twins showed significantly higher correlations than dizygotic twins for the impacts of two asthma triggers: respiratory infection and physical activity. These results indicate a role of heredity in the presence of asthma and suggest that genetic factors may also affect the severity of children's asthma condition and the impact of respiratory infection and physical exertion as asthma triggers.},
language = {en},
number = {2},
urldate = {2018-04-26},
journal = {Archives of Disease in Childhood},
author = {Sarafino, E. P. and Goldfedder, J.},
month = aug,
year = {1995},
pmid = {7574852},
pages = {112--116},
}

@article{janssens_effects_2015,
title = {Effects of {Symptom} {Perception} {Interventions} on {Trigger} {Identification} and {Quality} of {Life} in {Children} with {Asthma}},
url = {https://www.hindawi.com/journals/pm/2015/825137/abs/},
doi = {10.1155/2015/825137},
abstract = {Background. Management of individual triggers is suboptimal in practice. In this project, we investigated the impact of symptom perception interventions on asthma trigger identification and self-reported asthma quality of life. Methods. Children with asthma () participated in three asthma education sessions and then were randomized first to one of three home monitoring conditions (symptom monitoring and peak flow training with feedback, peak flow training without feedback, or no peak flow training) and then subsequently to one of three resistive load discrimination training conditions (signal detection training with feedback, signal detection training without feedback, or no training). Triggers were reported at enrollment, following home monitoring, and following discrimination training; quality of life was measured after home monitoring and after resistive load testing. Results. Symptom perception interventions resulted in increases in reported triggers, which increased reliably as a function of home monitoring, and increased further in participants who completed discrimination training with feedback. Increases in the number of reported asthma triggers were associated with decreases in quality of life. Discussion. Patients may benefit from strategies that make trigger-symptom contingencies clear. Complementary strategies are needed to address changes in the perceived burden of asthma which comes from awareness of new asthma triggers.},
language = {en},
urldate = {2018-04-26},
journal = {Pulmonary Medicine},
author = {Janssens, Thomas and Harver, Andrew},
year = {2015},
}

@article{ritz_asthma_2016,
title = {Asthma {Trigger} {Reports} {Are} {Associated} with {Low} {Quality} of {Life}, {Exacerbations}, and {Emergency} {Treatments}},
volume = {13},
issn = {2325-6621},
doi = {10.1513/AnnalsATS.201506-390OC},
abstract = {RATIONALE: Despite the importance of trigger perceptions for asthma diagnosis and management, associations among asthma triggers, affective disorders, and asthma outcome have received little attention.
OBJECTIVES: Because anxiety and depression are known to influence patients' health reports, we measured and controlled for these affective disorders in analyzing associations among patient perceptions of asthma triggers and asthma treatment outcomes.
METHODS: Patients from a nationally representative sample of respiratory specialist practices (N = 459) were assessed for clinically significant anxiety and depression and completed questionnaires on asthma triggers, quality of life, and asthma control. Physicians recorded exacerbation and emergency treatment frequencies in the prior year, spirometric lung function, and allergy test results. Hierarchical multiple regressions examined associations among reported trigger factors, anxiety, depression, and asthma outcomes, including quality of life, asthma control, exacerbations, emergencies, and spirometry.
MEASUREMENTS AND MAIN RESULTS: Patients across asthma severity levels were well represented. Anxiety and depression were associated with more frequent nonallergic, in particular psychological, triggers. Controlling for demographics, asthma severity, anxiety, and depression, nonallergic asthma triggers (including psychological triggers) explained substantial portions of variance in asthma control (total of 19.5\%, odds ratios [ORs] = 2.07-1.37 for individual triggers), asthma-related quality of life (total of 27.5\%, ORs = 3.21-1.49), and general quality of life (total of 11.3\%, ORs = 1.93-1.55). Psychological triggers were consistently associated with exacerbations and emergency treatments (ORs = 1.96-2.04) over and above other triggers and affective disorders. Spirometric lung function was largely unrelated to perceived asthma triggers.
CONCLUSIONS: Patients' perceptions of asthma triggers are important determinants of asthma outcomes, which can help identify individuals at risk for suboptimal asthma management.},
language = {eng},
number = {2},
journal = {Annals of the American Thoracic Society},
author = {Ritz, Thomas and Wittchen, Hans-Ulrich and Klotsche, Jens and Mühlig, Stephan and Riedel, Oliver and {sap-NEEDs study group *}},
month = feb,
year = {2016},
pmid = {26599372},
keywords = {Adult, Air pollution, Anxiety, Anxiety Disorders, Asthma, Attitude to Health, Cross-Sectional Studies, Depression, Depressive Disorder, Disease Progression, Emergency Treatment, Female, Humans, Hypersensitivity, Logistic Models, Male, Middle Aged, Mood Disorders, Odds ratio, Perception, Pollen, Quality of Life, Severity of Illness Index, Stress, Psychological, Surveys and Questionnaires, perceived asthma triggers, spirometry},
pages = {204--211},
}

@article{reddy_evaluation_2017,
title = {An {Evaluation} of a {State}-{Funded} {Healthy} {Homes} {Intervention} on {Asthma} {Outcomes} in {Adults} and {Children}},
volume = {23},
issn = {1550-5022},
doi = {10.1097/PHH.0000000000000530},
abstract = {CONTEXT: Reducing exposure to environmental triggers is a critical part of asthma management.
OBJECTIVE: To evaluate the impact of a healthy homes intervention on asthma outcomes and assess the impact of different targeting strategies.
SETTING: The New York State (NYS) Healthy Neighborhoods Program (HNP) operates in select communities with a higher burden of housing-related illness and associated risk factors.
PARTICIPANTS: Residents with asthma were recruited through 3 mechanisms: door-to-door canvassing (CANVASSED), 752 residents in 457 dwellings; referrals from community partners (REFERRED), 573 residents in 307 dwellings; referrals of Medicaid enrollees with poorly controlled asthma (TARGETED), 140 residents in 140 dwellings.
INTERVENTION: The NYS HNP provides visual assessments and low-cost interventions to identify and address asthma triggers and trigger-promoting conditions in the home environment. Conditions are reassessed during a revisit conducted 3 to 6 months after the initial visit.
MAIN OUTCOME MEASURE(S): The analysis compares improvements across the 3 groups for measures of asthma self-management, health care access, morbidity, and environmental conditions. An asthma trigger score characterizing the extent of multiple triggers in a dwelling was also calculated.
RESULTS: Among 1465 adults and children, there were significant improvements in environmental conditions and self-reported self-management, health care access, and asthma morbidity outcomes for each group. The improvement was greatest in the TARGETED group for most outcomes, but selected measures of self-management and health care access were greater in the other groups. The mean improvement was significantly greater in the TARGETED group.
CONCLUSION: Targeting the intervention to people with poorly controlled asthma maximizes improvements in trigger avoidance and asthma morbidity; however, other recruitment strategies are effective for impacting endpoints related to health care access and self-management. This evaluation demonstrates that a low-intensity home-based environmental intervention is effective as well as practical and feasible. Health care payers, state and local health departments, and others should consider investing in these home-based services as part of a comprehensive asthma care package.},
language = {eng},
number = {2},
journal = {Journal of public health management and practice: JPHMP},
author = {Reddy, Amanda L. and Gomez, Marta and Dixon, Sherry L.},
month = apr,
year = {2017},
pmid = {28121774},
keywords = {Adult, Asthma, Child, Environmental Exposure, Female, Government Programs, House Calls, Humans, Male, Medication Adherence, Morbidity, New York, Outcome Assessment (Health Care), Patient Care Management, State Government},
pages = {219--228},
}

@article{vazquez_emotionally_2017,
title = {Emotionally triggered asthma and its relationship to panic disorder, ataques de nervios, and asthma-related death of a loved one in {Latino} adults},
volume = {93},
issn = {1879-1360},
doi = {10.1016/j.jpsychores.2016.11.010},
abstract = {OBJECTIVE: Research has demonstrated high comorbidity between asthma and panic disorder (PD). Less is known about the relationship between asthma and the Latino cultural idiom of distress of ataques de nervios, as well as the role that psychosocial stressors play. The current study tested the hypotheses that Latino asthma patients who experience PD, ataques de nervios, and/or asthma-related death of a loved one endorse greater psychological triggers of asthma, greater perceived impact of asthma triggers, and greater difficulty controlling such triggers than do those without these conditions.
METHODS: Data originated from an interview conducted prior to a randomized controlled trial in which 292 Latino adults with self-reported asthma were recruited from outpatient clinics in the Bronx, NY. The PRIME-MD Patient Health Questionnaire (PHQ) was used to screen for PD symptoms, while the Structured Clinical Interview for DSM-IV (SCID-I) was used to confirm diagnosis of PD. Lifetime history of ataques de nervios and asthma-related death of a loved one were based upon self-report. Asthma triggers were examined using the Asthma Trigger Inventory (ATI).
RESULTS: PD, ataques de nervios, and asthma-related death of a loved one each predicted a higher frequency of psychological asthma triggers, controlling for gender and comorbid medical conditions. Participants with PD also reported greater impact of asthma triggers than those without PD, while no significant differences in perceived control were observed.
CONCLUSION: Providers should screen for PD, ataques de nervios, and asthma-related death of a loved one in Latino asthma patients, given their observed association with emotionally triggered asthma.},
language = {eng},
journal = {Journal of Psychosomatic Research},
author = {Vazquez, Karinna and Sandler, Jonathan and Interian, Alejandro and Feldman, Jonathan M.},
year = {2017},
pmid = {28107897},
pmcid = {PMC5260801},
keywords = {Activities of Daily Living, Adolescent, Adult, Aged, Aged, 80 and over, Anxiety Disorders, Asthma, Ataques de nervios, Bereavement, Comorbidity, Death of a loved one, Female, Hispanic Americans, Humans, Interview, Psychological, Latinos, Male, Middle Aged, Neuroticism, Panic Disorder, Psychological triggers, Risk Factors, Sick Role, Statistics as Topic, Stress, Psychological, Young Adult},
pages = {76--82},
}

@article{kakumanu_building_2017,
title = {Building school health partnerships to improve pediatric asthma care: the {School}-based {Asthma} {Management} {Program}},
volume = {17},
issn = {1473-6322},
shorttitle = {Building school health partnerships to improve pediatric asthma care},
doi = {10.1097/ACI.0000000000000347},
abstract = {PURPOSE OF REVIEW: Children with asthma require care that is seamlessly coordinated so that asthma symptoms are recognized and managed at home and at school. The purpose of this review is to discuss recent consensus recommendations in school-based asthma care.
RECENT FINDINGS: The School-based Asthma Management Program (SAMPRO) provides a widely endorsed framework to coordinate care with schools and consists of four components: establishing a circle of support around the child with asthma; facilitating bidirectional communication between clinicians and schools; comprehensive asthma education for schools; and assessment and remediation of environmental asthma triggers at school. SAMPRO standardizes recommendations for school-based asthma care coordination and provides a toolkit with websites and resources useful for the care of children with asthma in the school setting.
SUMMARY: The review will discuss the need for coordinated school asthma partnerships, the inception and development of SAMPRO, and its vision to improve pediatric asthma care coordination within the circle of support, comprising clinicians, school nurses, families, and communities.},
language = {eng},
number = {2},
journal = {Current Opinion in Allergy and Clinical Immunology},
author = {Kakumanu, Sujani and Antos, Nicholas and Szefler, Stanley J. and Lemanske, Robert F.},
month = apr,
year = {2017},
pmid = {28177950},
keywords = {Allergy and Immunology, Animals, Asthma, Child, Consensus, Disease Management, Humans, Partnership Practice, Pediatrics, School Health Services},
pages = {160--166},
}

@article{gautier_environmental_2017,
title = {Environmental triggers and avoidance in the management of asthma},
volume = {10},
issn = {1178-6965},
doi = {10.2147/JAA.S121276},
abstract = {Identifying asthma triggers forms the basis of environmental secondary prevention. These triggers may be allergenic or nonallergenic. Allergenic triggers include indoor allergens, such as house dust mites (HDMs), molds, pets, cockroaches, and rodents, and outdoor allergens, such as pollens and molds. Clinical observations provide support for the role of HDM exposure as a trigger, although avoidance studies provide conflicting results. Molds and their metabolic products are now considered to be triggers of asthma attacks. Pets, dogs, and especially cats can undoubtedly trigger asthmatic symptoms in sensitized subjects. Avoidance is difficult and rarely adhered to by families. Cockroach allergens contribute to asthma morbidity, and avoidance strategies can lead to clinical benefit. Mouse allergens are mostly found in inner-city dwellings, but their implication in asthma morbidity is debated. In the outdoors, pollens can induce seasonal asthma in sensitized individuals. Avoidance relies on preventing pollens from getting into the house and on minimizing seasonal outdoor exposure. Outdoor molds may lead to severe asthma exacerbations. Nonallergenic triggers include viral infections, active and passive smoking, meteorological changes, occupational exposures, and other triggers that are less commonly involved. Viral infection is the main asthma trigger in children. Active smoking is associated with higher asthma morbidity, and smoking cessation interventions should be personalized. Passive smoking is also a risk factor for asthma exacerbation. The implementation of public smoking bans has led to a reduction in the hospitalization of asthmatic children. Air pollution levels have been linked with asthmatic symptoms, a decrease in lung function, and increased emergency room visits and hospitalizations. Since avoidance is not easy to achieve, clean air policies remain the most effective strategy. Indoor air is also affected by air pollutants, such as cigarette smoke and volatile organic compounds generated by building and cleaning materials. Occupational exposures include work-exacerbated asthma and work-related asthma.},
language = {eng},
journal = {Journal of Asthma and Allergy},
author = {Gautier, Clarisse and Charpin, Denis},
year = {2017},
pmid = {28331347},
pmcid = {PMC5349698},
keywords = {Asthma, Environment, avoidance, prevention, triggers},
pages = {47--56},
}

@article{sarafino_relationships_1998,
title = {Relationships among respiratory infections, triggers of attacks, and asthma severity in children},
volume = {35},
issn = {0277-0903},
abstract = {The present study of asthmatic children examined relationships among the frequencies of prior respiratory infections (i.e., those prior to the development of asthma) and recent (past year) respiratory infections, asthma severity, and the impacts of 12 common asthma triggers: air pollution, allergy problems, anger, cigarette smoke, excitement, high humidity, high or low environmental temperature, laughter, nighttime hours, physical activity, respiratory infection, and stress or worry. Data on these variables were obtained through a survey in which 325 families completed questionnaires; 121 families had asthmatic children who were 2-20 years of age. Pearson correlational analyses revealed many significant positive correlations: The frequencies of prior and recent infections were correlated. The frequency of prior infections was correlated with the impacts of all asthma triggers except allergy problems, but the frequency of recent infections was correlated only with the impacts of air pollution, cigarette smoke, respiratory infection, and nighttime hours as triggers of asthma attacks. Asthma severity was correlated with the frequencies of prior and recent respiratory infections and with the impact of respiratory infection as an asthma trigger.},
language = {eng},
number = {6},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Sarafino, E. P. and Dillon, J. M.},
year = {1998},
pmid = {9751067},
keywords = {Adolescent, Adult, Asthma, Child, Child, Preschool, Data Collection, Female, Humans, Male, Respiratory Tract Infections, Severity of Illness Index, Statistics as Topic, United States},
pages = {497--504},
}

@article{dautel_asthma_1999,
title = {Asthma triggers in the elementary school environment: a pilot study},
volume = {36},
issn = {0277-0903},
shorttitle = {Asthma triggers in the elementary school environment},
abstract = {Asthma, a major cause of school absenteeism, can be triggered by allergens and irritants in the child's environment. A new measurement tool, the Environmental Observation Checklist (EOC), was developed and piloted for qualitative assessment of indoor asthma triggers (allergens and irritants), adequacy of ventilation, and existing environmental control practices. Seventy-five classrooms in 20 schools from two large urban school districts in Texas were surveyed using the EOC. A Q-TRAK Air Quality Monitor was used to assess indoor carbon dioxide, temperature, and relative humidity, concurrently. The EOC appears to be a useful screening tool for identifying schools in need of intervention.},
language = {eng},
number = {8},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Dautel, P. J. and Whitehead, L. and Tortolero, S. and Abramson, S. and Sockrider, M. M.},
month = dec,
year = {1999},
pmid = {10609624},
keywords = {Air Pollutants, Air Pollution, Indoor, Allergens, Asthma, Cross-Sectional Studies, Humans, Irritants, Pilot Projects, Schools, Ventilation},
pages = {691--702},
}

@article{weiss_prevalence_2001,
title = {The prevalence of environmental exposure to perceived asthma triggers in children with mild-to-moderate asthma: data from the {Childhood} {Asthma} {Management} {Program} ({CAMP})},
volume = {107},
issn = {0091-6749},
shorttitle = {The prevalence of environmental exposure to perceived asthma triggers in children with mild-to-moderate asthma},
doi = {10.1067/mai.2001.113869},
abstract = {BACKGROUND: The Childhood Asthma Management Program, a 5-year randomized clinical trial of treatments for childhood asthma, has enrolled and characterized a cohort of 1041 children with mild-to-moderate asthma.
OBJECTIVE: We sought to describe self-reported sensitivities and environmental exposures and investigate the relationships between self-report of these exposures as asthma triggers and their prevalence in the home.
METHODS: Self-reports of sensitivities and home exposures were obtained by interview with the child or parent. Sensitivities were further assessed by using allergy skin testing (prick or puncture) against a core battery of allergens. Home exposures were further assessed by using analysis of a home dust sample.
RESULTS: Environmental exposures were surprisingly common despite self-reported sensitivities to environmental factors. Of patients reporting that cigarette smoking frequently causes asthma symptoms, 26\% reported having at least one parent who smokes cigarettes. Thirty-nine percent of patients reporting that exposure to animals frequently causes asthma symptoms live with a furry pet in their home. We found a smaller proportion of homes with a high level of cat allergen (P {\textless}.001) among the children who reported that animals frequently or always trigger asthma symptoms compared with those who reported that animals never or occasionally trigger asthma symptoms, suggesting modification of the home environment. No such results were seen for dog exposure. However, clinical symptoms did not reduce exposure to parental cigarette smoking (P =.15), house dust (P =.31), or damp and musty areas (P =.51).
CONCLUSION: These data suggest that children with mild-to-moderate asthma are frequently symptomatic and exposed to a wide variety of environmental exposures that are perceived to trigger symptoms by means of self-report. Although environmental modification of asthmatic homes may occur, many children remain exposed to agents that are known to trigger their asthma.},
language = {eng},
number = {4},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Weiss, S. T. and Horner, A. and Shapiro, G. and Sternberg, A. L. and {Childhood Asthma Management Program (CAMP) Research Group}},
month = apr,
year = {2001},
pmid = {11295651},
keywords = {Asthma, Child, Child, Preschool, Environmental Exposure, Female, Humans, Infant, Male, Skin Tests, Smoking},
pages = {634--640},
}

@article{sarafino_role_2001,
title = {The role of age at asthma diagnosis in the development of triggers of asthma episodes},
volume = {51},
issn = {0022-3999},
abstract = {This study examined the relationship of age at asthma diagnosis to the subsequent impacts of 12 common asthma triggers, which we classified as either mainly physically based or strongly psychosocially mediated. The physically based triggers were air pollution, cigarette smoke, high humidity, high/low environmental temperature, allergy problems, respiratory infection, physical activity, and nighttime hours; the psychosocially mediated triggers were stress or worry, anger, excitement, and laughter. Data were collected with questionnaires from families with asthmatic children (n=115), 2 to 20 years of age, as part of a larger study of biological and psychosocial factors in asthma and other illnesses. Using parents' reports, we classified the children as early-diagnosed (before age 2) or later-diagnosed (at or after 2) for asthma and compared these groups, separated by gender, in 2 x 2 multivariate analyses. The impacts of all four psychosocially mediated triggers on asthma attacks were significantly greater for the later-diagnosed children than the early-diagnosed children. No age of diagnosis differences were found for any of the physically based triggers, and no gender or interaction effects were found for either type of trigger.},
language = {eng},
number = {5},
journal = {Journal of Psychosomatic Research},
author = {Sarafino, E. P. and Gates, M. and DePaulo, D.},
month = nov,
year = {2001},
pmid = {11728502},
keywords = {Age Factors, Asthma, Child, Child, Preschool, Chronic Disease, Female, Humans, Male, Surveys and Questionnaires},
pages = {623--628},
}

@article{mo_analysis_2003,
title = {Analysis of prevalence, triggers, risk factors and the related socio-economic effects of childhood asthma in the {Student} {Lung} {Health} {Survey} ({SLHS}) database, {Canada} 1996},
volume = {15},
issn = {0334-0139},
abstract = {The purpose of this study was to provide information to improve the management of childhood asthma in Canada. The Student Lung Health Survey (SLHS) was conducted as a stratified and multi-staged cluster survey across Canada in 1996. It included a total of 136 public, private and separate schools in nine health units. The target study population was schoolchildren aged 5 to 19 years. Among all 5-19 years old students, the prevalence of asthma was 13.0\%, with the prevalence for males being higher than for females, the adjusted Odds Ratio (OR) was 1.17, (95\% CI 1.14-1.19) for males, in comparison with females. The prevalence in the 15-19 age group was higher than that in the 5-9 and 10-14 age group in females, but it was higher in the 5-9 and 10-14 age group than in the 15-19 age group in males. The mean delay from the onset of symptoms to time of first diagnosis was 1, 0.4 and 0.3 years for the 1-4, 5-9 and 10-14 age group respectively. However, there was no delay in the 15-19 group. The prevalence of asthma in Prince Edward Island (17.9\%), Halifax (17.1\%), and Kingston (16.1\%) was higher than that in Saskatoon (10.0\%). Sherbrooke (9.7\%) and Kelowna (11.9\%). The proportion of asthma for students who smoked more than 11 cigarettes per day (OR = 1.41), were exposed to passive smoke in home (OR = 7.29), in car (OR = 4.71), and in school (OR = 4.24) or had a family income less than CAN\$40,000 (OR = 1.19), was significantly higher than groups without those factors. Risk factors and socio-economic status such as living conditions and environment, pets or plants in the home, parental education levels also affected the morbidity of asthma. The results of the SLHS study demonstrated the serious burden of childhood asthma, and asthma triggers, living and environmental conditions and lifestyle influence the prevalence and the effects of childhood asthma diagnosis, treatment, and education in Canada. Asthma is still a serious chronic condition for students and it influences their academic performance and their quality of life. The diagnostic methods and the practice guidelines for asthma control are useful for preventing and controlling asthma. These findings provide indications of interventions are being used for the control of asthma in Canada.},
language = {eng},
number = {4},
journal = {International Journal of Adolescent Medicine and Health},
author = {Mo, Frank and Robinson, Chris and Choi, Bernard C. and Li, Felix C.},
month = dec,
year = {2003},
pmid = {14719417},
keywords = {Adolescent, Adult, Age distribution, Asthma, Canada, Child, Child, Preschool, Cost of Illness, Female, Geography, Humans, Logistic Models, Male, Population Surveillance, Prevalence, Public Health Informatics, Risk Factors, Schools, Sex Distribution, Smoking, Socioeconomic Factors},
pages = {349--358},
}

@article{takaro_effect_2004,
title = {Effect of environmental interventions to reduce exposure to asthma triggers in homes of low-income children in {Seattle}},
volume = {14 Suppl 1},
issn = {1053-4245},
doi = {10.1038/sj.jea.7500367},
abstract = {The effectiveness of community health workers (CHWs) assisting families in reducing exposure to indoor asthma triggers has not been studied. In all, 274 low-income asthmatic children were randomly assigned to high- or low-intensity groups. CHWs visited all homes to assess exposures, develop action plans and provide bedding encasements. The higher-intensity group also received cleaning equipment and five to nine visits over a year focusing on asthma trigger reduction. The asthma trigger composite score decreased from 1.56 to 1.19 (Delta=-0.37, 95\% CI 0.13, 0.61) in the higher-intensity group and from 1.63 to 1.43 in the low-intensity group (Delta=-0.20, 95\% CI 0.004, 0.4). The difference in this measure due to the intervention was significant at the P=0.096 level. The higher-intensity group also showed improvement during the intervention year in measurements of condensation, roaches, moisture, cleaning behavior, dust weight, dust mite antigen, and total antigens above a cut point, effects not demonstrated in the low-intensity group. CHWs are effective in reducing asthma trigger exposure in low-income children. Further research is needed to determine the effectiveness of specific interventions and structural improvements on asthma trigger exposure and health.},
language = {eng},
journal = {Journal of Exposure Analysis and Environmental Epidemiology},
author = {Takaro, Tim K. and Krieger, James W. and Song, Lin},
year = {2004},
pmid = {15118754},
keywords = {Air Pollution, Indoor, Animals, Antigens, Asthma, Child, Child, Preschool, Cockroaches, Community Health Workers, Dust, Education, Female, Housing, Humans, Hygiene, Male, Poverty, Urban Population, Washington},
pages = {S133--143},
}

@article{cabana_parental_2004,
title = {Parental management of asthma triggers within a child's environment},
volume = {114},
issn = {0091-6749},
doi = {10.1016/j.jaci.2004.04.047},
abstract = {BACKGROUND: Control of environmental precipitants of asthma is an important component of self-management.
OBJECTIVE: To assess the type and frequency of attempts by families to control environmental precipitants of symptoms and their degree of consistency with current guidelines.
METHODS: We analyzed data from a nationwide sample of 896 children (2-12 years) with asthma. We collected data on insurance, race, sex, income, asthma education exposure, and severity. Parents were asked open-ended questions about their child's asthma triggers and what, if any, actions they took to control these triggers.
RESULTS: We completed interviews with the parents of 896 of 1077 (83\%) eligible patients. Patients had a mean age of 7.2 years, 65\% were boys, 13\% had Medicaid insurance, 12\% were African American, and 31\% had persistent asthma. Eighty percent (717/896) of parents could identify at least 1 asthma trigger (mean, 2.2; range, 0-9). Eighty-two percent (582/717) of these parents had attempted an environmental control measure. Of 1788 actions initiated, 916 (51\%) were unlikely to be beneficial on the basis of current guidelines. No specific demographic characteristic predicted which parents were more or less likely to institute environmental controls.
CONCLUSION: In our sample, more than half (51\%) of the environmental actions initiated were not specifically endorsed by current guidelines. Improving awareness about recognized methods to address triggers may help families use more effective measures. Clinicians should not assume that they can predict which families will be more or less likely to attempt environmental control, but should provide education regarding effective environmental measures for all families with potentially modifiable asthma triggers},
language = {eng},
number = {2},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Cabana, Michael D. and Slish, Kathryn K. and Lewis, Toby C. and Brown, Randall W. and Nan, Bin and Lin, Xihong and Clark, Noreen M.},
month = aug,
year = {2004},
pmid = {15316515},
keywords = {Asthma, Child, Environment, Female, Humans, Male, Parents},
pages = {352--357},
}

@article{krieger_seattle-king_2005,
title = {The {Seattle}-{King} {County} {Healthy} {Homes} {Project}: a randomized, controlled trial of a community health worker intervention to decrease exposure to indoor asthma triggers},
volume = {95},
issn = {0090-0036},
shorttitle = {The {Seattle}-{King} {County} {Healthy} {Homes} {Project}},
doi = {10.2105/AJPH.2004.042994},
abstract = {OBJECTIVES: We assessed the effectiveness of a community health worker intervention focused on reducing exposure to indoor asthma triggers.
METHODS: We conducted a randomized controlled trial with 1-year follow-up among 274 low-income households containing a child aged 4-12 years who had asthma. Community health workers provided in-home environmental assessments, education, support for behavior change, and resources. Participants were assigned to either a high-intensity group receiving 7 visits and a full set of resources or a low-intensity group receiving a single visit and limited resources.
RESULTS: The high-intensity group improved significantly more than the low-intensity group in its pediatric asthma caregiver quality-of-life score (P=.005) and asthma-related urgent health services use (P=.026). Asthma symptom days declined more in the high-intensity group, although the across-group difference did not reach statistical significance (P=.138). Participant actions to reduce triggers generally increased in the high-intensity group. The projected 4-year net savings per participant among the high-intensity group relative to the low-intensity group were 189-721 dollars.
CONCLUSIONS: Community health workers reduced asthma symptom days and urgent health services use while improving caregiver quality-of-life score. Improvement was greater with a higher-intensity intervention.},
language = {eng},
number = {4},
journal = {American Journal of Public Health},
author = {Krieger, James W. and Takaro, Tim K. and Song, Lin and Weaver, Marcia},
month = apr,
year = {2005},
pmid = {15798126},
pmcid = {PMC1449237},
keywords = {Air Pollution, Indoor, Asthma, Chi-Square Distribution, Child, Child, Preschool, Community Health Services, Community Health Workers, Female, Housing, Humans, Logistic Models, Male, Poverty, Prevalence, Program Evaluation, Risk Factors, Statistics, Nonparametric, Urban Health, Washington},
pages = {652--659},
}

@article{martin_reducing_2006,
title = {Reducing home triggers for asthma: the {Latino} community health worker approach},
volume = {43},
issn = {0277-0903},
shorttitle = {Reducing home triggers for asthma},
doi = {10.1080/02770900600709781},
abstract = {This study assessed the ability of a community health worker asthma intervention to change home asthma triggers. A total of 56 children and 47 adults with asthma were enrolled. Home trigger scores for the children averaged 2.8 at the initial home visit and then 2.3, 2.1, and 2.0 at 3, 6, and 12 months. Home trigger scores for the adults showed a similar trend. Every home visit was associated with a 0.32 reduction in home trigger score (p {\textless} 0.01) for children and a 0.41 reduction (p {\textless} 0.01) for adults. This intervention shows promise as a way to reduce asthma triggers in urban low-income Latino communities.},
language = {eng},
number = {5},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Martin, Molly A. and Hernández, Olivia and Naureckas, Edward and Lantos, John},
month = jul,
year = {2006},
pmid = {16801141},
keywords = {Adolescent, Adult, Aged, Asthma, Chicago, Child, Child, Preschool, Community Health Workers, Environmental Exposure, Female, Health Education, Hispanic Americans, Housing, Humans, Infant, Male, Middle Aged, Poverty, Socioeconomic Factors, Urban Population},
pages = {369--374},
}

@article{ritz_asthma_2006,
title = {The asthma trigger inventory: validation of a questionnaire for perceived triggers of asthma},
volume = {68},
issn = {1534-7796},
shorttitle = {The asthma trigger inventory},
doi = {10.1097/01.psy.0000248898.59557.74},
abstract = {BACKGROUND: Asthma patients' perceptions of triggers have been explored in a largely unstructured fashion in the past. We therefore developed and validated a questionnaire of commonly perceived asthma triggers.
METHODS: Two hundred forty-seven primary care patients with asthma filled in an asthma trigger survey together with questionnaires on demographics, asthma-relevant information, perceived control of asthma, and general health status. Factor structure of the item pool and psychometric properties of trigger subscales were evaluated. We also investigated the relationship between allergen or psychological trigger reports and allergy skin test response or respiratory impedance during emotional film viewing, respectively.
RESULTS: Principal component analysis yielded six factors that were thematically associated with psychology, animal allergens, pollen allergens, physical activity, infection, and air pollution/irritants. Subscales showed good internal consistencies and low to moderately positive intercorrelations. Psychological triggers were consistently associated with less favorable health status, a reduced perception of asthma control, and greater medical treatment utilization. Animal allergen scores correlated positively with skin test responses to animal allergens. Respiratory impedance increases during emotional film clips were positively correlated with the psychological trigger subscale.
CONCLUSION: The questionnaire is a reliable measure of commonly perceived asthma triggers. Aspects of patients' trigger reports reflect actual reactivity to specific trigger factors.},
language = {eng},
number = {6},
journal = {Psychosomatic Medicine},
author = {Ritz, Thomas and Steptoe, Andrew and Bobb, Carol and Harris, Alexander H. S. and Edwards, Martin},
month = dec,
year = {2006},
pmid = {17132841},
keywords = {Adult, Asthma, Female, Health Services, Health Status, Health Surveys, Humans, Male, Middle Aged, Psychometrics, Skin Tests, Surveys and Questionnaires},
pages = {956--965},
}

@article{shendell_outdoor_2007,
title = {The outdoor air quality flag program in central {California}: a school-based educational intervention to potentially help reduce children's exposure to environmental asthma triggers},
volume = {70},
issn = {0022-0892},
shorttitle = {The outdoor air quality flag program in central {California}},
abstract = {This paper describes a novel school-based, visual environmental public health educational intervention intended to help reduce the exposure of children-and adults-to outdoor air pollution, including known environmental asthma triggers like ozone and particles. The overarching goal was to enhance the learning, recreational, and work environments of students and staff. The specific purpose of the Asthma-Friendly Outdoor (Ambient) Air Quality Flag Program was to establish an education and communication tool for Central California communities that would accomplish two things: (1) Establish permanent local policy change to existing operating procedures in school districts and schools to help reduce the exposure of students, teachers, staff, and nearby communities to outdoor environmental asthma triggers and (2) provide education on air quality and potential health effects of exposure to air pollutants. Data on the program from its initial years are presented. To date, the following important lessons have been learned: (1) Science-based, simple, visual, low-cost school-based educational interventions to help reduce human exposure to outdoor environmental asthma triggers (i.e., ozone, particles, and pollens) can work in socioeconomically and ethnically diverse urban and rural or agricultural communities, and (2) local health and environmental justice groups such as asthma coalitions can successfully lead school-based environmental interventions to help improve children's quality of life.},
language = {eng},
number = {3},
journal = {Journal of Environmental Health},
author = {Shendell, Derek G. and Rawling, Mary-Michal and Foster, Christine and Bohlke, Alicia and Edwards, Bobbie and Rico, Susie A. and Felix, Justina and Eaton, Sandra and Moen, Stephanie and Roberts, Eric M. and Love, Mary Beth},
month = oct,
year = {2007},
pmid = {17941400},
keywords = {Air Pollutants, Asthma, California, Child, Child Welfare, Community Participation, Environmental Exposure, Environmental Health, Humans, Ozone, Particulate Matter, Schools},
pages = {28--31},
}

@article{ritz_perceived_2008,
title = {Perceived triggers of asthma: evaluation of a {German} version of the {Asthma} {Trigger} {Inventory}},
volume = {102},
issn = {0954-6111},
shorttitle = {Perceived triggers of asthma},
doi = {10.1016/j.rmed.2007.10.009},
abstract = {BACKGROUND AND OBJECTIVE: Patients' perception of asthma triggers has been explored in a largely unstructured fashion in the past. Therefore, we developed the Asthma Trigger Inventory (ATI), a questionnaire that allows for a psychometrically valid measurement of patients' perceived asthma triggers. Here we evaluate a German language version of the ATI and studied the relationship of subscales with self-reported health status, health care use, psychopathology, and results of allergy skin testing.
METHOD: Data were obtained from 370 asthma patients recruited from the community, primary care, and in-patient asthma treatment and education.
RESULTS: Analysis revealed a five-factor structure that largely confirmed results with the English original. Reliability was good to satisfactory (Cronbach's alpha=0.77-0.89) for allergy, exercise, air pollution/irritants, infection, and psychological trigger subscales. In hierarchical regression analysis adjusting for demographics and asthma severity, asthma patients with stronger non-allergic triggers showed less physical and mental well-being and more asthma-related health care use. Psychological triggers showed unique associations with anxious and depressed mood. Pollen and animal allergen scores of the ATI were significantly related to skin test results for relevant allergens. Non-allergic but not allergic triggers showed substantial associations with asthma control.
CONCLUSION: The German version of the ATI reliably measures asthma patients' trigger perceptions. Non-specific asthma triggers exert a greater burden on patients' well-being and primary health care use.},
language = {eng},
number = {3},
journal = {Respiratory Medicine},
author = {Ritz, Thomas and Kullowatz, Antje and Kanniess, Frank and Dahme, Bernhard and Magnussen, Helgo},
month = mar,
year = {2008},
pmid = {18061421},
keywords = {Adolescent, Adult, Aged, Asthma, Female, Health Services, Health Status, Humans, Male, Middle Aged, Patient Acceptance of Health Care, Psychometrics, Severity of Illness Index, Surveys and Questionnaires},
pages = {390--398},
}

@article{ritz_psychological_2008,
title = {Psychological triggers and hyperventilation symptoms in asthma},
volume = {100},
issn = {1081-1206},
doi = {10.1016/S1081-1206(10)60466-8},
abstract = {BACKGROUND: Anecdotal accounts have identified hyperventilation as one route through which psychological factors can trigger bronchoconstriction. However, little is known about the empirical association between psychological and other trigger factors and hyperventilation in asthma exacerbations.
OBJECTIVE: To study the cross-sectional association between perceived triggers and hyperventilation symptoms in 1 British and 1 German sample of patients with asthma who were recruited from the community and from primary care clinics.
METHOD: Patients completed relevant language versions of the Asthma Trigger Inventory and the Asthma Symptom Checklist.
RESULTS: After controlling for demographics and asthma severity, perceived asthma triggers measured by subscales of the Asthma Trigger Inventory explained 12.5\% to 37.3\% of the variance in Asthma Symptom Checklist hyperventilation-hypocapnia symptoms. Psychological triggers accounted for 10.6\% to 26.7\% of the variance alone and 4.3\% to 11.0\% of the variance over and above other trigger factors. In contrast, perceived animal and pollen allergen triggers did not contribute unique variance to the hyperventilation symptom report. Psychological triggers did not explain variance in classic airway obstruction symptoms, thus arguing against a general bias toward inflated symptom reports in patients with psychologically induced asthma.
CONCLUSION: Differences in perceived asthma triggers are substantially associated with hyperventilation symptoms, and patients with more frequent psychological triggers also tend to report that they experience more hyperventilation symptoms during their asthma symptom episodes.},
language = {eng},
number = {5},
journal = {Annals of Allergy, Asthma \& Immunology: Official Publication of the American College of Allergy, Asthma, \& Immunology},
author = {Ritz, Thomas and Kullowatz, Antje and Bobb, Carol and Dahme, Bernhard and Magnussen, Helgo and Kanniess, Frank and Steptoe, Andrew},
month = may,
year = {2008},
pmid = {18517073},
keywords = {Adult, Asthma, Cross-Sectional Studies, Female, Germany, Humans, Hyperventilation, Linear Models, Male, Middle Aged, Psychometrics, Surveys and Questionnaires, United Kingdom},
pages = {426--432},
}

@article{myatt_control_2008,
title = {Control of asthma triggers in indoor air with air cleaners: a modeling analysis},
volume = {7},
issn = {1476-069X},
shorttitle = {Control of asthma triggers in indoor air with air cleaners},
doi = {10.1186/1476-069X-7-43},
abstract = {BACKGROUND: Reducing exposure to environmental agents indoors shown to increase asthma symptoms or lead to asthma exacerbations is an important component of a strategy to manage asthma for individuals. Numerous investigations have demonstrated that portable air cleaning devices can reduce concentrations of asthma triggers in indoor air; however, their benefits for breathing problems have not always been reproducible. The potential exposure benefits of whole house high efficiency in-duct air cleaners for sensitive subpopulations have yet to be evaluated.
METHODS: We used an indoor air quality modeling system (CONTAM) developed by NIST to examine peak and time-integrated concentrations of common asthma triggers present in indoor air over a year as a function of natural ventilation, portable air cleaners, and forced air ventilation equipped with conventional and high efficiency filtration systems. Emission rates for asthma triggers were based on experimental studies published in the scientific literature.
RESULTS: Forced air systems with high efficiency filtration were found to provide the best control of asthma triggers: 30-55\% lower cat allergen levels, 90-99\% lower risk of respiratory infection through the inhalation route of exposure, 90-98\% lower environmental tobacco smoke (ETS) levels, and 50-75\% lower fungal spore levels than the other ventilation/filtration systems considered. These results indicate that the use of high efficiency in-duct air cleaners provide an effective means of controlling allergen levels not only in a single room, like a portable air cleaner, but the whole house.
CONCLUSION: These findings are useful for evaluating potential benefits of high efficiency in-duct filtration systems for controlling exposure to asthma triggers indoors and for the design of trials of environmental interventions intended to evaluate their utility in practice.},
language = {eng},
journal = {Environmental Health: A Global Access Science Source},
author = {Myatt, Theodore A. and Minegishi, Taeko and Allen, Joseph G. and Macintosh, David L.},
month = aug,
year = {2008},
pmid = {18684328},
pmcid = {PMC2543006},
keywords = {Air Conditioning, Air Pollution, Indoor, Allergens, Animals, Asthma, Cats, Environmental Exposure, Environmental Monitoring, Humans, Orthomyxoviridae, Particulate Matter, Rhinovirus, Spores, Fungal, Tobacco Smoke Pollution, Ventilation, filtration},
pages = {43},
}

@article{goksel_triggers_2009,
title = {Triggers in adult asthma: are patients aware of triggers and doing right?},
volume = {37},
issn = {0301-0546},
shorttitle = {Triggers in adult asthma},
doi = {10.1016/S0301-0546(09)71723-9},
abstract = {BACKGROUND: As triggers have a potential to induce asthma exacerbations, awareness of the patients to individual triggers as well as protective measures might be helpful to prevent asthma attacks. Though allergens and allergen avoidance have been studied extensively, there are only few studies on non-allergic triggers and their avoidance for adult patients with asthma. In this study, we wanted to investigate asthma triggers and compliance to the preventive measures in an adult population.
METHODS: One hundred and thirty one adult asthma patients were enrolled into the study. A face to face interview was done by using a questionnaire including individual asthma triggers, prevention measures against major modifiable triggers and knowledge sources of the cases.
RESULTS: Regardless of asthma severity, 59.5 \% of the subjects reported to be triggered by more than 10 factors. The most common triggers were air pollutants (89.3 \%) and weather changes (81.7 \%). Severe group was more frequently affected by medications, emotional stress, weather changes and indoor pollutants than other severity groups (p=0.017, 0.014, 0.049 and 0.018, respectively) whereas stress was reported more frequently by females than males. Prevention measures were insufficient regarding some major triggers.
CONCLUSION: Adult patients are vulnerable to several triggers regardless from underlying severity of the illness. Insufficient compliance to the major preventive measures indicates that new strategies are needed to prevent asthma attacks caused by modifiable triggers.},
language = {eng},
number = {3},
journal = {Allergologia Et Immunopathologia},
author = {Göksel, Ozlem and Celik, Gülfem E. and Erkekol, Ferda Oner and Güllü, Emine and Mungan, Dilşad and Misirligil, Zeynep},
month = jun,
year = {2009},
pmid = {19769844},
keywords = {Adult, Air Pollutants, Asthma, Disease Progression, Drug-Related Side Effects and Adverse Reactions, Female, Humans, Male, Middle Aged, Patient Education as Topic, Prognosis, Sex Factors, Socioeconomic Factors, Stress, Psychological, Surveys and Questionnaires},
pages = {122--128},
}

@article{rank_trigger_2010,
title = {Trigger recognition and management in poorly controlled asthmatics},
volume = {31},
issn = {1539-6304},
doi = {10.2500/aap.2010.31.3405},
abstract = {Previous studies using cross-sectional designs suggest that asthma trigger recognition and management are suboptimal in clinical practice. The objective of this study was to assess gaps between asthma guideline recommendations and clinical practice regarding asthma trigger recognition and management by tracking poorly controlled asthma patients over a 2-year period. A retrospective cohort study of a representative sample of 102 children and adult residents of Olmsted County, MN, with poor asthma control in 2003-2004 was performed. All medical records from each asthma-related visit were examined for documented asthma trigger inquiries, specific trigger avoidance advice, and for adherence to the trigger avoidance advice. One hundred two subjects made 686 asthma-related visits that were included for analysis. At least 1 trigger inquiry occurred in 83\% of visits, with an average of 2.0 triggers queried per visit. The most common trigger inquiries were for infection (47\%), environmental tobacco smoke (41\%), and allergens (29\%). The mean number of triggers queried was higher during exacerbation visits versus nonexacerbation visits (2.1 versus 1.8; p {\textless} 0.001) and in the emergency care settings compared with outpatient settings (2.4 versus 1.7; p {\textless} 0.001). Advice for managing asthma triggers was given in 30\% of visits and adherence to trigger advice was evaluated at 6\% of visits. Future interventions for improving asthma trigger management should be targeted to routine asthma outpatient visits, where trigger avoidance advice is infrequent and rarely addressed in follow-up visits.},
language = {eng},
number = {6},
journal = {Allergy and Asthma Proceedings},
author = {Rank, Matthew A. and Wollan, Peter and Li, James T. and Yawn, Barbara P.},
month = dec,
year = {2010},
pmid = {20977834},
pmcid = {PMC3233838},
keywords = {Adult, Advance Directive Adherence, Asthma, Child, Cohort Studies, Delivery of Health Care, Female, Follow-Up Studies, Humans, Immunization, Male, Minnesota, Patient Education as Topic, Practice Guidelines as Topic, Retrospective Studies},
pages = {99--105},
}

@article{washington_communication_2012,
title = {Communication and education about triggers and environmental control strategies during pediatric asthma visits},
volume = {86},
issn = {1873-5134},
doi = {10.1016/j.pec.2011.04.015},
abstract = {OBJECTIVE: To determine the extent to which providers, caregivers, and pediatric asthma patients discussed environmental trigger control during primary care visits, and any demographic characteristics associated with having these discussions.
METHODS: Children ages 8-16 with persistent asthma and their caregivers were recruited at five pediatric practices in non-urban areas of North Carolina. All of the medical visits were audio-tape recorded. We administered questionnaires to the child's caregiver following the visit.
RESULTS: Two hundred and ninety-six patients had useable audio-tape data. Providers typically discussed at least one type of asthma trigger during these visits (86\% of visits). The most common discussions were about exercise (70\%), the weather/season (42\%), and allergies/pollen (35\%). Environmental control strategies were discussed less frequently (27\% of visits). Providers educated the patient and their caregiver about environmental control strategies during 14\% of the visits.
CONCLUSION: Although providers frequently discuss some environmental triggers and provide education, there is room for more comprehensive discussions of these issues, which may contribute to decreased asthma exacerbations.
PRACTICE IMPLICATIONS: Providers, or alternatively, asthma health educators, should devote more time to discussing environmental asthma triggers and control strategies with pediatric asthma patients and their families, as they are important components of overall asthma control.},
language = {eng},
number = {1},
journal = {Patient Education and Counseling},
author = {Washington, Deidre and Yeatts, Karin and Sleath, Betsy and Ayala, Guadalupe X. and Gillette, Chris and Williams, Dennis and Davis, Stephanie and Tudor, Gail},
month = jan,
year = {2012},
pmid = {21600721},
pmcid = {PMC3168678},
keywords = {Adolescent, Adult, Aged, Asthma, Child, Child Welfare, Clinical Competence, Communication, Environmental Exposure, Environmental Health, Female, Health Knowledge, Attitudes, Practice, Humans, Male, Middle Aged, North Carolina, Patient Education as Topic, Pediatrics, Physician-Patient Relations, Risk Assessment, Tape Recording, Young Adult},
pages = {63--69},
}

@article{crocker_effectiveness_2011,
title = {Effectiveness of home-based, multi-trigger, multicomponent interventions with an environmental focus for reducing asthma morbidity: a community guide systematic review},
volume = {41},
issn = {1873-2607},
shorttitle = {Effectiveness of home-based, multi-trigger, multicomponent interventions with an environmental focus for reducing asthma morbidity},
doi = {10.1016/j.amepre.2011.05.012},
abstract = {CONTEXT: Asthma exacerbations are commonly triggered by exposure to allergens and irritants within the home. The purpose of this review was to evaluate evidence that interventions that target reducing these triggers through home visits may be beneficial in improving asthma outcomes. The interventions involve home visits by trained personnel to conduct two or more components that address asthma triggers in the home. Intervention components focus on reducing exposures to a range of asthma triggers (allergens and irritants) through environmental assessment, education, and remediation.
EVIDENCE ACQUISITION: Using methods previously developed for the Guide to Community Preventive Services, a systematic review was conducted to evaluate the evidence on effectiveness of home-based, multi-trigger, multicomponent interventions with an environmental focus to improve asthma-related morbidity outcomes. The literature search identified over 10,800 citations. Of these, 23 studies met intervention and quality criteria for inclusion in the final analysis.
EVIDENCE SYNTHESIS: In the 20 studies targeting children and adolescents, the number of days with asthma symptoms (symptom-days) was reduced by 0.8 days per 2 weeks, which is equivalent to 21.0 symptom-days per year (range of values: reduction of 0.6 to 2.3 days per year); school days missed were reduced by 12.3 days per year (range of values: reduction of 3.4 to 31.2 days per year); and the number of asthma acute care visits were reduced by 0.57 visits per year (interquartile interval: reduction of 0.33 to 1.71 visits per year). Only three studies reported outcomes among adults with asthma, finding inconsistent results.
CONCLUSIONS: Home-based, multi-trigger, multicomponent interventions with an environmental focus are effective in improving overall quality of life and productivity in children and adolescents with asthma. The effectiveness of these interventions in adults is inconclusive due to the small number of studies and inconsistent results. Additional studies are needed to (1) evaluate the effectiveness of these interventions in adults and (2) determine the individual contributions of the various intervention components.},
language = {eng},
number = {2 Suppl 1},
journal = {American Journal of Preventive Medicine},
author = {Crocker, Deidre D. and Kinyota, Stella and Dumitru, Gema G. and Ligon, Colin B. and Herman, Elizabeth J. and Ferdinands, Jill M. and Hopkins, David P. and Lawrence, Briana M. and Sipe, Theresa A. and {Task Force on Community Preventive Services}},
month = aug,
year = {2011},
pmid = {21767736},
keywords = {Adolescent, Adult, Allergens, Asthma, Child, Efficiency, Environmental Exposure, Environmental Restoration and Remediation, Home Care Services, House Calls, Housing, Humans, Quality of Life},
pages = {S5--32},
}

@article{oleary_asthma_2012,
title = {Asthma triggers on the {Cheyenne} {River} {Indian} {Reservation} in western {South} {Dakota}: the {Breathing} {Relief} {Education} and {Tribal} {Health} {Empowerment} ({BREATHE}) {Study}},
volume = {65},
issn = {0038-3317},
shorttitle = {Asthma triggers on the {Cheyenne} {River} {Indian} {Reservation} in western {South} {Dakota}},
abstract = {BACKGROUND: The purpose of this article is to better understand asthma triggers and possible causes of exacerbations among BREATHE participants on the Cheyenne River Indian Reservation in western South Dakota.
METHODS: To qualify for enrollment, participants had to have physician-diagnosed asthma, be uncontrolled and have persistent symptoms. Participants were asked to identify their top two asthma triggers throughout their one-year enrollment during initial visits and subsequent phone follow-ups. In addition, participant's medical records were reviewed for visits to the emergency department (ED) to demonstrate asthma exacerbations.
RESULTS: In 2008, 127 interviews were conducted with 45 enrolled participants for a total of 254 results. Overall, the three most common self reported triggers were cold air, dust and smoke and these comprised nearly half (48.4 percent) of all reports. Dust was reported in 16.5 percent of interviews and ranked among the top four for every season. Smoke (12.6 percent) and cold air (19.3 percent) were leaders in all seasons except summer, but humid air, pollens and strong odors were unique to summer. Exercise/activity ranked high during the winter and spring, but was reported less in summer and fall. There was no identifiable trend in ER visits by season.
CONCLUSION: People with asthma living on the Cheyenne River Indian Reservation or other locations with similar community and geographic demographics are most likely to suffer an asthma exacerbation from exposure to cold air, dust, smoke and exercise/activity. Asthma education is necessary on all levels, but information on avoidance and control of these most common reported triggers is especially important.},
language = {eng},
number = {2},
journal = {South Dakota Medicine: The Journal of the South Dakota State Medical Association},
author = {O'Leary, Rae and Wallace, James and {BREATH Study Research Group}},
month = feb,
year = {2012},
pmid = {22359973},
keywords = {Adolescent, Adult, Asthma, Child, Dust, Female, Humans, Humidity, Indians, North American, Interviews as Topic, Male, Middle Aged, Motor Activity, Odorants, Pollen, Prevalence, Risk Factors, Seasons, Smoke, South Dakota, Weather},
pages = {57, 59, 61 passim},
}

@article{peterson_history_2012,
title = {History of symptom triggers in patients presenting to the emergency department for asthma},
volume = {49},
issn = {1532-4303},
doi = {10.3109/02770903.2012.690480},
abstract = {OBJECTIVES: Understanding triggers is important for managing asthma particularly for patients who seek emergency department (ED) care for exacerbations. The objectives of this analysis were to delineate self-reported triggers in ED patients and to assess associations between triggers and asthma knowledge, severity, and quality of life.
METHODS: At the time of an ED visit, 296 patients were asked what were their usual asthma triggers based on a checklist of 25 potential items, and what they thought specifically precipitated their current ED visit. Using standardized scales, patients also were asked about asthma knowledge, severity, and quality of life.
RESULTS: The mean age was 44 years and 72\% were women. Patients cited a mean of 12 triggers; most patients had diverse triggers spanning respiratory infections, environmental irritants, emotions, allergens, weather, and exercise. Patients with more triggers were more likely to be women (odds ratio (OR) = 2.0, confidence interval (CI) = 1.3, 3.2, p = .002), obese (OR = 1.7, CI = 1.1, 2.5, p = .01), and to not have a smoking history (OR = 1.9, CI = 1.3, 2.9, p = .001). There were no associations between number of triggers and current age, age at diagnosis, education, socioeconomic status, or race/ethnicity. Patients who cited more triggers had more frequent flares (OR = 1.1, CI = 1.1, 1.2, p {\textless} .0001), worse quality of life scores (OR 1.6, CI = 1.1, 2.4, p = .02), and were more likely to have been previously hospitalized for asthma (OR = 1.9, CI = 1.3, 2.9, p = .003) and to have previously required oral corticosteroids (OR = 2.9, CI = 1.6, 5.1, p = .003). There was little clustering of specific triggers according to the variables we considered except for more frequent animal allergy in patients diagnosed at a younger age (OR = 2.8, CI = 1.7, 4.5, p {\textless} .0001) and worse quality of life in patients citing emotional stress as a trigger (OR = 2.5, CI = 1.5, 4.0, p = .0002). Patients attributed their current ED visit to multiple precipitants, particularly respiratory infections and weather, and these were concordant with what they reported were known triggers.
CONCLUSIONS: Patients presenting to the ED for asthma reported multiple triggers spanning diverse classes of precipitants and having more triggers was associated with worse clinical status. ED patients should be instructed that although it may not be possible to eliminate all triggers, mitigating even some triggers can be helpful.},
language = {eng},
number = {6},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Peterson, Margaret G. E. and Gaeta, Theodore J. and Birkhahn, Robert H. and Fernández, José L. and Mancuso, Carol A.},
month = aug,
year = {2012},
pmid = {22742414},
pmcid = {PMC3423316},
keywords = {Adult, Asthma, Emergency Service, Hospital, Female, Humans, Male, Middle Aged, Obesity, Quality of Life, Smoking, Surveys and Questionnaires},
pages = {629--636},
}

@article{vernon_what_2012,
title = {What do we know about asthma triggers? a review of the literature},
volume = {49},
issn = {1532-4303},
shorttitle = {What do we know about asthma triggers?},
doi = {10.3109/02770903.2012.738268},
abstract = {OBJECTIVE: For patients with asthma, exacerbations and poor control can result from exposure to environmental triggers, such as allergens and air particulates. This study reviewed the international literature to determine whether a global checklist of common asthma triggers might be feasible for use as a research or management tool in clinical practice.
METHODS: Literature published from 2002 to 2012 was identified through PubMed and EMBASE using the following search terms: asthma, asthma triggers, prevalence, among others. A total of 1046 abstracts were found; 85 articles were reviewed covering six continents (number of articles): Africa (1), Asia (22), Australia (1), Europe (27), North America (22), and South America (4).
RESULTS: The literature consistently pointed to asthma triggers as one contributor to poor asthma control. Frequently cited triggers were similar across countries/regions and included allergens (particularly pollens, molds, dust, and pet dander), tobacco smoke, exercise, air pollutants/particulates, weather patterns/changes, and respiratory infections. Definitions of asthma triggers, how triggers are taken into account in definitions of asthma control, and scientific inquiry into optimal management techniques for triggers were inconsistent and sparse.
CONCLUSIONS: Given the apparent importance of triggers in attaining and maintaining asthma control, empirical research concerning optimal trigger management is needed. Results demonstrate that asthma triggers are similar across continents, suggesting a global checklist of triggers for use in research and clinical practice would be feasible.},
language = {eng},
number = {10},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Vernon, Margaret K. and Wiklund, Ingela and Bell, Jill A. and Dale, Peter and Chapman, Kenneth R.},
month = dec,
year = {2012},
pmid = {23574397},
keywords = {Air Pollutants, Allergens, Asthma, Environment, Exercise, Global Health, Humans, Hypersensitivity, Particulate Matter, Respiratory Tract Infections, Tobacco Smoke Pollution, Weather},
pages = {991--998},
}

@article{martin_home_2013,
title = {Home asthma triggers: barriers to asthma control in {Chicago} {Puerto} {Rican} children},
volume = {24},
issn = {1548-6869},
shorttitle = {Home asthma triggers},
doi = {10.1353/hpu.2013.0073},
abstract = {We sought objectively to measure, summarize, and contextualize the asthma triggers found in the homes of urban high-risk Puerto Rican children and adolescents with asthma in Chicago. Data were from the baseline home assessments of Project CURA. Research assistants interviewed caregivers, conducted a home visual inspection, and collected saliva samples for cotinine analysis. A trigger behavior summary score was created. The housing inspected was old with multiple units and obvious structural deficiencies. Many allergic and irritant triggers were observed. Having a controller medicine or private insurance was associated with lower trigger behavior summary scores; caregiver depression, caregiver perceived stress, and child negative life events were associated with high trigger scores. The final multivariate model retained had a controller medicine, private insurance, and caregiver perceived stress. The data from this high-risk cohort identified modifiable areas where environmental interventions could reduce morbidity in Puerto Rican children and adolescents.},
language = {eng},
number = {2},
journal = {Journal of Health Care for the Poor and Underserved},
author = {Martin, Molly A. and Thomas, Ann Marie and Mosnaim, Giselle and Greve, Matthew and Swider, Susan M. and Rothschild, Steven K.},
month = may,
year = {2013},
pmid = {23728047},
keywords = {Adolescent, Allergens, Asthma, Caregivers, Chicago, Child, Preschool, Cotinine, Cross-Sectional Studies, Environmental Exposure, Female, Hispanic Americans, Housing, Humans, Male, Mental health, Puerto Rico, Saliva, Severity of Illness Index, Socioeconomic Factors, Tobacco Smoke Pollution, Urban Population},
pages = {813--827},
}

@article{turyk_multifaceted_2013,
title = {A multifaceted community-based asthma intervention in {Chicago}: effects of trigger reduction and self-management education on asthma morbidity},
volume = {50},
issn = {1532-4303},
shorttitle = {A multifaceted community-based asthma intervention in {Chicago}},
doi = {10.3109/02770903.2013.796971},
abstract = {OBJECTIVES: Home-based, multifaceted interventions have been effective in reducing asthma morbidity in children. However, identification of independent components that contribute to outcomes and delineating effectiveness by level of asthma symptoms would help to refine the intervention and target appropriate populations.
METHODS: A community health educator led asthma intervention implemented in a low-income African-American neighborhood included asthma management education, individually tailored low-cost asthma home trigger remediation, and referrals to social and medical agencies, when appropriate. Changes in asthma morbidity measures were assessed in relation to implementation of individual intervention components using multivariable logistic regression.
RESULTS: Among the 218 children who completed the year-long program, there were significant reductions in measures of asthma morbidity, including symptoms, urgent care visits, emergency department (ED) visits, hospitalizations, missed school days, and missed work days for caretakers. We also found significant decreases in the prevalence of many home asthma triggers and improvements in asthma management practices. Improvement in caretaker's ability to manage the child's asthma was associated with reduction in ED visits for asthma and uncontrolled asthma. Specific home interventions, such as repair of water leaks and reduced exposure to plants, dust, clutter and stuffed toys, may be related to reduction in asthma morbidity.
CONCLUSIONS: This program was effective in reducing asthma morbidity in low-income African-American children and identified specific interventions as possible areas to target in future projects. Furthermore, the intervention was useful in children with persistent asthma symptoms as well as those with less frequent asthma exacerbations.},
language = {eng},
number = {7},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Turyk, Mary and Banda, Elizabeth and Chisum, Gay and Weems, Dolores and Liu, Yangyang and Damitz, Maureen and Williams, Rhonda and Persky, Victoria},
month = sep,
year = {2013},
pmid = {23745594},
keywords = {Adolescent, African Americans, Anti-Asthmatic Agents, Asthma, Chicago, Child, Child, Preschool, Disease Management, Housing, Humans, Infant, Logistic Models, Multivariate Analysis, Patient Education as Topic, Poverty},
pages = {729--736},
}

@article{janssens_perceived_2013,
title = {Perceived triggers of asthma: key to symptom perception and management},
volume = {43},
issn = {1365-2222},
shorttitle = {Perceived triggers of asthma},
doi = {10.1111/cea.12138},
abstract = {Adequate asthma management depends on an accurate identification of asthma triggers. A review of the literature on trigger perception in asthma shows that individuals vary in their perception of asthma triggers and that the correlation between self-reported asthma triggers and allergy tests is only modest. In this article, we provide an overview of psychological mechanisms involved in the process of asthma triggers identification. We identify sources of errors in trigger identification and targets for behavioural interventions that aim to improve the accuracy of asthma trigger identification and thereby enhance asthma control.},
language = {eng},
number = {9},
journal = {Clinical and Experimental Allergy: Journal of the British Society for Allergy and Clinical Immunology},
author = {Janssens, T. and Ritz, T.},
month = sep,
year = {2013},
pmid = {23957335},
pmcid = {PMC3748392},
keywords = {Allergens, Asthma, Humans, Perception, Prognosis, Risk Factors},
pages = {1000--1008},
}

@article{mccarty_identifying_2014,
title = {Identifying asthma triggers},
volume = {47},
issn = {1557-8259},
doi = {10.1016/j.otc.2013.08.012},
abstract = {Asthma has many triggers including rhinosinusitis; allergy; irritants; medications (aspirin in aspirin-exacerbated respiratory disease); and obesity. Paradoxic vocal fold dysfunction mimics asthma and may be present along with asthma. This article reviews each of these triggers, outlining methods of recognizing the trigger and then its management. In many patients more than one trigger may be present. Full appreciation of the complexity of these relationships and targeted therapy to the trigger is needed to best care for the patient with asthma.},
language = {eng},
number = {1},
journal = {Otolaryngologic Clinics of North America},
author = {McCarty, Justin C. and Ferguson, Berrylin J.},
month = feb,
year = {2014},
pmid = {24286684},
keywords = {Allergens, Aspirin, Asthma, Asthma triggers, Disease Progression, Female, Food allergies, Gastroesophageal Reflux, Humans, Inhalant allergies, Male, Obesity, Paradoxic vocal fold dysfunction, Prognosis, Reflux, Rhinitis, Allergic, Rhinitis, Allergic, Perennial, Risk Assessment, Vocal Cord Dysfunction, sinusitis},
pages = {109--118},
}

@article{banda_exposure_2013,
title = {Exposure to home and school environmental triggers and asthma morbidity in {Chicago} inner-city children},
volume = {24},
issn = {1399-3038},
doi = {10.1111/pai.12162},
abstract = {BACKGROUND: In children, asthma hospitalization rates are highest among those aged 0-4 yr, indicating more acute and/or severe asthma exacerbations in younger children. We investigated the relationship between indoor exposures and three asthma morbidity measures in children of different age groups (0-4, 5-11, and 12 yr of age or older). Identifying the factors leading to asthma morbidity in specific subgroups may lead to a better understanding of the disease and contribute to the development of effective interventions tailored to subgroups.
METHODS: Children between 0 and 18 yr of age with asthma were enrolled in an asthma intervention program. At enrollment, hospitalizations, emergency room visits (ED), asthma night symptoms, and exposure to conditions in the child's home and school/daycare related to indoor allergens were collected using standardized questionnaires. Associations of exposure with the three asthma outcomes were estimated using logistic regression, stratified by age group.
RESULTS: Of 246 children enrolled, the youngest age group had more hospitalizations in the past year, more ED visits in the past year, and more night awakenings in the past month due to asthma than the oldest two age groups (p = 0.02; p {\textless} 0.0001; and p = 0.01, respectively). Overall, more associations of exposures to home triggers were found with hospitalization in children aged 0-11 yr, while classroom triggers were more likely to be associated with hospitalizations among the oldest two groups, 5-18 yr of age.
CONCLUSIONS: Examining the relationship of specific environmental exposures with asthma exacerbations and hospitalizations across age group and in different indoor environments warrants further study.},
language = {eng},
number = {8},
journal = {Pediatric Allergy and Immunology: Official Publication of the European Society of Pediatric Allergy and Immunology},
author = {Banda, Elizabeth and Persky, Victoria and Chisum, Gay and Damitz, Maureen and Williams, Rhonda and Turyk, Mary},
month = dec,
year = {2013},
pmid = {24299551},
keywords = {Adolescent, Age Factors, Air Pollution, Indoor, Asthma, Chicago, Child, Child, Preschool, Emergency Medical Services, Environmental Exposure, Female, Hospitalization, Humans, Infant, Infant, Newborn, Male, Morbidity, Schools, Urban Population, asthma age groups, asthma emergency department visit, asthma hospitalization, asthma morbidity, indoor asthma triggers, inner-city children},
pages = {734--741},
}

@article{brown_reducing_2014,
title = {Reducing patients' exposures to asthma and allergy triggers in their homes: an evaluation of effectiveness of grades of forced air ventilation filters},
volume = {51},
issn = {1532-4303},
shorttitle = {Reducing patients' exposures to asthma and allergy triggers in their homes},
doi = {10.3109/02770903.2014.895011},
abstract = {OBJECTIVE: Many interventions to reduce allergen levels in the home are recommended to asthma and allergy patients. One that is readily available and can be highly effective is the use of high performing filters in forced air ventilation systems.
METHODS: We conducted a modeling analysis of the effectiveness of filter-based interventions in the home to reduce airborne asthma and allergy triggers. This work used "each pass removal efficiency" applied to health-relevant size fractions of particles to assess filter performance. We assessed effectiveness for key allergy and asthma triggers based on applicable particle sizes for cat allergen, indoor and outdoor sources of particles {\textless}2.5 µm in diameter (PM2.5), and airborne influenza and rhinovirus.
RESULTS: Our analysis finds that higher performing filters can have significant impacts on indoor particle pollutant levels. Filters with removal efficiencies of {\textgreater}70\% for cat dander particles, fine particulate matter (PM2.5) and respiratory virus can lower concentrations of those asthma triggers and allergens in indoor air of the home by {\textgreater}50\%. Very high removal efficiency filters, such as those rated a 16 on the nationally recognized Minimum Efficiency Removal Value (MERV) rating system, tend to be only marginally more effective than MERV12 or 13 rated filters.
CONCLUSIONS: The results of this analysis indicate that use of a MERV12 or higher performing air filter in home ventilation systems can effectively reduce indoor levels of these common asthma and allergy triggers. These reductions in airborne allergens in turn may help reduce allergy and asthma symptoms, especially if employed in conjunction with other environmental management measures recommended for allergy and asthma patients.},
language = {eng},
number = {6},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Brown, Kathleen Ward and Minegishi, Taeko and Allen, Joseph G. and McCarthy, John F. and Spengler, John D. and MacIntosh, David L.},
month = aug,
year = {2014},
pmid = {24555523},
pmcid = {PMC4133967},
keywords = {Air Filters, Air Pollution, Indoor, Allergens, Animals, Asthma, Asthma and allergy triggers, Cats, Environmental Exposure, Environmental Monitoring, Humans, PM2.5, Particulate Matter, Ventilation, Viruses, filtration, indoor air, particulate},
pages = {585--594},
}

@article{luskin_impact_2014,
title = {Impact of asthma exacerbations and asthma triggers on asthma-related quality of life in patients with severe or difficult-to-treat asthma},
volume = {2},
issn = {2213-2201},
doi = {10.1016/j.jaip.2014.02.011},
abstract = {BACKGROUND: Few data are available that evaluate the relationship among asthma exacerbations, asthma triggers, and asthma-related quality of life (QoL).
OBJECTIVE: To evaluate the impact of asthma exacerbations and asthma triggers on QoL.
METHODS: Patients with severe or difficult-to-treat asthma, ages ≥ 13 years (n = 2679) from the TENOR (The Epidemiology and Natural History of Asthma: Outcomes and Treatment Regimens) 3-year observational study were included. Exacerbations were defined hierarchically in descending order of severity (hospitalization, emergency department [ED] visit, steroid burst, no exacerbation) by using data from months 6 and 12. The total number (frequency) of exacerbations was assessed. Asthma-related QoL was measured at month 12 by using the Mini-Asthma QoL Questionnaire (Mini-AQLQ); self-reported asthma triggers were collected at baseline and annually. We used 1-way ANOVA to test for differences in Mini-AQLQ domain scores across asthma exacerbation severity, the total number of asthma exacerbations, and the number of asthma triggers.
RESULTS: A significant decrease (P {\textless} .001) in Mini-AQLQ domain scores was seen with increasing severity of asthma exacerbation (no exacerbation, steroid burst, ED visit, and hospitalization); symptom (5.5, 4.8, 4.3, and 4.2), activity (5.8, 5.2, 4.6, and 4.4), emotional (5.6, 5.0, 4.4, and 4.2), exposure (5.0, 4.5, 4.0, and 3.9); and overall (5.5, 4.9, 4.3, and 4.1). Increasing exacerbation frequency and the number of baseline asthma triggers also were associated with significant decreases in Mini-AQLQ domain scores. An increasing number of asthma triggers were associated with an increase in severity and frequency of exacerbations.
CONCLUSION: Avoidance of asthma triggers may reduce exacerbation rates and improve asthma-related QoL in patients with severe or difficult-to-treat asthma. Interventional studies are warranted to further explore these outcomes.},
language = {eng},
number = {5},
journal = {The Journal of Allergy and Clinical Immunology. In Practice},
author = {Luskin, Allan T. and Chipps, Bradley E. and Rasouliyan, Lawrence and Miller, Dave P. and Haselkorn, Tmirah and Dorenbaum, Alejandro},
month = oct,
year = {2014},
pmid = {25213047},
keywords = {Adult, Allergic triggers, Asthma, Cohort Studies, Difficult-to-treat asthma, Emergency Service, Hospital, Female, Hospitalization, Humans, Male, Middle Aged, Quality of Life, Quality-of-life, Self Report, Severe asthma, Severity of Illness Index, Surveys and Questionnaires, Young Adult},
pages = {544--552.e1--2},
}

@article{valizadeh_effects_2014,
title = {The effects of triggers' modifying on adolescent self-efficacy with asthma: a randomized controlled clinical trial},
volume = {3},
issn = {2251-9920},
shorttitle = {The effects of triggers' modifying on adolescent self-efficacy with asthma},
doi = {10.5681/jcs.2014.013},
abstract = {INTRODUCTION: The management of asthma during adolescence has specific challenges and is likely influenced, to some extent, by the patient's belief in their ability to affect change, their self-efficacy. Bolstering self-efficacy could potentially improve an adolescent's ability to self-manage their asthma. The aim of this study was to examine the effects of a triggers' educational-modifying intervention on self-efficacy among adolescents diagnosed with asthma living in Iran.
METHODS: Sixty adolescents, aged 12 to 18 years, diagnosed with asthma participated in this randomized clinical trial. Participants randomly assigned to the control group received standard care while those assigned to the experimental group participated in a 5 week, nurse led, triggers modifying educational intervention in specialized clinics of lung in Tabriz, Iran. The self-efficacy scale developed by Bursh et al., was used for data collection.
RESULTS: The level of self- efficacy in two groups before intervention was not statistically significant, while the post intervention measures were statistically significant. Intervention was effective in improving adolescents' self-efficacy.
CONCLUSION: Since this type of intervention has the potential to improve Self- efficacy in adolescents with asthma, it is suggested that adolescence directly education about asthma triggers along with modulating triggers will be of value and parent-centered could be diminished. The need for such interventions emphasizes in clinic and outpatient clinics.},
language = {eng},
number = {2},
journal = {Journal of Caring Sciences},
author = {Valizadeh, Leila and Zarei, Soheila and Zamanazadeh, Vahid and Bilan, Nemat and Nasiri, Khadijeh and Howard, Fushia},
month = jun,
year = {2014},
pmid = {25276755},
pmcid = {PMC4134172},
keywords = {Adolescent, Asthma, Self-efficacy, Trigger},
pages = {121--129},
}

@article{janssens_learning_2017,
title = {Learning to {Detect} {Triggers} of {Airway} {Symptoms}: {The} {Role} of {Illness} {Beliefs}, {Conceptual} {Categories} and {Actual} {Experience} with {Allergic} {Symptoms}},
volume = {8},
issn = {1664-1078},
shorttitle = {Learning to {Detect} {Triggers} of {Airway} {Symptoms}},
doi = {10.3389/fpsyg.2017.00926},
abstract = {Background: In asthma and allergic rhinitis, beliefs about what triggers allergic reactions often do not match objective allergy tests. This may be due to insensitivity for expectancy violations as a result of holding trigger beliefs based on conceptual relationships among triggers. In this laboratory experiment, we aimed to investigate how pre-existing beliefs and conceptual relationships among triggers interact with actual experience when learning differential symptom expectations. Methods: Healthy participants (N = 48) received information that allergic reactions were a result of specific sensitivities versus general allergic vulnerability. Next, they performed a trigger learning task using a differential conditioning paradigm: brief inhalation of CO2 enriched air was used to induce symptoms, while participants were led to believe that the symptoms came about as a result of inhaled allergens (conditioned stimuli, CS's; CS+ followed by symptoms, CS- not followed by symptoms). CS+ and CS- stimuli either shared (e.g., birds-mammals) or did not share (e.g. birds-fungi) category membership. During Acquisition, participants reported symptom expectancy and symptom intensity for all triggers. During a Test 1 day later, participants rated symptom expectancies for old CS+/CS- triggers, for novel triggers within categories, and for exemplars of novel trigger categories. Data were analyzed using multilevel models. Findings: Only a subgroup of participants (n = 22) showed differences between CO2 and room air symptoms. In this group of responders, analysis of symptom expectancies during acquisition did not result in significant differential symptom CS+/CS- acquisition. A retention test 1 day later showed differential CS+/CS- symptom expectancies: When CS categories did not share category membership, specific sensitivity beliefs improved retention of CS+/CS- differentiation. However, when CS categories shared category membership, general vulnerability beliefs improved retention of CS+/CS- differentiation. Furthermore, participants showed some selectivity in generalization of symptom expectancies to novel categories, as symptom expectancies did not generalize to novel categories that were unrelated to CS+ or CS- categories. Generalization to novel categories was not affected by information about general vulnerability or specific sensitivities. Discussion: Pre-existing vulnerability beliefs and conceptual relationships between trigger categories influence differential symptom expectancies to allergic triggers.},
language = {eng},
journal = {Frontiers in Psychology},
author = {Janssens, Thomas and Caris, Eva and Van Diest, Ilse and Van den Bergh, Omer},
year = {2017},
pmid = {28638358},
pmcid = {PMC5461359},
keywords = {Asthma triggers, contingency learning, expectancy violation, generalization (psychology), illness perceptions},
pages = {926},
}

@article{stridsman_asthma_2017,
title = {Asthma in adolescence affects daily life and school attendance - {Two} cross-sectional population-based studies 10 years apart},
volume = {4},
issn = {2054-1058},
doi = {10.1002/nop2.77},
abstract = {AIM: The aim of this study was to study the impact of asthma on daily life, school absenteeism and physical education. In addition, to describe asthma triggers at school.
DESIGN: Two cross-sectional population-based studies ten years apart.
METHOD: Within the OLIN-studies, in 2003 (n = 3,327) and in 2013 (n = 2,345) adolescents (14-15 years) answered an expanded ISAAC questionnaire. Of these, 8\% and 11\%, respectively with current asthma participated in this study.
RESULTS: Between the years 2003-2013, the proportion of adolescents reporting that asthma interfered with daily life had increased, in 2013, girls were significantly more affected than boys. The proportion reporting a worsening of asthma at school had decreased, but it was still over a quarter. The proportion of absenteeism from school and from physical education was at the same level both years. Asthma triggers were described to be poor air quality, poorly cleaned environment, allergens, strong fragrance, rebuilding projects, physical education and stress.},
language = {eng},
number = {3},
journal = {Nursing Open},
author = {Stridsman, Caroline and Dahlberg, Elisabeth and Zandrén, Karin and Hedman, Linnéa},
month = jul,
year = {2017},
pmid = {28694978},
pmcid = {PMC5500462},
keywords = {Absenteeism, Asthma, Environment, Epidemiology, adolescents, nursing, physical education, school nursing},
pages = {143--148},
}

@article{chipps_asthma_2018,
title = {Asthma {Exacerbations} and {Triggers} in {Children} in {TENOR}: {Impact} on {Quality} of {Life}},
volume = {6},
issn = {2213-2198},
shorttitle = {Asthma {Exacerbations} and {Triggers} in {Children} in {TENOR}},
url = {http://www.sciencedirect.com/science/article/pii/S2213219817304221},
doi = {10.1016/j.jaip.2017.05.027},
abstract = {Background
Data examining associations between asthma exacerbations, triggers, and asthma-related quality of life (QOL) in children with severe/difficult-to-treat asthma are unavailable.
Objective
To evaluate real-world data on relationships between asthma exacerbations, triggers, and QOL in children using data from TENOR (The Epidemiology and Natural History of Asthma Outcomes and Treatment Regimens), a 3-year observational study of patients with severe/difficult-to-treat asthma, including those aged 6 to 12 years.
Methods
QOL was examined using the Pediatric Asthma Quality of Life Questionnaire (PAQLQ) and defined exacerbations hierarchically (descending order of severity): hospitalization, emergency department visit, steroid burst, no exacerbation, using the highest value from months 6 and 12. One-way ANOVA was used to test for differences in PAQLQ domain scores at month 12 across exacerbation severity, total number of asthma exacerbations, and number of baseline asthma triggers. Mantel-Haenszel chi-square test was used to test the association between the number of triggers and exacerbation hierarchy.
Results
Greater severity of asthma exacerbations was associated with significantly (P {\textless} .001) lower mean PAQLQ domain scores, indicating poorer QOL. A higher number of asthma exacerbations was associated with significantly (P {\textless} .001) lower mean PAQLQ domain scores. PAQLQ scores were significantly lower with higher numbers of baseline triggers. Higher baseline number of asthma triggers was associated with greater severity (P = .05) and number of asthma exacerbations (P {\textless} .001).
Conclusions
A higher number of asthma triggers at baseline was associated with greater asthma severity and number of asthma exacerbations and lower QOL in children with severe/difficult-to-treat asthma.},
number = {1},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
author = {Chipps, Bradley E. and Haselkorn, Tmirah and Rosén, Karin and Mink, David R. and Trzaskoma, Benjamin L. and Luskin, Allan T.},
month = jan,
year = {2018},
keywords = {Asthma triggers, Asthma-related quality of life, Difficult-to-treat asthma, Pediatric asthma, Severe asthma, Severe exacerbations},
pages = {169--176.e2},
}

@article{harris_improving_2017,
title = {Improving the asthma disparity gap with legal advocacy? {A} qualitative study of patient-identified challenges to improve social and environmental factors that contribute to poorly controlled asthma},
issn = {1532-4303},
shorttitle = {Improving the asthma disparity gap with legal advocacy?},
doi = {10.1080/02770903.2017.1373393},
abstract = {OBJECTIVE: To identify challenges that disadvantaged adults with asthma face in mitigating social and environmental factors associated with poor symptom control.
METHODS: Using a community-engaged approach, we partnered with a community health center in New Haven, CT to conduct in-person interviews and a written survey of asthmatic adults with poor symptom control. Using the constant comparative method, we analyzed participant interviews to establish emerging themes and identify common barriers to improved outcomes. Through a written survey utilizing clinically validated questions, we assessed information on access to medical care, asthma control, and selected social and environmental risk factors.
RESULTS: Twenty-one patients (mean age 47, 62\% female, 71\% Black, 95\% insured by Medicaid) participated. The average Asthma Control Test (ACT) score was 11.6. Seventy-six percent of participants were currently employed and of those, 75\% reported work-related symptoms. Among participants currently in housing, 59\% reported exposure to domiciliary mice and 47\% to mold. We identified three themes that summarize the challenges the study participants face: 1) Lack of knowledge about home and workplace asthma triggers; 2) Lack of awareness of legal rights or resources available to mitigate adverse conditions in the home or work environment; and 3) Fear of retaliation from landlords or employers, including threats of eviction, sexual assault, and job loss.
CONCLUSION: Patients with poorly controlled asthma in a disadvantaged urban northeast community identified common barriers in both the domestic and work environments that impeded attainment of symptom control. These challenges may be best addressed through legal advocacy for those most at risk.},
language = {eng},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Harris, Drew A. and Mainardi, Anne and Iyamu, Osatohamwen and Rosenthal, Marjorie S. and Bruce, R. Douglas and Pisani, Margaret A. and Redlich, Carrie A.},
month = sep,
year = {2017},
pmid = {28872933},
keywords = {Asthma disparities, community-based participatory research, community-engaged research, legal advocacy, medical-legal partnerships, social determinants of health},
pages = {1--9},
}

@article{lakhanpaul_qualitative_2017,
title = {A qualitative study to identify parents' perceptions of and barriers to asthma management in children from {South} {Asian} and {White} {British} families},
volume = {17},
issn = {1471-2466},
doi = {10.1186/s12890-017-0464-9},
abstract = {BACKGROUND: Over one million children receive treatment for asthma in the UK. South Asian children experience excess morbidity and higher rates of hospitalization than the White population. This study aimed to explore perceptions and experiences of asthma and asthma management in British South Asian and White British families, to identify barriers to optimal management and to inform culturally appropriate interventions to improve management.
METHODS: A qualitative methodology, using semi-structured interviews was adopted. Members of 30 families from six major South Asian ethnic-religious groups were purposively sampled (n = 49). For comparison, 17 White British parents were interviewed. Topics included understandings of asthma; day-to-day management; interactions with health care providers and the perceived quality of healthcare services. Data were analyzed using interpretive thematic analysis, facilitated by NVivo. Similarities and differences between South Asian and White families were analysed across key themes.
RESULTS: Many of the problems facing families of a child with asthma were common to South Asian and White British families. Both had limited understanding of asthma causes and triggers and expressed confusion about the use of medications. Both groups reported delays in receiving a clear diagnosis and many experienced what was perceived as uncoordinated care and inconsistent advice from health professionals. No family had received an asthma plan. South Asian families had more difficulty in recognising severity of symptoms and those with limited English faced additional barriers to receiving adequate information and advice about management due to poor communication support systems. South Asian parents reported higher levels of involvement of wider family and higher levels of stigma. Attendance at the emergency department was related to previous experience, difficulties in accessing primary care, lack of knowledge of alternatives and difficulties in assessing severity.
CONCLUSIONS: Barriers to optimal asthma management exist at the individual family, community and healthcare systems levels. Culturally sensitive, holistic and collaboratively designed interventions are needed. Improved communication support for families with lower proficiency in English is required. Healthcare professionals need to ensure that families receive an asthma plan and make greater efforts to check families' understandings of asthma triggers, use of medications, assessment of asthma severity and accessing help.},
language = {eng},
number = {1},
journal = {BMC pulmonary medicine},
author = {Lakhanpaul, Monica and Culley, Lorraine and Robertson, Noelle and Bird, Deborah and Hudson, Nicky and Johal, Narynder and McFeeters, Melanie and Angell, Emma and Hamlyn-Williams, Charlotte and Abbas, Nadine and Manikam, Logan and Johnson, Mark},
month = sep,
year = {2017},
pmid = {28931381},
pmcid = {PMC5607610},
keywords = {Asthma management, Barriers, Participatory, Qualitative, South Asian, Tailored, children, interventions},
pages = {126},
}

@article{braman_asthma_2017,
title = {Asthma in the {Elderly}},
volume = {33},
issn = {1879-8853},
doi = {10.1016/j.cger.2017.06.005},
abstract = {The older population has seen the greatest increase in the prevalence of current asthma in recent years. Asthma may begin at any age and when it occurs at an advanced as opposed to a young age, it is often nonatopic, severe, and unremitting. Unfortunately, geriatric-specific guidelines are not available for the diagnosis and treatment of asthma. However, with objective monitoring, avoidance of asthma triggers, appropriate pharmacotherapy, and patient education, the disease can be managed successfully.},
language = {eng},
number = {4},
journal = {Clinics in Geriatric Medicine},
author = {Braman, Sidney S.},
month = nov,
year = {2017},
pmid = {28991648},
keywords = {Aging, Asthma, Overlap syndrome, Phenotypes, lung function},
pages = {523--537},
}

@article{dong_evaluation_2018,
title = {Evaluation of the {Environmental} {Scoring} {System} in {Multiple} {Child} {Asthma} {Intervention} {Programs} in {Boston}, {Massachusetts}},
volume = {108},
issn = {1541-0048},
doi = {10.2105/AJPH.2017.304125},
abstract = {OBJECTIVES: To test the applicability of the Environmental Scoring System, a quick and simple approach for quantitatively measuring environmental triggers collected during home visits, and to evaluate its contribution to improving asthma outcomes among various child asthma programs.
METHODS: We pooled and analyzed data from multiple child asthma programs in the Greater Boston Area, Massachusetts, collected in 2011 to 2016, to examine the association of environmental scores (ES) with measures of asthma outcomes and compare the results across programs.
RESULTS: Our analysis showed that demographics were important contributors to variability in asthma outcomes and total ES, and largely explained the differences among programs at baseline. Among all programs in general, we found that asthma outcomes were significantly improved and total ES significantly reduced over visits, with the total Asthma Control Test score negatively associated with total ES.
CONCLUSIONS: Our study demonstrated that the Environmental Scoring System is a useful tool for measuring home asthma triggers and can be applied regardless of program and survey designs, and that demographics of the target population may influence the improvement in asthma outcomes.},
language = {eng},
number = {1},
journal = {American Journal of Public Health},
author = {Dong, Zhao and Nath, Anjali and Guo, Jing and Bhaumik, Urmi and Chin, May Y. and Dong, Sherry and Marshall, Erica and Murphy, Johnna S. and Sandel, Megan T. and Sommer, Susan J. and Ursprung, W. W. Sanouri and Woods, Elizabeth R. and Reid, Margaret and Adamkiewicz, Gary},
month = jan,
year = {2018},
pmid = {29161061},
pmcid = {PMC5719687},
keywords = {Adolescent, Asthma, Boston, Child, Child, Preschool, Environment, Female, House Calls, Humans, Infant, Male, Reproducibility of Results, Socioeconomic Factors, Surveys and Questionnaires},
pages = {103--111},
}

@article{mohammad_uncontrolled_2017,
title = {Uncontrolled and under-diagnosed asthma in a {Damascus} shelter during the {Syrian} crisis},
volume = {9},
issn = {2072-1439},
doi = {10.21037/jtd.2017.08.86},
abstract = {Background: Studies have shown that poor shelter or dwelling conditions may lead to deteriorations in health. Those with asthma may be more susceptible to compromised living conditions and stress leading to a higher risk of asthma exacerbations. To describe the asthma control and quality of life of individuals with diagnosed asthma living in a shelter in Damascus, Syria and estimate the prevalence of respiratory symptoms in shelter dwellers without diagnosed asthma.
Methods: In this cross-sectional study, all individuals 5 years and older living in Al-Herjalleh shelter with diagnosed asthma were recruited to complete a questionnaire, which included items related to their respiratory symptoms, asthma exacerbations, exposure to asthma triggers, medication use, and health-related quality of life before and since entering the shelter. A representative sample of shelter dwellers without diagnosed asthma also completed a questionnaire to establish their demographics, respiratory symptoms, environment and chronic disease co-morbidities, in order to identify factors associated with under-diagnosed asthma. All participants underwent spirometry to measure their lung function. Descriptive statistics were calculated, and chi-square tests and Student's t-tests were used to compare individuals with asthma before and since entering the shelter, as well as to compare those with under-diagnosed asthma and individuals without asthma.
Results: The prevalence of asthma at the Al-Herjalleh shelter in those aged 5 years and older was approximately 8.5\%. Nearly 70\% of the asthma group felt their asthma had worsened since entering the shelter, and there was a significant drop in the proportion of individuals using inhaled corticosteroids (ICS), with only 4.3\% using daily ICS in the shelter (P{\textless}0.0001). The proportion of individuals experiencing a severe asthma attack did not change after entering the shelter (P=0.97), but almost all individuals with asthma (94.4\%) reported worsening in their health-related quality of life. In the non-asthma group, 44.2\% of participants reported episodes of wheezing, coughing and breathlessness at night, consistent with under-diagnosed asthma. A higher proportion of those with under-diagnosed asthma had allergic rhinitis (57.1\%), symptoms of post-traumatic stress disorder (PTSD) (35.1\%), and abnormal spirometry (60.0\%), compared to those without asthma.
Conclusions: The findings of our study highlight the need for asthma programs in Syrian shelters as significant gaps exist in both the screening and management of chronic respiratory diseases to minimize asthma deterioration in Syrian shelter dwellers.},
language = {eng},
number = {9},
journal = {Journal of Thoracic Disease},
author = {Mohammad, Yousser and Rafea, Shaaban and Latifeh, Youssef and Khaddam, Ali and Sawaf, Bisher and Zakaria, Mhd Ismael and Al Masalmeh, Mohammad Sadek and Fawaz, Yaser and Allaham, Abdoulraouf and Almani, Imad and El-Tarcheh, Hiba and Ghazal, Ayham and Zaher, Ali and Rifai, Hala and Joumah, Hamed and Glockler-Lauf, S. Dresden and To, Teresa},
month = sep,
year = {2017},
pmid = {29221328},
pmcid = {PMC5708366},
keywords = {PTSD in asthma, Underdiagnosed asthma, asthma in shelters, war-time asthma},
pages = {3415--3424},
}

@article{alhekail_association_2017,
title = {The association between body mass index and frequency of emergency department visits and hospitalization for asthma exacerbation in a pediatric population},
volume = {37},
issn = {0975-4466},
doi = {10.5144/0256-4947.2017.415},
abstract = {BACKGROUND: The prevalence of both asthma and obesity are increasing. Although some studies suggest an association between body mass index (BMI) and frequency of emergency department (ED) visits and hospitalization for asthma exacerbation, any association remains unproven.
OBJECTIVE: Estimate the frequency of asthma exacerbation in obese children, and identify any relationship between BMI and frequency of ED visits and hospitalization for asthma exacerbation.
DESIGN: Retrospective review of medical records.
SETTINGS: Tertiary children's hospital, Riyadh.
SUBJECTS AND METHODS: All children aged 2-15 years who attended the ED for asthma exacerbation between January 2015 and January 2016 were included. Children with comorbidities or undocumented asthma were excluded. The Centers for Disease Control and Prevention BMI-for-age growth charts for boys and girls aged 2 to 20 years were used to classify underweight, normal, overweight, and obese.
MAIN OUTCOME MEASURES: The frequency of ED visits and the rate, frequency, and duration of hospitalization.
RESULTS: Of the 1000 cases reviewed, 64.6\% were boys and the mean age (standard deviation) of all sub.jects was 5.6 (3.3) years. The proportions of overweight and obese children was 11.8\% and 12.1\%, respectively. There was no association between increased BMI and frequency of ED visits for asthma exacerbation (P=.84), duration of hospitalization (P=.41) or frequency of hospitalization (P=.89).
CONCLUSION: There was no evidence of an association between BMI and frequency of ED visits and hospitalization for asthma exacerbation among children.
LIMITATIONS: This study included patients as young as 2 years, while asthma is only well-defined in children {\textgreater} 5 years. Asthma triggers that can cause exacerbation despite body weight were not included. We included only frequency of ED visits and hospitalization, which may be inadequate to measure asthma severity.},
language = {eng},
number = {6},
journal = {Annals of Saudi Medicine},
author = {Alhekail, Ghadah Abdulrahman and Althubaiti, Alaa and AlQueflie, Sulaiman},
month = dec,
year = {2017},
pmid = {29229888},
pages = {415--419},
}

@article{falliers_aspirin_1973,
title = {Aspirin and subtypes of asthma: risk factor analysis},
volume = {52},
issn = {0091-6749},
shorttitle = {Aspirin and subtypes of asthma},
language = {eng},
number = {3},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Falliers, C. J.},
month = sep,
year = {1973},
pmid = {4725111},
keywords = {Adolescent, Age Factors, Aspirin, Asthma, Child, Chronic Disease, Drug Hypersensitivity, Female, Humans, Male, Mass Screening, Rhinitis, Allergic, Seasonal, Surveys and Questionnaires, eczema},
pages = {141--147},
}

@article{wang_familial_2001,
title = {Familial risk of asthma among adolescents and their relatives in {Taiwan}},
volume = {38},
issn = {0277-0903},
abstract = {Although family studies have established that asthma has a hereditary basis, little evidence has been presented about the family risk of simple asthma (AS or nonatopic asthma) and asthma with other atopic diseases (AWAD or atopic asthma) after adjusting for potential risk factors. In this study, data were collected on demographic variables and a wide range of known risk factors for asthma. Study participants were asthmatic adolescents and controls, and their relatives. The role of a familial history of asthma and atopic diseases in predicting asthma risk among asthmatic adolescents and their relatives was evaluated in a population-based family study conducted in southern Taiwan. Asthma risk factor data were collected through telephone interviews with students' parents for 207 asthmatic adolescents 11-16 years of age, their 1600 relatives, and 207 nonasthmatic adolescents in the control group and their 1638 relatives. The results show (after adjusting potential confounders) that a family history of asthma is highly associated with asthma in adolescents. Having two or more family members with asthma was associated with a 3.4-fold (95\% confidence interval [CI] = 1.0-12.0) increased risk of asthma among adolescents. Logistic regression was used to assess the effects of having an asthmatic relative and the effect of atopic diseases among relatives of cases. Having a family history of asthma and other atopic conditions, such as rhinitis and atopic dermatitis (adjusted odds ratio [AOR] = 3.64, 95\% CI = 2.29-5.74 and AOR = 1.94, 95\% CI = 1.53-2.46, respectively), was found to be a significant predictor of asthma in children. Along with a history of allergic rhinitis or atopic dermatitis, familial risks of asthma occurring in adolescents with and without other atopic diseases will be analyzed separately. A critical finding was the significant difference in a risk of asthma and atopic diseases among the relatives of asthma cases with atopic diseases and controls. However, for relatives of asthma cases without atopic diseases compared to control probands, AORs were highly significant for family history of asthma, but not for the family history of atopic diseases. These findings suggest that both forms of asthma may be hereditary, but there are differences in their modes of inheritance. Atopic status itself did not predispose a child to AS. A concomitant inheritance of a predisposition to asthma and atopic condition for AWAD cases was suggested.},
language = {eng},
number = {6},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Wang, T. N. and Chao, Y. Y. and Wang, T. H. and Chen, C. J. and Ko, Y. C.},
month = sep,
year = {2001},
pmid = {11642415},
keywords = {Adolescent, Asthma, Child, Female, Humans, Male, Pedigree, Risk Factors, Taiwan},
pages = {485--494},
}

@article{sutherland_atypical_2004,
title = {Atypical bacterial pneumonia and asthma risk},
volume = {41},
issn = {0277-0903},
abstract = {The role of respiratory infections in asthma is poorly understood. Atypical bacteria Mycoplasma pneumoniae and Chlamydia pneumoniae are present in the lower airways of approximately 50\% of asthmatics. This study tested the hypothesis that early life community-acquired pneumonia caused by Mycoplasma pneumoniae or Chlamydia pneumoniae is associated with increased asthma prevalence. Thirty-five subjects with a history of community-acquired pneumonia (22 due to atypical bacteria, 13 due to nonatypical pathogens) were evaluated by questionnaire 7-9 years after the episode of pneumonia. Subjects with a history of either typical or atypical pneumonia demonstrated increased asthma prevalence. Current or past asthma prevalence was 55\% in subjects with atypical bacterial pneumonia and 61.5\% in subjects with nonatypical bacterial pneumonia. Significant between-group differences were not demonstrated with regard to asthma prevalence (risk ratio=0.89; 95\% confidence interval=0.49-1.61), current bronchodilator use [1.18 (0.44-3.17)], and family history of atopy [1.18 (0.73-1.91)], or asthma [1.63 (0.68-3.88)]. These data suggest that atypical bacterial pneumonia confers a risk of asthma similar to that seen with nonatypical bacterial pneumonia. Prospective studies are warranted to more fully evaluate the importance of atypical bacterial pneumonia as an asthma risk factor.},
language = {eng},
number = {8},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Sutherland, E. Rand and Brandorff, Jennifer M. and Martin, Richard J.},
year = {2004},
pmid = {15641636},
keywords = {Adolescent, Adult, Asthma, Child, Chlamydia Infections, Chlamydophila pneumoniae, Community-Acquired Infections, Female, Follow-Up Studies, Humans, Male, Pneumonia, Bacterial, Pneumonia, Mycoplasma, Randomized Controlled Trials as Topic, Retrospective Studies, Risk Factors},
pages = {863--868},
}

@article{quiralte_ole_2005,
title = {Ole e 2 and {Ole} e 10: new clinical aspects and genetic restrictions in olive pollen allergy},
volume = {60},
issn = {0105-4538},
shorttitle = {Ole e 2 and {Ole} e 10},
doi = {10.1111/j.1398-9995.2005.00698.x},
abstract = {BACKGROUND: The clinical characteristics in olive pollen allergy are dependent on the antigenic load, the allergens profile, and the genetic restrictions. Our objective was to determine specific response pattern in Ole e 2 and Ole e 10 sensitization at those levels.
METHODS: We studied 146 patients with seasonal rhinitis and/or asthma and positive prick test to Olea europaea pollen. IgE against Ole e 2 and Ole e 10 were detected by skin prick test and ELISA. HLA-DRB1 and HLA-DQB1 loci were typed by polymerase chain reaction sequence-specific primers method.
RESULTS: A total of 102 (69.9\%) and 79 (54.0\%) patients showed significant IgE antibody response against Ole e 2 and Ole e 10, respectively. There was a significant association between Ole e 2 (OR 2.2, P = 0.04) and Ole e 10 reactivities (OR 2.8, P = 0.007) with asthma. In addition, total and specific IgE antibody levels significantly correlated with asthma (P {\textless} 0.05). Patients who reacted to both allergens reached the highest asthma risk factor (OR 4.3, P = 0.002). Phenotypic frequency of DR7 (OR 5.4, Pc = 0.003) and DQ2 (OR 3.6, Pc = 0.02) were increased in positive Ole e 2 patients compared with control subjects. DR2(15) phenotypic frequency was significantly increased (OR 5.6, Pc = 0.02) in positive Ole e 10 patients compared with control subjects.
CONCLUSIONS: Our data suggest an association of Ole e 2 and Ole e 10 with bronchial asthma. Also, we found a genetic control of Ole e 2 and Ole e 10 IgE-specific responses that could be relevant to clinical disease in olive pollen allergy.},
language = {eng},
number = {3},
journal = {Allergy},
author = {Quiralte, J. and Llanes, E. and Barral, P. and Arias de Saavedra, J. M. and Sáenz de San Pedro, B. and Villalba, M. and Florido, J. F. and Rodríguez, R. and Lahoz, C. and Cárdaba, B.},
month = mar,
year = {2005},
pmid = {15679723},
keywords = {Adolescent, Adult, Allergens, Antigens, Plant, Asthma, Case-Control Studies, Enzyme-Linked Immunosorbent Assay, Female, Genetic Predisposition to Disease, HLA-DQ Antigens, HLA-DR2 Antigen, HLA-DR7 Antigen, Haplotypes, Humans, Hypersensitivity, Immunoglobulin E, Male, Olea, Phenotype, Plant Proteins, Pollen, Rhinitis, Allergic, Seasonal, Risk Factors, Skin Tests},
pages = {360--365},
}

@article{li_maternal_2005,
title = {Maternal and grandmaternal smoking patterns are associated with early childhood asthma},
volume = {127},
issn = {0012-3692},
doi = {10.1378/chest.127.4.1232},
abstract = {OBJECTIVE: To investigate the associations of maternal and grandmaternal smoking before, during, and after pregnancy with childhood asthma.
DESIGN, SETTING, AND PARTICIPANTS: We conducted a case-control study nested within the Children's Health Study in southern California. The case patients consisted of 338 children with asthma that had been diagnosed in the first 5 years of life, and 570 control subjects were countermatched on in utero exposure to maternal smoking within grade, sex, and community of residence.
MEASUREMENTS: Detailed maternal and household smoking histories and other asthma risk factor information was obtained by telephone interview.
RESULTS: The participation rates were 72.3\% and 82.5\%, respectively, for control subjects and case patients. In utero exposure to maternal smoking was associated with increased risk for asthma diagnosed in the first 5 years of life (odds ratio [OR], 1.5; 95\% confidence interval [CI], 1.0 to 2.3), and for persistent asthma (OR, 1.5; 95\% CI, 1.0 to 2.3). The associations did not differ in children with early transient asthma compared to those with early persistent asthma. Relative to never-smokers, children whose mothers smoked throughout the pregnancy had an elevated risk of asthma in the first 5 years of life (OR, 1.6; 95\% CI, 1.0 to 2.6). Children of mothers who quit smoking prior to the pregnancy showed no increased risk (OR, 0.9; 95\% CI, 0.5 to 1.5). We were unable to assess the association of smoking cessation during pregnancy because very few mothers were reported to have done so (15\%). Asthma risk did not increase in a monotonic pattern with smoking intensity during pregnancy. Postnatal secondhand smoke exposure was not independently associated with asthma. Grandmaternal smoking during the mother's fetal period was associated with increased asthma risk in her grandchildren (OR, 2.1; 95\% CI, 1.4 to 3.2).
CONCLUSIONS: Maternal and grandmaternal smoking during pregnancy may increase the risk of childhood asthma.},
language = {eng},
number = {4},
journal = {Chest},
author = {Li, Yu-Fen and Langholz, Bryan and Salam, Muhammad T. and Gilliland, Frank D.},
month = apr,
year = {2005},
pmid = {15821200},
keywords = {Adolescent, Asthma, Case-Control Studies, Child, Female, Humans, Male, Maternal Behavior, Maternal-Fetal Exchange, Pregnancy, Prenatal Exposure Delayed Effects, Tobacco Smoke Pollution, risk},
pages = {1232--1241},
}

@article{warman_asthma_2006,
title = {Asthma risk factor assessment: what are the needs of inner-city families?},
volume = {97},
issn = {1081-1206},
shorttitle = {Asthma risk factor assessment},
abstract = {BACKGROUND: A complex array of risk factors contributes to sustained high levels of asthma morbidity in inner-city children.
OBJECTIVE: To describe risk factors for asthma morbidity in a national sample of inner-city children with persistent asthma.
METHODS: This study examined baseline questionnaire results from 1,772 children ages 5 to 11 years old with moderate to severe persistent asthma who enrolled in the Centers for Disease Control and Prevention-funded Inner-City Asthma Intervention between April 2001 and March 2004. Risk for asthma morbidity was assessed in 9 domains using the Child Asthma Risk Assessment Tool. The domains included environmental exposures, parental stress, medication adherence, pessimistic asthma beliefs, smoke exposure, aeroallergen exposure, child psychological well-being, responsibility for medication administration, and medical care.
RESULTS: A total of 51\% of families demonstrated high risk of asthma morbidity in 3 or more domains. High risk of asthma morbidity was suggested based on household environmental exposures (47.7\%), high parental stress (38.5\%), poor medication adherence (38.3\%), pessimistic asthma beliefs (31.8\%), environmental tobacco smoke (24.4\%), sensitization to aeroallergens in the home (24.8\%), child behavioral or emotional concerns (22.9\%), child assigned responsibility for medication administration (21.2\%), and poor medical care (20.7\%). Allergy testing was completed for 40\% of the participating children. Of these children, 61\% were exposed to aeroallergens in their home to which they were sensitized.
CONCLUSIONS: In this national sample of inner-city children, multiple risk factors for asthma morbidity were identified. Asthma programs that provide multilevel support and intervention are needed to reduce the burden of asthma on inner-city families.},
language = {eng},
number = {1 Suppl 1},
journal = {Annals of Allergy, Asthma \& Immunology: Official Publication of the American College of Allergy, Asthma, \& Immunology},
author = {Warman, Karen and Silver, Ellen Johnson and Wood, Pamela R.},
month = jul,
year = {2006},
pmid = {16892765},
keywords = {Air Pollution, Indoor, Allergens, Animals, Asthma, Attitude to Health, Child, Child, Preschool, Culture, Delivery of Health Care, Female, Government Programs, Health Services Needs and Demand, Housing, Humans, Hypersensitivity, Male, Parents, Patient Compliance, Risk Factors, Stress, Physiological, Surveys and Questionnaires, Tobacco Smoke Pollution, United States, Urban Health, Urban Population},
pages = {S11--15},
}

@article{beuther_overweight_2007,
title = {Overweight, obesity, and incident asthma: a meta-analysis of prospective epidemiologic studies},
volume = {175},
issn = {1073-449X},
shorttitle = {Overweight, obesity, and incident asthma},
doi = {10.1164/rccm.200611-1717OC},
abstract = {RATIONALE: Although obesity has been implicated as an asthma risk factor, there is heterogeneity in the published literature regarding its role in asthma incidence, particularly in men.
OBJECTIVES: To quantify the relationship between categories of body mass index (BMI) and incident asthma in adults and to evaluate the impact of sex on this relationship.
METHODS: Online bibliographic databases were searched for prospective studies evaluating BMI and incident asthma in adults. Independent observers extracted data regarding annualized asthma incidence from studies meeting predetermined criteria, within defined categories of normal weight (BMI {\textless} 25), overweight (BMI, 25-29.9), and obesity (BMI {\textgreater}or= 30). Data were analyzed by inverse-variance-weighted, random-effects meta-analysis. Stratified analysis between BMI categories and within sex was performed.
RESULTS: Seven studies (n=333,102 subjects) met inclusion criteria. Compared with normal weight, overweight and obesity (BMI {\textgreater}or= 25) conferred increased odds of incident asthma, with an odds ratio (OR) of 1.51 (95\% confidence interval [CI], 1.27-1.80). A dose-response effect of elevated BMI on asthma incidence was observed; the OR for incident asthma for normal-weight versus overweight subjects was 1.38 (95\% CI, 1.17-1.62) and was further elevated for normal weight versus obesity (OR, 1.92; 95\% CI, 1.43-2.59; p{\textless}0.0001 for the trend). A similar increase in the OR of incident asthma due to overweight and obesity was observed in men (OR, 1.46; 95\% CI, 1.05-2.02) and women (OR, 1.68; 95\% CI, 1.45-1.94; p=0.232 for the comparison).
CONCLUSIONS: Overweight and obesity are associated with a dose-dependent increase in the odds of incident asthma in men and women, suggesting asthma incidence could be reduced by interventions targeting overweight and obesity.},
language = {eng},
number = {7},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Beuther, David A. and Sutherland, E. Rand},
month = apr,
year = {2007},
pmid = {17234901},
pmcid = {PMC1899288},
keywords = {Adult, Asthma, Body Mass Index, Epidemiologic Studies, Female, Humans, Male, Obesity, Risk Assessment, Sex Factors, incidence},
pages = {661--666},
}

@article{ownby_comparison_2015,
title = {Comparison of asthma prevalence among {African} {American} teenage youth attending public high schools in rural {Georgia} and urban {Detroit}},
volume = {136},
issn = {1097-6825},
doi = {10.1016/j.jaci.2015.02.007},
abstract = {BACKGROUND: The high prevalence of asthma among urban African American (AA) populations has attracted research attention, whereas the prevalence among rural AA populations is poorly documented.
OBJECTIVE: We sought to compare the prevalence of asthma among AA youth in rural Georgia and urban Detroit, Michigan.
METHODS: The prevalence of asthma was compared in population-based samples of 7297 youth attending Detroit public high schools and in 2523 youth attending public high schools in rural Georgia. Current asthma was defined as a physician diagnosis and symptoms in the previous 12 months. Undiagnosed asthma was defined as multiple respiratory symptoms in the previous 12 months without a physician diagnosis.
RESULTS: In Detroit, 6994 (95.8\%) youth were AA compared with 1514 (60.0\%) in Georgia. Average population density in high school postal codes was 5628 people/mile(2) in Detroit and 45.1 people/mile(2) in Georgia. The percentages of poverty and of students qualifying for free or reduced lunches were similar in both areas. The prevalence of current diagnosed asthma among AA youth in Detroit and Georgia was similar: 15.0\% (95\% CI, 14.1-15.8) and 13.7\% (95\% CI, 12.0-17.1) (P = .22), respectively. The prevalence of undiagnosed asthma in AA youth was 8.0\% in Detroit and 7.5\% in Georgia (P = .56). Asthma symptoms were reported more frequently among those with diagnosed asthma in Detroit, whereas those with undiagnosed asthma in Georgia reported more symptoms.
CONCLUSIONS: Among AA youth living in similar socioeconomic circumstances, asthma prevalence is as high in rural Georgia as it is in urban Detroit, suggesting that urban residence is not an asthma risk factor.},
language = {eng},
number = {3},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Ownby, Dennis R. and Tingen, Martha S. and Havstad, Suzanne and Waller, Jennifer L. and Johnson, Christine C. and Joseph, Christine L. M.},
month = sep,
year = {2015},
pmid = {25825215},
pmcid = {PMC4562865},
keywords = {Adolescent, African American, African Americans, Asthma, Female, Georgia, Humans, Male, Michigan, Population Density, Poverty, Prevalence, Risk Factors, Rural Population, Schools, Urban Population, high school students, inner-city, rural, urban, youth},
pages = {595--600.e3},
}

@article{worgall_sphingolipids_2017,
title = {Sphingolipids, {ORMDL3} and asthma: what is the evidence?},
volume = {20},
issn = {1473-6519},
shorttitle = {Sphingolipids, {ORMDL3} and asthma},
doi = {10.1097/MCO.0000000000000349},
abstract = {PURPOSE OF REVIEW: Genome-wide association studies identified ORMDL3, a protein of the endoplasmic reticulum, as a significant asthma risk factor. ORMDL3 is one of three ORMDL proteins that integrate multiple signals to maintain sphingolipid homeostasis. Studies that investigated potential mechanisms for how increased ORMDL3 might affect asthma are summarized.
RECENT FINDINGS: Investigations focused on decreased sphingolipid synthesis and on the unfolded protein response because ORMDL3 had been implicated in both.Airway reactivity is increased in a genetic model with decreased de-novo sphingolipid synthesis and in wild-type mice treated with myriocin, a sphingolipid synthesis inhibitor. Inflammation, mucus production and airway smooth muscle hypertrophy are absent. ORMDL3 was not evaluated directly but results suggest that decreased sphingolipid synthesis is sufficient to induce airway hyperreactivity (AHR).Direct effects of ORMDL3 were investigated in allergic asthma models. Sensitization with ovalbumin, house dust mites and Alternaria alternata increase ORMDL3 mRNA. Universal overexpression of ORMDL3 decreases serum sphingolipids, increases inflammatory markers, airway remodeling and AHR in response to allergic stimuli. Addition of myriocin during sensitization drastically exacerbates house dust mites-induced AHR.ORMDL3 knockout mice are protected from developing A. alternata-induced AHR. The effect is specific to Alternaria and limited to smooth muscle contraction, as inflammation persists. ORMDL3 might have a critical role for smooth muscle contraction.Little is known about how the different ORMDL3 single nucleotide polymorphisms affect human blood and tissue sphingolipid profiles. One group measured total sphingoid levels and found no association with ORMDL3 single nucleotide polymorphisms in a general population. Others evaluated sphingolipid profiles in 7-8-year old children with mild asthma and found significantly higher C18 and C20 ceramides in those with persistence of asthma symptoms 3 years later, suggesting that sphingolipid profiles might predict asthma persistence.
SUMMARY: Possible mechanisms how ORMDL3 affects asthma include inhibition of sphingolipid synthesis, synergistic effects with known allergens and a combination of both.},
language = {eng},
number = {2},
journal = {Current Opinion in Clinical Nutrition and Metabolic Care},
author = {Worgall, Tilla S.},
month = mar,
year = {2017},
pmid = {28030368},
keywords = {Allergens, Animals, Asthma, Humans, Membrane Proteins, Mice, Sphingolipids},
pages = {99--103},
}

@article{polley_cockroach_2017,
title = {Cockroach allergen serine proteinases: {Isolation}, sequencing and signalling via proteinase-activated receptor-2},
volume = {47},
issn = {1365-2222},
shorttitle = {Cockroach allergen serine proteinases},
doi = {10.1111/cea.12921},
abstract = {BACKGROUND: Allergy to the German cockroach (Blattella germanica) is a significant asthma risk factor for inner-city communities. Cockroach, like other allergens, contains trypsin-like enzyme activity that contributes to allergenicity and airway inflammation by activating proteinase-activated receptors (PARs). To date, the enzymes responsible for the proteolytic activity of German cockroach allergen have not been characterized.
OBJECTIVES: We aimed to identify, isolate and characterize the trypsin-like proteinases in German cockroach allergen extracts used for clinical skin tests. For each enzyme, we sought to determine (1) its substrate and inhibitor enzyme kinetics (Km and IC50), (2) its amino acid sequence and (3) its ability to activate calcium signalling and/or ERK1/2 phosphorylation via PAR2.
METHODS: Using a trypsin-specific activity-based probe, we detected three distinct enzymes that were isolated using ion-exchange chromatography. Each enzyme was sequenced by mass spectometery (deconvoluted with an expressed sequence tag library), evaluated kinetically for its substrate/inhibitor profile and assessed for its ability to activate PAR2 signalling.
FINDINGS: Each of the three serine proteinase activity-based probe-labelled enzymes isolated was biochemically distinct, with different enzyme kinetic profiles and primary amino acid sequences. The three enzymes showed a 57\%-71\% sequence identity with a proteinase previously cloned from the American cockroach (Per a 10). Each enzyme was found to activate both Ca++ and MAPK signalling via PAR2.
CONCLUSIONS AND RELEVANCE: We have identified three different serine proteinases from the German cockroach that may, via PAR2 activation, play different roles for allergen sensitization in vivo and may represent attractive therapeutic targets for asthma.},
language = {eng},
number = {7},
journal = {Clinical and Experimental Allergy: Journal of the British Society for Allergy and Clinical Immunology},
author = {Polley, D. J. and Mihara, K. and Ramachandran, R. and Vliagoftis, H. and Renaux, B. and Saifeddine, M. and Daines, M. O. and Boitano, S. and Hollenberg, M. D.},
month = jul,
year = {2017},
pmid = {28317204},
pmcid = {PMC5501740},
keywords = {Allergens, Amino Acid Sequence, Animals, Asthma, Blattellidae, Calcium Signaling, Cell Line, Chromatography, Ion Exchange, Cockroaches, Humans, Hypersensitivity, Ligands, Receptor, PAR-2, Serine Proteases, Signal Transduction, beta-Arrestins, calcium signalling, cockroach, protease, proteinase-activated receptor-2 (PAR2)},
pages = {946--960},
}

@article{kuhni_yentl_1995,
title = {The {Yentl} syndrome in childhood asthma: risk factors for undertreatment in {Swiss} children},
volume = {19},
issn = {8755-6863},
shorttitle = {The {Yentl} syndrome in childhood asthma},
abstract = {Recent prevalence data for childhood asthma in Switzerland suggest a substantial underdiagnosis which seems to be more pronounced in girls. We further analysed our data trying to specify risk factors for underdiagnosis and undertreatment. Our special interest was focused on female sex as there is evidence for a sex-dependent diagnosis and treatment of chronic disease in adults, called the Yentl syndrome. The data are derived from a parent completed questionnaire survey of a stratified cluster sample of schoolchildren aged 7, 12, and 15 years. Besides the 12 months prevalence of asthma symptoms and bronchodilator treatment, the lifetime prevalence of an asthma diagnosis was noted. With a response rate of 97\%, a total of 4353 completed questionnaires were analysed. While age was not associated with undertreatment (except for exercise-induced symptoms in adolescents), the lack of a formal diagnosis of asthma and atypical asthma symptoms other than wheeze such as chronic night cough were confirmed as significant risk factors for undertreatment. Of all boys reporting asthma symptoms 31\% received bronchodilator treatment compared with only 15\% of the symptom-reporting girls (P {\textless} 0.001). For all particular asthma-related symptoms (except wheeze), significantly more boys than girls (approximately double) received treatment. The physiological and psychological bases for these findings are discussed and suggest that gender is an important risk factor for underdiagnosis and undertreatment of asthma. Our research indicates that the Yentl syndrome may exist for childhood asthma.},
language = {eng},
number = {3},
journal = {Pediatric Pulmonology},
author = {Kühni, C. E. and Sennhauser, F. H.},
month = mar,
year = {1995},
pmid = {7792117},
keywords = {Adolescent, Age Factors, Asthma, Child, Cross-Sectional Studies, Female, Humans, Male, Prevalence, Risk Factors, Sex Factors, Surveys and Questionnaires, Switzerland, Syndrome, bronchodilator agents},
pages = {156--160},
}

@article{bener_genetic_1996,
title = {Genetic and environmental factors associated with asthma},
volume = {68},
issn = {0018-7143},
abstract = {We investigate the familial and environmental risk factors associated with asthma among United Arab Emirates schoolchildren aged 6-14 years. A cross-sectional study of 850 schoolchildren living in both urban and rural areas (average age 9.36 +/- 2.11 years; 46.8\% boys, 53.2\% girls) was conducted using self-administered questionnaires between October 1992 and May 1993. The population sample had a high prevalence rate of diagnosed asthma (13.6\%) and allergic rhinitis (22.9\%). The frequency of asthma, allergic rhinitis, and eczema among parents and siblings reflected the same pattern as that seen in the children. Environmental risk factors associated with asthma were pets, medicine, plants, dust storm, physical exercise, humidity, and perfume. All other factors, such as foods, climate, and parental smoking, showed no apparent relation to the development of asthma. The logistic regression analysis showed that parental asthma, plants, perfume, dust storm, humidity, and pets were the only significant predictors after adjusting for sex and other confounding covariates in the model. In conclusion, risk factors for asthma identified by our study are similar to those found in other community-based studies. Consistencies and discrepancies between our findings and those from other studies with respect to asthma risk factors support the hypothesis that asthma is a multifactorial disease related to both familial and environmental influences.},
language = {eng},
number = {3},
journal = {Human Biology},
author = {Bener, A. and Abdulrazzaq, Y. M. and Al-Mutawwa, J. and Debuse, P.},
month = jun,
year = {1996},
pmid = {8935321},
keywords = {Adolescent, Age distribution, Asthma, Child, Cross-Sectional Studies, Data Collection, Environmental Pollution, Female, Humans, Logistic Models, Male, Risk Factors, Sex Distribution, United Arab Emirates, incidence},
pages = {405--414},
}

@article{devereux_diet_2005,
title = {Diet as a risk factor for atopy and asthma},
volume = {115},
issn = {0091-6749},
doi = {10.1016/j.jaci.2004.12.1139},
abstract = {It has been hypothesized that decreasing antioxidant (fruit and vegetables), increased n-6 polyunsaturated fatty acid (PUFA; (margarine, vegetable oil), and decreased n-3 PUFA (oily fish) intakes have contributed to the recent increases in asthma and atopic disease. Epidemiologic studies in adults and children have reported beneficial associations between dietary antioxidants and lipids and parameters of asthma and atopic disease. The associations with n-6 and n-3 PUFA appear to be very complex and might differ between asthma and atopic dermatitis. Dietary antioxidants are probably exerting antioxidant and nonantioxidant immunomodulatory effects. Dietary lipids exert numerous complex effects on proinflammatory and immunologic pathways. It has also been suggested that atopic dermatitis is associated with an enzyme defect in lipid metabolism. In spite of this, the results of interventional supplementation studies in established disease have been disappointing, and there is now increasing interest in the possibility that dietary antioxidant and lipid intakes might be important in determining expression of disease during pregnancy and early childhood and that dietary interventions should be targeted at these groups. It also seems likely that there is individual variation in the responses of individuals to lipid, and probably antioxidant, supplementation. Further research to determine whether dietary intervention can reduce the risk of asthma and atopic disease is justified.},
language = {eng},
number = {6},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Devereux, Graham and Seaton, Anthony},
month = jun,
year = {2005},
pmid = {15940119},
keywords = {Animals, Antioxidants, Ascorbic Acid, Asthma, Child, Preschool, Clinical Trials as Topic, Dietary Fats, Dietary Supplements, Disease Models, Animal, Female, Fish Oils, Fruit, Humans, Hypersensitivity, Immediate, Lipid Metabolism, Lipids, Male, Pregnancy, Pregnancy Complications, Risk Factors, Selenium, Vegetables, Vitamin A, Vitamin E, diet},
pages = {1109--1117; quiz 1118},
}

@article{farber_young_1998,
title = {Young inner-city children visiting the emergency room ({ER}) for asthma: risk factors and chronic care behaviors},
volume = {35},
issn = {0277-0903},
shorttitle = {Young inner-city children visiting the emergency room ({ER}) for asthma},
abstract = {Inner-city children visiting emergency rooms (ER) for asthma often rely on the ER as their primary source of care. To evaluate chronic asthma control, structured interviews were conducted with the adult accompanying a sample of 46 children, 2-6 years old, presenting to an inner-city pediatric ER for asthma. Fifty-one percent had 10 or more prior ER visits and 46\% had 2 or more previous hospitalizations. Seventy-two percent had functional severity scores in the moderate to severe range. Only 11\% used daily inhaled anti-inflammatory medication. Not one patient had a written self-management plan. Most young children visiting an inner-city ER for asthma have poorly controlled and poorly managed chronic asthma.},
language = {eng},
number = {7},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Farber, H. J. and Johnson, C. and Beckerman, R. C.},
year = {1998},
pmid = {9777881},
keywords = {Albuterol, Asthma, Child, Child Welfare, Child, Preschool, Drug Utilization, Emergency Medical Services, Health Behavior, Hospitalization, Humans, Risk Factors, Urban Population, bronchodilator agents},
pages = {547--552},
}

@article{sims_descriptive_1999,
title = {A descriptive analysis of asthma in the {U}.{S}. {Navy} {Submarine} {Force}},
volume = {70},
issn = {0095-6562},
abstract = {BACKGROUND: The U.S. Navy Submarine Force offers a unique opportunity to study asthma because of the relative socioeconomic and physical homogeneity of the population and the closed environment occupational exposure. Currently, asthma is disqualifying from submarine service, which results in a significant loss of experienced personnel.
METHODS: We performed a retrospective analysis of 119 U.S. Navy submariner disqualification packages for asthma between 1989-1993.
RESULTS: We found a 0.16\% annual period prevalence of asthma in the active duty enlisted Atlantic Fleet Submarine Force. Two groups of asthma disqualifications were identified with a significant increase above their proportional representation in the fleet: enlisted personnel (p {\textless} 0.01) and submarine recruits (p {\textless} 0.0001). The proportion of African-American personnel also had a tendency toward increased asthma disqualification (p {\textless} 0.08). There were no differences in prevalence of asthma between crews of ballistic missile submarines or fast attack submarines. Asthma risk factors reported in the civilian literature (childhood history of asthma, family history of asthma and non-drug allergies) were highly represented in our study (41\%, 46\% and 68\% of submariners, respectively). Most disqualified submariners had "mild" asthma based on the diagnostic work-up. The methacholine challenge test appeared to carry a disproportionate diagnostic weight despite its low specificity.
CONCLUSION: Although the period prevalence of asthma is low in the U.S. Navy Submarine Force, submariners disqualified for asthma have similar historical and ethnic risk factors as the civilian population.},
language = {eng},
number = {12},
journal = {Aviation, Space, and Environmental Medicine},
author = {Sims, J. R. and Tibbles, P. M. and Jackman, R. P.},
month = dec,
year = {1999},
pmid = {10596778},
keywords = {Adult, Asthma, Bronchoconstrictor Agents, Continental Population Groups, Disability Evaluation, Humans, Mass Screening, Methacholine Chloride, Military Personnel, Prevalence, Retrospective Studies, Risk Factors, Sensitivity and Specificity, Severity of Illness Index, Skin Tests, Socioeconomic Factors, Submarine Medicine, United States, spirometry},
pages = {1214--1218},
}

@article{armentia_early_2001,
title = {Early introduction of cereals into children's diets as a risk-factor for grass pollen asthma},
volume = {31},
issn = {0954-7894},
abstract = {BACKGROUND: The prevalence of asthma has increased from the 1950s to the 1990s. The relationship between diet and asthma is an area of controversy that has never been fully evaluated. Attempts at dietary prevention of asthma have produced conflicting results. We have recently identified allergens from cereals that show cross-reactivity with proteins in grass pollen. An early intake of cereals in the diet during early life might cause IgE sensitization to cereals. It is not known whether such sensitization predisposes the development of allergy to pollen.
METHODS: To test this hypothesis, a cross-sectional study and an observational case-control analysis of reviewed data were carried out on 16381 patients who had been admitted to our Allergy Unit between 1989 and 1999. All the patients underwent allergy tests to identify asthma risk-factors. All information in our data base was analysed using the SPSS computer system.
RESULTS: There has been an increase of 7.8\% in incidences of allergic asthma and a 7.3\% increase in asthma due to grass pollen in the last decade. Grass-pollen asthma was associated with sensitization to cereals. The early introduction of cereals in the diet of children was found to be a risk factor for grass-pollen asthma (OR = 5.95; 95\% CI 3.89-9.10).
CONCLUSIONS: These findings document the progression of allergic asthma during a decade in a large sample of people who were influenced by similar environmental conditions and studied with the same diagnostic methods. This study represents the largest database of patients in which a common food is shown to be a risk factor for asthma.},
language = {eng},
number = {8},
journal = {Clinical and Experimental Allergy: Journal of the British Society for Allergy and Clinical Immunology},
author = {Armentia, A. and Bañuelos, C. and Arranz, M. L. and Del Villar, V. and Martín-Santos, J. M. and Gil, F. J. and Vega, J. M. and Callejo, A. and Paredes, C.},
month = aug,
year = {2001},
pmid = {11529895},
keywords = {Adult, Allergens, Asthma, Case-Control Studies, Cross-Sectional Studies, Data Interpretation, Statistical, Edible Grain, Female, Humans, Logistic Models, Male, Poaceae, Pollen, Risk Factors, Spain, diet},
pages = {1250--1255},
}

@article{rojas_molina_[prevalence_2001,
title = {[{Prevalence} and asthma risk factors in municipalities of the {State} of {Guerrero}, {Mexico}]},
volume = {48},
issn = {0002-5151},
abstract = {OBJECTIVE: To determine the incidence and the principal risk factors cause of asthma in scholar children between 4 to 6 years old and in adolescents students between 13 to 14 years old in six municipalities in Guerrero State, Mexico.
MATERIAL AND METHOD: A cross-sectional study was carried out with 6,136 students (both groups) in the Acapulco municipality on the second semester of 1999 and with 1,128 students in municipalities near to Acapulco in the first semester of year 2000. The procedure was to use the questionnaire ISAAC to interview the mothers of the children between 4 to 6 years old, and apply directly interviews to the 12 to 14 years old group. The study was carried out in public school with the more social recognition.
RESULTS: Asthma prevalence in the Acapulco municipality was 33.55\%. Detected in girls 34.8\% and 32.0\% in boys. In the rural municipalities near Acapulco the asthma prevalence was of 31.8\%. Detected in girls 34.0\% and 29.2\% in boys. One of the principal risk factory cause of incidence in the urban area of Acapulco was the presence of the cement factory. In the rural area near Acapulco the principal risk factor was the common presence of cotton toys. A very high asthma incidence was identified in the studied municipalities. The principal group affected was the students between 13 to 14 years old without a remarkable difference between gender in the urban areas.},
language = {spa},
number = {4},
journal = {Revista Alergia Mexico (Tecamachalco, Puebla, Mexico: 1993)},
author = {Rojas Molina, N. and Legorreta Soberanis, J. and Olvera Guerra, F.},
month = aug,
year = {2001},
pmid = {11593915},
keywords = {Adolescent, Asthma, Child, Child, Preschool, Cross-Sectional Studies, Female, Humans, Male, Mexico, Prevalence, Risk Factors},
pages = {115--118},
}

@article{klinnert_unraveling_2002,
title = {Unraveling the ecology of risks for early childhood asthma among ethnically diverse families in the southwest},
volume = {92},
issn = {0090-0036},
abstract = {OBJECTIVES: We describe the prevalence of asthma risk factors within racial/ethnic and language groups of infants participating in an intervention study for reducing chronic asthma.
METHODS: Low-income children aged 9 to 24 months with 3 or more episodes of wheezing illness were enrolled. Baseline information included family and medical histories, allergic status, environmental exposures, emotional environment, and caregiver psychosocial resources.
RESULTS: Racial/ethnic and language groups-European Americans, African Americans, high-acculturated Hispanics, and low-acculturated Hispanics-showed different patterns of risk factors for childhood asthma, with low-acculturated Hispanics showing the most distinctive pattern.
CONCLUSIONS: Patterns of covariation of biological and psychosocial risk factors for childhood asthma were associated with racial/ethnic and language status among urban, low-income children.},
language = {eng},
number = {5},
journal = {American Journal of Public Health},
author = {Klinnert, Mary D. and Price, Marcella R. and Liu, Andrew H. and Robinson, JoAnn L.},
month = may,
year = {2002},
pmid = {11988449},
pmcid = {PMC1447163},
keywords = {African Americans, Air Pollution, Indoor, Allergens, Asthma, Caregivers, Colorado, Environmental Exposure, European Continental Ancestry Group, Female, Hispanic Americans, Humans, Infant, Male, Poverty, Prevalence, Risk Assessment, Risk Factors, Social Conditions, Socioeconomic Factors, Stress, Psychological, Urban Health},
pages = {792--798},
}

@article{akpinar-elci_prevalence_2002,
title = {Prevalence and risk factors of occupational asthma among hairdressers in {Turkey}},
volume = {44},
issn = {1076-2752},
abstract = {This study was designed to evaluate the questionnaire-based prevalence and possible risk factors of occupational asthma among hairdressers in Turkey. We investigated occupational history and respiratory, ocular, dermal, and nasal symptoms using a standardized questionnaire, evaluated worksite pulmonary function tests, and performed allergen skin testing. We then determined asthma risk factors using age- and gender-adjusted logistic regression models. The prevalence of occupational asthma in hairdressers was 14.6\%. The odds ratio for hairdressers in a high work intensity group was 3.6 (95\% confidence interval, 1.2 to 10.9) with a significant dose-response trend (chi 2 trend = 4.875; P = 0.027). The odds ratio for occupational asthma among workers with atopy was 4.5 (95\% confidence interval, 1.2 to 17.2). We also observed an excess risk of occupational asthma with allergic rhinitis and conjunctivitis. Occupational asthma did not differ among subgroups of hairdressers. We observed an important risk of occupational asthma among hairdressers. The most prominent risk factors were work intensity and atopy.},
language = {eng},
number = {6},
journal = {Journal of Occupational and Environmental Medicine},
author = {Akpinar-Elci, Muge and Cimrin, Arif Hikmet and Elci, Omur Cinar},
month = jun,
year = {2002},
pmid = {12085487},
keywords = {Adolescent, Adult, Air Pollutants, Occupational, Asthma, Beauty Culture, Confidence intervals, Dermatitis, Atopic, Female, Hair Preparations, Humans, Male, Middle Aged, Occupational Diseases, Risk Factors, Turkey, regression analysis},
pages = {585--590},
}

@article{horner_impact_2002,
title = {The impact of asthma risk factors on home management of childhood asthma},
volume = {17},
issn = {0882-5963},
abstract = {There have been few studies of childhood asthma among families who live in nonmetropolitan settings. This work is part of the baseline assessment conducted before implementing a health education program to study the impact of asthma risk factors (gender, ethnicity, socioeconomic status, asthma severity) on home asthma management. Data analysis yielded no significant differences in home asthma management performed by parents or children with asthma based on the child's gender, ethnicity, asthma severity, or family socioeconomic status. Factors that define the child's experienced asthma pattern, such as activity limitations, number of allergens, and school absenteeism, were associated with the parent's work of asthma management. Trends in the data for the different ethnic and gender subgroups that have implications for clinical practice were identified. Future directions for research to address questions that emerged in this analysis are discussed.},
language = {eng},
number = {3},
journal = {Journal of Pediatric Nursing},
author = {Horner, Sharon D. and Surratt, Dawn and Smith, Susan B.},
month = jun,
year = {2002},
pmid = {12094362},
keywords = {Adolescent, Analysis of Variance, Asthma, Child, Female, Health Education, Humans, Male, Parenting, Risk Factors, Rural Population, Self Care, Socioeconomic Factors, United States},
pages = {211--221},
}

@article{peroni_food_2002,
title = {Food allergy: what can be done to prevent progression to asthma?},
volume = {89},
issn = {1081-1206},
shorttitle = {Food allergy},
abstract = {OBJECTIVES: The primary objective of this review is to discuss risk factors for asthma development in food allergen-sensitized children. In the paper we discuss the possible measures to prevent progression to asthma by allergen and other adjuvant factor avoidance.
DATA SOURCES: A review from literature of articles on these topics was performed.
STUDY SELECTION: Relevant publications on asthma risk factors and implementation of protective factors were critically evaluated.
RESULTS: Children with familiar history of atopy and sensitization to food proteins in early infancy are at high risk of subsequent respiratory allergic diseases and require specific prevention. Because early allergic sensitization is a significant risk factor for later development of asthma, prevention of asthma by early allergen avoidance is mandatory in high-risk children. Adjuvant factors such as tobacco smoke and mold exposure may act as nonspecific triggers for the development of atopy. The role of protective factors such as infections in early life, breast-feeding, a "healthy" diet needs to be evaluated in prospective studies. Pharmacologic intervention with antihistamines led to significant reduction in incidence of asthma in high-risk children, but confirmatory longitudinal studies in large populations are necessary.
CONCLUSIONS: There is now accumulating evidence that preventing exposure to house-dust mite may significantly reduce the prevalence of childhood asthma. However, allergen avoidance can not be recommended as the only strategy. Avoidance of adjuvant factors and implementation of potential protective factors aimed to reduce the risk to progression to asthma need to be evaluated in prospective studies.},
language = {eng},
number = {6 Suppl 1},
journal = {Annals of Allergy, Asthma \& Immunology: Official Publication of the American College of Allergy, Asthma, \& Immunology},
author = {Peroni, Diego G. and Chatzimichail, Atanasio and Boner, Attilio L.},
month = dec,
year = {2002},
pmid = {12487204},
keywords = {Adjuvants, Immunologic, Air Pollution, Indoor, Allergens, Asthma, Breast Feeding, Disease Progression, Environmental Exposure, Fatty Acids, Unsaturated, Food Hypersensitivity, Histamine Antagonists, Humans, Inhalation Exposure, Risk Factors, Tobacco Smoke Pollution, diet},
pages = {44--51},
}

@article{sotir_presence_2003,
title = {Presence of asthma risk factors and environmental exposures related to upper respiratory infection-triggered wheezing in middle school-age children},
volume = {111},
issn = {0091-6765},
abstract = {Viral respiratory infections and exposure to environmental constituents such as tobacco smoke are known or suspected to trigger wheezing/asthma exacerbations in children. However, few population-based data exist that examine the relationship between wheezing triggered by viral respiratory infections and environmental exposures. In this investigation we used population-based data to evaluate differences in exposures between symptomatic middle school-age children who did and did not report wheezing triggered by viral respiratory infections. As part of the North Carolina School Asthma Survey (NCSAS), a 66-question data instrument was used to collect information from children enrolled in North Carolina public middle schools during the 1999-2000 school year. Associations between exposures and upper respiratory infection-triggered wheezing (URI-TW) among symptomatic children were examined using adjusted prevalence odds ratios (PORs). Video methods developed for the International Study of Asthma and Allergies in Childhood were used to assess wheezing. Among the 33,534 NCSAS symptomatic participants, positive associations were observed between most exposures and URI-TW. Reported presence of all allergy variables (PORs ranging from 2.11 to 2.45) was more strongly associated with URI-TW than either smoking or other exposures. Presence of URI-TW was higher at increasing levels of tobacco smoke exposure, but no apparent dose-response effect was observed for other indoor air pollutants. URI-TW in middle school children is most associated with reported allergen sensitivity, relative to other asthma risk factors and environmental exposures. Data from this investigation may be useful in developing assessment, screening, and targeting strategies to improve asthma and wheezing management in children.},
language = {eng},
number = {4},
journal = {Environmental Health Perspectives},
author = {Sotir, Mark and Yeatts, Karin and Shy, Carl},
month = apr,
year = {2003},
pmid = {12676631},
pmcid = {PMC1241460},
keywords = {Adolescent, Asthma, Child, Environmental Exposure, Female, Humans, Male, North Carolina, Respiratory Sounds, Respiratory Tract Infections, Risk Factors, Severity of Illness Index, Virus Diseases, incidence},
pages = {657--662},
}

@article{kozyrskyj_childhood_2003,
title = {Childhood wheezing syndromes and healthcare data},
volume = {36},
issn = {8755-6863},
doi = {10.1002/ppul.10312},
abstract = {There is convincing evidence that several distinct wheezing syndromes exist in childhood. The purpose of this research was to assess the potential of using healthcare utilization profiles to identify wheezing syndromes in children which are distinct from asthma. Using population-based healthcare administrative data, a cohort of children, aged 5-15 years, with bronchitis diagnoses from time of birth to 1995, but no physician diagnoses of asthma, was followed over the period January 1996-March 1998. In this follow-up period, 13\% had subsequent healthcare utilization for asthma, 23\% had continued healthcare utilization for bronchitis, and 64\% had no further healthcare utilization. The likelihood of bronchitis vs. asthma outcomes was determined for a variety of asthma risk factors. In a cohort of 11,043 children with initial healthcare contact for bronchitis but not asthma, two potentially distinct entities of bronchitis emerged from our data: 1) transient bronchitis, similar to transient wheezing of early childhood, which was associated with winter-only healthcare utilization and absence of allergy, and 2) recurrent bronchitis which differed from asthma on the basis of winter-only healthcare utilization, prematurity at birth, absence of allergy, and low socioeconomic status. Healthcare administrative records can be used to describe the natural history of wheezing in children and to identify markers which may discriminate asthma from other syndromes.},
language = {eng},
number = {2},
journal = {Pediatric Pulmonology},
author = {Kozyrskyj, Anita L. and Mustard, Cameron A. and Becker, Allan B.},
month = aug,
year = {2003},
pmid = {12833492},
keywords = {Adolescent, Asthma, Bronchitis, Child, Cohort Studies, Databases, Factual, Female, Follow-Up Studies, Health Resources, Humans, Infant, Newborn, Infant, Premature, Male, Manitoba, Multivariate Analysis, Recurrence, Respiratory Sounds, Risk Factors, Seasons, Single-Parent Family, Socioeconomic Factors},
pages = {131--136},
}

@article{maher_infant_2004,
title = {Infant vaccinations and childhood asthma among full-term infants},
volume = {13},
issn = {1053-8569},
doi = {10.1002/pds.821},
abstract = {PURPOSE: To determine if infant vaccinations are associated with childhood asthma among full-term infants. The secondary objective was to describe relationships between characteristics of infant wheezing and childhood asthma.
METHODS: We used baseline data from a study of infant wheezing that selected full-term infants born into a health maintenance organization (HMO) during 1991-1994, continuously enrolled for at least 12 months and without perinatal pulmonary or other selected conditions. Information had been abstracted for infancy (0-18 months) regarding wheezing, vaccinations and asthma risk factors. Using automated data, we identified asthma cases in 1998 among those enrolled for at least 6 months during the year.
RESULTS: A total of 1778 full-term infants met our study criterion and 9\% had asthma in 1998. Childhood asthma was not significantly associated with having received Hepatitis B vaccine or age at first Hepatitis B vaccine; number of whole-cell pertussis, Haemophilis influenzae type b or oral polio vaccine doses; having received measles, mumps, rubella vaccine; or total number of vaccine doses combined. Childhood asthma was significantly associated with number of infant wheezing episodes.
CONCLUSIONS: Our findings do not support concerns that vaccines are associated with increased risk of asthma but confirm that frequency of infant wheezing is associated with childhood asthma.},
language = {eng},
number = {1},
journal = {Pharmacoepidemiology and Drug Safety},
author = {Maher, Julie E. and Mullooly, John P. and Drew, Lois and DeStefano, Frank},
month = jan,
year = {2004},
pmid = {14971117},
keywords = {Asthma, Female, Humans, Immunization Schedule, Infant, Infant, Newborn, Male, Prevalence, Respiratory Sounds, Retrospective Studies, Risk Factors, Vaccines},
pages = {1--9},
}

@article{fredrickson_understanding_2004,
title = {Understanding frequent emergency room use by {Medicaid}-insured children with asthma: a combined quantitative and qualitative study},
volume = {17},
issn = {0893-8652},
shorttitle = {Understanding frequent emergency room use by {Medicaid}-insured children with asthma},
abstract = {BACKGROUND: Medicaid-insured asthmatic children frequently use emergency rooms (ERs). The reasons are unclear and have predominantly been studied in inner-city populations.
METHODS: We used billing data and focus groups to clarify reasons for frequent ER use by Medicaid-insured children with asthma living in rural areas and 23 towns in Kansas.
RESULTS: High ER utilization was concentrated in a small percentage of provider practices and children with asthma. Parents expressed strong preference for primary care treatment, and identified real or perceived difficulties in using primary care as the principal reasons for ER use. Difficulties included trouble contacting primary care physicians or obtaining urgent appointments, limited continuity of care, practice systems poorly adapted to patient needs, a perception that physicians preferred patients to use emergency services, and difficulties in obtaining medications. Parents were not aware of preventive measures or case management but reported high interest in these. Parents did not recall provider discussion of asthma risk factors/preventive strategies during primary care visits, although all children with high ER utilization had multiple risk factors, including exposure to high levels of household smoking.
CONCLUSIONS: Reducing ER utilization by Medicaid-insured asthmatic children depends on overcoming barriers to effective treatment in primary care and in greater attention to preventive services.},
language = {eng},
number = {2},
journal = {The Journal of the American Board of Family Practice},
author = {Fredrickson, Doren D. and Molgaard, Craig A. and Dismuke, S. Edwards and Schukman, Jay S. and Walling, Anne},
month = apr,
year = {2004},
pmid = {15082667},
keywords = {Adolescent, Adolescent Health Services, Asthma, Child, Child Health Services, Child, Preschool, Emergency Service, Hospital, Focus Groups, Humans, Infant, Infant, Newborn, Kansas, Medicaid, Qualitative Research, Rural Population, United States, Urban Population},
pages = {96--100},
}

@article{lodrup_carlsen_is_2004,
title = {Is bronchodilator response in 2-yr-old children associated with asthma risk factors?},
volume = {15},
issn = {0905-6157},
doi = {10.1111/j.1399-3038.2004.00147.x},
abstract = {Factors that might influence lung function bronchodilator response by 2 yr of age is largely unknown, thus we aimed to assess this in the 'Environment and Childhood asthma' (ECA) study in Oslo. A clinical investigation at mean age 26 months was attended by 516 (84\%) children included in a nested case-control study [children with recurrent bronchial obstruction (rBO)] (n = 265) and controls without a history of lower respiratory disease (n = 251). Tidal lung function measures before and after inhaled nebulized salbutamol (bronchodilator response) (when clinically without BO) were obtained in 46\%. Clinical characteristics and personal and family history of allergic/respiratory diseases (asthma risk factors) were ascertained by structured interview and clinical examination. Allergic sensitization was assessed by skin prick test/specific IgE antibody analyses to common allergens. Mean (95\% CI) per cent change in time to reach peak flow/total expiratory time (t(PTEF)/t(E)) from before to after salbutamol was significantly larger in children with rBO [17.3 (9.4-25.3) than controls (-2.2 (-7.7 to 3.0)]. The bronchodilator response increased significantly (p = 0.001) with increasing number of asthma risk factors, but was not significantly associated with allergic sensitization, parental 'atopy', or maternal smoking alone. Children treated with inhaled corticosteroids had greater bronchodilator response than those treated with bronchodilators alone. Bronchodilator response in asymptomatic 2-yr-old children was most closely associated with the presence of rBO, but increasing number of asthma risk factors and treatment with inhaled corticosteroids were associated with increased bronchodilator response.},
language = {eng},
number = {4},
journal = {Pediatric Allergy and Immunology: Official Publication of the European Society of Pediatric Allergy and Immunology},
author = {Lødrup Carlsen, Karin C. and Pettersen, Morten and Carlsen, Kai-Håkon},
month = aug,
year = {2004},
pmid = {15305941},
keywords = {Administration, Inhalation, Adrenal Cortex Hormones, Airway Obstruction, Albuterol, Case-Control Studies, Child, Preschool, Dermatitis, Atopic, Female, Humans, Male, Risk Factors, Skin Tests, Tidal Volume, bronchodilator agents, lung},
pages = {323--330},
}

@article{kelley_asthma_2005,
title = {Asthma phenotypes, risk factors, and measures of severity in a national sample of {US} children},
volume = {115},
issn = {1098-4275},
doi = {10.1542/peds.2004-0529},
abstract = {OBJECTIVE: To examine a nationally representative sample of US children aged 6 to 16 years old and determine whether there are differences in risk factors and measures of severity between children with different asthma phenotypes.
METHODS: We analyzed data from the Third National Health and Nutrition Examination Survey. We used questionnaire and skin-prick testing data to separate children into the following mutually exclusive categories: atopic asthma, nonatopic asthma, resolved asthma, frequent respiratory symptoms with no asthma diagnosis, and normal. We used multivariate regression to determine whether demographic or potential risk factors varied between phenotypes and whether measures of severity varied by phenotype.
RESULTS: We found that 4.8\% of children had atopic asthma, 1.9\% had nonatopic asthma, 3.4\% had resolved asthma, and 4.3\% had frequent respiratory symptoms. Risk factors varied by phenotype, for example, the mean BMI was higher among children with nonatopic asthma, prenatal maternal smoking was a risk factor for resolved asthma, and child care attendance was a risk factor for frequent respiratory symptoms with no asthma diagnosis. Patients with atopic and nonatopic asthma were similar for most measures of asthma severity (medication use, health status, and lung function impairment). In contrast, patients with resolved asthma had fewer symptoms but a similar level of lung function impairment to that seen in patients with current asthma, whereas children with frequent respiratory symptoms but no asthma diagnosis had normal lung function.
CONCLUSIONS: Asthma risk factors and measures of severity vary between children with different asthma phenotypes.},
language = {eng},
number = {3},
journal = {Pediatrics},
author = {Kelley, Colleen F. and Mannino, David M. and Homa, David M. and Savage-Brown, Amanda and Holguin, Fernando},
month = mar,
year = {2005},
pmid = {15741378},
keywords = {Adolescent, Asthma, Body Mass Index, Child, Child Day Care Centers, Female, Forced Expiratory Volume, Humans, Hypersensitivity, Immediate, Male, Nutrition Surveys, Phenotype, Respiratory Tract Diseases, Risk Factors, Severity of Illness Index, Surveys and Questionnaires, Tobacco Smoke Pollution, United States, Vital Capacity},
pages = {726--731},
}

@article{cullinan_occupational_2005,
title = {Occupational asthma: risk factors, diagnosis and preventive measures},
volume = {1},
issn = {1744-8409},
shorttitle = {Occupational asthma},
doi = {10.1586/1744666X.1.1.123},
abstract = {In adulthood, new or recurrent asthma is caused by work in approximately 10\% of cases. The term occupational asthma is reserved for those cases arising from respiratory hypersensitivity to a specific workplace agent; in others (work-exacerbated asthma) the mechanism is of nonspecific airway irritation on a background of bronchial hyper-reactivity. Some 300 workplace agents are capable of inducing asthma de novo; fortunately, most cases are attributed to a much smaller number to which exposure occurs in a few high-risk occupations. Exposure level is the most important remediable risk factor; the factors governing individual susceptibility are poorly understood. Diagnosis is generally straightforward. Management is rarely pharmacologic and often difficult since the diagnosis incurs important employment and other social consequences.},
language = {eng},
number = {1},
journal = {Expert Review of Clinical Immunology},
author = {Cullinan, Paul},
month = may,
year = {2005},
pmid = {20477660},
pages = {123--132},
}

@article{garcia-marcos_different_2005,
title = {A different pattern of risk factors for atopic and non-atopic wheezing in 9-12-year-old children},
volume = {16},
issn = {0905-6157},
doi = {10.1111/j.1399-3038.2005.00318.x},
abstract = {Few epidemiological studies have compared the risk factors of asthma or wheezing between atopic and non-atopic children. The objective of this study was to determine if there are specific risk factors for current wheezing related to atopic status in schoolchildren. Schoolchildren 9-12 yr of age from three Spanish cities (n = 2720) were subject to a cross-sectional study of asthma risk factors (by questionnaire) and atopy (by skin prick test) according to the ISAAC phase-II protocol. Risk factors for current wheezing (in the last 12 months) as reported by parents were investigated among the atopic (positive prick test to at least one allergen) and the non-atopic (negative prick test) children. The prevalence of current wheezing was 13.1\% in the whole group, 22.1\% in the atopic group and 7.8\% in the non-atopic group. However, only 62.4\% of children with current wheezing were atopic. Male gender and asthma in the mother and/or the father were both significant and independent risk factors for current atopic wheezing, whereas maternal smoking in the first year of the child's life and mould stains on the household walls were for current non-atopic wheezing. In summary, this study shows that atopic and current non-atopic wheezing children in Spain do not share identical environmental and family risk factors.},
language = {eng},
number = {6},
journal = {Pediatric Allergy and Immunology: Official Publication of the European Society of Pediatric Allergy and Immunology},
author = {García-Marcos, Luis and Castro-Rodríguez, Jose A. and Suarez-Varela, María Morales and Garrido, Jose Batlles and Hernandez, Gloria García and Gimeno, Antonio Martínez and González, Agustín Llopis and Ruiz, Teresa Rubí and Torres, Antonela Martínez},
month = sep,
year = {2005},
pmid = {16176393},
keywords = {Child, Child Welfare, Cross-Sectional Studies, Family Health, Female, Humans, Hypersensitivity, Immediate, Male, Multivariate Analysis, Prevalence, Respiratory Sounds, Risk Factors, Sensitivity and Specificity, Skin Tests, Spain},
pages = {471--477},
}

@article{higgins_risk_2005,
title = {Risk factors for asthma and asthma severity in nonurban children in {Connecticut}},
volume = {128},
issn = {0012-3692},
doi = {10.1378/chest.128.6.3846},
abstract = {STUDY OBJECTIVE: To examine asthma diagnosis, asthma severity, and the presence of established asthma risk factors in children who reside in nonurban communities.
DESIGN: A cross-sectional study was conducted of 19,076 children (6 months to 18 years of age) who lived in 146 nonurban communities in the greater Hartford, CT, region and who were enrolled in a disease-management program (Easy Breathing II; Michelle Cloutier, MD; Hartford, CT) designed to improve asthma diagnosis and treatment.
RESULTS: The overall frequency of physician-confirmed asthma in children seeking health care was 18\%. Asthma frequency was related to low socioeconomic status (SES), non-Caucasian ethnicity, male gender, age {\textgreater} or = 5 years, and exposure to tobacco smoke, dust, or cockroaches in the multivariate analysis. When controlling for SES, African-American children were 1.33 times more likely (95\% confidence interval [CI], 1.15 to 1.53) and Hispanic children were 1.60 times as likely (95\% CI, 1.38 to 1.85) as Caucasian children to have asthma. In contrast, asthma severity was related to dust exposure, a family history of asthma, non-Caucasian ethnicity, and age {\textless} or = 4 years in the multivariate analysis. African-American children (odds ratio, 1.31; 95\% CI, 1.03 to 1.67) had more severe asthma diagnosed as compared to Caucasian children. Hispanic ethnicity was not associated with an increase in asthma severity.
CONCLUSION: Risk factors for asthma in nonurban children are similar to risk factors in urban children. Ethnicity is a risk factor for asthma regardless of SES. Even in nonurban environments, African-American and Hispanic children have more asthma, and African-American children have more severe disease than their Caucasian counterparts.},
language = {eng},
number = {6},
journal = {Chest},
author = {Higgins, Pamela Sangeloty and Wakefield, Dorothy and Cloutier, Michelle M.},
month = dec,
year = {2005},
pmid = {16354853},
keywords = {Adolescent, Age distribution, Asthma, Child, Child, Preschool, Cohort Studies, Confidence intervals, Connecticut, Cross-Sectional Studies, Educational Status, Female, Humans, Infant, Male, Odds ratio, Prognosis, Respiratory Function Tests, Risk Factors, Rural Population, Severity of Illness Index, Sex Distribution, Socioeconomic Factors, incidence, probability},
pages = {3846--3853},
}

@article{lara_heterogeneity_2006,
title = {Heterogeneity of childhood asthma among {Hispanic} children: {Puerto} {Rican} children bear a disproportionate burden},
volume = {117},
issn = {1098-4275},
shorttitle = {Heterogeneity of childhood asthma among {Hispanic} children},
doi = {10.1542/peds.2004-1714},
abstract = {OBJECTIVES: To estimate differences in asthma prevalence among Hispanic subgroups and non-Hispanic children living in the United States and to explore the association between these differences and risk factors.
METHODS: Weighted logistic regression analyses of merged 1997 to 2001 National Health Interview Survey data were used to estimate the prevalence of asthma diagnosis and asthma attacks in a sample of 46511 children (age: 2-17 years) living in the 50 states and the District of Columbia.
RESULTS: Puerto Rican children had the highest prevalence of lifetime asthma (26\%) and recent asthma attacks (12\%), compared with non-Hispanic black children (16\% and 7\%, respectively), non-Hispanic white children (13\% and 6\%, respectively), and Mexican children (10\% and 4\%, respectively). Adjustment for asthma risk factors did not change these comparisons appreciably. Compared with non-Hispanic white children, the adjusted odds ratios (ORs) for a lifetime asthma diagnosis were 2.33 (95\% confidence interval [CI]: 1.90-2.84) for Puerto Rican children, 1.16 (95\% CI: 1.04-1.29) for non-Hispanic black children, and 0.90 (95\% CI: 0.79-1.03) for Mexican children. Birthplace influenced the association between ethnicity and lifetime asthma diagnosis differently for Puerto Rican and Mexican children. Compared with United States-born non-Hispanic white children with United States-born parents, the adjusted ORs were 1.95 (95\% CI: 1.48-2.57) for Puerto Rican children in families with the child and parent(s) born in the 50 states/District of Columbia and 2.50 (95\% CI: 1.51-4.13) for island-born Puerto Rican children with island-born parents. The corresponding adjusted ORs for Mexican children were 1.05 (95\% CI: 0.90-1.22) for families born in the 50 states/District of Columbia and 0.43 (95\% CI: 0.29-0.64) for those born in Mexico. The results were similar for recent asthma attacks.
CONCLUSIONS: The appreciably higher asthma morbidity rates experienced by Puerto Rican children cannot be explained by sociodemographic and other risk factors measured in the National Health Interview Survey. The heterogeneity of asthma among Hispanic subgroups should be considered in developing effective public health prevention and intervention strategies.},
language = {eng},
number = {1},
journal = {Pediatrics},
author = {Lara, Marielena and Akinbami, Lara and Flores, Glenn and Morgenstern, Hal},
month = jan,
year = {2006},
pmid = {16396859},
keywords = {Adolescent, African Americans, Asthma, Child, Child, Preschool, European Continental Ancestry Group, Hispanic Americans, Humans, Prevalence, Puerto Rico, Risk Factors, Socioeconomic Factors, United States},
pages = {43--53},
}

@article{reisman_treating_2006,
title = {Treating asthma with omega-3 fatty acids: where is the evidence? {A} systematic review},
volume = {6},
issn = {1472-6882},
shorttitle = {Treating asthma with omega-3 fatty acids},
doi = {10.1186/1472-6882-6-26},
abstract = {BACKGROUND: Considerable interest exists in the potential therapeutic value of dietary supplementation with the omega-3 fatty acids. Given the interplay between pro-inflammatory omega-6 fatty acids, and the less pro-inflammatory omega-3 fatty acids, it has been thought that the latter could play a key role in treating or preventing asthma. The purpose was to systematically review the scientific-medical literature in order to identify, appraise, and synthesize the evidence for possible treatment effects of omega-3 fatty acids in asthma.
METHODS: Medline, Premedline, Embase, Cochrane Central Register of Controlled Trials, CAB Health, and, Dissertation Abstracts were searched to April 2003. We included randomized controlled trials (RCT's) of subjects of any age that used any foods or extracts containing omega-3 fatty acids as treatment or prevention for asthma. Data included all asthma related outcomes, potential covariates, characteristics of the study, design, population, intervention/exposure, comparators, and co interventions.
RESULTS: Ten RCT's were found pertinent to the present report.
CONCLUSION: Given the largely inconsistent picture within and across respiratory outcomes, it is impossible to determine whether or not omega-3 fatty acids are an efficacious adjuvant or monotherapy for children or adults. Based on this systematic review we recommend a large randomized controlled study of the effects of high-dose encapsulated omega-3 fatty acids on ventilatory and inflammatory measures of asthma controlling diet and other asthma risk factors. This review was limited because Meta-analysis was considered inappropriate due to missing data; poorly or heterogeneously defined populations, interventions, intervention-comparator combinations, and outcomes. In addition, small sample sizes made it impossible to meaningfully assess the impact on clinical outcomes of co-variables. Last, few significant effects were found.},
language = {eng},
journal = {BMC complementary and alternative medicine},
author = {Reisman, J. and Schachter, H. M. and Dales, R. E. and Tran, K. and Kourad, K. and Barnes, D. and Sampson, M. and Morrison, A. and Gaboury, I. and Blackman, J.},
month = jul,
year = {2006},
pmid = {16854238},
pmcid = {PMC1550729},
keywords = {Adult, Asthma, Child, Dose-Response Relationship, Drug, Evidence-Based Medicine, Fatty Acids, Omega-3, Humans, Nausea, Respiratory Function Tests, Treatment Outcome, Vomiting},
pages = {26},
}

@article{del-rio-navarro_identification_2006,
title = {Identification of asthma risk factors in {Mexico} {City} in an {International} {Study} of {Asthma} and {Allergy} in {Childhood} survey},
volume = {27},
issn = {1088-5412},
abstract = {The International Study of Asthma and Allergy in Childhood (ISAAC) has assessed the prevalence of asthma, as well as the factors related to the disease in different countries. The aim of this study was to identify asthma risks factors in Mexico City. Data were obtained from questionnaires of children participating in a phase 3b ISAAC survey. Two thousand ninety-eight boys and 2008 girls were recruited in the 6- to 7-year-old group and 3243 boy and 3333 girls were recruited in the 13- to 14-year-old group. Logistic regression was used to determine the asthma risks factors. In the logistic regression for cumulative and current asthma prevalence, the variables allergic rhinitis and atopic dermatitis were the most important risk factors with the highest odds ratios (OR {\textgreater} 1.5; p {\textless} 0.05). The use of antibiotics and paracetamol in the first 12 months of life were related to cumulative asthma in both genders in the 6- to 7-year-old group. Contact of pregnant mother with farm animals was positively related with cumulative asthma in boys in the 6- to 7-year-old group. The main factors associated with the cumulative and current prevalence of asthma in both age groups were atopic dermatitis and allergic rhinitis. Future interventions for the prevention and early diagnosis and treatment could be focused in the natural history of the atopic march.},
language = {eng},
number = {4},
journal = {Allergy and Asthma Proceedings},
author = {Del-Rio-Navarro, Blanca and Berber, Arturo and Blandón-Vijil, Virginia and Ramírez-Aguilar, Matiana and Romieu, Isabelle and Ramírez-Chanona, Nelly and Heras-Acevedo, Samuel and Serrano-Sierra, Alejandro and Barraza-Villareal, Albino and Baeza-Bacab, Manuel and Sienra-Monge, Juan J. L.},
month = aug,
year = {2006},
pmid = {16948345},
keywords = {Adolescent, Asthma, Child, Cross-Sectional Studies, Dermatitis, Atopic, Female, Health Surveys, Humans, Male, Mexico, Prevalence, Rhinitis, Allergic, Perennial, Rhinitis, Allergic, Seasonal, Risk Factors, Urban Health},
pages = {325--333},
}

@article{delclos_occupational_2007,
title = {Occupational risk factors and asthma among health care professionals},
volume = {175},
issn = {1073-449X},
doi = {10.1164/rccm.200609-1331OC},
abstract = {RATIONALE: Recent U.S. data suggest an increased risk of work-related asthma among health care workers, yet only a few specific determinants have been elucidated.
OBJECTIVES: To evaluate associations of asthma prevalence with occupational exposures in a cross-sectional survey of health care professionals.
METHODS: A detailed questionnaire was mailed to a random sample (n=5,600) of all Texas physicians, nurses, respiratory therapists, and occupational therapists with active licenses in 2003. Information on asthma symptoms and nonoccupational asthma risk factors obtained from the questionnaire was linked to occupational exposures derived through an industry-specific job-exposure matrix.
MEASUREMENTS: There were two a priori defined outcomes: (1) physician-diagnosed asthma with onset after entry into health care ("reported asthma") and (2) "bronchial hyperresponsiveness-related symptoms," defined through an 8-item symptom-based predictor.
MAIN RESULTS: Overall response rate was 66\%. The final study population consisted of 862 physicians, 941 nurses, 968 occupational therapists, and 879 respiratory therapists (n=3,650). Reported asthma was associated with medical instrument cleaning (odds ratio [OR], 2.22; 95\% confidence interval [CI], 1.34-3.67), general cleaning (OR, 2.02; 95\% CI, 1.20-3.40), use of powdered latex gloves between 1992 and 2000 (OR, 2.17; 95\% CI, 1.27-3.73), and administration of aerosolized medications (OR, 1.72; 95\% CI, 1.05-2.83). The risk associated with latex glove use was not apparent after 2000. Bronchial hyperresponsiveness-related symptoms were associated with general cleaning (OR, 1.63; 95\% CI, 1.21-2.19), aerosolized medication administration (OR, 1.40; 95\% CI, 1.06-1.84), use of adhesives on patients (OR, 1.65; 95\% CI, 1.22-2.24), and exposure to a chemical spill (OR, 2.02; 95\% CI, 1.28-3.21).
CONCLUSIONS: The contribution of occupational exposures to asthma in health care professionals is not trivial, meriting both implementation of appropriate controls and further study.},
language = {eng},
number = {7},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Delclos, George L. and Gimeno, David and Arif, Ahmed A. and Burau, Keith D. and Carson, Arch and Lusk, Christine and Stock, Thomas and Symanski, Elaine and Whitehead, Lawrence W. and Zock, Jan-Paul and Benavides, Fernando G. and Antó, Josep M.},
month = apr,
year = {2007},
pmid = {17185646},
pmcid = {PMC1899286},
keywords = {Asthma, Cross-Sectional Studies, Female, Health Personnel, Health Surveys, Humans, Male, Middle Aged, Occupational Diseases, Occupational Exposure, Prevalence, Risk Factors},
pages = {667--675},
}

@article{pereira_nonatopic_2007,
title = {Nonatopic asthma is associated with helminth infections and bronchiolitis in poor children},
volume = {29},
issn = {0903-1936},
doi = {10.1183/09031936.00127606},
abstract = {Asthma is common in urban centres in Latin America, but atopic asthma may not be the main phenotype among children. Helminth infections are highly prevalent in poor populations, and it was hypothesised that they attenuate allergic asthma, whereas other factors are related to the expression of a nonatopic wheeze/asthma phenotype. A total of 1,982 children from Southern Brazil with a mean+/-sd age of 10.1+/-0.76 yrs completed asthma questionnaires, and 1,011 were evaluated for intestinal parasites and atopy using skin-prick tests (SPTs). Wheeze in the previous 12 months was reported by 25.6\%, and 9.3\% showed current asthma; 13\% were SPT-positive and 19.1\% were positive for any helminths. Most children with either wheeze or asthma were SPT-negative; however, severe wheeze was more prevalent among the atopic minority. Helminth infections were inversely associated with positive SPT results. Bronchiolitis before the age of 2 yrs was the major independent risk factor for asthma at age 10 yrs; high-load Ascaris infection, a family history of asthma and positive SPT results were also asthma risk factors. Most asthma and wheeze are of the nonatopic phenotype, suggesting that some helminths may exert an attenuating effect on the expression of the atopic portion of the disease, whereas viral bronchiolitis predisposes more specifically to recurrent airway symptoms.},
language = {eng},
number = {6},
journal = {The European Respiratory Journal},
author = {Pereira, M. U. and Sly, P. D. and Pitrez, P. M. and Jones, M. H. and Escouto, D. and Dias, A. C. O. and Weiland, S. K. and Stein, R. T.},
month = jun,
year = {2007},
pmid = {17331964},
keywords = {Adolescent, Asthma, Brazil, Child, Helminthiasis, Humans, Phenotype, Poverty, Respiratory Tract Infections, Risk Factors, Skin Tests, Surveys and Questionnaires, Time Factors, bronchiolitis, regression analysis},
pages = {1154--1160},
}

@article{kozyrskyj_increased_2007,
title = {Increased risk of childhood asthma from antibiotic use in early life},
volume = {131},
issn = {0012-3692},
doi = {10.1378/chest.06-3008},
abstract = {BACKGROUND: To address the major methodological issues of reverse causation and selection bias in epidemiologic studies of antibiotic use in early life and the development of asthma, we undertook a cohort study of this association in a complete population of children.
METHODS: Using the health-care and prescription databases of Manitoba, Canada, this longitudinal study assessed the association between antibiotic prescription use during the first year of life and asthma at age 7 years in a 1995 birth cohort of 13,116 children.
RESULTS: Independent of well-known asthma risk factors, asthma was significantly more likely to develop in children who had received antibiotics in the first year of life at age 7 years. The association with asthma was observed for antibiotic use in non-respiratory tract infections (adjusted odds ratio [OR], 1.86; 95\% confidence interval [CI], 1.02 to 3.37). The risk of asthma was highest in children receiving more than four courses of antibiotics (adjusted OR, 1.46; 95\% CI, 1.14 to 1.88), especially among rural children, and in the absence of maternal asthma or a dog in the birth year. Broad-spectrum (BS) cephalosporin use was more common in these subpopulations of children.
CONCLUSIONS: Antibiotic use in early life was associated with the development of childhood asthma, a risk that may be reduced by avoiding the use of BS cephalosporins.},
language = {eng},
number = {6},
journal = {Chest},
author = {Kozyrskyj, Anita L. and Ernst, Pierre and Becker, Allan B.},
month = jun,
year = {2007},
pmid = {17413050},
keywords = {Anti-Bacterial Agents, Asthma, Cephalosporins, Child, Cohort Studies, Drug Hypersensitivity, Female, Humans, Infant, Infant Welfare, Longitudinal Studies, Male, Manitoba, Odds ratio, Respiratory Tract Infections, Risk Factors},
pages = {1753--1759},
}

@article{bener_pattern_2007,
title = {The pattern and genetics of pediatric extrinsic asthma risk factors in polluted environment},
volume = {39},
issn = {1764-1489},
abstract = {AIM: The aim of the present study is to determine the effect of polluted environment on extrinsic of asthma and allergic diseases among school children.
DESIGN: This is case and control study.
SETTING: The study was carried out among school children living and attending the school in industrial and residential area during the period of October 2004 and June 2005.
SUBJECTS: The study based on age, sex, and ethnicity of 716 cases (with asthma) and 716 controls (without asthma) school children living in both urban and in industrial polluted with oil refinery and chemical pollutant.
METHODS: The International study of asthma and allergies in childhood (ISAAC) and some additional questionnaires were used to collect the data of the school children. The questionnaire included information about: socio-demographic characteristics; respiratory symptoms; associated respiratory illness; family history of allergic diseases among first-degree relatives of asthmatic children; behavioural factors which could be additive to asthma. Univariate and multivariate statistical analyses were performed.
RESULTS: The proportion of children in the asthmatic group who reported symptoms was significantly higher than in non-asthmatic group ({\textless}0.0001). The asthmatic group reported that 47.5\% morning time breathlessness, shortness of breath (61.4\%), wheeze after exercise (65.4\%), phlegm (45.3\%) and chronic cough (42.2\%). Male asthmatics had a average age at onset of symptoms of 6.9\% (+/-4.8\%) years compared with female asthmatics who had higher age at onset of symptoms, 7.6 (+/-5.9). Male asthmatics also had longer duration of symptoms (7.5 +/- 4.9 in males and 6.4 +/- 4.6 years in females). Significantly odds ratios were found higher in asthmatic compared to controls for pneumonia, bronchitis, atopy (allergic rhinitis and atopic dermatitis), sinusitis, croup, parental asthmas, parental atopy including parental allergic rhinitis, atopic dermatitis and parental smoking (p {\textless} 0.0001). The logistic regression model showed that shortness of breath, bronchitis, pneumonia, sinusitis, parental asthma, allergic rhinitis, atopic dermatitis, croup, pets ownership and parental smoking were significant risk factors for asthma
CONCLUSION: The present study provides some evidence that exposure to outdoor air pollutants increases the risk of childhood asthma and allergic diseases in school children. The results are consistent with the hypothesis that long term exposure to NOx and CO levels suggests that emissions from photochemical air pollution and oil refinery contributes to adverse health effects in Qatar.},
language = {eng},
number = {2},
journal = {European Annals of Allergy and Clinical Immunology},
author = {Bener, Abdulbari and Ehlayel, Mohammed and Sabbah, Alfred},
month = feb,
year = {2007},
pmid = {17441417},
keywords = {Adolescent, Air Pollutants, Asthma, Case-Control Studies, Child, Environmental Pollution, Female, Genetic Predisposition to Disease, Humans, Male, Risk Factors, eczema, rhinitis},
pages = {58--63},
}

@article{dumanovsky_variation_2007,
title = {Variation in adult asthma prevalence in {Hispanic} subpopulations in {New} {York} {City}},
volume = {44},
issn = {0277-0903},
doi = {10.1080/02770900701344140},
abstract = {BACKGROUND: We compared asthma prevalence among New York City Hispanics-Puerto Rican, Dominican, and other Hispanics-in relation to nativity, socioeconomic status, and asthma risk factors.
METHODS: Weighted logistic regression analyses on telephone survey data for New York City (NYC) adults in 2003/2004.
RESULTS: Asthma prevalence was highest among Puerto Ricans (11.8\%) compared with Dominicans and other Hispanics. Non-US-born Dominicans and other Hispanics were significantly less likely to report current asthma than were Puerto Ricans (OR = 0.27, 95\% CI 0.18-0.41 and OR = 0.17, 95\% CI 0.11-0.26, respectively). In multivariate analyses, US-born Dominicans and other Hispanics had rates comparable to Puerto Ricans.
CONCLUSIONS: Puerto Ricans, both mainland- and native-born, report the highest rates of adult asthma. Non-US-born Hispanics report lower rates. Acculturation and patterns of residential settlement may account for this variation.},
language = {eng},
number = {4},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Dumanovsky, Tamara and Matte, Thomas D.},
month = may,
year = {2007},
pmid = {17530529},
keywords = {Acculturation, Adolescent, Adult, Aged, Air Pollution, Indoor, Asthma, Cross-Sectional Studies, Emigration and Immigration, Female, Hispanic Americans, Humans, Insurance Coverage, Insurance, Health, Male, Middle Aged, New York City, Prevalence, Risk Factors, Smoking, Socioeconomic Factors},
pages = {297--303},
}

@article{arnedo_[incidence_2007,
title = {[{Incidence} of asthma and risk factors in a cohort of schoolchildren aged from 6-7 years old to 14-15 years old in {Castellón} ({Spain}) following the {International} {Study} of {Asthma} and {Allergies} in {Childhood} ({ISAAC})]},
volume = {129},
issn = {0025-7753},
abstract = {BACKGROUND AND OBJECTIVE: To estimate the incidence of asthma in schoolchildren from 6-7 years old to 14-15 years old and associated risk factors.
POPULATION AND METHOD: A cohort study, with the ISAAC phases I and III in 1994 and 2002, respectively, was carried out in Castellón, and the nearby towns Vila-real, Almassora, Benicàssim, El Grau de Castelló, Borriol, and L'Alcora. In 1992, 3,607 schoolchildren aged 6-7 years old took part, of whom 1,805 were again studied in 2002, at the age of 14-15. New cases of asthma were defined following the ISAAC questionnaire. Poisson regression was used in the analysis of asthma risk factors.
RESULTS: Participation was 50.0\%. The cumulative incidence of asthma was 6.4\% during the 8 years of study, 108 new cases of 1,698 schoolchildren free of asthma at beginning. Incidence was greater in boys than girls, and in 14-year old teenagers compared to 15-year olds, although differences were not significant. Risk factors associated with the incidence of asthma were: family history of asthma, history of allergic rhinitis, history of bronchitis and upper-middle compared to lower social class.
CONCLUSIONS: A low incidence of asthma was found in schoolchildren from Castellón, Spain, in comparison with other cohort studies. Estimated risk factors were generally in accordance with incidence studies.},
language = {spa},
number = {5},
journal = {Medicina Clinica},
author = {Arnedo, Alberto and Bellido, Juan B. and Pac, María Rosario and Artero, Adrián and Campos, Joan-Baptista and Museros, Lidón and Puig-Barberà, Joan and Tosca, Ricardo and Tornador, Ester},
month = jun,
year = {2007},
pmid = {17669332},
keywords = {Adolescent, Asthma, Child, Female, Humans, Male, Prospective Studies, Risk Factors, Spain, incidence},
pages = {165--170},
}

@article{gonzales_risk_2007,
title = {Risk factors for asthma and cough among {Hispanic} children in the southwestern {United} {States} of {America}, 2003-2004},
volume = {21},
issn = {1020-4989},
abstract = {OBJECTIVES: To investigate the impact of environmental tobacco smoke (ETS) exposure and mother's place of birth (Mexico vs. United States of America) on the prevalence of asthma and dry nighttime cough among children 2-12 years old residing in the southwestern United States.
METHODS: Data were collected from November 2003 through March 2004 as part of a health survey of Hispanic mothers with young children who sought emergency, nutrition, or other clinical services. Information about respiratory health was obtained for one randomly selected child per United States-born (no. = 144) or Mexico-born (no. = 125) mother. Information on maternal and household sociodemographic variables, smoking, parental asthma, and child's exposure to room or automobile ETS during the previous seven days was also collected. Adjusted prevalence ratios were estimated with modified Poisson regression models.
RESULTS: Most sociodemographic and ETS exposure variables differed significantly by mother's country of birth. Modeled asthma prevalence was 1.95 [95\% confidence interval (CI) = 1.03-3.68] times greater in children of United States-born mothers than children of Mexico-born mothers. This difference persisted after known asthma risk factors were controlled for, including parental asthma, socioeconomic and demographic variables, and child ETS exposure. Children's recent automobile ETS exposure was associated with dry nighttime cough [adjusted prevalence ratio (PR) = 1.94, 95\% CI = 1.19-3.15] and asthma (PR = 2.09; 95\% CI = 0.99-4.39).
CONCLUSIONS: Exposure to ETS in automobiles is an important risk factor for asthma and dry nighttime cough among Hispanic children in the southwest United States, regardless of mother's country of birth. Further research is needed to identify causes of the higher prevalence of asthma in Hispanic children of United States-born mothers.},
language = {eng},
number = {5},
journal = {Revista Panamericana De Salud Publica = Pan American Journal of Public Health},
author = {Gonzales, Melissa and Malcoe, Lorraine H. and Myers, Orrin B. and Espinoza, Judith},
month = may,
year = {2007},
pmid = {17697480},
keywords = {Asthma, Child, Child, Preschool, Cough, Female, Hispanic Americans, Humans, Male, Prevalence, Risk Factors, United States},
pages = {274--281},
}

@article{kozyrskyj_continued_2008,
title = {Continued exposure to maternal distress in early life is associated with an increased risk of childhood asthma},
volume = {177},
issn = {1535-4970},
doi = {10.1164/rccm.200703-381OC},
abstract = {RATIONALE: Evidence is emerging that exposure to maternal distress in early life plays a causal role in the development of childhood asthma.
OBJECTIVES: Because much of the data are from high-risk cohorts, we undertook a birth cohort study in a complete population of children to test this association.
METHODS: Using Manitoba, Canada's, health care and prescription databases, this longitudinal study assessed the association between maternal distress during the first year of life and onward, and asthma at age 7 in a 1995 birth cohort of 13,907 children.
MEASUREMENTS AND MAIN RESULTS: Maternal distress was defined on the basis of health care or prescription medication use for depression or anxiety. Asthma status was derived from health care and prescription records for asthma, using a definition validated by comparison to pediatric allergist diagnosis. Multiple logistic regression was used to determine the likelihood of asthma (odds ratio [OR], 95\% confidence interval [95\% CI]). Independent of well-known asthma risk factors, our population-based study of a non-high-risk cohort demonstrated an increased risk of childhood asthma (OR, 1.25; 95\% CI, 1.01-1.55) among children exposed to continued maternal distress from birth until age 7. Exposure to maternal depression and anxiety limited to the first year of life did not have a demonstrable association with subsequent asthma. Of interest, we observed that the risk of asthma associated with continued maternal distress was increased in children living in high- versus low-income households (OR, 1.44; 95\% CI, 1.12-1.85).
CONCLUSIONS: Maternal distress in early life plays a role in the development of childhood asthma, especially if it continues beyond the postpartum period.},
language = {eng},
number = {2},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Kozyrskyj, Anita L. and Mai, Xiao-Mei and McGrath, Patrick and Hayglass, Kent T. and Becker, Allan B. and Macneil, Brian},
month = jan,
year = {2008},
pmid = {17932381},
keywords = {Anxiety, Asthma, Child, Child, Preschool, Confounding Factors (Epidemiology), Depression, Female, Health Services, Humans, Infant, Infant, Newborn, Logistic Models, Longitudinal Studies, Male, Mothers, Risk Factors, Socioeconomic Factors},
pages = {142--147},
}

@article{whu_risk_2007,
title = {Risk factors for pediatric asthma in the {South} {Bronx}},
volume = {44},
issn = {1532-4303},
doi = {10.1080/02770900701752516},
abstract = {We identified main asthma risk factors for children living in the South Bronx, where asthma rates are eight times higher than the national average. This case-control study enrolled 261 children at Lincoln Medical and Mental Health Center from 2002 to 2003. We questioned the mothers on medical history and home environment. The most important risk factors for asthma in the South Bronx pediatric population are Hispanic ethnicity, family history of asthma, and exposure to tobacco smoke. South Bronx children limited to breast-feeding during the first 3 months of age are less likely to develop asthma.},
language = {eng},
number = {10},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Whu, Rafael and Cirilo, Ginaida and Wong, Jonathan and Finkel, Madelon L. and Mendez, Hermann A. and Leggiadro, Robert J.},
month = dec,
year = {2007},
pmid = {18097863},
keywords = {Asthma, Case-Control Studies, Child, Preschool, Humans, New York City, Risk Factors},
pages = {855--859},
}

@article{acosta_new_2008,
title = {The {New} {York} {City} {Puerto} {Rican} asthma project: study design, methods, and baseline results},
volume = {45},
issn = {1532-4303},
shorttitle = {The {New} {York} {City} {Puerto} {Rican} asthma project},
doi = {10.1080/02770900701815784},
abstract = {OBJECTIVE: We examined asthma risk factors among 274 Puerto Rican children born in New York to atopic mothers.
METHODS: We prospectively followed the cohort to measure aeroallergens in their homes and assess allergic sensitization. Baseline data are presented.
RESULTS: Maternal smoking was significantly higher among women born on the continental United States (25\%) vs. those born elsewhere (11\%). Cat ownership was more frequent among mainland-born women (15\%) compared with those born in Puerto Rico (4\%). While some aeroallergens were prevalent, few dust samples contained detectable dust mite allergens.
CONCLUSIONS: By following this cohort, we hope to identify the roles that socio-cultural factors play in the process of allergic sensitization.},
language = {eng},
number = {1},
journal = {The Journal of Asthma: Official Journal of the Association for the Care of Asthma},
author = {Acosta, Luis M. and Acevedo-García, Dolores and Perzanowski, Matthew S. and Mellins, Robert and Rosenfeld, Lindsay and Cortés, Dharma and Gelman, Andrew and Fagan, Joanne K. and Bracero, Luis A. and Correa, Juan C. and Reardon, Ann Marie and Chew, Ginger L.},
month = feb,
year = {2008},
pmid = {18259996},
keywords = {Adult, Air Pollution, Indoor, Allergens, Asthma, Child, Preschool, Female, Follow-Up Studies, Humans, Male, New York City, Prospective Studies, Puerto Rico, Risk Factors, Surveys and Questionnaires},
pages = {51--57},
}

@article{horner_childhood_2008,
title = {Childhood asthma in a rural environment: implications for clinical nurse specialist practice},
volume = {22},
issn = {1538-9782},
shorttitle = {Childhood asthma in a rural environment},
doi = {10.1097/01.NUR.0000311708.40190.ca},
abstract = {PURPOSE: The purpose of this study was to identify factors that impact asthma morbidity in rural school-aged children.
DESIGN: Exploratory analysis of baseline data collected in a longitudinal intervention study was performed.
SETTING: Four rural school districts that served small towns and unincorporated areas participated in this study.
SAMPLE: Participants were children in grades 2 to 5 who had current asthma and who spoke English or Spanish. There were 183 children (108 boys, 75 girls) with an average age of 8.78 years and who were Hispanic (46\%), white (31\%), or African American (22\%).
METHODS: Associations between asthma risk factors (gender, ethnicity/race, socioeconomic status, asthma severity), asthma resources (access to care, health insurance), family asthma management, and asthma morbidity (absenteeism, emergency department visits, hospitalizations) were analyzed.
FINDINGS: Children with more severe asthma had higher absenteeism and more hospitalizations, and their parents performed more asthma management behaviors. Families who had difficulty accessing care had more hospitalizations and emergency department visits and were more likely to be poor. More boys, more Hispanic and African American children, and more children from poorer families were hospitalized for asthma than were middle-class and non-Hispanic white children.
CONCLUSIONS: Asthma is a chronic condition that is fairly easy for some families to manage, whereas other families are having higher asthma morbidity that needs to be addressed through targeted interventions.},
language = {eng},
number = {4},
journal = {Clinical nurse specialist CNS},
author = {Horner, Sharon D.},
month = aug,
year = {2008},
pmid = {18596488},
pmcid = {PMC2504731},
keywords = {Absenteeism, Asthma, Child, Female, Humans, Male, Risk Factors, Rural Population, Social Class, Specialties, Nursing},
pages = {192--198; quiz 199--200},
}

@article{peroni_preschool_2009,
title = {Preschool asthma in {Italy}: prevalence, risk factors and health resource utilization},
volume = {103},
issn = {1532-3064},
shorttitle = {Preschool asthma in {Italy}},
doi = {10.1016/j.rmed.2008.07.016},
abstract = {Asthma in preschool children is greatly under-diagnosed worldwide. Aim was to investigate prevalence of wheezing, and asthma risk factors, doctor diagnosis, treatment and health resource utilization in preschool children. About 1402 children (3-5 years) attending local kindergartens participated in the study. The International Study of Asthma and Allergies in Childhood (ISAAC) written questionnaire (WQ) was used with additional questions on risk factors, asthma diagnosis, treatments, resource utilization. Allergic sensitisation was evaluated by skin prick tests for the common allergens. Prevalence of "wheezing in previous 12 months" and "doctor diagnosed asthma" were 12.1\% and 8.6\%, respectively. 4.7\% of children have had both wheezing in the last 12 months and asthma diagnosis. Significant risk factors for wheezing were rhinitis, parental history of atopy and sensitivity to mites and grass pollens. 27.3\% of children with asthma diagnosis, but only 4.9\% of children without diagnosis, received regular treatment during the previous year (p{\textless}0.0001). Children with more than 4 episodes of wheezing a year received more frequently an asthma diagnosis, but 68.6\% were not on regular treatment. Asthma diagnosis was associated with a significant increase in control visits for wheezing (p{\textless}0.0001). The prevalence of children requiring at least one hospital emergency visit in the previous year was not different among the two groups (83.3\% vs. 82.5\%). In preschool children the prevalence of wheezing and asthma is elevated. Preschool asthma seems to be under-treated with few cases receiving regular therapy. The social cost of the disease at this age seems to be elevated because of the high frequency of control and emergency visits.},
language = {eng},
number = {1},
journal = {Respiratory Medicine},
author = {Peroni, Diego G. and Piacentini, Giorgio L. and Bodini, Alessandro and Boner, Attilio L.},
month = jan,
year = {2009},
pmid = {18760577},
keywords = {Asthma, Child, Preschool, Dermatitis, Atopic, Diagnosis, Differential, Female, Humans, Hypersensitivity, Italy, Male, Patient Acceptance of Health Care, Prevalence, Respiratory Sounds, Risk Factors, Skin Tests, rhinitis},
pages = {104--108},
}

@article{ross_obesity_2009,
title = {Obesity and obesity related co-morbidities in a referral population of children with asthma},
volume = {44},
issn = {1099-0496},
doi = {10.1002/ppul.21065},
abstract = {OBJECTIVE: Although there is mounting evidence that childhood obesity is a risk factor for incident asthma, it remains unclear if there is a distinct "asthma-obesity" phenotype. This study characterized body composition, obesity related co-morbidities, and traditional risk factors for asthma in a cohort of children referred for asthma management in a pulmonary clinic. We hypothesized that children with asthma and obesity would have distinct risk factors and co-morbidities, particularly with respect to metabolic and sleep abnormalities.
PARTICIPANTS AND METHODS: One hundred sixteen asthmatic children ages 4-18 years underwent comprehensive measurements of common asthma risk factors as well as measurements of obesity-related morbidities, including lung function tests, atopy, and assessments of sleep (overnight oximetry and actigraphy), physical activity (accelerometry), and metabolism. Characteristics of children who were obese (BMI {\textgreater} or =95th percentile) were compared to those who were not obese (BMI {\textless}95th percentile).
RESULTS: Obesity was present in 44\% of participants. Obese participants had similar rates of atopy and family history of atopy, lung function, and asthma control at enrolment as their non-obese peers. A significantly higher proportion of obese participants had metabolic syndrome (23\% vs. 0\%) and habitual snoring (60\% vs. 33\%) compared to non-obese participants; insufficient sleep and nocturnal desaturations tended to be more prevalent among obese subjects.
CONCLUSIONS: Obesity and obesity related co-morbidities were common in a referral population of children with asthma. The specific influence of metabolic abnormalities on asthma morbidity and management is still uncertain and likely will need to be addressed in prospective studies.},
language = {eng},
number = {9},
journal = {Pediatric Pulmonology},
author = {Ross, Kristie R. and Hart, Meeghan A. and Storfer-Isser, Amy and Kibler, Anna Marie V. and Johnson, Nathan L. and Rosen, Carol L. and Kercsmar, Carolyn M. and Redline, Susan},
month = sep,
year = {2009},
pmid = {19639627},
pmcid = {PMC2940418},
keywords = {Adolescent, Asthma, Child, Child, Preschool, Female, Humans, Male, Metabolic Syndrome, Obesity, Ohio, Prevalence, Snoring},
pages = {877--884},
}

@article{hung_antenatal_2010,
title = {Antenatal steroid treatment reduces childhood asthma risk in very low birth weight infants without bronchopulmonary dysplasia},
volume = {38},
issn = {1619-3997},
doi = {10.1515/JPM.2010.002},
abstract = {Bronchopulmonary dysplasia (BPD) and very low birth weight (VLBW) are associated with increased incidences of asthma and pulmonary dysfunction in childhood. However, no studies exist which examine asthma risk factors in children who were VLBW infants and did not have BPD. To address this issue, we assessed the asthma incidence and risk factors for asthma in 117 children (approximate mean age of 5 years) who were VLBW [{\textless}1500 g, mean gestational age (GA): 30 weeks] infants without BPD. The risk factors were both perinatal (such as steroid treatment, mechanical ventilation, surfactant treatment) and environmental (parental smoking, pet adoption, etc). The asthma incidence was 18.8\%. Following multivariate analysis, it was determined that a family history of atopy was a strong risk factor for childhood asthma. Maternal antenatal steroid treatment was associated with a significantly reduced risk for asthma. GA and birth weight were not predictive of childhood asthma. These findings indicate that a history of familial atopy and antenatal steroid treatment are positively and negatively associated (independent of BPD) with childhood asthma in VLBW infants. The finding regarding antenatal steroid treatment warrants more extensive investigations.},
language = {eng},
number = {1},
journal = {Journal of Perinatal Medicine},
author = {Hung, Yi-Li and Hsieh, Wu-Shiun and Chou, Hung-Chieh and Yang, Yao-Hsu and Chen, Chien-Yi and Tsao, Po-Nien},
year = {2010},
pmid = {19921992},
keywords = {Asthma, Bronchopulmonary Dysplasia, Child, Child, Preschool, Dexamethasone, Environmental Exposure, Female, Glucocorticoids, Humans, Infant, Newborn, Infant, Very Low Birth Weight, Male, Pregnancy, Respiratory Sounds, Risk Factors, Taiwan},
pages = {95--102},
}

@article{kozyrskyj_frequent_2009,
title = {Frequent nocturnal awakening in early life is associated with nonatopic asthma in children},
volume = {34},
issn = {1399-3003},
doi = {10.1183/09031936.00040509},
abstract = {Sleep deprivation has become a common phenomenon of the Western world and is associated with a variety of medical problems in children. This retrospective longitudinal analysis of a community-based birth cohort was undertaken to determine whether frequent nocturnal awakening during early life was associated with the development of childhood asthma. 2,398 children born to mothers recruited from the antenatal clinics of a single hospital in Perth, Australia during 1989-1991 were followed up at years 1, 2, 3, 6, 8, 10 and 14. Parent-completed questionnaires were analysed. The odds ratio for asthma at age 6 and 14 yrs in children with frequent nocturnal awakening during the first 3 yrs after birth was determined from multiple logistic regression. Following adjustment for asthma risk factors, co-sleeping and family stress, persistent nocturnal awakening was associated with nonatopic asthma at age 6 and 14 yrs (at age 14 yrs: OR 2.18, 95\% CI 1.15-4.13) but not with atopic asthma. We found an increased risk of nonatopic asthma in children following frequent nocturnal awakening during the first 3 yrs of life. These hypothesis-generating data suggest the need for further systematic study of the effects of disordered sleep in early life on the development of asthma.},
language = {eng},
number = {6},
journal = {The European Respiratory Journal},
author = {Kozyrskyj, A. L. and Kendall, G. E. and Zubrick, S. R. and Newnham, J. P. and Sly, P. D.},
month = dec,
year = {2009},
pmid = {19948910},
keywords = {Adolescent, Asthma, Australia, Bronchial Hyperreactivity, Child, Child, Preschool, Female, Humans, Infant, Male, Odds ratio, Risk Factors, Sleep Wake Disorders, Time Factors, Treatment Outcome, regression analysis},
pages = {1288--1295},
}

@article{redlich_skin_2010,
title = {Skin exposure and asthma: is there a connection?},
volume = {7},
issn = {1943-5665},
shorttitle = {Skin exposure and asthma},
doi = {10.1513/pats.201002-025RM},
abstract = {Numerous occupational and environmental exposures that increase asthma risk have been identified. Research and prevention have focused primarily on the respiratory tract. However, recent studies suggest that the skin may also be an important route of exposure and site of sensitization that contributes to asthma development. Factors that impair skin barrier function, such as filaggrin gene mutations or skin trauma, may facilitate allergen entry and promote Th2-like sensitization and subsequent asthma. Animal studies demonstrate that skin exposure to chemical and protein allergens is highly effective at inducing sensitization, with subsequent inhalation challenge eliciting asthmatic responses. A similar role for human skin exposure to certain sensitizing agents, such as isocyanates, is likely. Skin exposure methodologies are being developed to incorporate skin exposure assessment into epidemiology studies investigating asthma risk factors.},
language = {eng},
number = {2},
journal = {Proceedings of the American Thoracic Society},
author = {Redlich, Carrie A.},
month = may,
year = {2010},
pmid = {20427586},
pmcid = {PMC3266020},
keywords = {Allergens, Asthma, Dermatitis, Atopic, Environmental Exposure, Humans, Skin Absorption},
pages = {134--137},
}

@article{malling_differences_2010,
title = {Differences in associations between markers of antioxidative defense and asthma are sex specific},
volume = {7},
issn = {1878-7398},
doi = {10.1016/j.genm.2010.03.004},
abstract = {BACKGROUND: Lungs are exposed to high levels of oxygen, air pollutants, and smoke, all of which stimulate the production of reactive oxygen species (ROS). In addition, inflammatory cells produce ROS, and thus there may be increased demand for antioxidants, including antioxidant enzymes, in inflammatory lung diseases such as asthma. Sex-specific differences have been noted for asthma, which in postpubertal subjects is predominantly found in females. These sex-specific differences may be associated with differences on the molecular level as well.
OBJECTIVE: The aim of this cross-sectional study was to examine associations between markers of antioxidative defense and asthma, and to investigate whether these associations were different between women and men.
METHODS: Based on the European Community Respiratory Health Survey protocol, subjects were enrolled in a study of asthma risk factors. The multicenter study was conducted in 5 west Danish counties between 2003 and 2006, and the subjects were recruited as a case-enriched random sample of 10,000 Danish inhabitants aged 20 to 44 years selected by their civil registration number. Participants were identified by positive answers to asthma questions on a screening questionnaire, random sampling, or both. Serum selenium concentrations and antioxidant enzyme activities (superoxide dismutase, glutathione peroxidase [GPX], glutathione reductase [GR], and glucose-6-phosphate dehydrogenase [G6PD]) in erythrocytes were measured. Asthma was defined as either current asthma symptoms with bronchial hyperresponsiveness (BHR) or a continuous asthma score based on 8 questions.
RESULTS: A total of 1191 mostly white women and men (mean [SD] age, 34.0 [7.1] and 35.1 [7.1] years, respectively) were enrolled in the study. Current asthma symptoms were present in 29.9\% (200/670) of women and 22.5\% (117/521) of men, with women reporting more positive answers (51.1\% vs 40.9\%, respectively; P {\textless} 0.01) to asthma questions. Serum selenium concentrations were measured in 1151 subjects (640 women, 511 men), and antioxidant enzyme activities were measured in 295 subjects (161 women, 134 men). Women had higher enzyme activities of most antioxidant enzymes (GPX, P = 0.006; GR, P {\textless} 0.001; and G6PD, P = 0.009) than did men. Although the serum selenium concentration was inversely associated with asthma in both sexes, there was a female preponderance, with 3.5\% lower serum selenium in subjects with current asthma symptoms with BHR (n = 77) compared with controls (n = 287). GR activity was associated with asthma in men, with 5.7\% higher enzyme activity in subjects with current asthma symptoms with BHR (n = 14) compared with controls (n = 77). However, a significant interaction with gender was observed for analyses of GR (P = 0.02), but not for analyses of selenium.
CONCLUSIONS: In this study of asthma risk factors, women had higher levels of enzyme activities than did men in a randomly selected Danish population, and sex-specific differences were found in the associations between markers of antioxidative defense and asthma.},
language = {eng},
number = {2},
journal = {Gender Medicine},
author = {Malling, Tine Halsen and Sigsgaard, Torben and Andersen, Helle R. and Deguchi, Yoji and Brandslund, Ivan and Skadhauge, Lars and Thomsen, Gert and Baelum, Jesper and Sherson, David and Omland, Oyvind},
month = apr,
year = {2010},
pmid = {20435274},
keywords = {Adult, Antioxidants, Asthma, Biomarkers, Case-Control Studies, Cross-Sectional Studies, Denmark, Erythrocytes, Female, Glucosephosphate Dehydrogenase, Glutathione Peroxidase, Glutathione Reductase, Humans, Male, Oxidative Stress, Reactive Oxygen Species, Risk Factors, Selenium, Sex Characteristics, Superoxide Dismutase},
pages = {115--124},
}

@article{uthaisangsook_risk_2010,
title = {Risk factors for development of asthma in {Thai} adults in {Phitsanulok}: a university-based study},
volume = {28},
issn = {0125-877X},
shorttitle = {Risk factors for development of asthma in {Thai} adults in {Phitsanulok}},
abstract = {Studies have shown that asthma in children is caused by environmental and genetic factors. In adult asthma, risk factors were less well recognized. Likewise, in Thailand, data in adult asthma is limited. This study aimed to evaluate risk factors, determine skin reactivities to allergens, and assess concomitant allergy among adult asthma in Phitsanulok, a major city in the lower northern Thailand. Five hundred and thirteen Naresuan University staff members and students completed 2 sets of questionnaires and underwent allergy skin prick tests. The first set of questionnaires was standardized Thai version of ISAAC questionnaire for identifying asthma, allergic rhinitis, and atopic eczema. The second set was modified from ISAAC phase II questionnaire to identify asthma risk factors. Fifty-eight subjects (11.6\%) were identified as having physician's diagnosed asthma and 89 subjects (17.7\%) wheezed in the past 12 months. Among 89 subjects, 14.4\% wheezed more than once a month, 45.6\% had wheezes interfering with sleep. Concomitant allergic rhinitis, rhinoconjunctivitis and atopic eczema among these asthma subjects were 82.5\%, 67.9\%, and 14.9\%, respectively. Eighty seven point nine percent of asthmatic subjects had positive skin reactivities to at least one allergen. Two of the most common allergens were house dust mites and cockroaches. Maternal smoking during pregnancy, smoking among family members, and family history of allergy were statistically significant risks for developing asthma, while having a rice field around the residence represented a significant protective factor. In conclusion, high prevalence of asthma presented in Phitsanulok and many asthmatic subjects were partly controlled or uncontrolled. The environment such as a rice field could protect against asthma, however atopy and smoking exposure were significant risks for asthma development},
language = {eng},
number = {1},
journal = {Asian Pacific Journal of Allergy and Immunology},
author = {Uthaisangsook, Suwannee},
month = mar,
year = {2010},
pmid = {20527512},
keywords = {Adolescent, Adult, Allergens, Asthma, Conjunctivitis, Allergic, Dermatitis, Atopic, Female, Humans, Male, Middle Aged, Prevalence, Risk Factors, Skin Tests, Smoking, Students, Surveys and Questionnaires, Thailand, Universities, rhinitis},
pages = {23--28},
}

@article{boneberger_asthma_2010,
title = {Asthma in changing environments--chances and challenges of international research collaborations between {South} {America} and {Europe}--study protocol and description of the data acquisition of a case-control-study},
volume = {10},
issn = {1471-2466},
doi = {10.1186/1471-2466-10-43},
abstract = {BACKGROUND: Asthma in children is an emerging public health problem in South America. So far, research in this part of the world is limited. This paper presents the methodology and description of the data acquisition of an asthma case-control study conducted in the Central South of Chile.
METHODS/DESIGN: A hospital-based case-control study about asthma (188 cases, 294 controls) in children (6-15 years) was carried out in Valdivia, Chile between November 2008 and December 2009. Data on asthma risk factors were collected by computer-assisted personal interview using validated questions from e.g. ISAAC phase II. Data on household dust exposure (endotoxin, allergen analyses), skin prick tests to most common allergens, stool examinations for parasitic infection, and blood samples (total IgE, genetics) were collected. Additionally, 492 randomly chosen blood donors were recruited in order to assess allele frequencies in the population of Valdivia.
DISCUSSION: Overall 1,173 participants were contacted. Response was 82\% among cases and 65\% among controls. Atopic sensitization was high (78\% among cases, 47\% among controls). Cases had a statistically significantly (p {\textless} .0001) increased self-reported 12-month prevalence of symptoms of rhinitis (82\% vs. 51\%) and wheeze (68\% vs. 16\%). The study is well placed to address current hypotheses about asthma and its correlates in the South American context. Results of this study might help develop novel, innovative and individualized prevention strategies in countries in transition with respect to the South American context.},
language = {eng},
journal = {BMC pulmonary medicine},
author = {Boneberger, Anja and Radon, Katja and Baer, Jennifer and Kausel, Leonie and Kabesch, Michael and Haider, Daniel and Schierl, Rudolf and von Kries, Rüdiger and Calvo, Mario},
month = aug,
year = {2010},
pmid = {20718949},
pmcid = {PMC2930633},
keywords = {Adolescent, Adult, Allergens, Asthma, Blood Donors, Case-Control Studies, Child, Chile, Dust, Endotoxins, Environment, Environmental Exposure, Female, Gene Frequency, Genetic Variation, Haplotypes, Humans, Hypersensitivity, Immunoglobulin E, Male, Middle Aged, Risk Factors, Skin Tests, Surveys and Questionnaires, Young Adult, rhinitis},
pages = {43},
}

@article{agache_risk_2010,
title = {Risk factors and asthma phenotypes in children and adults with seasonal allergic rhinitis},
volume = {38},
issn = {0091-3847},
doi = {10.3810/psm.2010.12.1829},
abstract = {BACKGROUND: There are few data on asthma risk factors and phenotypes in patients with seasonal allergic rhinitis (SAR).
METHODS: Thirty-three children (mean age, 8.27 ± 1.77 years) and 82 adults (mean age, 34.12 ± 10.59 years) with SAR were evaluated for asthma (history, reversibility of bronchial obstruction, increased inhaled nitric oxide). The following asthma risk factors were considered in the multiple regression analysis: male sex, family history of asthma, breastfeeding {\textless} 2 months, passive/active smoking, obesity, pets/molds exposure, high total serum immunoglobulin E (IgE), polysensitization (sensitized to 3 seasonal pollens with different structure), mixed sensitization (seasonal and perennial allergens), severe rhinitis (according to the Allergic Rhinitis and its Impact on Asthma guidelines), and lack of allergen-specific immunotherapy (SIT) for rhinitis preceding asthma diagnosis. Asthma phenotypes were characterized using the k-means clustering (silhouette method for cluster validation).
RESULTS: Asthma was diagnosed in 22 (66.7\%) children and in 57 (69.5\%) adults with SAR. Independent risk factors for asthma were lack of SIT preceding asthma diagnosis, both for children (P = 0.008132) and adults (P = 0.000017), and mixed sensitization for children (P = 0.035694). Asthma phenotypes identified in children according to the associated risk factors were: breastfeeding {\textless} 2 months and severe rhinitis in 16 (63.6\%) patients; male, polysensitized, and severe rhinitis in 8 (36.4\%) patients. Asthma phenotypes in adults were: polysensitization and severe rhinitis in 30 (52.6\%) patients; male, exposure to pets, and severe rhinitis in 11 (19.3\%) patients; and high total serum IgE and polysensitization in 16 (28.1\%) patients.
CONCLUSION: Lack of SIT is an independent risk factor for asthma both in children and adults with SAR, whereas polysensitization is a risk factor only for children. The dominant asthma phenotype in children with SAR is breastfeeding {\textless} 2 months and severe rhinitis. In adults with SAR, the dominant asthma phenotype is polysensitization and severe rhinitis.},
language = {eng},
number = {4},
journal = {The Physician and Sportsmedicine},
author = {Agache, Ioana and Ciobanu, Cristina},
month = dec,
year = {2010},
pmid = {21150146},
keywords = {Adult, Asthma, Bronchial Provocation Tests, Child, Child, Preschool, Cluster Analysis, Cross-Sectional Studies, Enzyme-Linked Immunosorbent Assay, Female, Humans, Male, Phenotype, Rhinitis, Allergic, Seasonal, Risk Factors, regression analysis},
pages = {81--86},
}

@article{durham_epigenetics_2011,
title = {Epigenetics of asthma},
volume = {1810},
issn = {0006-3002},
doi = {10.1016/j.bbagen.2011.03.006},
abstract = {Asthma is caused by both heritable and environmental factors. It has become clear that genetic studies do not adequately explain the heritability and susceptibility to asthma. The study of epigenetics, heritable non-coding changes to DNA may help to explain the heritable component of asthma. Additionally, epigenetic modifications can be influenced by the environment, including pollution and cigarette smoking, which are known asthma risk factors. These environmental trigger-induced epigenetic changes may be involved in skewing the immune system towards a Th2 phenotype following in utero exposure and thereby enhancing the risk of asthma. Alternatively, they may directly or indirectly modulate the immune and inflammatory processes in asthmatics via effects on treatment responsiveness. The study of epigenetics may therefore play an important role in our understanding and possible treatment of asthma and other allergic diseases. This article is part of a Special Issue entitled: Biochemistry of Asthma.},
language = {eng},
number = {11},
journal = {Biochimica Et Biophysica Acta},
author = {Durham, Andrew L. and Wiegman, Coen and Adcock, Ian M.},
month = nov,
year = {2011},
pmid = {21397662},
keywords = {Acetylation, Air pollution, Animals, Asthma, DNA Methylation, Epigenesis, Genetic, Histones, Humans, MicroRNAs, Smoking, diet},
pages = {1103--1109},
}

@article{holt_interaction_2011,
title = {Interaction between adaptive and innate immune pathways in the pathogenesis of atopic asthma: operation of a lung/bone marrow axis},
volume = {139},
issn = {1931-3543},
shorttitle = {Interaction between adaptive and innate immune pathways in the pathogenesis of atopic asthma},
doi = {10.1378/chest.10-2397},
abstract = {Atopic asthma is the most common form of asthma, particularly during childhood, and in many cases it persists into adult life. Although atopy is clearly a risk factor for development of this disease, only a small subset of subjects sensitized to aeroallergens express persistent symptoms, suggesting that additional pathogenic mechanisms are involved. Recent studies have implicated respiratory viral infections as key cofactors in asthma development in atopic patients. In relation to initial expression of the asthma phenotype in early childhood, it has been shown that although both atopic sensitization and early severe lower respiratory tract infections can operate as independent asthma risk factors, the persistence of asthma is most frequent among children who experience both insults, suggesting that the relevant inflammatory pathways interact to maximally drive disease pathogenesis. Importantly, it has been established that both these factors must be operative contemporaneously for these interactions to occur (ie, the interactions are likely to be direct). Recent studies on viral-induced asthma exacerbations in atopic children have provided a plausible mechanism for these interactions. Notably, it has been demonstrated that signals triggered during the innate immune response to the virus can lead to the release of large numbers of migrating high-affinity IgE receptor-bearing bone marrow-derived precursors of mucosal dendritic cells into the blood. The subsequent trafficking of these cells to the infected airway mucosa where dendritic cell turnover is very high provides a potential mechanism for recruitment of underlying aeroallergen-specific T-helper 2 immunity into the already inflamed milieu in the infected airway mucosa.},
language = {eng},
number = {5},
journal = {Chest},
author = {Holt, Patrick G. and Sly, Peter D.},
month = may,
year = {2011},
pmid = {21540215},
keywords = {Acute Disease, Adaptive Immunity, Adult, Asthma, Child, Humans, Hypersensitivity, Immediate, Immunity, Innate, Phenotype, Severity of Illness Index},
pages = {1165--1171},
}

@article{dietert_maternal_2011,
title = {Maternal and childhood asthma: risk factors, interactions, and ramifications},
volume = {32},
issn = {1873-1708},
shorttitle = {Maternal and childhood asthma},
doi = {10.1016/j.reprotox.2011.04.007},
abstract = {Asthma is emerging as a premier example of a health risk that can largely be molded by the status of the mother and the environmental conditions encountered during sensitive windows of prenatal and early childhood development. While genetic background, allergic status of parents, and predisposition for atopy and inflammation play a role, early-life environmental conditions can completely alter the course of immune and respiratory system development. Environmentally induced alterations that (1) maintain the Th2 bias seen during gestation, (2) block the maturation of innate immune cells and (3) create inflammatory dysfunction in the infant provide the foundation for childhood asthma. No single risk factor can fully explain the increased prevalence of asthma in recent decades but it is assumed that the rapid increase is due to environmental and/or epigenetic changes. Well-established and suspected environmental risk factors cover all categories of early life interactions from diet, exposure to environmental contaminants and drugs, maternal and neonatal infections, hygiene, timing of vaccinations and even the mode of birth delivery. Because asthma is connected to the risk of several comorbid chronic conditions, the benefit of asthma risk reduction and prevention is greater than initially may be apparent. This review discusses strategies to optimize preventative and therapeutic options across life stages.},
language = {eng},
number = {2},
journal = {Reproductive Toxicology (Elmsford, N.Y.)},
author = {Dietert, Rodney R.},
month = sep,
year = {2011},
pmid = {21575714},
keywords = {Asthma, Child, Child Development, Environmental Exposure, Female, Gene-Environment Interaction, Genetic Predisposition to Disease, Humans, Immune System, Pregnancy, Prenatal Exposure Delayed Effects, Prevalence, Risk Factors},
pages = {198--204},
}

@article{loisel_ifng_2011,
title = {{IFNG} genotype and sex interact to influence the risk of childhood asthma},
volume = {128},
issn = {1097-6825},
doi = {10.1016/j.jaci.2011.06.016},
abstract = {BACKGROUND: Asthma is a complex disease characterized by sex-specific differences in incidence, prevalence, and severity, but little is known about the molecular basis of these sex-based differences.
OBJECTIVE: To investigate the genetic architecture of sex differences in asthma risk, we evaluated (1) associations between polymorphisms in the IFNG gene and childhood-onset asthma in combined and sex-specific samples and (2) interactions between polymorphisms and sex on asthma risk.
METHODS: Main and sex-interaction effects of IFNG genetic diversity on asthma risk and IFN-γ levels were examined in a birth cohort of children at high risk for asthma and allergic diseases. Replication of the genetic association was assessed in an independent sample of asthma cases.
RESULTS: Significant genotype-sex interactions on asthma were observed for 2 IFNG single nucleotide polymorphisms, rs2069727 and rs2430561, which were in strong linkage disequilibrium with each other. In contrast, none of the 10 IFNG single nucleotide polymorphisms showed significant main effects on asthma. The observed genotype-sex interaction on asthma was characterized by nonadditivity; that is, heterozygous boys had the highest risk for asthma, and heterozygous girls had the lowest risk. The interaction effect was robust to other asthma risk factors but was limited to children who experienced wheezing illnesses with viral infections during the first 3 years of life. Genotype-sex interactions were also observed in the IFN-γ response to LPS in the first year of life. Finally, the sex-interaction effect was replicated in an independent population of childhood asthma cases.
CONCLUSIONS: These results provide insight into the genetic basis of sex differences in asthma and highlight the potential importance of interactions among sex, genotype, and environmental factors in asthma pathogenesis.},
language = {eng},
number = {3},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Loisel, Dagan A. and Tan, Zheng and Tisler, Christopher J. and Evans, Michael D. and Gangnon, Ronald E. and Jackson, Daniel J. and Gern, James E. and Lemanske, Robert F. and Ober, Carole},
month = sep,
year = {2011},
pmid = {21798578},
pmcid = {PMC3548570},
keywords = {Asthma, Child, Female, Genetic Predisposition to Disease, Genotype, Humans, Interferon-gamma, Male, Polymorphism, Single Nucleotide, Sex Factors},
pages = {524--531},
}

@article{bjorksten_global_2011,
title = {Global analysis of breast feeding and risk of symptoms of asthma, rhinoconjunctivitis and eczema in 6-7 year old children: {ISAAC} {Phase} {Three}},
volume = {39},
issn = {1578-1267},
shorttitle = {Global analysis of breast feeding and risk of symptoms of asthma, rhinoconjunctivitis and eczema in 6-7 year old children},
doi = {10.1016/j.aller.2011.02.005},
abstract = {BACKGROUND: In Phase Three of the International Study of Asthma and Allergies in Childhood (ISAAC), we investigated the relationship between breast feeding in infancy and symptoms of asthma, rhinoconjunctivitis and eczema in 6-7 year old children.
METHODS: Parents or guardians of 6-7 year old children completed written questionnaires on current symptoms of asthma, rhinoconjunctivitis and eczema, and on a range of possible asthma risk factors including a history of breast feeding ever. Prevalence odds ratios were estimated using logistic regression, adjusted for gender, region of the world, language, per capita gross national income, and other risk factors.
RESULTS: In all 206,453 children from 72 centres in 31 countries participated in the study. Reported breast feeding ever was not associated with current wheeze, with an odds ratio (adjusted for gender, region of the world, language, per capita gross national income, and factors encountered in infancy) of 0.99 (95\% CI 0.92-1.05), current rhinoconjunctivitis (OR 1.00, 95\% CI 0.93-1.08), current eczema (OR 1.05, 95\% CI 0.97-1.12), or symptoms of severe asthma (OR 0.95, 95\% CI 0.87-1.05). Breast feeding was however associated with a reduced risk of severe rhinoconjunctivitis (OR 0.74, 95\% CI 0.59-0.94) and severe eczema (OR 0.79, 95\% CI 0.66-0.95).
CONCLUSIONS: There was no consistent association between breast feeding use in the first year of life and either a history or current symptoms of wheezing, rhinoconjunctivitis or eczema in 6-7 year old children, but possibly an effect on severe symptoms of the latter two conditions.},
language = {eng},
number = {6},
journal = {Allergologia Et Immunopathologia},
author = {Björkstén, B. and Aït-Khaled, N. and Innes Asher, M. and Clayton, T. O. and Robertson, C. and {ISAAC Phase Three Study Group}},
month = dec,
year = {2011},
pmid = {21802826},
keywords = {Adolescent, Asthma, Child, Conjunctivitis, Cross-Sectional Studies, Female, Humans, Hypersensitivity, Infant, Male, Milk, Human, Pregnancy, Prevalence, Risk Factors, Surveys and Questionnaires, eczema, rhinitis},
pages = {318--325},
}

@article{debley_bronchodilator_2012,
title = {Bronchodilator responsiveness in wheezy infants and toddlers is not associated with asthma risk factors},
volume = {47},
issn = {1099-0496},
doi = {10.1002/ppul.21567},
abstract = {BACKGROUND: There are limited data assessing bronchodilator responsiveness (BDR) in infants and toddlers with recurrent wheezing, and factors associated with a positive response.
OBJECTIVES: In a multicenter study of children ≤ 36 months old, we assessed the prevalence of and factors associated with BDR among infants/toddlers with recurrent episodes of wheezing.
METHODS: Forced expiratory flows and volumes using the raised-volume rapid thoracic compression method were measured in 76 infants/toddlers [mean (SD) age 16.8 (7.6) months] with recurrent wheezing before and after administration of albuterol. Prior history of hospitalization or emergency department treatment for wheezing, use of inhaled or systemic corticosteroids, physician treatment of eczema, environmental tobacco smoke exposure, and family history of asthma or allergic rhinitis were ascertained.
RESULTS: Using the published upper limit of normal for post bronchodilator change (FEV(0.5)  ≥ 13\% and/or FEF(25-75)  ≥ 24\%) in healthy infants, 24\% (n = 18) of children in our study exhibited BDR. The BDR response was not associated with any clinical factor other than body size. Dichotomizing subjects into responders (defined by published limits of normal) or by quartile to identify children with the greatest change from baseline (4th quartile vs. other) did not identify any other factor associated with BDR.
CONCLUSIONS: Approximately one quarter of infants/toddlers with recurrent wheezing exhibited BDR at their clinical baseline. However, BDR in wheezy infants/toddlers was not associated with established clinical asthma risk factors.},
language = {eng},
number = {5},
journal = {Pediatric Pulmonology},
author = {Debley, Jason and Stanojevic, Sanja and Filbrun, Amy G. and Subbarao, Padmaja},
month = may,
year = {2012},
pmid = {22006677},
pmcid = {PMC3325342},
keywords = {Albuterol, Asthma, Child, Preschool, Female, Humans, Infant, Male, Prevalence, Respiratory Function Tests, Respiratory Sounds, Risk Factors, Tobacco Smoke Pollution, bronchodilator agents, rhinitis},
pages = {421--428},
}

@article{zedan_does_2012,
title = {Does decline of lung function in wheezy infants justify the early start of controller medications?},
volume = {79},
issn = {0973-7693},
doi = {10.1007/s12098-012-0694-z},
abstract = {OBJECTIVE: To compare lung function in wheezy infants, with risk factors of asthma and with some immunological parameters which may be useful as predictors of subsequent asthma.
METHODS: The data of 241 infants aged 5–36 mo, with recurrent wheeze (≥3 episodes of physician confirmed wheeze) prior to receiving inhaled corticosteroids or anti-leukotrine agents was retrospectively analyzed. They were subdivided into 2 subgroups; those with asthma risk factors (132 patients) and those without (109 patients) Also, 67 healthy, age and sex matched children without recurrent wheezes were taken as control group. Total serum IgE, eosinophilic percentage, tPTEF/tE (time to peak expiratory flow to total expiratory time), total respiratory system compliance (Crs) and resistance of the respiratory system (Rrs) was done for patients and control groups.
RESULTS: Wheezy infants had a significantly higher eosinophilic percentage and total serum IgE as well as a significantly lower pulmonary function parameters when compared to healthy controls. Wheezy infants with positive family history of asthma and those who had not been breast fed showed significant reduction in the mean values of tPTEF/tE and increased both eosinophilic percentage and total serum IgE. Crs was significantly decreased in wheezy infants with positive seasonal variations and those who had increased both eosinophilic percentage and total serum IgE. Rrs showed significant increase in wheezy infants with positive family history of atopy and those who had increased eosinophilic percentage and increased total serum IgE.
CONCLUSIONS: Lung function, eosinophilic percentage, total serum IgE and asthma risk factors could be used as predictors for ongoing wheeze in this subset of children.},
language = {eng},
number = {9},
journal = {Indian Journal of Pediatrics},
author = {Zedan, Magdy and Nasef, Nehad and El-Bayoumy, Mohamed and El-Assmy, Mohamed and Attia, Gehan and Zedan, Mohamed and AlWakeel, Angi and Kandil, Shaimaa and Laimon, Wafaa and Fouda, Ashraf},
month = sep,
year = {2012},
pmid = {22297650},
keywords = {Asthma, Child, Preschool, Female, Humans, Infant, Male, Respiratory Function Tests, Respiratory Sounds, Retrospective Studies, Risk Factors, lung},
pages = {1176--1180},
}

@article{gudelj_intraregional_2012,
title = {Intraregional differences in asthma prevalence and risk factors for asthma among adolescents in {Split}-{Dalmatia} {County}, {Croatia}},
volume = {18},
issn = {1643-3750},
abstract = {BACKGROUND: Our aim was to assess the differences in intraregional prevalence of asthma in adolescents in Split-Dalmatia County to determine asthma risk factors in our population and estimate the specificity and sensitivity of the questionnaire used.
MATERIAL/METHODS: We conducted the study using the European Community Respiratory Health Survey II short questionnaire supplemented by some questions from the International Study of Asthma in Childhood questionnaire. The participants suspected to have asthma were invited for examination by an asthma specialist who established the final diagnosis of asthma according to the medical history, physical examination, skin-prick tests, and peak flow measurements.
RESULTS: A total of 4027 students (51.2\% male) participated in the study. According to the prevalence of wheezing during the last 12 months, asthma prevalence was estimated at 9.7\%. The total prevalence of asthma confirmed by an asthma specialist in the selected population was 5.60\% (95\% CI, 4.93-6.36\%); 6.18\% in Split (95\% CI, 5.37-7.09), 5.63\% in Imotski (95\% CI, 3.48-8.58), and 2.90\% in Sinj (95\% CI, 1.67-4.68) (P=0.0028). We found sensitization to aeroallergens and peanuts, and active smoking to be independent risk factors for asthma.
CONCLUSIONS: Split-Dalmatia County has moderate asthma prevalence, with a significant intraregional difference. Asthma prevalence estimated by a questionnaire (9.7\%) overestimates the prevalence of asthma confirmed by an asthma specialist (5.6\%) in adolescents in Croatia. Our data confirmed the need of a more complex questionnaire to evaluate the accurate prevalence of current asthma or the need for subsequent clinical evaluation of the questionnaire obtained data. Allergic sensitization to aeroallergens and active smoking were important risk factors for asthma.},
language = {eng},
number = {4},
journal = {Medical Science Monitor: International Medical Journal of Experimental and Clinical Research},
author = {Gudelj, Ivan and Mrkić Kobal, Iva and Munivrana Škvorc, Helena and Miše, Kornelija and Vrbica, Zarko and Plavec, Davor and Tudorić, Neven},
month = apr,
year = {2012},
pmid = {22460102},
pmcid = {PMC3560826},
keywords = {Adolescent, Asthma, Croatia, Female, Humans, Male, Prevalence, Risk Factors, Surveys and Questionnaires},
pages = {PH43--50},
}

@article{wendt_estimation_2012,
title = {Estimation of asthma incidence among low-income children in {Texas}: a novel approach using {Medicaid} claims data},
volume = {176},
issn = {1476-6256},
shorttitle = {Estimation of asthma incidence among low-income children in {Texas}},
doi = {10.1093/aje/kws150},
abstract = {Few recent estimates of childhood asthma incidence exist in the literature, although the importance of incidence surveillance for understanding asthma risk factors has been recognized. Asthma prevalence, morbidity, and mortality reports have repeatedly shown that low-income children are disproportionately impacted by the disease. The aim of this study was to demonstrate the utility of Medicaid claims data for providing statewide estimates of asthma incidence. Medicaid analytic extract (MAX) data for Texas children aged 0-17 years enrolled in Medicaid between 2004 and 2007 were used to estimate incidence overall and by age group, gender, race, and county of residence. A ≥13-month period of continuous enrollment was required in order to distinguish incident from prevalent cases identified in the claims data. The age-adjusted incidence of asthma was 4.26/100 person-years during 2005-2007, higher than reported in other populations. Incidence rates decreased with age, were higher for males than females, differed by race, and tended to be higher in rural than urban areas. This study demonstrates the utility of Medicaid analytic extract data for estimating asthma incidence and describes the methodology required for a population with unstable enrollment.},
language = {eng},
number = {8},
journal = {American Journal of Epidemiology},
author = {Wendt, Judy K. and Symanski, Elaine and Du, Xianglin L.},
month = oct,
year = {2012},
pmid = {23024134},
pmcid = {PMC3571251},
keywords = {Adolescent, Asthma, Child, Child, Preschool, Female, Humans, Infant, Infant, Newborn, Insurance Claim Reporting, Male, Medicaid, Population Surveillance, Poverty, Prevalence, Risk Factors, Texas, United States, incidence},
pages = {744--750},
}

@article{mai_serum_2012,
title = {Serum 25-hydroxyvitamin {D} levels and incident asthma in adults: the {HUNT} {Study}},
volume = {176},
issn = {1476-6256},
shorttitle = {Serum 25-hydroxyvitamin {D} levels and incident asthma in adults},
doi = {10.1093/aje/kws235},
abstract = {The impact of low vitamin D status on asthma development is unclear. The authors investigated the relation between the baseline serum 25-hydroxyvitamin D (25(OH)D) level and incident asthma in adults, including possible effect modification by allergy status, using allergic rhinitis as a proxy measure. A cohort of 25,616 Norwegian adults aged 19-55 years participated in 2 surveys of the Nord-Trøndelag Health Study known as HUNT 2 (1995-1997) and HUNT 3 (2006-2008). Of this cohort, a nested case-control study included 584 new-onset asthma cases and 1,958 nonasthma controls whose baseline serum 25(OH)D levels were measured. After adjustment for potential asthma risk factors, the baseline serum level of 25(OH)D ({\textless}50 nmol/L) was not significantly associated with asthma in either women (adjusted odds ratio = 0.94, 95\% confidence interval (CI): 0.67, 1.32) or men (adjusted odds ratio = 1.47, 95\% CI: 0.93, 2.32). In men, allergic rhinitis modified the association with the adjusted odds ratio being 0.87 (95\% CI: 0.36, 2.06) among men with allergic rhinitis and 2.32 (95\% CI: 1.06, 5.10) among men without allergic rhinitis. The serum 25(OH)D level was not associated with incident asthma in women, regardless of allergy status. Low vitamin D status was not significantly associated with incident asthma in most adults, but it may have increased risk among men without allergy.},
language = {eng},
number = {12},
journal = {American Journal of Epidemiology},
author = {Mai, Xiao-Mei and Langhammer, Arnulf and Camargo, Carlos A. and Chen, Yue},
month = dec,
year = {2012},
pmid = {23204497},
keywords = {Adult, Asthma, Case-Control Studies, Female, Humans, Logistic Models, Male, Middle Aged, Multivariate Analysis, Norway, Prospective Studies, Rhinitis, Allergic, Rhinitis, Allergic, Perennial, Risk Factors, Sex Distribution, Vitamin D, Vitamin D Deficiency, incidence},
pages = {1169--1176},
}

@article{agrawal_prevalence_2013,
title = {Prevalence and risk factors for self-reported asthma in an adult {Indian} population: a cross-sectional survey},
volume = {17},
issn = {1815-7920},
shorttitle = {Prevalence and risk factors for self-reported asthma in an adult {Indian} population},
doi = {10.5588/ijtld.12.0438},
abstract = {BACKGROUND AND METHODS: We estimated the prevalence of self-reported asthma in adult Indians and examined several risk factors influencing disease prevalence. Analysis is based on 99,574 women and 56,742 men aged 20-49 years included in India's third National Family Health Survey, 2005-2006. Multiple logistic regression analysis was used to estimate the prevalence odds ratios for asthma, adjusting for various risk factors.
RESULTS: The prevalence of self-reported asthma was 1.8\% (95\%CI 1.6-2.0) among men and 1.9\% (95\%CI 1.8-2.0) among women, with higher rates in rural than in urban areas and marked geographic differences. After adjustment for known asthma risk factors, women were 1.2 times more likely to have asthma than men. Daily/weekly consumption of milk/milk products, green leafy vegetables and fruits were associated with a lower asthma risk, whereas consumption of chicken/meat, a lower body mass index (BMI; {\textless}16 kg/m(2), OR 2.08, 95\%CI 1.73-2.50) as well as a higher BMI ({\textgreater}30 kg/m(2), OR 1.67, 95\%CI 1.36-2.06), current tobacco smoking (OR 1.30, 95\%CI 1.12-1.50) and ever use of alcohol (OR 1.21, 95\%CI 1.05-1.39) were associated with an increased asthma risk.
CONCLUSIONS: There are wide regional variations in the prevalence of asthma in India. With the exception of the findings for BMI, however, most of the associations of asthma with the risk factors are relatively weak and account for only a small proportion of cases.},
language = {eng},
number = {2},
journal = {The International Journal of Tuberculosis and Lung Disease: The Official Journal of the International Union Against Tuberculosis and Lung Disease},
author = {Agrawal, S. and Pearce, N. and Ebrahim, S.},
month = feb,
year = {2013},
pmid = {23317966},
pmcid = {PMC4284294},
keywords = {Adult, Age distribution, Alcohol Drinking, Asthma, Body Mass Index, Cross-Sectional Studies, Female, Health Surveys, Humans, India, Male, Middle Aged, Odds ratio, Prevalence, Prognosis, Retrospective Studies, Risk Factors, Rural Population, Sex Distribution, Smoking, Socioeconomic Factors, Young Adult},
pages = {275--282},
}

@article{ergoz_genetic_2014,
title = {Genetic variation in {Ameloblastin} is associated with caries in asthmatic children},
volume = {15},
issn = {1996-9805},
doi = {10.1007/s40368-013-0096-6},
abstract = {AIM: Evidence suggests caries experience is higher in children with asthma. This study compared caries experience in asthmatic and non-asthmatic children and defined whether variation in the distribution of caries experience differed between the two groups and was dependent on the presence of genetic variation in enamel formation genes.
METHODS: Children with asthma were recruited at the Istanbul University, Faculty of Medicine, Department of Paediatrics, Division of Paediatric Allergy and Pulmonary Diseases, and non-affected children were recruited at the Istanbul University, Faculty of Dentistry, Department of Paedodontics. Cases (N = 100) were defined as children between the ages of 6 and 12 years with asthma and controls (N = 100) as children without asthma. Cases and controls were matched by sex and age. All study subjects received a complete dental exam, provided demographic and other caries and asthma risk factors data, and a saliva sample for DNA extraction. Caries experience was defined based on DMFT/dmft and DMFS/dmfs scores. Genotypes of 11 SNPs were selected in intronic regions of enamel development genes. PCR with TaqMan chemistry was used for genotyping all selected markers. Association between caries experience (caries-free versus caries affected) depending on asthma status and SNPs was tested with PLINK by logistic regression, adjusting by risk, and other preventive measures. p values below 0.0045 (0.05/11) were considered statistically significant.
RESULTS: Logistic regression analysis showed an association between AMBN rs4694075 and caries experience (p = 2.525e-007).
CONCLUSIONS: This study provides, for the first time, evidence that ameloblastin is associated with caries in asthmatic children.},
language = {eng},
number = {3},
journal = {European Archives of Paediatric Dentistry: Official Journal of the European Academy of Paediatric Dentistry},
author = {Ergöz, N. and Seymen, F. and Gencay, K. and Tamay, Z. and Deeley, K. and Vinski, S. and Vieira, A. R.},
month = jun,
year = {2014},
pmid = {24203249},
pmcid = {PMC4014527},
keywords = {Amelogenesis, Amelogenin, Asthma, Case-Control Studies, Child, DMF Index, Dental Caries, Dental Enamel Proteins, Dental Plaque Index, Extracellular Matrix Proteins, Female, Genetic Variation, Genotype, Humans, Introns, Male, Nuclear Proteins, Polymorphism, Single Nucleotide, Thymine, Toothbrushing},
pages = {211--216},
}

@article{forno_maternal_2014,
title = {Maternal obesity in pregnancy, gestational weight gain, and risk of childhood asthma},
volume = {134},
issn = {1098-4275},
doi = {10.1542/peds.2014-0439},
abstract = {BACKGROUND AND OBJECTIVE: Environmental or lifestyle exposures in utero may influence the development of childhood asthma. In this meta-analysis, we aimed to assess whether maternal obesity in pregnancy (MOP) or increased maternal gestational weight gain (GWG) increased the risk of asthma in offspring.
METHODS: We included all observational studies published until October 2013 in PubMed, Embase, CINAHL, Scopus, The Cochrane Database, and Ovid. Random effects models with inverse variance weights were used to calculate pooled risk estimates.
RESULTS: Fourteen studies were included (N = 108 321 mother-child pairs). Twelve studies reported maternal obesity, and 5 reported GWG. Age of children was 14 months to 16 years. MOP was associated with higher odds of asthma or wheeze ever (OR = 1.31; 95\% confidence interval [CI], 1.16-1.49) or current (OR = 1.21; 95\% CI, 1.07-1.37); each 1-kg/m(2) increase in maternal BMI was associated with a 2\% to 3\% increase in the odds of childhood asthma. High GWG was associated with higher odds of asthma or wheeze ever (OR = 1.16; 95\% CI, 1.001-1.34). Maternal underweight and low GWG were not associated with childhood asthma or wheeze. Meta-regression showed a negative association of borderline significance for maternal asthma history (P = .07). The significant heterogeneity among existing studies indicates a need for standardized approaches to future studies on the topic.
CONCLUSIONS: MOP and high GWG are associated with an elevated risk of childhood asthma; this finding may be particularly significant for mothers without asthma history. Prospective randomized trials of maternal weight management are needed.},
language = {eng},
number = {2},
journal = {Pediatrics},
author = {Forno, Erick and Young, Omar M. and Kumar, Rajesh and Simhan, Hyagriv and Celedón, Juan C.},
month = aug,
year = {2014},
pmid = {25049351},
pmcid = {PMC4187236},
keywords = {Asthma, Body Mass Index, Female, Humans, Mothers, Obesity, Pregnancy, Pregnancy Complications, Prenatal Exposure Delayed Effects, Risk Assessment, Weight Gain, asthma risk factors, childhood asthma, gestational weight gain, maternal obesity, meta-analysis},
pages = {e535--546},
}

@article{debaun_factors_2014,
title = {Factors predicting future {ACS} episodes in children with sickle cell anemia},
volume = {89},
issn = {1096-8652},
doi = {10.1002/ajh.23819},
abstract = {While a doctor-diagnosis of asthma is associated with an increased risk of pain and acute chest syndrome (ACS) in children with sickle cell anemia (SCA), little is known about the relationship between specific asthma characteristics and clinical factors and future morbidity in children with SCA. We evaluated the relationship between (i) asthma risk factors at the time of a clinical visit (respiratory symptoms, maternal history of asthma, allergy skin tests, spirometry results) and (ii) the known risk factor of ACS early in life, on prospective pain and ACS episodes in a cohort of 159 children with SCA followed from birth to a median of 14.7 years. An ACS episode prior to 4 years of age, (incidence rate ratio [IRR] = 2.84; P {\textless} 0.001], female gender (IRR = 1.80; P = 0.009), and wheezing causing shortness of breath (IRR = 1.68; P = 0.042) were associated with future ACS rates. We subsequently added spirometry results (obstruction defined as FEV1 /FVC less than the lower limits of normal; and bronchodilator response, FEV1 ≥ 12\%) and prick skin test responses to the model. Only ≥ 2 positive skin tests had a significant effect (IRR 1.87; P = 0.01). Thus, early in life ACS events, wheezing causing shortness of breath, and ≥ 2 positive skin tests predict future ACS events.},
language = {eng},
number = {11},
journal = {American Journal of Hematology},
author = {DeBaun, Michael R. and Rodeghier, Mark and Cohen, Robyn and Kirkham, Fenella J. and Rosen, Carol L. and Roberts, Irene and Cooper, Ben and Stocks, Janet and Wilkey, Olu and Inusa, Baba and Warner, John O. and Strunk, Robert C.},
month = nov,
year = {2014},
pmid = {25088663},
pmcid = {PMC4866602},
keywords = {Acute Chest Syndrome, Adolescent, Anemia, Sickle Cell, Asthma, Child, Child, Preschool, Dyspnea, Female, Follow-Up Studies, Humans, Hypersensitivity, Immediate, Male, Prognosis, Prospective Studies, Respiratory Sounds, Risk Factors, Sickle Cell Trait, Skin Tests, beta-Thalassemia, bronchodilator agents, spirometry},
pages = {E212--217},
}

@article{rolfsjord_children_2015,
title = {Children hospitalised with bronchiolitis in the first year of life have a lower quality of life nine months later},
volume = {104},
issn = {1651-2227},
doi = {10.1111/apa.12792},
abstract = {AIM: Acute bronchiolitis increases the risk of asthma, and reduced quality of life (QoL) is reported in children with asthma and allergy. However, the impact of asthma risk factors on QoL is unclear. This study investigated whether bronchiolitis and common asthma risk factors in infancy had an influence on later QoL.
METHODS: The parents of 209 infants recruited during hospitalisation for bronchiolitis at a mean age of 4 months, and 206 controls responded to the generic Infant Toddler Quality of Life Questionnaire 9 months later. We used robust regression analyses to assess the association between four asthma risk factors, atopic eczema, parental asthma, parental allergic rhinoconjunctivitis and second-hand smoke and QoL in the two groups.
RESULTS: QoL was lower among children with previous bronchiolitis in the overall health and general health domains and lower in six of 13 domains in children with atopic eczema. Compared with no risk factors, children with previous bronchiolitis and three risk factors had lower scores in four domains, and control children with three risk factors had lower scores in three domains.
CONCLUSION: Having acute bronchiolitis, atopic eczema and three asthma risk factors were negatively associated with later QoL in early childhood.},
language = {eng},
number = {1},
journal = {Acta Paediatrica (Oslo, Norway: 1992)},
author = {Rolfsjord, Leif Bjarte and Skjerven, Håvard Ove and Bakkeheim, Egil and Carlsen, Kai-Håkon and Hunderi, Jon Olav Gjengstø and Kvenshagen, Bente Krane and Mowinckel, Petter and Lødrup Carlsen, Karin C.},
month = jan,
year = {2015},
pmid = {25169812},
keywords = {Acute bronchiolitis, Asthma, Atopic eczema, Case-Control Studies, Female, Hospitalization, Humans, Infant, Infant, Newborn, Male, Norway, Quality of Life, Risk Factors, bronchiolitis},
pages = {53--58},
}

@article{hovland_early_2015,
title = {Early risk factors for pubertal asthma},
volume = {45},
issn = {1365-2222},
doi = {10.1111/cea.12409},
abstract = {BACKGROUND: Early life risk factors are previously described for childhood asthma, but less is known related to asthma in adolescence. We aimed to investigate early risk factors (before 2 years) for pubertal asthma and secondarily for pubertal asthma phenotypes based upon allergic comorbidities.
METHODS: Based on data from 550 adolescents in the prospective birth cohort 'Environment and Childhood Asthma' study, subjects were categorized by recurrent bronchial obstruction (rBO) 0-2 years, asthma 2-10 years, and pubertal asthma from 10 to 16 years including incident asthma in puberty and asthma in remission from 10 to 16 years or as never rBO/asthma 0-16 years. Asthma in puberty was further classified based on the comorbidities atopic dermatitis and allergic rhinitis (AR) from 10 to 16 years. Twenty-three common asthma risk factors identified by 2 years of age, including frequency and persistence of bronchial obstruction (severity score), were analysed by weighted logistic regression for each phenotype.
RESULTS: In adjusted models, the risk of pubertal asthma increased significantly with higher severity score, parental rhinitis, being the firstborn child, and familial stress around birth. Pubertal asthma in remission was significantly associated with severity score and number of lower respiratory tract infections and inversely associated with breastfeeding beyond 4 months. Pubertal incident asthma was more common among firstborn children. All asthma phenotypes with allergic diseases were significantly associated with severity score, whereas familial perinatal stress increased the risk of asthma only. Asthma combined with AR was associated with parental asthma and being firstborn, whereas the risk of asthma with both atopic dermatitis and AR increased with higher paternal education, atopic dermatitis, being firstborn, and familial perinatal stress.
CONCLUSION AND CLINICAL RELEVANCE: Important early risk factors for pubertal asthma were early airways obstruction, parental rhinitis, being the firstborn child, and perinatal familial stress.},
language = {eng},
number = {1},
journal = {Clinical and Experimental Allergy: Journal of the British Society for Allergy and Clinical Immunology},
author = {Hovland, V. and Riiser, A. and Mowinckel, P. and Carlsen, K.-H. and Lødrup Carlsen, K. C.},
month = jan,
year = {2015},
pmid = {25220447},
keywords = {Adolescent, Age Factors, Asthma, Child, Child, Preschool, Female, Follow-Up Studies, Humans, Infant, Infant, Newborn, Male, Puberty, Risk Factors, Stress, adolescence, allergic comorbidity, birth cohort, prospective, pubertal},
pages = {164--176},
}

@article{seo_eosinophilic_2015,
title = {Eosinophilic otitis media is associated with asthma severity and smoking history},
volume = {77},
issn = {1423-0275},
doi = {10.1159/000370122},
abstract = {PURPOSE: Eosinophilic otitis media (EOM) is an intractable otitis media characterized by an accumulation of eosinophils in the middle ear and a strong association with asthma. We investigated the relationship between EOM and asthma severity, asthma risk factors, lung function, and airway structural changes assessed by high-resolution computed tomographic (HRCT) scanning.
MATERIALS AND METHODS: Forty-one asthma patients with chronic rhinosinusitis (18 men and 23 women; mean age 56 years; age range 25-82 years) were included in this study. EOM was diagnosed according to the published diagnostic criteria. Asthma severity and risk factors for asthma, such as smoking history (Brinkman index, BI), were examined. Airway wall thickness and emphysema were assessed with HRCT scanning by a blinded respiratory specialist using a validated method. Lung function was measured using standard procedures.
RESULTS: EOM was diagnosed in 34\% of the patients. Asthma severity, BI and airway wall thickness were each statistically greater in patients with EOM than in patients without EOM.
CONCLUSION: There was a close relationship between EOM and asthma severity in asthma patients with chronic rhinosinusitis. Cessation of smoking might help prevent EOM by reducing airway wall thickness.},
language = {eng},
number = {1},
journal = {ORL; journal for oto-rhino-laryngology and its related specialties},
author = {Seo, Yukako and Nonaka, Manabu and Tagaya, Etsuko and Tamaoki, Jun and Yoshihara, Toshio},
year = {2015},
pmid = {25633710},
keywords = {Adult, Aged, Aged, 80 and over, Asthma, Case-Control Studies, Chronic Disease, Eosinophilia, Female, Humans, Male, Middle Aged, Otitis Media, Risk Factors, Severity of Illness Index, Smoking, Tomography, X-Ray Computed, rhinitis, sinusitis, spirometry},
pages = {1--9},
}

@article{ardura-garcia_risk_2015,
title = {Risk factors for acute asthma in tropical {America}: a case-control study in the {City} of {Esmeraldas}, {Ecuador}},
volume = {26},
issn = {1399-3038},
shorttitle = {Risk factors for acute asthma in tropical {America}},
doi = {10.1111/pai.12401},
abstract = {BACKGROUND: Despite the high asthma rates described in Latin America, asthma risk factors in poor urban settings are not well established. We investigated risk factors for acute asthma among Ecuadorian children.
METHODS: A matched case-control study was carried out in a public hospital serving a coastal city. Children with acute asthma were age- and sex-matched to non-asthmatics. A questionnaire was administered, and blood, as well as stool, and nasopharyngeal swabs were collected.
RESULTS: Sixty cases and 119 controls aged 5-15 were evaluated. High proportions of cases were atopic with population-attributable fractions for atopy of 68.5\% for sIgE and 57.2\% for SPT. Acute asthma risk increased with greater titers of mite IgE (3.51-50 kU/l vs. {\textless}0.70kU/l - OR 4.56, 95\% CI 1.48-14.06, p = 0.008; {\textgreater}50kU/l vs. {\textless}0.70kU/l - OR 41.98, 95\% CI: 8.97-196.39, p {\textless} 0.001). Asthma risk was significantly independently associated with bronchiolitis (adj. OR: 38.9, 95\% CI 3.26-465), parental educational level (adj. OR 1.26, 95\% CI: 1.08-1.46), and presence of sIgE (adj. OR: 36.7, 95\% CI: 4.00-337), while a reduced risk was associated with current contact with pets (adj. OR: 0.07, 95\% CI: 0.01-0.56). Rhinovirus infection was more frequent in cases (cases 35.6\% vs. controls 7.8\%, p = 0.002). None of the cases were on maintenance therapy with inhaled corticosteroids and most relied on emergency department for control.
CONCLUSIONS: A high proportion of children presenting to a public hospital with acute asthma were allergic to mite, particularly at high IgE titer. Poor asthma control resulted in overuse of emergency care.},
language = {eng},
number = {5},
journal = {Pediatric Allergy and Immunology: Official Publication of the European Society of Pediatric Allergy and Immunology},
author = {Ardura-Garcia, Cristina and Vaca, Maritza and Oviedo, Gisela and Sandoval, Carlos and Workman, Lisa and Schuyler, Alexander J. and Perzanowski, Matthew S. and Platts-Mills, Thomas A. E. and Cooper, Philip J.},
month = aug,
year = {2015},
pmid = {25955441},
pmcid = {PMC4737128},
keywords = {Acute Disease, Adolescent, Age distribution, Allergens, Animals, Anti-Asthmatic Agents, Asthma, Biomarkers, Case-Control Studies, Child, Child, Preschool, Disease Progression, Ecuador, Emergency Service, Hospital, Female, Hospitals, Public, Humans, Immunoglobulin E, Immunologic Tests, Inhalation Exposure, Insect Proteins, Logistic Models, Male, Mites, Multivariate Analysis, Odds ratio, Prognosis, Respiratory Tract Infections, Risk Factors, Urban Health, acute asthma, atopy, tropics, urban},
pages = {423--430},
}

@article{kamran_risk_2015,
title = {Risk factors of childhood asthma in children attending {Lyari} {General} {Hospital}},
volume = {65},
issn = {0030-9982},
abstract = {OBJECTIVE: To determine the factors associated with asthma in children.
METHODS: The case-control study was conducted in the paediatrics clinic of Lyari General Hospital, Karachi, from May to October 2010. Children 1-15 years of age attending the clinic represented the cases, while the control group had children who were closely related (sibling or cousin) to the cases but did not have the symptoms of disease at the time. Data was collected through a proforma and analysed using SPSS 10.
RESULTS: Of the total 346 subjects, 173(50\%) each comprised the two groups. According to univariable analysis the risk factors were presence of at least one smoker (odds ratio: 3.6; 95\% confidence interval: 2.3-5.8), resident of kacha house (odds ratio: 16.2; 95\% confidence interval: 3.8-69.5),living in room without windows (odds ratio: 9.3; 95\% confidence interval: 2.1-40.9) and living in houses without adequate sunlight (odds ratio: 1.6; 95\% confidence interval: 1.2-2.4).Using multivariable modelling, family history of asthma (odds ratio: 5.9; 95\% confidence interval: 3.1-11.6), presence of at least one smoker at home (odds ratio: 4.1; 95\% confidence interval: 2.3-7.2), people living in a room without a window (odds ratio: 5.5; 95\% confidence interval: 1.15-26.3) and people living in an area without adequate sunlight (odds ratio: 2.2; 95\% confidence interval: 1.13-4.31) were found to be independent risk factors of asthma in children adjusting for age, gender and history of weaning.
CONCLUSIONS: Family history of asthma, children living with at least one smoker at home, room without windows and people living in an area without sunlight were major risk factors of childhood asthma.},
language = {eng},
number = {6},
journal = {JPMA. The Journal of the Pakistan Medical Association},
author = {Kamran, Amber and Hanif, Shahina and Murtaza, Ghulam},
month = jun,
year = {2015},
pmid = {26060164},
keywords = {Adolescent, Asthma, Case-Control Studies, Child, Child, Preschool, Childhood asthma, Risk factors, Inadequate sunlight, Smoker, Residence., Construction Materials, Family, Female, Housing, Humans, Infant, Male, Multivariate Analysis, Odds ratio, Pakistan, Risk Factors, Siblings, Sunlight, Tobacco Smoke Pollution, Ventilation},
pages = {647--650},
}

@article{andrusaityte_associations_2016,
title = {Associations between neighbourhood greenness and asthma in preschool children in {Kaunas}, {Lithuania}: a case-control study},
volume = {6},
issn = {2044-6055},
shorttitle = {Associations between neighbourhood greenness and asthma in preschool children in {Kaunas}, {Lithuania}},
doi = {10.1136/bmjopen-2015-010341},
abstract = {OBJECTIVES: The aim of this study was to investigate the associations between surrounding greenness levels and asthma among children, and to explore a possible change of this association by the distance of the residence to a city park.
DESIGN: A nested case-control study.
SETTING: Children aged 4-6 years residing at their current address since birth in Kaunas, Lithuania, whose mothers were recruited in 2007-2009 to the KANC newborns cohort study.
PARTICIPANTS: The participants were 1489 children whose parents in 2012-2013 filled in the questionnaires and agreed to participate in the study.
PRIMARY AND SECONDARY OUTCOME MEASURES: We estimated clinically diagnosed asthma risk factors. The surrounding greenness was measured as the average of the satellite-based Normalised Difference Vegetation Index (NDVI) within the buffers of 100, 300 and 500 m from each child's home address, and the distance to a city park was defined as the distance to the nearest city park. Multivariate logistic regression was performed to study the relationship between the greenness exposures and asthma adjusted for relevant covariates.
RESULTS: An increase in the NDVI ({\textgreater}median) in buffers of 100, 300 and 500 m was associated with a slightly increased risk of asthma, while an IQR increase in NDVI-100 m statistically significantly increased the risk of asthma (OR 1.43, 95\% CI 1.10 to 1.85). The stratified analysis by surrounding greenness revealed indications of stronger associations for children with higher surrounding greenness (NDVI-100{\textgreater}median) and those living farther away from parks ({\textgreater}1000 m), compared to NDVI-100≤median and the distance to a city park {\textgreater}1000 m (OR 1.47, 95\% CI 0.56 to 3.87).
CONCLUSIONS: A higher level of the surrounding greenness was associated with a slightly increased relative risk of asthma in children. Further investigation is needed to elucidate the influence of city parks and neighbourhood greenness levels on asthma.},
language = {eng},
number = {4},
journal = {BMJ open},
author = {Andrusaityte, Sandra and Grazuleviciene, Regina and Kudzyte, Jolanta and Bernotiene, Asta and Dedele, Audrius and Nieuwenhuijsen, Mark J.},
month = apr,
year = {2016},
pmid = {27067890},
pmcid = {PMC4838715},
keywords = {Asthma, Case-Control Studies, Child, Child asthma, Child, Preschool, Cities, City park, Environment, Female, Green spaces, Humans, Lithuania, Logistic Models, Male, Plants, Prevalence, Quantified greenness levels, Residence Characteristics},
pages = {e010341},
}

@article{liu_pathways_2016,
title = {Pathways through which asthma risk factors contribute to asthma severity in inner-city children},
volume = {138},
issn = {1097-6825},
doi = {10.1016/j.jaci.2016.06.060},
abstract = {BACKGROUND: Pathway analyses can be used to determine how host and environmental factors contribute to asthma severity.
OBJECTIVE: To investigate pathways explaining asthma severity in inner-city children.
METHODS: On the basis of medical evidence in the published literature, we developed a conceptual model to describe how 8 risk-factor domains (allergen sensitization, allergic inflammation, pulmonary physiology, stress, obesity, vitamin D, environmental tobacco smoke [ETS] exposure, and rhinitis severity) are linked to asthma severity. To estimate the relative magnitude and significance of hypothesized relationships among these domains and asthma severity, we applied a causal network analysis to test our model in an Inner-City Asthma Consortium study. Participants comprised 6- to 17-year-old children (n = 561) with asthma and rhinitis from 9 US inner cities who were evaluated every 2 months for 1 year. Asthma severity was measured by a longitudinal composite assessment of day and night symptoms, exacerbations, and controller usage.
RESULTS: Our conceptual model explained 53.4\% of the variance in asthma severity. An allergy pathway (linking allergen sensitization, allergic inflammation, pulmonary physiology, and rhinitis severity domains to asthma severity) and the ETS exposure pathway (linking ETS exposure and pulmonary physiology domains to asthma severity) exerted significant effects on asthma severity. Among the domains, pulmonary physiology and rhinitis severity had the largest significant standardized total effects on asthma severity (-0.51 and 0.48, respectively), followed by ETS exposure (0.30) and allergic inflammation (0.22). Although vitamin D had modest but significant indirect effects on asthma severity, its total effect was insignificant (0.01).
CONCLUSIONS: The standardized effect sizes generated by a causal network analysis quantify the relative contributions of different domains and can be used to prioritize interventions to address asthma severity.},
language = {eng},
number = {4},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Liu, Andrew H. and Babineau, Denise C. and Krouse, Rebecca Z. and Zoratti, Edward M. and Pongracic, Jacqueline A. and O'Connor, George T. and Wood, Robert A. and Khurana Hershey, Gurjit K. and Kercsmar, Carolyn M. and Gruchalla, Rebecca S. and Kattan, Meyer and Teach, Stephen J. and Makhija, Melanie and Pillai, Dinesh and Lamm, Carin I. and Gern, James E. and Sigelman, Steven M. and Gergen, Peter J. and Togias, Alkis and Visness, Cynthia M. and Busse, William W.},
month = oct,
year = {2016},
pmid = {27720018},
pmcid = {PMC5381517},
keywords = {Adolescent, Asthma, Child, Disease Management, Environmental Exposure, Female, Humans, Inflammation, Male, Models, Theoretical, Poverty, Rhinitis, Allergic, Perennial, Risk Factors, Severity of Illness Index, Tobacco Smoke Pollution, Urban Population, allergy, children, environmental tobacco smoke exposure, inner-city, lung function, pulmonary physiology, rhinitis, sensitization},
pages = {1042--1050},
}

@article{hollams_vitamin_2017,
title = {Vitamin {D} over the first decade and susceptibility to childhood allergy and asthma},
volume = {139},
issn = {1097-6825},
doi = {10.1016/j.jaci.2016.07.032},
abstract = {BACKGROUND: Vitamin D (25(OH)D) deficiency has been implicated as a possible risk factor for asthma development, but studies at selected time points measuring 25(OH)D levels during childhood have yielded conflicting findings. Prospective studies tracking 25(OH)D levels during the initiation phase of asthma in early childhood have not been reported.
OBJECTIVE: We sought to elucidate relationships between 25(OH)D levels from birth to age 10 years and susceptibility to allergic sensitization, respiratory tract infections, and asthma.
METHODS: Asthma-, allergy-, and respiratory tract infection-associated phenotypes (including pathogen identification) were characterized in a high-risk birth cohort. Plasma 25(OH)D concentrations were quantified at birth and at clinical follow-ups at the ages of 0.5, 1, 2, 3, 4, 5, and 10 years, and relationships with clinical outcomes were examined.
RESULTS: Cross-sectional analyses demonstrated inverse associations between 25(OH)D concentrations and the risk for concurrent sensitization at age 0.5, 2, and 3 years, and mixed-effects regression demonstrated inverse longitudinal associations of 25(OH)D levels with both sensitization and eczema. Multivariate regression modeling suggested that the number of 25(OH)D-deficient follow-ups was positively associated with risk for asthma/wheeze, eczema, and sensitization at 10 years; adjustment for sensitization (particularly by 2 years) in the asthma/wheeze models reduced 25(OH)D associations with these latter outcomes. 25(OH)D levels were also inversely associated with early nasopharyngeal colonization with Streptococcus species and age of first febrile lower respiratory illness, both of which are known asthma risk factors.
CONCLUSION: 25(OH)D deficiency in early childhood is associated with increased risk for persistent asthma, potentially through modulating susceptibility to early allergic sensitization, upper respiratory tract colonization with bacterial pathogens, or both. These relationships are only evident if 25(OH)D status is monitored prospectively and longitudinally.},
language = {eng},
number = {2},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Hollams, Elysia M. and Teo, Shu Mei and Kusel, Merci and Holt, Barbara J. and Holt, Kathryn E. and Inouye, Michael and De Klerk, Nicholas H. and Zhang, Guicheng and Sly, Peter D. and Hart, Prue H. and Holt, Patrick G.},
month = feb,
year = {2017},
pmid = {27726947},
keywords = {Asthma, Child, Child, Preschool, Cohort Studies, Cross-Sectional Studies, Disease Susceptibility, Female, Follow-Up Studies, Humans, Hypersensitivity, Immunization, Immunoglobulin E, Infant, Infant, Newborn, Male, Prospective Studies, Respiratory infections, Streptococcus, Vitamin D, allergy, childhood, longitudinal birth cohort, microbiome, risk},
pages = {472--481.e9},
}

@article{greenblatt_gender-specific_2017,
title = {Gender-specific determinants of asthma among {U}.{S}. adults},
volume = {3},
issn = {2054-7064},
doi = {10.1186/s40733-017-0030-5},
abstract = {BACKGROUND: Asthma, a chronic respiratory disease affecting over 18.7 million American adults, has marked disparities by gender, race/ethnicity and socioeconomic status. Our goal was to identify gender-specific demographic and socioeconomic determinants of asthma prevalence among U.S. adults using data from the Behavioral Risk Factors Surveillance System (BRFSS) and the National Health and Nutrition Examination Survey (NHANES).
METHODS: Gender-specific regression analyses were performed to model the relationship between asthma prevalence with age, race/ethnicity, income, education level, smoking status, and body mass index (BMI), while taking into account the study designs.
RESULTS: Based on BRFSS data from 1,003,894 respondents, weighted asthma prevalence was 6.2\% in males and 10.6\% in females. Asthma prevalence among grade 2 obese and grade 3 obese vs. not overweight or obese women was 2.5 and 3.5 times higher, respectively, while that in men was 1.7 and 2.4 times higher; asthma prevalence among current vs. never smoker women was 1.4 times higher, while that in men was 1.1 times higher. Similar results were obtained with NHANES data from 13,364 respondents: asthma prevalence among grade 2 obese and grade 3 obese vs. not overweight or obese respondents was 2.0 and 3.3 times higher for women, though there was no significant difference for men; asthma prevalence among current vs. never smokers was 1.8 times higher for women and not significantly different in men. Asthma prevalence by race/ethnicity and income levels did not differ considerably between men and women.
CONCLUSIONS: Our results underscore the importance of obesity and smoking as modifiable asthma risk factors that most strongly affect women.},
language = {eng},
journal = {Asthma Research and Practice},
author = {Greenblatt, Rebecca and Mansour, Omar and Zhao, Edward and Ross, Michelle and Himes, Blanca E.},
year = {2017},
pmid = {28138394},
pmcid = {PMC5259982},
keywords = {Adult asthma, Asthma, Obesity, Smoking},
pages = {2},
}

@article{jackson_lessons_2017,
title = {Lessons learned from birth cohort studies conducted in diverse environments},
volume = {139},
issn = {1097-6825},
doi = {10.1016/j.jaci.2016.12.941},
abstract = {Childhood asthma develops from a complex interaction among host and environmental factors in early life. Birth cohort studies have provided valuable insight into asthma risk factors and the natural history of wheezing and asthma through childhood and beyond. Early life aeroallergen sensitization and wheezing illnesses associated with virus and bacterial infections have been identified as pivotal risk factors for asthma inception. Recently, focus has turned toward protective factors that promote lung health in children. Studies in a variety of environments, including farms and urban communities, suggest that diverse exposures to microbes in early life lead to a lower risk of allergy and asthma in childhood. The mechanisms underlying how these exposures and the gut and airway microbiomes alter the host response to allergens and viruses are of interest and an area of ongoing study. Longitudinal follow up of birth cohorts in diverse environments worldwide will continue to provide critical knowledge about the factors that impact the natural history of asthma.},
language = {eng},
number = {2},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Jackson, Daniel J. and Gern, James E. and Lemanske, Robert F.},
month = feb,
year = {2017},
pmid = {28183432},
pmcid = {PMC5508737},
keywords = {Allergens, Animals, Asthma, Child, Child, Preschool, Cohort Studies, Common Cold, Environmental Exposure, Homeostasis, Humans, Immunity, Mucosal, Infant, Infant, Newborn, Microbiota, RSV, Rhinovirus, microbes, microbiome, wheezing},
pages = {379--386},
}

@article{lukkarinen_rhinovirus-induced_2017,
title = {Rhinovirus-induced first wheezing episode predicts atopic but not nonatopic asthma at school age},
volume = {140},
issn = {1097-6825},
doi = {10.1016/j.jaci.2016.12.991},
abstract = {BACKGROUND: Persistent childhood asthma is mainly atopy driven. However, limited data exist on the risk factors for childhood asthma phenotypes.
OBJECTIVE: We sought to identify risk factors at the first severe wheezing episode for current asthma 7 years later and separately for atopic and nonatopic asthma.
METHODS: One hundred twenty-seven steroid-naive children with the first severe wheezing episode (90\% hospitalized/10\% emergency department treated) were followed for 7 years. The primary outcome was current asthma at age 8 years, which was also analyzed separately as atopic and nonatopic asthma. Risk factors, including sensitization, viral cause, and other main asthma risk factors, were analyzed.
RESULTS: At study entry, median age was 11 months (interquartile range, 6-16 months); 17\% were sensitized, and 98\% were virus positive. Current asthma (n = 37) at 8 years was divided into atopic (n = 19) and nonatopic (n = 18) asthma. The risk factors for current atopic asthma at study entry were sensitization (adjusted odds ratio [OR], 12; P {\textless} .001), eczema (adjusted OR, 4.8; P = .014), and wheezing with rhinovirus (adjusted OR, 5.0; P = .035). The risk factors for nonatopic asthma were the first severe respiratory syncytial virus/rhinovirus-negative wheezing episode (adjusted OR, 8.0; P = .001), first wheezing episode at age less than 12 months (adjusted OR, 7.3; P = .007), and parental smoking (adjusted OR, 3.8; P = .028).
CONCLUSIONS: The data suggest diverse asthma phenotypes and mechanisms that can be predicted by using simple clinical markers at the time of the first severe wheezing episode. These findings are important for designing early intervention strategies for secondary prevention of asthma.},
language = {eng},
number = {4},
journal = {The Journal of Allergy and Clinical Immunology},
author = {Lukkarinen, Minna and Koistinen, Annamari and Turunen, Riitta and Lehtinen, Pasi and Vuorinen, Tytti and Jartti, Tuomas},
month = oct,
year = {2017},
pmid = {28347734},
keywords = {Asthma, Child, Child, Preschool, Female, Follow-Up Studies, Humans, Hypersensitivity, Immediate, Infant, Male, Picornaviridae Infections, Population, Prognosis, Respiratory Sounds, Rhinovirus, allergy, atopy, bronchiolitis, eczema, respiratory syncytial virus, risk, sensitization, virus, wheeze, wheezing},
pages = {988--995},
}

@article{el-zein_association_2017,
title = {Association {Between} {Bacillus} {Calmette}-{Guérin} {Vaccination} and {Childhood} {Asthma} in the {Quebec} {Birth} {Cohort} on {Immunity} and {Health}},
volume = {186},
issn = {1476-6256},
doi = {10.1093/aje/kwx088},
abstract = {We estimated the association between bacillus Calmette-Guérin (BCG) vaccination and childhood asthma in a birth cohort using administrative databases, and we determined the impact of adjusting for potential confounders collected from a subset of the cohort members. Data were collected in 2 waves: 1) Administrative data for 76,623 individuals (stage 1) was gathered from the Quebec Birth Cohort on Immunity and Health (1974-1994), including BCG vaccination status, perinatal and sociodemographic characteristics, and use of health services for asthma; and 2) self-reported asthma risk factors were collected in 2012 by telephone interviews with 1,643 participants (stage 2) using a balanced 2-stage sampling design. We estimated odds ratios and 95\% confidence intervals for asthma using logistic regression and correcting for the known sampling fractions from stage 1 to stage 2, overall and sex-stratified. In total, 35,612 (46.5\%) individuals were BCG vaccinated, and 5,870 (7.7\%) had asthma. The final odds ratio, integrating results from both stages of sampling, was 0.95 (95\% confidence interval: 0.87, 1.04). Results did not differ according to sex (P for interaction = 0.327). To our knowledge, this is the largest study ever conducted on this topic, and using the best possible comprehensive adjustment for confounders, we found no association between BCG vaccination and asthma.},
language = {eng},
number = {3},
journal = {American Journal of Epidemiology},
author = {El-Zein, Mariam and Conus, Florence and Benedetti, Andrea and Menzies, Dick and Parent, Marie-Elise and Rousseau, Marie-Claude},
month = aug,
year = {2017},
pmid = {28472373},
pmcid = {PMC5860497},
keywords = {2-stage sampling, Age Factors, Asthma, BCG Vaccine, Child, Child, Preschool, Educational Status, Female, Humans, Infant, Infant, Newborn, Male, Parents, Quebec, Risk Factors, Sex Factors, administrative data, bacillus Calmette-Guérin, birth cohort},
pages = {344--355},
}

@article{smith_respiratory_2017,
title = {Respiratory {Syncytial} {Virus} {Bronchiolitis} in {Children}},
volume = {95},
issn = {0002-838X, 1532-0650},
url = {https://www.aafp.org/afp/2017/0115/p94.html},
abstract = {Bronchiolitis is a common lower respiratory tract infection in infants and young children, and respiratory syncytial virus (RSV) is the most common cause of this infection. RSV is transmitted through contact with respiratory droplets either directly from an infected person or self-inoculation by contaminated secretions on surfaces. Patients with RSV bronchiolitis usually present with two to four days of upper respiratory tract symptoms such as fever, rhinorrhea, and congestion, followed by lower respiratory tract symptoms such as increasing cough, wheezing, and increased respiratory effort. In 2014, the American Academy of Pediatrics updated its clinical practice guideline for diagnosis and management of RSV bronchiolitis to minimize unnecessary diagnostic testing and interventions. Bronchiolitis remains a clinical diagnosis, and diagnostic testing is not routinely recommended. Treatment of RSV infection is mainly supportive, and modalities such as bronchodilators, epinephrine, corticosteroids, hypertonic saline, and antibiotics are generally not useful. Evidence supports using supplemental oxygen to maintain adequate oxygen saturation; however, continuous pulse oximetry is no longer required. The other mainstay of therapy is intravenous or nasogastric administration of fluids for infants who cannot maintain their hydration status with oral fluid intake. Educating parents on reducing the risk of infection is one of the most important things a physician can do to help prevent RSV infection, especially early in life. Children at risk of severe lower respiratory tract infection should receive immunoprophylaxis with palivizumab, a humanized monoclonal antibody, in up to five monthly doses. Prophylaxis guidelines are restricted to infants born before 29 weeks’ gestation, infants with chronic lung disease of prematurity, and infants and children with hemodynamically significant heart disease.},
language = {en},
number = {2},
urldate = {2018-04-24},
journal = {American Family Physician},
author = {Smith, Dustin K. and Seales, Sajeewane and Budzik, Carol},
month = jan,
year = {2017},
pages = {94--99},
}

@article{kurai_virus-induced_2013,
title = {Virus-induced exacerbations in asthma and {COPD}},
volume = {4},
issn = {1664-302X},
url = {https://www.frontiersin.org/articles/10.3389/fmicb.2013.00293/full#B76},
doi = {10.3389/fmicb.2013.00293},
abstract = {Chronic obstructive pulmonary disease (COPD) is characterized by chronic airway inflammation and/or airflow limitation due to pulmonary emphysema. Chronic bronchitis, pulmonary emphysema, and bronchial asthma may all be associated with airflow limitation; therefore, exacerbation of asthma may be associated with the pathophysiology of COPD. Furthermore, recent studies have suggested that the exacerbation of asthma, namely virus-induced asthma, may be associated with a wide variety of respiratory viruses. COPD and asthma have different underlying pathophysiological processes and thus require individual therapies. Exacerbation of both COPD and asthma, which are basically defined and diagnosed by clinical symptoms, is associated with a rapid decline in lung function and increased mortality. Similar pathogens, including human rhinovirus, respiratory syncytial virus, influenza virus, parainfluenza virus and coronavirus, are also frequently detected during exacerbation of asthma and/or COPD. Immune response to respiratory viral infections, which may be related to the severity of exacerbation in each disease, varies in patients with both COPD and asthma. In this regard, it is crucial to recognize and understand both the similarities and differences of clinical features in patients with COPD and/or asthma associated with respiratory viral infections, especially in the exacerbative stage. In relation to definition, epidemiology, and pathophysiology, this review aims to summarize current knowledge concerning exacerbation of both COPD and asthma by focusing on the clinical significance of associated respiratory virus infections.},
language = {English},
urldate = {2018-04-24},
journal = {Frontiers in Microbiology},
author = {Kurai, Daisuke and Saraya, Takeshi and Ishii, Haruyuki and Takizawa, Hajime},
year = {2013},
keywords = {Asthma, COPD, Overlap syndrome, exacerbation, human rhinovirus, respiratory syncytial virus, respiratory virus},
}

@article{sigurs_severe_2005,
title = {Severe {Respiratory} {Syncytial} {Virus} {Bronchiolitis} in {Infancy} and {Asthma} and {Allergy} at {Age} 13},
volume = {171},
issn = {1073-449X},
url = {https://www.atsjournals.org/doi/abs/10.1164/rccm.200406-730OC},
doi = {10.1164/rccm.200406-730OC},
abstract = {We have prospectively studied wheezing disorder and allergy in 47 children hospitalized with respiratory syncytial virus (RSV) bronchiolitis in infancy and 93 matched control subjects. Subjects with at least three episodes of wheezing were defined as recurrent wheezers and as having asthma if the episodes were doctor verified. Here we report the outcome at age 13 years in 46/47 children with RSV and 92/93 control subjects. Wheezing disorder and clinical allergy were estimated using a questionnaire. Skin prick tests were performed and serum IgE antibodies measured. Spirometry was undertaken at rest, after dry air challenge, and after β2-agonist inhalation. The occurrence of symptoms over the previous 12 months was significantly higher in the RSV group than among the control subjects, 43\% versus 8\% for asthma/recurrent wheezing and 39\% versus 15\% for allergic rhinoconjunctivitis. Sensitization to common inhaled allergens was more frequent in the RSV group than in the control subjects, judged by skin prick tests (50\% versus 28\%; p = 0.022), or by serum IgE antibodies (45\% versus 26\%; p = 0.038). Compared with the control subjects, the RSV group showed mild airway obstruction both at rest and after bronchodilation, and had slightly more reactive airways. RSV bronchiolitis in infancy severe enough to cause hospitalization is a risk factor for allergic asthma in early adolescence.},
number = {2},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Sigurs, Nele and Gustafsson, Per M. and Bjarnason, Ragnar and Lundberg, Fredrik and Schmidt, Susanne and Sigurbergsson, Fridrik and Kjellman, Bengt},
month = jan,
year = {2005},
pages = {137--141},
}

@article{sigurs_respiratory_2000,
title = {Respiratory {Syncytial} {Virus} {Bronchiolitis} in {Infancy} {Is} an  {Important} {Risk} {Factor} for {Asthma} and {Allergy} at {Age} 7},
volume = {161},
issn = {1073-449X},
url = {https://www.atsjournals.org/doi/abs/10.1164/ajrccm.161.5.9906076},
doi = {10.1164/ajrccm.161.5.9906076},
abstract = {We previously reported an increased risk for bronchial obstructive  disease and allergic sensitization up to age 3 in 47 children hospitalized with a respiratory syncytial virus (RSV) bronchiolitis in infancy compared with 93 matched control subjects recruited during infancy. The aims of the present study were to evaluate the  occurrences of bronchial obstructive disease and allergic sensitization in these children at age 71/ 2.  All 140 children reported for the  follow-up, which included physical examination, skin prick tests,  and serum IgE tests for common food and inhaled allergens. The  cumulative prevalence of asthma was 30\% in the RSV group and  3\% in the control group (p  {\textless}  0.001), and the cumulative prevalence of “any wheezing” was 68\% and 34\%, respectively (p  {\textless}   0.001). Asthma during the year prior to follow-up was seen in 23\%  of the RSV children and 2\% in the control subjects (p  {\textless}  0.001). Allergic sensitization was found in 41\% of the RSV children and 22\%  of the control subjects (p  =  0.039). Multivariate evaluation of possible risk factors for asthma and sensitization using a stepwise logistic statistical procedure for all 140 children showed that RSV  bronchiolitis had the highest independent risk ratio for asthma  (OR: 12.7, 95\% CI 3.4 to 47.1) and a significantly elevated independent risk ratio for allergic sensitization (OR: 2.4, 95\% CI 1.1 to  5.5). In conclusion, RSV bronchiolitis in infancy severe enough to  cause hospitalization was highly associatied with the development  of asthma and allergic sensitization up to age 71/ 2.  The results support the theory that the RSV influences the mechanisms involved  in the development of asthma and allergy in children.},
number = {5},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Sigurs, Nele and Bjarnason, Ragnar and Sigurbergsson, Fridrik and Kjellman, Bengt},
month = may,
year = {2000},
pages = {1501--1507},
}

@article{grissell_interleukin-10_2005,
title = {Interleukin-10 {Gene} {Expression} in {Acute} {Virus}-induced {Asthma}},
volume = {172},
issn = {1073-449X},
url = {https://www.atsjournals.org/doi/abs/10.1164/rccm.200412-1621OC},
doi = {10.1164/rccm.200412-1621OC},
abstract = {Rationale: Virus-induced asthma is characterized by marked neutrophil influx and eosinophil degranulation, suggesting a mode of immunopathogenesis different from that of allergen-induced asthma. Objectives: This study compared induced sputum cytokine responses in subjects with severe asthma exacerbation and respiratory virus infection with those of patients with stable asthma, healthy control subjects, and virus-infected nonasthmatic subjects. Methods: Subject infection status and pulmonary history were established on the basis of common cold and asthma questionnaires, and lung function and atopy tests were performed. Respiratory virus infection was diagnosed by cell culture and direct polymerase chain reaction, using induced sputum. The induced sputum cellular profile was examined and cytokine gene expression was assessed by quantitative real-time polymerase chain reaction. Results: A respiratory virus was detected in 78\% of subjects with acute asthma. Specific viruses detected were rhinovirus (83\%), influenza (15\%), enterovirus (4\%), and respiratory syncytial virus (2\%). Virus-infected subjects with acute asthma or no asthma had increased RANTES (regulated on activation, normal T cell expressed and secreted) and macrophage inflammatory protein-1α messenger RNAs compared with other groups. Interleukin (IL)-10 mRNA was significantly increased in virus-infected acute asthma and reduced on recovery from acute asthma. IL-5, eotaxin, and IL-8 mRNA transcripts were similar across groups. Conclusions: Asthma exacerbation triggered by respiratory virus infection is characterized by increased IL-10 gene expression that may explain the suppressed eosinophil influx in acute asthma. Airway neutrophilia due to respiratory virus infection is associated with chemokine gene expression involving RANTES and macrophage inflammatory protein-1α.},
number = {4},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Grissell, Terry V. and Powell, Heather and Shafren, Darren R. and Boyle, Michael J. and Hensley, Michael J. and Jones, Peter D. and Whitehead, Bruce F. and Gibson, Peter G.},
month = aug,
year = {2005},
pages = {433--439},
}

@inproceedings{jun_anytime_2016,
title = {Anytime {Exploration} for {Multi}-armed {Bandits} using {Confidence} {Information}},
url = {http://proceedings.mlr.press/v48/jun16.html},
abstract = {We introduce anytime Explore-m, a pure exploration problem for multi-armed bandits (MAB) that requires making a prediction of the top-m arms at every time step. Anytime Explore-m is more practical ...},
language = {en},
urldate = {2018-02-22},
booktitle = {International {Conference} on {Machine} {Learning}},
author = {Jun, Kwang-Sung and Nowak, Robert},
month = jun,
year = {2016},
pages = {974--982},
}

@article{ravikumar_sparse_2007,
title = {Sparse {Additive} {Models}},
url = {http://arxiv.org/abs/0711.4555},
abstract = {We present a new class of methods for high-dimensional nonparametric regression and classification called sparse additive models (SpAM). Our methods combine ideas from sparse linear modeling and additive nonparametric regression. We derive an algorithm for fitting the models that is practical and effective even when the number of covariates is larger than the sample size. SpAM is closely related to the COSSO model of Lin and Zhang (2006), but decouples smoothing and sparsity, enabling the use of arbitrary nonparametric smoothers. An analysis of the theoretical properties of SpAM is given. We also study a greedy estimator that is a nonparametric version of forward stepwise regression. Empirical results on synthetic and real data are presented, showing that SpAM can be effective in fitting sparse nonparametric models in high dimensional data.},
journal = {arXiv:0711.4555 [math, stat]},
author = {Ravikumar, Pradeep and Lafferty, John and Liu, Han and Wasserman, Larry},
month = nov,
year = {2007},
note = {arXiv: 0711.4555},
keywords = {Mathematics - Statistics Theory},
}

@article{noauthor_childhood_1999,
title = {The {Childhood} {Asthma} {Management} {Program} ({CAMP}): {Design}, {Rationale}, and {Methods}},
volume = {20},
issn = {0197-2456},
shorttitle = {The {Childhood} {Asthma} {Management} {Program} ({CAMP})},
url = {http://www.sciencedirect.com/science/article/pii/S0197245698000440},
doi = {10.1016/S0197-2456(98)00044-0},
abstract = {The Childhood Asthma Management Program (CAMP) is a multicenter, randomized, double-masked clinical trial designed to determine the long-term effects of three inhaled treatments for mild to moderate childhood asthma: budesonide (a glucocorticoid used daily) and albuterol (a short-acting β-agonist bronchodilator used as needed); nedocromil (a nonsteroid anti-inflammatory agent used daily) and albuterol; and placebo and albuterol. One thousand forty-one children (32\% from ethnic minority groups), aged 5 to 12 years at screening, are currently participating. The primary outcome measure is lung growth as indicated by postbronchodilator forced expiratory volume in 1 second (FEV1) percent of predicted, observed over 5- to 6-year period. The trial also assesses differences between treatment groups with respect to airway responsiveness, morbidity, physical growth and development, and psychological growth and development. This report describes the design of the trial, the rationale for the design choices made, and the methods used to carry out the trial.},
number = {1},
journal = {Controlled Clinical Trials},
month = feb,
year = {1999},
keywords = {Albuterol, Allergens, Clinical trials, Environmental Exposure, Glucocorticoids, anti-inflammatory agents, atopy, bronchial provocation test, bronchodilator agents, budesonide, childhood asthma, growth, inhaled bronchodilator, nedocromil, psychological test, spirometry},
pages = {91--120},
}

@article{marchetti-bowick_time-varying_2016,
title = {A time-varying group sparse additive model for genome-wide association studies of dynamic complex traits},
volume = {32},
issn = {1367-4803},
url = {https://academic.oup.com/bioinformatics/article/32/19/2903/2196488},
doi = {10.1093/bioinformatics/btw347},
abstract = {Motivation: Despite the widespread popularity of genome-wide association studies (GWAS) for genetic mapping of complex traits, most existing GWAS methodologies are still limited to the use of static phenotypes measured at a single time point. In this work, we propose a new method for association mapping that considers dynamic phenotypes measured at a sequence of time points. Our approach relies on the use of Time-Varying Group Sparse Additive Models (TV-GroupSpAM) for high-dimensional, functional regression.Results: This new model detects a sparse set of genomic loci that are associated with trait dynamics, and demonstrates increased statistical power over existing methods. We evaluate our method via experiments on synthetic data and perform a proof-of-concept analysis for detecting single nucleotide polymorphisms associated with two phenotypes used to assess asthma severity: forced vital capacity, a sensitive measure of airway obstruction and bronchodilator response, which measures lung response to bronchodilator drugs.Availability and Implementation: Source code for TV-GroupSpAM freely available for download at http://www.cs.cmu.edu/{\textasciitilde}mmarchet/projects/tv\_group\_spam, implemented in MATLAB.Contact:epxing@cs.cmu.eduSupplementary Information:Supplementary data are available at Bioinformatics online.},
language = {en},
number = {19},
urldate = {2018-02-04},
journal = {Bioinformatics},
author = {Marchetti-Bowick, Micol and Yin, Junming and Howrylak, Judie A. and Xing, Eric P.},
month = oct,
year = {2016},
pages = {2903--2910},
}

@article{ehrlich_risk_1996,
title = {Risk factors for childhood asthma and wheezing. {Importance} of maternal and household smoking},
volume = {154},
issn = {1073-449X},
doi = {10.1164/ajrccm.154.3.8810605},
abstract = {To identify modifiable risk factors for wheezing illness in childhood, the associations between current asthma or wheezing and factors such as household smoking, damp and dietary salt preference were measured in a questionnaire-based prevalence study of schoolchildren 7 to 9 yr of age in Cape Town. In a random sample of 15 schools, questionnaires were completed by parents of 1,955 children, from which 368 cases and 294 controls were selected on the basis of reported asthma diagnosis or symptoms. Urinary cotinine concentrations were measured, and the parents were interviewed. An exposure-response relationship between the urinary cotinine creatinine ratio and asthma/wheeze was observed. In multivariate analysis, predictors of asthma/wheeze were hay fever (odds ratio [OR] - 5.30; 95\% confidence interval [CI] = 3.16 to 8.89), eczema (OR = 2.19; 95\% CI = 1.33-3.62), parental asthma (OR = 1.77; 95\% CI = 1.11 to 2.84), absence of paternal contribution to income (OR = 1.72; 95\% CI = 1.17 to 2.54), maternal smoking in pregnancy (OR = 1.87; 95\% CI = 1.25 to 2.81), and each additional household smoker (OR = 1.15; 95\% CI = 1.01 to 1.30). Findings were similar, with higher odds ratios for most variables, except number of household smokers, when the group was restricted to children with parent-reported asthma. The findings confirm that household smoking is an important modifiable risk factor in asthma/wheeze among young schoolchildren, and they suggest that maternal smoking in pregnancy and current household exposure are independent contributors to this effect.},
language = {eng},
number = {3 Pt 1},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Ehrlich, R. I. and Du Toit, D. and Jordaan, E. and Zwarenstein, M. and Potter, P. and Volmink, J. A. and Weinberg, E.},
month = sep,
year = {1996},
pmid = {8810605},
keywords = {Asthma, Child, Cotinine, Creatinine, Female, Humans, Male, Multivariate Analysis, Pregnancy, Prenatal Exposure Delayed Effects, Prevalence, Random Allocation, Respiratory Sounds, Risk Factors, Sampling Studies, Smoking, Socioeconomic Factors, Sodium Chloride, Dietary, South Africa, Surveys and Questionnaires, Tobacco Smoke Pollution},
pages = {681--688},
}

@incollection{woolcock_evidence_2007,
title = {Evidence for the {Increase} in {Asthma} {Worldwide}},
copyright = {Copyright © Ciba Foundation 1997},
isbn = {978-0-470-51533-4},
url = {http://onlinelibrary.wiley.com/doi/10.1002/9780470515334.ch8/summary},
abstract = {This chapter reviews the evidence that asthma is increasing and that changes in exposure to environmental risk factors may explain the increase. Although asthma is difficult to define for epidemiological studies, the prevalence of asthma as measured by the questionnaire definitions ‘asthma ever diagnosed’ and ‘wheeze ever’ is large and increasing. In all countries where serial studies using the same methods have been undertaken over the last 20 years, an increase in wheezing illness in children and adolescents has been recorded but there are insufficient data to determine whether the disease is increasing in adults. Despite the recorded increases, there remains a large difference in the prevalence of asthma between populations, with high rates of wheezing illness in Australasia and low rates in villages in poor countries. The male to female ratio for the occurrence of asthma remains at about 1.5 in children, 1.0 in late adolescence and less than 1.0 in adults, when more females than males have symptoms. The risk factors for childhood asthma are atopy (positive skin tests), parental asthma, allergen load, respiratory infections, some aspects of diet and an ‘affluence’ factor. There is some evidence for an increase in the prevalence of atopy in children but this may be due to earlier acquisition of atopy. Changes in the other risk factors have not been documented. The evidence for changes in indoor allergen loads, in diet, in the severity and nature of respiratory infections, and in ‘affluence’ is indirect and comes from a number of small studies rather than from serial epidemiological studies. It seems unlikely that a single, environmental risk factor has changed dramatically worldwide. Rather, a number of lifestyle changes may have combined to cause the disease to be expressed in children who, in previous times, were immunologically protected from developing asthma, perhaps by their T helper cell phenotype, or were not exposed to high allergen levels.},
language = {en},
booktitle = {Ciba {Foundation} {Symposium} 206 - {The} {Rising} {Trends} in {Asthma}},
publisher = {John Wiley \& Sons, Ltd.},
author = {Woolcock, Ann J. and Peat, Jennifer K.},
editor = {Organizer, Derek J. Chadwick and Cardew, Gail},
year = {2007},
doi = {10.1002/9780470515334.ch8},
keywords = {Asthma, Respiratory infections, atopic children, diet, lifestyle},
pages = {122--139},
}

@article{damato_environmental_2005,
title = {Environmental risk factors and allergic bronchial asthma},
volume = {35},
issn = {1365-2222},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1365-2222.2005.02328.x/abstract},
doi = {10.1111/j.1365-2222.2005.02328.x},
abstract = {The prevalence of allergic respiratory diseases such as bronchial asthma has increased in recent years, especially in industrialized countries. A change in the genetic predisposition is an unlikely cause of the increase in allergic diseases because genetic changes in a population require several generations. Consequently, this increase may be explained by changes in environmental factors, including indoor and outdoor air pollution. Over the past two decades, there has been increasing interest in studies of air pollution and its effects on human health. Although the role played by outdoor pollutants in allergic sensitization of the airways has yet to be clarified, a body of evidence suggests that urbanization, with its high levels of vehicle emissions, and a westernized lifestyle are linked to the rising frequency of respiratory allergic diseases observed in most industrialized countries, and there is considerable evidence that asthmatic persons are at increased risk of developing asthma exacerbations with exposure to ozone, nitrogen dioxide, sulphur dioxide and inhalable particulate matter. However, it is not easy to evaluate the impact of air pollution on the timing of asthma exacerbations and on the prevalence of asthma in general. As concentrations of airborne allergens and air pollutants are frequently increased contemporaneously, an enhanced IgE-mediated response to aeroallergens and enhanced airway inflammation could account for the increasing frequency of allergic respiratory allergy and bronchial asthma. Pollinosis is frequently used to study the interrelationship between air pollution and respiratory allergy. Climatic factors (temperature, wind speed, humidity, thunderstorms, etc) can affect both components (biological and chemical) of this interaction. By attaching to the surface of pollen grains and of plant-derived particles of paucimicronic size, pollutants could modify not only the morphology of these antigen-carrying agents but also their allergenic potential. In addition, by inducing airway inflammation, which increases airway permeability, pollutants overcome the mucosal barrier and could be able to ‘prime’ allergen-induced responses. There are also observations that a thunderstorm occurring during pollen season can induce severe asthma attacks in pollinosis patients. After rupture by thunderstorm, pollen grains may release part of their cytoplasmic content, including inhalable, allergen-carrying paucimicronic particles.},
language = {en},
number = {9},
journal = {Clinical \& Experimental Allergy},
author = {D'Amato, G. and Liccardi, G. and D'Amato, M. and Holgate, S.},
month = sep,
year = {2005},
keywords = {Air pollution, bronchial asthma, pollen allergy, respiratory allergy, thunderstorm-associated asthma, urban air pollution},
pages = {1113--1124},
}

@article{arruda_risk_2005,
title = {Risk factors for asthma and atopy},
volume = {5},
issn = {1528-4050},
url = {https://journals.lww.com/co-allergy/Abstract/2005/04000/Risk_factors_for_asthma_and_atopy.9.aspx},
doi = {10.1097/01.all.0000162308.89857.6c},
abstract = {Purpose of review The aim of this article is to provide information on risk factors associated with the development of atopy and asthma in childhood.
    Recent findings Several gene polymorphisms have been associated with susceptibility to asthma and allergy; complex gene–environmental interactions, however, appear to play a key role in the development of the disease. Early life sensitization to aeroallergens, presence of atopic dermatitis or allergic rhinitis, maternal smoking during pregnancy and children's environmental exposure to tobacco smoke, lower respiratory tract infections with respiratory syncytial virus and potentially with other viruses including rhinovirus and metapneumovirus, exposure to air pollutants, several perinatal factors other than maternal smoking, are among factors associated with an increased risk for development of chronic asthma.
    Summary The prevalence of asthma and allergic diseases is increasing progressively. Those who are involved in the care of young children should be prepared to recognize risk factors for development of these diseases and to appreciate the role of gene–environment interactions. Preventive measures established at an early age may modify the natural history of asthma and other allergic diseases.},
language = {en-US},
number = {2},
urldate = {2018-01-30},
journal = {Current Opinion in Allergy and Clinical Immunology},
author = {Arruda, L. Karla and Solé, Dirceu and Baena-Cagnani, Carlos E. and Naspitz, Charles K.},
month = apr,
year = {2005},
pages = {153},
}

@article{infante-rivard_childhood_1993,
title = {Childhood {Asthma} and {Indoor} {Environmental} {Risk} {Factors}},
volume = {137},
issn = {0002-9262},
url = {https://academic.oup.com/aje/article/137/8/834/134089},
doi = {10.1093/oxfordjournals.aje.a116745},
abstract = {In a case-control study carried out in Montréal, Québec, Canada, between 1988 and 1990, indoor environmental factors were studied in relation to the incidence of asthma among 3- and 4-year-old children. Cases (n=457), whose parents were recruited at a hospital emergency room, were children who had a first-time diagnosis of asthma (International Classification of Diseases, Ninth Revision, code 493) made by a pediatrician. Controls \{\vphantom{\}}n=457) were chosen from family allowance files and were matched with case children on age and census tract. A telephone interview was administered to the children's parents. A 20\% feasibility subsample was chosen to wear a nitrogen dioxide monitoring badge during a 24-hour period. Multiple conditional logistic regression analysis showed that after personal susceptibility factors were controlled for, the following were independent risk factors for asthma: the mother's heavy smoking (odds ratio (OR)= 2.77, 95\% confidence interval (Cl) 1.35–5.66), use of a humidifier in the child's room (OR = 1.89, 95\% Cl 1.30–2.74), and the presence of an electric heating system in the home (OR = 2.27, 95\% Cl 1.42–3.65). The presence of other smokers in the home was not quite significant (OR = 1.82, 95\% Cl 0.98–3.38). A history of pneumonia, the absence of breast feeding, and a family history of asthma were also significant risk factors. In a separate unmatched multivariate analysis of subjects who had worn the nitrogen dioxide badge, there was a dose-response relation between nitrogen dioxide (in parts per billion) and asthma. These results confirm the role of susceptibility factors in asthma and show that indoor environmental factors contribute to the incidence of asthma.},
language = {en},
number = {8},
urldate = {2018-01-30},
journal = {American Journal of Epidemiology},
author = {Infante-Rivard, Claire},
month = apr,
year = {1993},
pages = {834--844},
}

@article{sarpong_socioeconomic_1996,
title = {Socioeconomic status and race as risk factors for cockroach allergen exposure and sensitization in children with asthma},
volume = {97},
issn = {0091-6749, 1097-6825},
url = {http://www.jacionline.org/article/S0091-6749(96)70209-9/abstract},
doi = {10.1016/S0091-6749(96)70209-9},
language = {English},
number = {6},
urldate = {2018-01-30},
journal = {Journal of Allergy and Clinical Immunology},
author = {Sarpong, Sampson B. and Hamilton, Robert G. and Eggleston, Peyton A. and Adkinson, N. Franklin},
month = jun,
year = {1996},
pmid = {8648037},
keywords = {Asthma, Cockroach allergen, SES:, children, race, sensitization, socioeconomic status, urban},
pages = {1393--1401},
}

@article{rhodes_early_2001,
title = {Early life risk factors for adult asthma: {A} birth cohort study of subjects at risk},
volume = {108},
issn = {0091-6749, 1097-6825},
shorttitle = {Early life risk factors for adult asthma},
url = {http://www.jacionline.org/article/S0091-6749(01)64304-5/abstract},
doi = {10.1067/mai.2001.119151},
language = {English},
number = {5},
urldate = {2018-01-30},
journal = {Journal of Allergy and Clinical Immunology},
author = {Rhodes, Helen L. and Sporik, Richard and Thomas, Peter and Holgate, Stephen T. and Cogswell, Jeremy J.},
month = nov,
year = {2001},
pmid = {11692095},
keywords = {Asthma, BHR:, OR:, Odds ratio, Risk Factors, aeroallergen, atopy, bronchial hyperresponsiveness, food allergen},
pages = {720--725},
}

@article{haby_asthma_2001,
title = {Asthma in preschool children: prevalence and risk factors},
volume = {56},
copyright = {British Thoracic Society},
issn = {0040-6376, 1468-3296},
shorttitle = {Asthma in preschool children},
url = {http://thorax.bmj.com/content/56/8/589},
doi = {10.1136/thorax.56.8.589},
abstract = {BACKGROUND The prevalence of asthma in children has increased in many countries over recent years. To plan effective interventions to reverse this trend we need a better understanding of the risk factors for asthma in early life. This study was undertaken to measure the prevalence of, and risk factors for, asthma in preschool children.
METHODS Parents of children aged 3–5 years living in two cities (Lismore, n=383; Wagga Wagga, n=591) in New South Wales, Australia were surveyed by questionnaire to ascertain the presence of asthma and various proposed risk factors for asthma in their children. Recent asthma was defined as ever having been diagnosed with asthma andhaving cough or wheeze in the last 12 monthsand having used an asthma medication in the last 12 months. Atopy was measured by skin prick tests to six common allergens.
RESULTS The prevalence of recent asthma was 22\% in Lismore and 18\% in Wagga Wagga. Factors which increased the risk of recent asthma were: atopy (odds ratio (OR) 2.35, 95\% CI 1.49 to 3.72), having a parent with a history of asthma (OR 2.05, 95\% CI 1.34 to 3.16), having had a serious respiratory infection in the first 2 years of life (OR 1.93, 95\% CI 1.25 to 2.99), and a high dietary intake of polyunsaturated fats (OR 2.03, 95\% CI 1.15 to 3.60). Breast feeding (OR 0.41, 95\% CI 0.22 to 0.74) and having three or more older siblings (OR 0.16, 95\% CI 0.04 to 0.71) decreased the risk of recent asthma.
CONCLUSIONS Of the factors tested, those that have the greatest potential to be modified to reduce the risk of asthma are breast feeding and consumption of polyunsaturated fats.},
language = {en},
number = {8},
urldate = {2018-01-30},
journal = {Thorax},
author = {Haby, M. M. and Peat, J. K. and Marks, G. B. and Woolcock, A. J. and Leeder, S. R.},
month = aug,
year = {2001},
pmid = {11462059},
keywords = {Asthma, Prevalence, Risk Factors, preschool children},
pages = {589--595},
}

@article{helenius_asthma_1998,
title = {Asthma and increased bronchial responsiveness in elite athletes: {Atopy} and sport event as risk factors},
volume = {101},
issn = {0091-6749, 1097-6825},
shorttitle = {Asthma and increased bronchial responsiveness in elite athletes},
url = {http://www.jacionline.org/article/S0091-6749(98)70173-3/abstract},
doi = {10.1016/S0091-6749(98)70173-3},
language = {English},
number = {5},
urldate = {2018-01-30},
journal = {Journal of Allergy and Clinical Immunology},
author = {Helenius, Ilkka J. and Tikkanen, Heikki O. and Sarna, Seppo and Haahtela, Tari},
month = may,
year = {1998},
pmid = {9600502},
keywords = {95\% CI, 95\% confidence interval, Asthma, OR, Odds ratio, PD15FEV1, Provocative dose of histamine that causes a 15\% fall in FEV1, atopic allergy, long-distance running, lung function, pollen allergy, speed and power sports, swimming},
pages = {646--652},
}

@article{lundback_epidemiology_1998,
title = {Epidemiology of rhinitis and asthma.},
volume = {28 Suppl 2},
issn = {0954-7894},
url = {http://europepmc.org/abstract/med/9678821},
abstract = {Abstract: Numerous published studies have reported that the prevalence rates of asthma and allergic rhinitis have increased over the last two to three...},
language = {eng},
urldate = {2018-01-30},
journal = {Clinical and experimental allergy : journal of the British Society for Allergy and Clinical Immunology},
author = {Lundbäck, B.},
month = jun,
year = {1998},
pmid = {9678821},
pages = {3--10},
}

@article{liu_national_2010,
title = {National prevalence and risk factors for food allergy and relationship to asthma: {Results} from the {National} {Health} and {Nutrition} {Examination} {Survey} 2005-2006},
volume = {126},
issn = {0091-6749, 1097-6825},
shorttitle = {National prevalence and risk factors for food allergy and relationship to asthma},
url = {http://www.jacionline.org/article/S0091-6749(10)01140-1/abstract},
doi = {10.1016/j.jaci.2010.07.026},
abstract = {Background
The national prevalence and patterns of food allergy (FA) in the United States are not well understood.
Objective
We developed nationally representative estimates of the prevalence of and demographic risk factors for FA and investigated associations of FA with asthma, hay fever, and eczema.
Methods
A total of 8203 participants in the National Health and Nutrition Examination Survey 2005-2006 had food-specific serum IgE measured to peanut, cow's milk, egg white, and shrimp. Food-specific IgE and age-based criteria were used to define likely FA (LFA), possible FA, and unlikely FA and to develop estimates of clinical FA. Self-reported data were used to evaluate demographic risk factors and associations with asthma and related conditions.
Results
In the United States, the estimated prevalence of clinical FA was 2.5\% (peanut, 1.3\%; milk, 0.4\%; egg, 0.2\%; shrimp, 1.0\%; not mutually exclusive). Risk of possible FA/LFA was increased in non-Hispanic blacks (odds ratio, 3.06; 95\% CI, 2.14-4.36), males (1.87; 1.32-2.66), and children (2.04; 1.42-2.93). Study participants with doctor-diagnosed asthma (vs no asthma) exhibited increased risk of all measures of food sensitization. Moreover, in those with LFA, the adjusted odds ratio for current asthma (3.8; 1.5-10.7) and an emergency department visit for asthma in the past year (6.9; 2.4-19.7) were both notably increased.
Conclusion
Population-based serologic data on 4 foods indicate an estimated 2.5\% of the US population has FA, and increased risk was found for black subjects, male subjects, and children. In addition, FA could be an under-recognized risk factor for problematic asthma.},
language = {English},
number = {4},
urldate = {2018-01-30},
journal = {Journal of Allergy and Clinical Immunology},
author = {Liu, Andrew H. and Jaramillo, Renee and Sicherer, Scott H. and Wood, Robert A. and Bock, S. Allan and Burks, A. Wesley and Massing, Mark and Cohn, Richard D. and Zeldin, Darryl C.},
month = oct,
year = {2010},
pmid = {20920770},
keywords = {Asthma, ED, Emergency department, FA, LFA, Likely food allergy, NHANES, National Health and Nutrition Examination Survey, OR, Odds ratio, PFA, PIR, Possible food allergy, Poverty Income Ratio, Prevalence, UFA, Unlikely food allergy, eczema, egg, food allergy, food sensitization, food-specific serum IgE, hay fever, milk, peanut, risk, shrimp},
pages = {798--806.e14},
}

@article{subbarao_asthma:_2009,
title = {Asthma: epidemiology, etiology and risk factors},
volume = {181},
copyright = {© 2009},
issn = {0820-3946, 1488-2329},
shorttitle = {Asthma},
url = {http://www.cmaj.ca/content/181/9/E181},
doi = {10.1503/cmaj.080612},
abstract = {Asthma is one of the most common chronic conditions affecting both children and adults, yet much remains to be learned of its etiology. This paper evolved from the extensive literature review undertaken as part of a proposal for a longitudinal birth cohort study to examine risk factors for the},
language = {en},
number = {9},
urldate = {2018-01-30},
journal = {Canadian Medical Association Journal},
author = {Subbarao, Padmaja and Mandhane, Piush J. and Sears, Malcolm R.},
month = oct,
year = {2009},
pmid = {19752106},
pages = {E181--E190},
}

@article{brinke_risk_2005,
title = {Risk factors of frequent exacerbations in difficult-to-treat asthma},
volume = {26},
copyright = {© ERS Journals Ltd},
issn = {0903-1936, 1399-3003},
url = {http://erj.ersjournals.com/content/26/5/812},
doi = {10.1183/09031936.05.00037905},
abstract = {Recurrent exacerbations are a major cause of morbidity and medical expenditure in patients with asthma. Various exogenous and endogenous factors are thought to influence the level of asthma control, but systematical data on the involvement of these factors in the recurrence of asthma exacerbations are scarce.
In this study, 13 clinical and environmental factors potentially associated with recurrent exacerbations were investigated in 136 patients with difficult-to-treat asthma. Patients with more than three severe exacerbations (n = 39) in the previous year were compared with those with only one exacerbation per year (n = 24). A systematic diagnostic protocol was used to assess 13 potential risk factors.
Factors significantly associated with frequent exacerbations included: severe nasal sinus disease (adjusted odds ratio (OR) 3.7); gastro-oesophageal reflux (OR 4.9); recurrent respiratory infections (OR 6.9); psychological dysfunctioning (OR 10.8); and obstructive sleep apnoea (OR 3.4). Severe chronic sinus disease and psychological dysfunctioning were the only independently associated factors (adjusted OR 5.5 and 11.7, respectively). All patients with frequent exacerbations exhibited at least one of these five factors, whilst 52\% showed three or more factors.
In conclusion, the results show that recurrent exacerbations in asthma are associated with specific co-morbid factors that are easy to detect and that are treatable. Therapeutic interventions aimed at correcting these factors are likely to reduce morbidity and medical expenditure in these patients.},
language = {en},
number = {5},
urldate = {2018-01-30},
journal = {European Respiratory Journal},
author = {Brinke, A. ten and Sterk, P. J. and Masclee, A. a. M. and Spinhoven, P. and Schmidt, J. T. and Zwinderman, A. H. and Rabe, K. F. and Bel, E. H.},
month = nov,
year = {2005},
pmid = {16264041},
keywords = {Asthma, Psychology, asthma exacerbations, gastro-oesophageal reflux, sinusitis},
pages = {812--818},
}

@article{settipane_long-term_1994,
title = {Long-{Term} {Risk} {Factors} for {Developing} {Asthma} and {Allergic} {Rhinitis}: {A} 23-{Year} {Follow}-{Up} {Study} of {College} {Students}},
volume = {15},
copyright = {Copyright OceanSide Publications Jan 1, 1994},
issn = {10469354},
shorttitle = {Long-{Term} {Risk} {Factors} for {Developing} {Asthma} and {Allergic} {Rhinitis}},
url = {https://search.proquest.com/docview/231734744?pq-origsite=gscholar},
language = {English},
number = {1},
journal = {Allergy Proceedings; Providence},
author = {Settipane, Robert J. and Hagy, George W. and Settipane, Guy A.},
month = jan,
year = {1994},
keywords = {Medical Sciences--Allergology And Immunology},
pages = {21--25},
}

@article{call_risk_1992,
title = {Risk factors for asthma in inner city children},
volume = {121},
issn = {0022-3476},
url = {http://www.sciencedirect.com/science/article/pii/S0022347605803294},
doi = {10.1016/S0022-3476(05)80329-4},
abstract = {Inner city children have the highest prevalence and the highest mortality rates for asthma in the United States. The purpose of this study was to evaluate sensitization and exposure to common indoor allergens among children aged 3 years to 15 years seen for treatment of asthma at Grady Memorial Hospital, Atlanta, Ga. Eighty children in this study were enrolled in the emergency department and 64 in hospital clinics. Dust from 57 homes, assayed for three indoor allergens (dust mite, cat, and cockroach), revealed similar exposure for asthma and control groups. Sixty-nine percent of the childen with asthma had IgE antibodies to dust mite, cockroach, or cat; only 27\% of the control subjects were similarly sensitized (p{\textless}0.001). Of 35 children with asthma 21 had both sensitization and significant exposure to the relevant allergen; this was true for only 3 of 22 control subjects (odds ratio, 9.5; p{\textless}0.001). Nelther sensitization nor exposure to cat allergen was common in this population. The results show that black children in inner city Atlanta are exposed to high levels of mite and cockroach allergens and that a high proportion of the children with asthma are sensitized to these allergens; the combination of sensitization and exposure is a major risk factor for asthma in this population.},
number = {6},
journal = {The Journal of Pediatrics},
author = {Call, Robert S. and Smith, Thomas F. and Morris, Elsie and Chapman, Martin D. and Platts-Mills, Thomas A. E.},
month = dec,
year = {1992},
pages = {862--866},
}

@article{andrew_aligne_risk_2000,
title = {Risk {Factors} for {Pediatric} {Asthma}},
volume = {162},
issn = {1073-449X},
url = {https://www.atsjournals.org/doi/full/10.1164/ajrccm.162.3.9908085},
doi = {10.1164/ajrccm.162.3.9908085},
abstract = {The Child Health Supplement to the 1988 National Health Interview Survey was used to examine parent-reported current asthma  among a nationally representative sample of 17,110 children zero  to 17 yr of age. Numerous demographic variables were analyzed  for independent associations with asthma using modified stepwise  logistic regression, with models including specific combinations of  risk factors. Black children had higher rates of asthma than did  white children in unadjusted analyses, but after controlling for  multiple factors, black race was not a significant correlate of  asthma (adjusted odds ratio  =  0.87, 95\% CI  =  0.63 to 1.21). Compared with nonurban white children, urban children, both black  and white, were at significantly increased risk of asthma: urban  and black (adjusted OR  =  1.45, 95\% CI  =  1.14 to 1.86), urban and  white (adjusted OR  =  1.22, 95\% CI  =  1.01 to 1.48), whereas nonurban black children were not: nonurban and black (adjusted OR  =   1.15, 95\% CI  =  0.83 to 1.61). Similarly, compared with nonurban,  nonpoor children, urban and poor (adjusted OR  =  1.44, 95\% CI  =   1.05 to 1.95), urban and nonpoor (adjusted OR  =  1.22, 95\% CI  =   1.004 to 1.48), urban children, both poor and nonpoor, were at significantly increased risk of asthma, whereas nonurban poor children  were not: nonurban and poor (adjusted OR  =  1.03, 95\% CI  =  0.72  to 1.48). These results suggest that the higher prevalence of  asthma among black children is not due to race or to low income  per se, and that all children living in an urban setting are at increased risk for asthma.},
number = {3},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Andrew Aligne, C. and Auinger, Peggy and Byrd, Robert S. and Weitzman, Michael},
month = sep,
year = {2000},
pages = {873--877},
}

@article{pizer_falsification_2016,
title = {Falsification {Testing} of {Instrumental} {Variables} {Methods} for {Comparative} {Effectiveness} {Research}},
volume = {51},
issn = {0017-9124},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4799892/},
doi = {10.1111/1475-6773.12355},
abstract = {Objectives
To demonstrate how falsification tests can be used to evaluate instrumental variables methods applicable to a wide variety of comparative effectiveness research questions.

Study Design
Brief conceptual review of instrumental variables and falsification testing principles and techniques accompanied by an empirical application. Sample STATA code related to the empirical application is provided in the Appendix.

Empirical Application
Comparative long‐term risks of sulfonylureas and thiazolidinediones for management of type 2 diabetes. Outcomes include mortality and hospitalization for an ambulatory care–sensitive condition. Prescribing pattern variations are used as instrumental variables.

Conclusions
Falsification testing is an easily computed and powerful way to evaluate the validity of the key assumption underlying instrumental variables analysis. If falsification tests are used, instrumental variables techniques can help answer a multitude of important clinical questions.},
number = {2},
journal = {Health Services Research},
author = {Pizer, Steven D.},
month = apr,
year = {2016},
pmid = {26293167},
pmcid = {PMC4799892},
pages = {790--811},
}

@article{hidalgo_dynamic_2009,
title = {A {Dynamic} {Network} {Approach} for the {Study} of {Human} {Phenotypes}},
volume = {5},
issn = {1553-7358},
url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000353},
doi = {10.1371/journal.pcbi.1000353},
abstract = {Author Summary To help the understanding of physiological failures, diseases are defined as specific sets of phenotypes affecting one or several physiological systems. Yet, the complexity of biological systems implies that our working definitions of diseases are careful discretizations of a complex phenotypic space. To reconcile the discrete nature of diseases with the complexity of biological organisms, we need to understand how diseases are connected, as connections between these different discrete categories can be informative about the mechanisms causing physiological failures. Here we introduce the Phenotypic Disease Network (PDN) as a map summarizing phenotypic connections between diseases and show that diseases progress preferentially along the links of this map. Furthermore, we show that this progression is different for patients with different genders and racial backgrounds and that patients affected by diseases that are connected to many other diseases in the PDN tend to die sooner than those affected by less connected diseases. Additionally, we have created a queryable online database (http://hudine.neu.edu/) of the 18 different datasets generated from the more than 31 million patients in this study. The disease associations can be explored online or downloaded in bulk.},
number = {4},
urldate = {2017-11-29},
journal = {PLOS Computational Biology},
author = {Hidalgo, César A. and Blumm, Nicholas and Barabási, Albert-László and Christakis, Nicholas A.},
month = apr,
year = {2009},
keywords = {Epidemiology, Genetic networks, Genetics of disease, Geriatrics, Hypertension, Phenotypes, Protein interaction networks, human genetics},
pages = {e1000353},
}

@article{zhou_human_2014,
title = {Human symptoms-disease network},
volume = {5},
issn = {2041-1723},
doi = {10.1038/ncomms5212},
abstract = {In the post-genomic era, the elucidation of the relationship between the molecular origins of diseases and their resulting phenotypes is a crucial task for medical research. Here, we use a large-scale biomedical literature database to construct a symptom-based human disease network and investigate the connection between clinical manifestations of diseases and their underlying molecular interactions. We find that the symptom-based similarity of two diseases correlates strongly with the number of shared genetic associations and the extent to which their associated proteins interact. Moreover, the diversity of the clinical manifestations of a disease can be related to the connectivity patterns of the underlying protein interaction network. The comprehensive, high-quality map of disease-symptom relations can further be used as a resource helping to address important questions in the field of systems medicine, for example, the identification of unexpected associations between diseases, disease etiology research or drug design.},
language = {eng},
journal = {Nature Communications},
author = {Zhou, XueZhong and Menche, Jörg and Barabási, Albert-László and Sharma, Amitabh},
month = jun,
year = {2014},
pmid = {24967666},
keywords = {Disease, Genetic Predisposition to Disease, Humans, Models, Theoretical, Phenotype, Proteins, Systems Theory},
pages = {4212},
}

@article{barabasi_network_2011,
title = {Network {Medicine}: {A} {Network}-based {Approach} to {Human} {Disease}},
volume = {12},
issn = {1471-0056},
shorttitle = {Network {Medicine}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3140052/},
doi = {10.1038/nrg2918},
abstract = {Given the functional interdependencies between the molecular components in a human cell, a disease is rarely a consequence of an abnormality in a single gene, but reflects the perturbations of the complex intracellular network. The emerging tools of network medicine offer a platform to explore systematically not only the molecular complexity of a particular disease, leading to the identification of disease modules and pathways, but also the molecular relationships between apparently distinct (patho)phenotypes. Advances in this direction are essential to identify new diseases genes, to uncover the biological significance of disease-associated mutations identified by genome-wide association studies and full genome sequencing, and to identify drug targets and biomarkers for complex diseases.},
number = {1},
journal = {Nature reviews. Genetics},
author = {Barabási, Albert-László and Gulbahce, Natali and Loscalzo, Joseph},
month = jan,
year = {2011},
pmid = {21164525},
pmcid = {PMC3140052},
pages = {56--68},
}

@article{goh_human_2007,
title = {The human disease network},
volume = {104},
issn = {0027-8424, 1091-6490},
url = {http://www.pnas.org/content/104/21/8685},
doi = {10.1073/pnas.0701361104},
abstract = {A network of disorders and disease genes linked by known disorder–gene associations offers a platform to explore in a single graph-theoretic framework all known phenotype and disease gene associations, indicating the common genetic origin of many diseases. Genes associated with similar disorders show both higher likelihood of physical interactions between their products and higher expression profiling similarity for their transcripts, supporting the existence of distinct disease-specific functional modules. We find that essential human genes are likely to encode hub proteins and are expressed widely in most tissues. This suggests that disease genes also would play a central role in the human interactome. In contrast, we find that the vast majority of disease genes are nonessential and show no tendency to encode hub proteins, and their expression pattern indicates that they are localized in the functional periphery of the network. A selection-based model explains the observed difference between essential and disease genes and also suggests that diseases caused by somatic mutations should not be peripheral, a prediction we confirm for cancer genes.},
language = {en},
number = {21},
urldate = {2017-11-29},
journal = {Proceedings of the National Academy of Sciences},
author = {Goh, Kwang-Il and Cusick, Michael E. and Valle, David and Childs, Barton and Vidal, Marc and Barabási, Albert-László},
month = may,
year = {2007},
pmid = {17502601},
keywords = {biological networks, complex networks, diseasome, human genetics, systems biology},
pages = {8685--8690},
}

@article{rual_towards_2005,
title = {Towards a proteome-scale map of the human protein–protein interaction network},
volume = {437},
copyright = {2005 Nature Publishing Group},
issn = {1476-4687},
url = {https://www.nature.com/articles/nature04209},
doi = {10.1038/nature04209},
abstract = {Towards a proteome-scale map of the human protein–protein interaction network},
language = {En},
number = {7062},
urldate = {2017-11-29},
journal = {Nature},
author = {Rual, Jean-François and Venkatesan, Kavitha and Hao, Tong and Hirozane-Kishikawa, Tomoko and Dricot, Amélie and Li, Ning and Berriz, Gabriel F. and Gibbons, Francis D. and Dreze, Matija and Ayivi-Guedehoussou, Nono and Klitgord, Niels and Simon, Christophe and Boxem, Mike and Milstein, Stuart and Rosenberg, Jennifer and Goldberg, Debra S. and Zhang, Lan V. and Wong, Sharyl L. and Franklin, Giovanni and Li, Siming and Albala, Joanna S. and Lim, Janghoo and Fraughton, Carlene and Llamosas, Estelle and Cevik, Sebiha and Bex, Camille and Lamesch, Philippe and Sikorski, Robert S. and Vandenhaute, Jean and Zoghbi, Huda Y. and Smolyar, Alex and Bosak, Stephanie and Sequerra, Reynaldo and Doucette-Stamm, Lynn and Cusick, Michael E. and Hill, David E. and Roth, Frederick P. and Vidal, Marc},
month = oct,
year = {2005},
pages = {1173},
}

@article{sokolova_systematic_2009,
title = {A systematic analysis of performance measures for classification tasks},
volume = {45},
issn = {0306-4573},
url = {http://www.sciencedirect.com/science/article/pii/S0306457309000259},
doi = {10.1016/j.ipm.2009.03.002},
abstract = {This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier’s evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies.},
number = {4},
journal = {Information Processing \& Management},
author = {Sokolova, Marina and Lapalme, Guy},
month = jul,
year = {2009},
keywords = {machine learning, performance evaluation, text classification},
pages = {427--437},
}

@incollection{resnik_evaluation_2013,
title = {Evaluation of {NLP} {Systems}},
isbn = {978-1-4051-5581-6},
url = {http://onlinelibrary.wiley.com/doi/10.1002/9781444324044.ch11/summary},
language = {english},
booktitle = {The handbook of computational linguistics and natural language processing},
publisher = {WILEY-BLACKWELL},
author = {Resnik, Philip and Lin, Jimmy},
month = apr,
year = {2013},
pages = {271--295},
}

@inproceedings{girju_text_2002,
title = {Text {Mining} for {Causal} {Relations}},
abstract = {Given a semantic relation, the automatic extraction  of linguistic patterns that express that relation is a  rather dicult problem. This paper presents a semiautomatic  method of discovering generally applicable  lexico-syntactic patterns that refer to the causal relation.},
booktitle = {In {Proceedings} of the {FLAIRS} {Conference}},
author = {Girju, Roxana and Moldovan, Dan},
year = {2002},
pages = {360--364},
}

@inproceedings{blanco_causal_2008,
address = {Morocco},
title = {Causal {Relation} {Extraction}},
isbn = {2-9517408-4-0},
url = {http://www.lrec-conf.org/proceedings/lrec2008/},
abstract = {This paper presents a supervised method for the detection and extraction of Causal Relations from open domain text. First we give a
brief outline of the definition of causation and how it relates to other Semantic Relations, as well as a characterization of their encoding.
In this work, we only consider marked and explicit causations. Our approach first identifies the syntactic patterns that may encode a
causation, then we use Machine Learning techniques to decide whether or not a pattern instance encodes a causation. We focus on the
most productive pattern, a verb phrase followed by a relator and a clause, and its reverse version, a relator followed by a clause and a
verb phrase. As relators we consider the words as, after, because and since. We present a set of lexical, syntactic and semantic features
for the classification task, their rationale and some examples. The results obtained are discussed and the errors analyzed.},
language = {english},
booktitle = {Proceedings of the {Sixth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'08)},
publisher = {European Language Resources Association (ELRA)},
author = {Blanco, Eduardo and Castell, Nuria and Moldovan, Dan},
month = may,
year = {2008},
pages = {310--313},
}

@inproceedings{chang_causal_2004,
series = {Lecture {Notes} in {Computer} {Science}},
title = {Causal {Relation} {Extraction} {Using} {Cue} {Phrase} and {Lexical} {Pair} {Probabilities}},
isbn = {978-3-540-24475-2 978-3-540-30211-7},
url = {https://link.springer.com/chapter/10.1007/978-3-540-30211-7_7},
doi = {10.1007/978-3-540-30211-7_7},
abstract = {This work aims to extract causal relations that exist between two events expressed by noun phrases or sentences. The previous works for the causality made use of causal patterns such as causal verbs. We concentrate on the information obtained from other causal event pairs. If two event pairs share some lexical pairs and one of them is revealed to be causally related, the causal probability of another event pair tends to increase. We introduce the lexical pair probability and the cue phrase probability. These probabilities are learned from raw corpus in unsupervised manner. With these probabilities and the Naive Bayes classifier, we try to resolve the causal relation extraction problem. Our inter-NP causal relation extraction shows the precision of 81.29\%, that is 7.05\% improvement over the baseline model. The proposed models are also applied to inter-sentence causal relation extraction.},
language = {en},
urldate = {2017-08-20},
booktitle = {Natural {Language} {Processing} – {IJCNLP} 2004},
publisher = {Springer, Berlin, Heidelberg},
author = {Chang, Du-Seong and Choi, Key-Sun},
month = mar,
year = {2004},
pages = {61--70},
}

@article{glasser_overview_2017,
title = {Overview of {Electronic} {Nicotine} {Delivery} {Systems}: {A} {Systematic} {Review}},
volume = {52},
issn = {0749-3797},
shorttitle = {Overview of {Electronic} {Nicotine} {Delivery} {Systems}},
url = {http://www.sciencedirect.com/science/article/pii/S0749379716305736},
doi = {10.1016/j.amepre.2016.10.036},
abstract = {Rapid developments in e-cigarettes, or electronic nicotine delivery systems (ENDS), and the evolution of the overall tobacco product marketplace warrant frequent evaluation of the published literature. The purpose of this article is to report updated findings from a comprehensive review of the published scientific literature on ENDS. The authors conducted a systematic review of published empirical research literature on ENDS through May 31, 2016, using a detailed search strategy in the PubMed electronic database, expert review, and additional targeted searches. Included studies presented empirical findings and were coded to at least one of nine topics: (1) Product Features; (2) Health Effects; (3) Consumer Perceptions; (4) Patterns of Use; (5) Potential to Induce Dependence; (6) Smoking Cessation; (7) Marketing and Communication; (8) Sales; and (9) Policies; reviews and commentaries were excluded. Data from included studies were extracted by multiple coders (October 2015 to August 2016) into a standardized form and synthesized qualitatively by topic. There were 687 articles included in this systematic review. The majority of studies assessed patterns of ENDS use and consumer perceptions of ENDS, followed by studies examining health effects of vaping and product features. Studies indicate that ENDS are increasing in use, particularly among current smokers, pose substantially less harm to smokers than cigarettes, are being used to reduce/quit smoking, and are widely available. More longitudinal studies and controlled trials are needed to evaluate the impact of ENDS on population-level tobacco use and determine the health effects of longer-term vaping.},
number = {2},
journal = {American Journal of Preventive Medicine},
author = {Glasser, Allison M. and Collins, Lauren and Pearson, Jennifer L. and Abudayyeh, Haneen and Niaura, Raymond S. and Abrams, David B. and Villanti, Andrea C.},
month = feb,
year = {2017},
pages = {e33--e66},
}

@article{dinakar_health_2016,
title = {The {Health} {Effects} of {Electronic} {Cigarettes}},
volume = {375},
issn = {1533-4406},
doi = {10.1056/NEJMra1502466},
language = {eng},
number = {14},
journal = {The New England Journal of Medicine},
author = {Dinakar, Chitra and O'Connor, George T.},
month = oct,
year = {2016},
pmid = {27705269},
keywords = {Aerosols, Air Pollutants, Animals, Electronic cigarettes, Humans, Nicotine},
pages = {1372--1381},
}

@article{orellana-barrios_electronic_2015,
title = {Electronic {Cigarettes}—{A} {Narrative} {Review} for {Clinicians}},
volume = {128},
issn = {1555-7162},
doi = {10.1016/j.amjmed.2015.01.033},
abstract = {Electronic cigarettes (e-cigarettes) were introduced into the US market in 2007 and have quickly become a popular source of nicotine for many patients. They are designed to simulate smoking by heating a nicotine-containing solution producing an aerosol that the user inhales. The short- and long-term effects of e-cigarette use are still unclear, but their use is increasing. Some acute effects of e-cigarettes on heart rate, blood pressure, and airway resistance are reported. Although there are some reports of improved cessation in a subset of users, there are also studies reporting decreased cessation in dual users of regular and e-cigarettes. Additionally, there is no current regulation of these devices, and this allows virtually anyone with a form of online payment to obtain them.},
language = {eng},
number = {7},
journal = {The American Journal of Medicine},
author = {Orellana-Barrios, Menfil A. and Payne, Drew and Mulkey, Zachary and Nugent, Kenneth},
month = jul,
year = {2015},
pmid = {25731134},
keywords = {Adult, Attitude of Health Personnel, Electronic cigarettes, Female, Humans, Male, Middle Aged, Narration, Needs Assessment, Nicotine, Practice Patterns, Physicians', Risk Factors, Safety Management, Smoking, Smoking Cessation, Toxicity, United States, Use patterns, tobacco industry},
pages = {674--681},
}

@inproceedings{pasca_organizing_2006,
title = {Organizing and searching the {World} {Wide} {Web} of facts - step one: the one-million fact extraction challenge},
shorttitle = {Organizing and searching the {World} {Wide} {Web} of facts - step one},
abstract = {Due to the inherent difficulty of processing noisy text, the potential of the Web as a decentralized repository of human knowledge remains largely untapped during Web search. The access to billions of binary relations among named entities would enable new search paradigms and alternative methods for presenting the search results. A first concrete step towards building large searchable repositories of factual knowledge is to derive such knowledge automatically at large scale from textual documents. Generalized contextual extraction patterns allow for fast iterative progression towards extracting one million facts of a given type (e.g., Person-BornIn-Year) from 100 million Web documents of arbitrary quality. The extraction starts from as few as 10 seed facts, requires no additional input knowledge or annotated text, and emphasizes scale and coverage by avoiding the use of syntactic parsers, named entity recognizers, gazetteers, and similar text processing tools and resources.},
booktitle = {In {Proceedings} of the 21st {National} {Conference} on {Artificial} {Intelligence} ({AAAI}-06},
author = {Pasca, Marius and Lin, Dekang and Bigham, Jeffrey and Lifchits, Andrei and Jain, Alpa},
year = {2006},
pages = {1400--1405},
}

@article{polosa_effect_2014,
title = {Effect of the use of electronic cigarettes (e-{Cig}) in smoking asthmatics ({SA}): {A} retrospective evaluation},
volume = {44},
copyright = {© 2014 ERS},
issn = {0903-1936, 1399-3003},
shorttitle = {Effect of the use of electronic cigarettes (e-{Cig}) in smoking asthmatics ({SA})},
url = {http://erj.ersjournals.com/content/44/Suppl_58/3440},
abstract = {Background
SA have frequent exacerbations, poor health status and disease control. E-Cigs are an alternative smoking strategy to conventional cigarettes.
Aim
To evaluate the effects of e-Cigs as an alternative to tobacco use in SA.
Methods
We retrospectively reviewed changes in lung function, methacholine airway hyperresponsiveness and asthma control in SA who had been using e-Cigs for at least 12 months. Measurements were taken prior to use, at 6 and 12 months.
Results
18 SA were identified with a mean age of 39 (±12) and smoking pack years of 21 (±10); 10 single (e-Cig only) and 8 dual users (e-Cig and conventional cigarettes ≤4cig/day). The findings are summarised below.
View this table:View inlineView popupParameter measurements at baseline (BL), 6- and 12-months (M)

No adverse events were reported.
Conclusions
E-Cig use appears to have beneficial effects on respiratory physiology and subjective asthma outcomes, suggesting that these products may be a valid and safe option for SA not intending or unable to quit tobacco use. Larger controlled studies are required to substantiate our findings.},
language = {en},
number = {Suppl 58},
urldate = {2017-08-18},
journal = {European Respiratory Journal},
author = {Polosa, Riccardo and Caponnetto, Pasquale and Caruso, Massimo and Strano, Simona and Russo, Cristina and Morjaria, Jaymin},
month = sep,
year = {2014},
keywords = {Asthma - management, Smoking},
pages = {3440},
}

@inproceedings{mcalinden_maternal_2017,
title = {Maternal {E}-cigarette {Vaping} {Enhances} {Development} {Of} {Allergic} {Asthma} {In} {The} {Offspring}},
abstract = {Our study suggests that maternal eCig vaping enhanced and worsened features of allergic asthma and this could be
attributed to aberrant mitochondrial function in the offspring.},
booktitle = {in {D98}. {Insights} into {Environmental} {Exposures} in {Asthma}, {COPD}, and {Constrictive} {Bronchiolitis}},
author = {McAlinden, Kiel D. and Chan, Yik L. and Kota, Anudeep and Chen, Hui and Oliver, Brian G. and Sharma, Pawan},
month = may,
year = {2017},
pages = {A7333--A7333},
}

@article{campagna_persisting_2016,
title = {Persisting {Long} {Term} {Benefits} of {Smoking} {Abstinence} and {Reduction} in {Asthmatic} {Smokers} {Who} {Have} {Switched} to {Electronic} {Cigarettes}},
volume = {137},
copyright = {Copyright Elsevier Limited Feb 2016},
issn = {00916749},
url = {https://search.proquest.com/docview/1765339135?pq-origsite=gscholar},
doi = {http://dx.doi.org/10.1016/j.jaci.2015.12.017},
abstract = {Methods We prospectively re-evaluated respiratory symptoms, lung function, airway hyperresponsiveness, asthma control, asthma exacerbations and tobacco consumption in adult daily ECs users with asthma who were previously studied in a retrospective study.},
language = {English},
number = {2},
journal = {Journal of Allergy and Clinical Immunology; St. Louis},
author = {Campagna, Davide and Morjaria, Jaymin B. and Caponnetto, Pasquale and Caruso, Massimo and Amaradio, Maria Domenica and Ciampi, Giovanni and Russo, Cristina and Polosa, Riccardo},
month = feb,
year = {2016},
keywords = {Abstracting And Indexing Services, Asthma, Electronic cigarettes, Long term, Medical Sciences--Allergology And Immunology},
pages = {AB5},
}

@article{nickels_pulmonologists_2017,
title = {Pulmonologists’ and {Primary} {Care} {Physicians}’ {Responses} to an {Adult} {Patient} with {Asthma} {Who} {Inquires} about {Using} {Electronic} {Cigarettes} as a {Smoking} {Cessation} {Tool}},
volume = {14},
issn = {2329-6933},
url = {http://www.atsjournals.org/doi/abs/10.1513/AnnalsATS.201610-828LE},
doi = {10.1513/AnnalsATS.201610-828LE},
number = {3},
journal = {Annals of the American Thoracic Society},
author = {Nickels, Andrew S. and Warner, David O. and Jenkins, Sarah M. and Tilburt, Jon and Hays, J. Taylor},
month = mar,
year = {2017},
pages = {466--468},
}

@misc{fda_products_nodate,
type = {{WebContent}},
title = {Products, {Ingredients} \& {Components} - {Vapes}, {E}-{Cigs}, {Hookah} {Pens}, and other {Electronic} {Nicotine} {Delivery} {Systems} ({ENDS})},
url = {https://www.fda.gov/tobaccoproducts/labeling/productsingredientscomponents/ucm456610.htm},
abstract = {Vaporizers, E-Cigs, and other Electronic Nicotine Delivery Systems  (ENDS)},
language = {en},
urldate = {2017-08-18},
author = {FDA},
}

@inproceedings{zhang_domain_2017,
address = {Houston, Texas},
title = {Domain {Adaptation} for {Signal} {Extraction} from {Large} {Social} {Media} {Datasets}},
author = {Zhang, Wenli and Ram, Sudha},
year = {2017},
}

@article{viergever_10_2016,
title = {The 10 largest public and philanthropic funders of health research in the world: what they fund and how they distribute their funds},
volume = {14},
issn = {1478-4505},
shorttitle = {The 10 largest public and philanthropic funders of health research in the world},
url = {https://doi.org/10.1186/s12961-015-0074-z},
doi = {10.1186/s12961-015-0074-z},
abstract = {Little is known about who the main public and philanthropic funders of health research are globally, what they fund and how they decide what gets funded. This study aims to identify the 10 largest public and philanthropic health research funding organizations in the world, to report on what they fund, and on how they distribute their funds.},
journal = {Health Research Policy and Systems},
author = {Viergever, Roderik F. and Hendriks, Thom C. C.},
month = feb,
year = {2016},
keywords = {Globalization, Health funding, Health policy, Health research, Priority setting, Research and development (R\&D), Research funding, Research governance, Research grants, Research policy},
pages = {12},
}

@inproceedings{zhang_extracting_2016,
address = {Nashville, USA},
title = {Extracting {Signals} from {Social} {Media} {Text} with {Natural} {Language} {Processing}, {Machine} {Learning} and {Domain} {Adaptation} [{INFORMS}]},
booktitle = {Business {Analytics} and {Text} {Mining}},
author = {Zhang, Wenli and Ram, Sudha},
month = nov,
year = {2016},
}

@inproceedings{zhang_domain_2017-1,
address = {Houston},
title = {Domain {Adaptation} for {Signal} {Extraction} from {Large} {Social} {Media} {Datasets} [{INFORMS}]},
abstract = {There has been increasing interest in using social media data for quantitative research in many different  domains.  Although  using  these  datasets  in  different  areas  has  significant  promise, mounting evidence  suggests that  many of the results being produced could be misrepresented 
because of various types of noises. We introduce novel and efficient techniques combining Natural Language Processing (NLP) and Machine Learning (ML) techniques to extract signal from social 
media  text.  The  proposed  framework  makes  a  significant  methodological  contribution  by developing a feature augmentation and sample reweighting based domain adaptation method. It 
reduces  the  training  effort  for  signal  extraction  by  re-using  previously  annotated  data.  The proposed framework was tested using several large real-world datasets from social media and outperforms other baseline methods by a large margin. The framework described in this paper can 
be used for a variety of purposes to yield improved analyses of social media and contributing to predictive analytics.},
author = {Zhang, Wenli and Ram, Sudha},
month = oct,
year = {2017},
}

@article{zhang_are_nodate,
title = {Are {Electronic} {Cigarettes} a {Safer} {Substitute} for {Cigarettes} for {Asthma} {Patients}?},
author = {Zhang, Wenli and Ram, Sudha},
}

@article{austin_b._frakt_promise_2016,
title = {The {Promise} and {Perils} of {Big} {Data} in {Healthcare}},
volume = {22},
url = {http://www.ajmc.com/journals/issue/2016/2016-vol22-n2/the-promise-and-perils-of-big-data-in-healthcare},
abstract = {Big Data analyses are observational, raising threats to causal inference. Validity checks help, but we must not let enthusiasm about Big Data obscure the science.},
number = {February 2016 2},
urldate = {2017-07-31},
journal = {American Journal of Managed Care},
author = {Austin B. Frakt, PhD},
month = feb,
year = {2016},
}

@incollection{rharbi_approaches_2012,
title = {Approaches to {Access} {Biological} {Data} {Sources}},
url = {http://www.intechopen.com/books/lipoproteins-role-in-health-and-diseases/approaches-to-access-biological-data-sources},
language = {en},
urldate = {2017-07-26},
booktitle = {Biochemistry, {Genetics} and {Molecular} {Biology}},
author = {Rharbi, Assia and Amine, Khadija and Bakkoury, Zohra and Mikou, Afaf and Betari, Anass Kettani andAbdelkader},
year = {2012},
pages = {82},
}

@book{derlaga_self-disclosure:_1987,
edition = {1},
series = {Perspectives in {Social} {Psychology}},
title = {Self-{Disclosure}: {Theory}, {Research}, and {Therapy}},
isbn = {978-0-306-42635-3},
shorttitle = {Self-{Disclosure}},
abstract = {Decisions about self-disclosure-whether to reveal one's thoughts, feel ings, or past experiences to another person, or the level of intimacy of such disclosure-are part of the everyday life of most persons. The nature of the decisions that a person makes will have an impact on his or her life. They will determine the kinds of relationships the person has with others; how others perceive him or her; and the degree of self knowledge and awareness that the person possesses. The study of self-disclosure has interested specialists from many disciplines, including personality and social psychologists, clinical and counseling psychologists, and communications researchers. Our book brings together the work of experts from these various disciplines with the hope that knowledge about work being done on self-disclosure in related disciplines will be increased. A strong emphasis in each of the chapters is theory development and the integration of ideas about self-disclosure. The book's chapters explore three major areas, including the interrelationship of self-disclosure and personality as well as the role of self-disclosure in the development, maintenance, and deterioration of personal relationships, and the con tribution of self-disclosure to psychotherapy, marital therapy, and counseling.},
language = {en},
publisher = {Springer},
author = {Derlaga, Valerian J. and Berg, John H.},
month = jul,
year = {1987},
note = {Google-Books-ID: osTqcaiflJQC},
keywords = {Psychology / Applied Psychology, Psychology / Clinical Psychology, Psychology / Personality},
}

@techreport{cdc_asthma_2013,
title = {Asthma {Facts}—{CDC}’s {National} {Asthma} {Control} {Program} {Grantees}},
url = {http://austinpureair.com/uploadimage/139828838266969.pdf},
institution = {Atlanta, GA: US Department of Health and Human Services, Centers for Disease Control and Prevention},
author = {CDC},
month = jul,
year = {2013},
pages = {1--18},
}

@article{andrade_self-disclosure_2002,
title = {Self-{Disclosure} on the {Web}: {The} {Impact} of {Privacy} {Policy}, {Reward}, and {Company} {Reputation}},
volume = {29},
shorttitle = {Self-{Disclosure} on the {Web}},
url = {http://acrwebsite.org/volumes/8674/volumes/v29/NA-29},
number = {1},
urldate = {2017-07-15},
journal = {Advances in Consumer Research},
author = {Andrade, Eduardo B. and Kaltcheva, Velitchka and Weitz, Barton},
year = {2002},
pages = {350--353},
}

@article{hunninghake_asthma_2006,
title = {Asthma in {Hispanics}},
volume = {173},
issn = {1073-449X},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2662985/},
doi = {10.1164/rccm.200508-1232SO},
abstract = {Hispanic individuals trace their ancestry to countries that were previously under Spanish rule, including Mexico, large parts of Central and South America, and some Caribbean islands. Most—but not all—Hispanics have variable proportions of European, Amerindian, and African ancestry. Hispanics are diverse with regard to many factors, including racial ancestry, country of origin, area of residence, socioeconomic status, education, and access to health care. Recent findings suggest that there is marked variation in the prevalence, morbidity, and mortality of asthma in Hispanics in the United States and in Hispanic America. The reasons for differences in asthma and asthma morbidity among and within Hispanic subgroups are poorly understood but are likely due to the interaction between yet-unidentified genetic variants and other factors, including environmental tobacco smoke exposure, obesity, allergen exposure, and availability of health care. Barriers to optimal management of asthma in Hispanics in the United States and in Hispanic America include inadequate access to health care, suboptimal use of antiinflammatory medications, and lack of reference values for spirometric measures of lung function in many subgroups (e.g., Puerto Ricans). Future studies of asthma in Hispanics should include large samples of subgroups that are well characterized with regard to self-reported ethnicity, country of origin, place of birth, area of residence, and indicators of socioeconomic status. Because Hispanics are disproportionately represented among the poor in the United States, implementation of adequate access to health care and social reforms (e.g., improving housing conditions) would likely have a major impact on reducing asthma morbidity in this population.},
number = {2},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Hunninghake, Gary M. and Weiss, Scott T. and Celedón, Juan C.},
month = jan,
year = {2006},
pmid = {16210666},
pmcid = {PMC2662985},
pages = {143--163},
}

@article{cortes_support-vector_1995,
title = {Support-vector networks},
volume = {20},
issn = {0885-6125, 1573-0565},
url = {https://link.springer.com/article/10.1007/BF00994018},
doi = {10.1007/BF00994018},
abstract = {Thesupport-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.},
language = {en},
number = {3},
urldate = {2017-07-24},
journal = {Machine Learning},
author = {Cortes, Corinna and Vapnik, Vladimir},
month = sep,
year = {1995},
pages = {273--297},
}

@article{landis_measurement_1977,
title = {The {Measurement} of {Observer} {Agreement} for {Categorical} {Data}},
volume = {33},
issn = {0006-341X},
url = {http://www.jstor.org/stable/2529310},
doi = {10.2307/2529310},
abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
number = {1},
journal = {Biometrics},
author = {Landis, J. Richard and Koch, Gary G.},
year = {1977},
pages = {159--174},
}

@article{sim_kappa_2005,
title = {The {Kappa} {Statistic} in {Reliability} {Studies}: {Use}, {Interpretation}, and {Sample} {Size} {Requirements}},
volume = {85},
issn = {0031-9023},
shorttitle = {The {Kappa} {Statistic} in {Reliability} {Studies}},
url = {https://academic.oup.com/ptj/article/85/3/257/2805022/The-Kappa-Statistic-in-Reliability-Studies-Use},
doi = {10.1093/ptj/85.3.257},
abstract = {Purpose. This article examines and illustrates the use and interpretation of the kappa statistic in musculoskeletal research. Summary of Key Points. The reliability of clinicians' ratings is an important consideration in areas such as diagnosis and the interpretation of examination findings. Often, these ratings lie on a nominal or an ordinal scale. For such data, the kappa coefficient is an appropriate measure of reliability. Kappa is defined, in both weighted and unweighted forms, and its use is illustrated with examples from musculoskeletal research. Factors that can influence the magnitude of kappa (prevalence, bias, and nonindependent ratings) are discussed, and ways of evaluating the magnitude of an obtained kappa are considered. The issue of statistical testing of kappa is considered, including the use of confidence intervals, and appropriate sample sizes for reliability studies using kappa are tabulated. Conclusions. The article concludes with recommendations for the use and interpretation of kappa.},
number = {3},
urldate = {2017-07-23},
journal = {Physical Therapy},
author = {Sim, Julius and Wright, Chris C.},
month = mar,
year = {2005},
pages = {257--268},
}

@article{landis_application_1977,
title = {An {Application} of {Hierarchical} {Kappa}-type {Statistics} in the {Assessment} of {Majority} {Agreement} among {Multiple} {Observers}},
volume = {33},
issn = {0006-341X},
url = {http://www.jstor.org/stable/2529786},
doi = {10.2307/2529786},
abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data involving agreement among more than two observers. Since these situations give rise to very large contingency tables in which most of the observed cell frequencies are zero, procedures based on indicator variables of the raw data for individual subjects are used to generate first-order margins and main diagonal sums from the conceptual multidimensional contingency table. From these quantities, estimates are generated to reflect the strength of an internal majority decision on each subject. Moreover, a subset of observers who demonstrate a high level of interobserver agreement can be identified by using pairwise agreement statistics between each observer and the internal majority standard opinion on each subject. These procedures are all illustrated within the context of a clinical diagnosis example involving seven pathologists.},
number = {2},
journal = {Biometrics},
author = {Landis, J. Richard and Koch, Gary G.},
year = {1977},
pages = {363--374},
}

@article{cohen_coefficient_1960,
title = {A {Coefficient} of {Agreement} for {Nominal} {Scales}},
volume = {20},
issn = {0013-1644},
url = {http://dx.doi.org/10.1177/001316446002000104},
doi = {10.1177/001316446002000104},
language = {en},
number = {1},
journal = {Educational and Psychological Measurement},
author = {Cohen, Jacob},
month = apr,
year = {1960},
pages = {37--46},
}

@inproceedings{dogan_improved_2012,
address = {Stroudsburg, PA, USA},
series = {{BioNLP} '12},
title = {An {Improved} {Corpus} of {Disease} {Mentions} in {PubMed} {Citations}},
url = {http://dl.acm.org/citation.cfm?id=2391123.2391135},
abstract = {The latest discoveries on diseases and their diagnosis/treatment are mostly disseminated in the form of scientific publications. However, with the rapid growth of the biomedical literature and a high level of variation and ambiguity in disease names, the task of retrieving disease-related articles becomes increasingly challenging using the traditional keyword-based approach. An important first step for any disease-related information extraction task in the biomedical literature is the disease mention recognition task. However, despite the strong interest, there has not been enough work done on disease name identification, perhaps because of the difficulty in obtaining adequate corpora. Towards this aim, we created a large-scale disease corpus consisting of 6900 disease mentions in 793 PubMed citations, derived from an earlier corpus. Our corpus contains rich annotations, was developed by a team of 12 annotators (two people per annotation) and covers all sentences in a PubMed abstract. Disease mentions are categorized into Specific Disease, Disease Class, Composite Mention and Modifier categories. When used as the gold standard data for a state-of-the-art machine-learning approach, significantly higher performance can be found on our corpus than the previous one. Such characteristics make this disease name corpus a valuable resource for mining disease-related information from biomedical text. The NCBI corpus is available for download at http://www.ncbi.nlm.nih.gov/CBBresearch/Fellows/Dogan/disease.html.},
booktitle = {Proceedings of the 2012 {Workshop} on {Biomedical} {Natural} {Language} {Processing}},
publisher = {Association for Computational Linguistics},
author = {Doğan, Rezarta Islamaj and Lu, Zhiyong},
year = {2012},
pages = {91--99},
}

@article{korkontzelos_analysis_2016,
title = {Analysis of the effect of sentiment analysis on extracting adverse drug reactions from tweets and forum posts},
volume = {62},
issn = {1532-0464},
url = {http://www.sciencedirect.com/science/article/pii/S1532046416300508},
doi = {10.1016/j.jbi.2016.06.007},
abstract = {The abundance of text available in social media and health related forums along with the rich expression of public opinion have recently attracted the interest of the public health community to use these sources for pharmacovigilance. Based on the intuition that patients post about Adverse Drug Reactions (ADRs) expressing negative sentiments, we investigate the effect of sentiment analysis features in locating ADR mentions. We enrich the feature space of a state-of-the-art ADR identification method with sentiment analysis features. Using a corpus of posts from the DailyStrength forum and tweets annotated for ADR and indication mentions, we evaluate the extent to which sentiment analysis features help in locating ADR mentions and distinguishing them from indication mentions. Evaluation results show that sentiment analysis features marginally improve ADR identification in tweets and health related forum posts. Adding sentiment analysis features achieved a statistically significant F-measure increase from 72.14\% to 73.22\% in the Twitter part of an existing corpus using its original train/test split. Using stratified 10×10-fold cross-validation, statistically significant F-measure increases were shown in the DailyStrength part of the corpus, from 79.57\% to 80.14\%, and in the Twitter part of the corpus, from 66.91\% to 69.16\%. Moreover, sentiment analysis features are shown to reduce the number of ADRs being recognized as indications. This study shows that adding sentiment analysis features can marginally improve the performance of even a state-of-the-art ADR identification method. This improvement can be of use to pharmacovigilance practice, due to the rapidly increasing popularity of social media and health forums.},
journal = {Journal of Biomedical Informatics},
author = {Korkontzelos, Ioannis and Nikfarjam, Azadeh and Shardlow, Matthew and Sarker, Abeed and Ananiadou, Sophia and Gonzalez, Graciela H.},
month = aug,
year = {2016},
keywords = {Adverse drug reactions, Social Media, Text mining, sentiment analysis},
pages = {148--158},
}

@inproceedings{mislove_understanding_2011,
title = {Understanding the {Demographics} of {Twitter} {Users}},
url = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/view/2816},
abstract = {\{Every second, the thoughts and feelings of millions of people across the world are recorded in the form of 140-character tweets using Twitter. However, despite the enormous potential presented by this remarkable data source, we still do not have an understanding of the Twitter population itself: Who are the Twitter users? How representative of the overall population are they? In this paper, we take the first steps towards answering these questions by analyzing data on a set of Twitter users representing over 1\% of the U.S. population. We develop techniques that allow us to compare the Twitter population to the U.S. population along three axes (geography, gender, and race/ethnicity), and find that the Twitter population is a highly non-uniform sample of the population.\}},
urldate = {2017-04-20},
booktitle = {International {Conference} on {Weblogs} and {Social} {Media}},
publisher = {AAAI Press},
author = {Mislove, Alan and Lehmann, Sune and Ahn, Yong-Yeol and Onnela, Jukka-Pekka and Rosenquist, Niels},
year = {2011},
keywords = {cosn2014, done, icwsm, metric-brief-0, metric-consent-0, metric-irb-0, metric-length-1, metric-n-1, metric-processing-0, metric-protocol-1, metric-sampling-1, metric-shared-0, metric-sourcesns-1, yes},
}

@article{salas-gonzalez_feature_2010,
title = {Feature selection using factor analysis for {Alzheimer}'s diagnosis using {18F}-{FDG} {PET} images},
volume = {37},
issn = {0094-2405},
doi = {10.1118/1.3488894},
abstract = {PURPOSE: This article presents a computer-aided diagnosis technique for improving the accuracy of the early diagnosis of Alzheimer's disease (AD). Two hundred and ten 18F-FDG PET images from the ADNI initiative [52 normal controls (NC), 114 mild cognitive impairment (MCI), and 53 AD subjects] are studied.
METHODS: The proposed methodology is based on the selection of voxels of interest using the t-test and a posterior reduction of the feature dimension using factor analysis. Factor loadings are used as features for three different classifiers: Two multivariate Gaussian mixture model, with linear and quadratic discriminant function, and a support vector machine with linear kernel.
RESULTS: An accuracy rate up to 95\% when NC and AD are considered and an accuracy rate up to 88\% and 86\% for NC-MCI and NC-MCI,AD, respectively, are obtained using SVM with linear kernel.
CONCLUSIONS: Results are compared to the voxel-as-features and a PCA- based approach and the proposed methodology achieves better classification performance.},
language = {eng},
number = {11},
journal = {Medical Physics},
author = {Salas-Gonzalez, D. and Górriz, J. M. and Ramírez, J. and Illán, I. A. and López, M. and Segovia, F. and Chaves, R. and Padilla, P. and Puntonet, C. G.},
month = nov,
year = {2010},
pmid = {21158320},
pmcid = {PMC2994934},
keywords = {Aged, Aged, 80 and over, Alzheimer Disease, Cognition Disorders, Diagnosis, Computer-Assisted, Fluorodeoxyglucose F18, Humans, Image Processing, Computer-Assisted, Middle Aged, Models, Statistical, Multivariate Analysis, Normal Distribution, Positron-Emission Tomography, Radiopharmaceuticals, Reproducibility of Results},
pages = {6084--6095},
}

@inproceedings{rodrigues_confidence_2014,
title = {Confidence factor and feature selection for semi-supervised multi-label classification methods},
doi = {10.1109/IJCNN.2014.6889564},
abstract = {In this paper, we investigate two important problems in multi-label classification algorithms, which are: the number of labeled instances and the high dimensionality of the labeled instances. In the literature, we can find several papers about multi-label classification problems, where an instance can be associated with more than one label simultaneously. One of the main issues with multi-label classification methods is that many of these require a high number of instances to be able to generalize in an efficient way. In order to solve this problem, we used semi-supervised learning, which combines labeled and unlabeled instances during the training process. In this sense, the semi-supervised learning may become an essential tool to define, efficiently, the process of automatic assignment of labels. Therefore, this paper presents four semi-supervised methods for the multi-label classification, focusing on the use of a confidence parameter in the process of automatic assignment of labels. In order to validate the feasibility of these methods, an empirical analysis will be conducted using high-dimensional datasets, aiming to evaluate the performance of such methods in different situations. In this case, we will apply a feature selection algorithm in order to reduce, in an efficient way, the number of features to be used by the classification methods.},
booktitle = {2014 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
author = {Rodrigues, F. M. and Câmara, C. J. and Canuto, A. M. P. and Santos, A. M.},
month = jul,
year = {2014},
keywords = {Accuracy, Classification algorithms, Labeling, Measurement, Standards, Training, automatic label assignment, confidence factor, confidence parameter, empirical analysis, feature selection, high-dimensional datasets, high-dimensional labeled instances, learning (artificial intelligence), pattern classification, performance evaluation, semisupervised learning, semisupervised multilabel classification methods, training process, unlabeled instances},
pages = {864--871},
}

@inproceedings{tamminen_excell_1982,
address = {Piscataway, NJ, USA},
series = {{DAC} '82},
title = {The {Excell} {Method} for {Efficient} {Geometric} {Access} to {Data}},
isbn = {978-0-89791-020-0},
url = {http://dl.acm.org/citation.cfm?id=800263.809228},
abstract = {The extendible cell (EXCELL) method provides a data structure for efficient geometric access. It stores geometric data into computer storage blocks corresponding to disjoint variable sized rectangular cells accessible by an address calculation type directory. We describe the method for point files and files of more complicated figures analyzing performance. We report algorithms for the nearest neighbour and point-in-polygon-network problems and describe applications to geographical data bases, hidden line elimination and geometric modeling.},
booktitle = {Proceedings of the 19th {Design} {Automation} {Conference}},
publisher = {IEEE Press},
author = {Tamminen, Markku and Sulonen, Reijo},
year = {1982},
pages = {345--351},
}

@article{rundell_self-reported_2001,
title = {Self-reported symptoms and exercise-induced asthma in the elite athlete},
volume = {33},
issn = {0195-9131},
abstract = {PURPOSE: The purpose of this study was to compare self-reported symptoms for exercise-induced asthma (EIA) to postexercise challenge pulmonary function test results in elite athletes.
METHODS: Elite athletes (N = 158; 83 men and 75 women; age: 22 +/- 4.4 yr) performed pre- and post-exercise spirometry and were grouped according to postexercise pulmonary function decrements (PFT-positive, PFT-borderline, and PFT-normal for EIA). Before the sport/environment specific exercise challenge, subjects completed an EIA symptoms-specific questionnaire.
RESULTS: Resting FEV1 values were above predicted values (114--121\%) and not different between groups. Twenty-six percent of the study population demonstrated {\textgreater}10\% postexercise drop in FEV1 and 29\% reported two or more symptoms. However, the proportion of PFT-positive and PFT-normal athletes reporting two or more symptoms was not different (39\% vs. 41\%). Postrace cough was the most reported symptom, reported significantly more frequently for PFT-positive athletes (P {\textless} 0.05). Sensitivity/specificity analysis demonstrated a lack of effectiveness of self-reported symptoms to identify PFT-positive or exclude PFT-normal athletes. Postexercise lower limit reference ranges (MN-2SDs) were determined from normal athletes for FEV1, FEF25--75\% and PEF to be -7\%, -12.5\%, and -18\%, respectively.
CONCLUSION: Although questionnaires provide reasonable estimates of EIA prevalence among elite cold-weather athletes, the use of self-reported symptoms for EIA diagnosis in this population will likely yield high frequencies of both false positive and false negative results. Diagnosis should include spirometry using an exercise/environment specific challenge in combination with the athlete's history of asthma symptoms.},
language = {eng},
number = {2},
journal = {Medicine and Science in Sports and Exercise},
author = {Rundell, K. W. and Im, J. and Mayers, L. B. and Wilber, R. L. and Szmedra, L. and Schmitz, H. R.},
month = feb,
year = {2001},
pmid = {11224807},
keywords = {Adolescent, Adult, Asthma, Exercise-Induced, Bronchial Spasm, Cross-Sectional Studies, Exercise, Female, Forced Expiratory Volume, Humans, Male, Physical Endurance, Severity of Illness Index, Sports, Temperature},
pages = {208--213},
}

@article{craven_constructing_1999,
title = {Constructing biological knowledge bases by extracting information from text sources.},
issn = {1553-0833},
url = {http://europepmc.org/abstract/med/10786289},
abstract = {Abstract: Recently, there has been much effort in making databases for molecular biology more accessible and interoperable. However, information in text...},
language = {eng},
urldate = {2017-07-11},
journal = {Proceedings. International Conference on Intelligent Systems for Molecular Biology},
author = {Craven, Mark and Kumlien, Johan},
year = {1999},
pmid = {10786289},
pages = {77--86},
}

@article{bradski_opencv_2000,
title = {The {OpenCV} {Library}.},
volume = {25},
issn = {1044-789X},
language = {английский},
number = {11},
journal = {Dr. Dobb's Journal: Software Tools for the Professional Programmer},
author = {Bradski, G.},
year = {2000},
keywords = {Opendata Manager (computer Software)},
pages = {120--123},
}

@article{strano_user_2008,
title = {User {Descriptions} and {Interpretations} of {Self}-{Presentation} through {Facebook} {Profile} {Images}},
volume = {2},
copyright = {Copyright (c) 2015 Cyberpsychology: Journal of Psychosocial Research on Cyberspace},
issn = {1802-7962},
url = {https://cyberpsychology.eu/article/view/4212},
language = {en},
number = {2},
urldate = {2017-07-19},
journal = {Cyberpsychology: Journal of Psychosocial Research on Cyberspace},
author = {Strano, Michele M.},
month = nov,
year = {2008},
keywords = {Facebook, digital photography, identity, profile images, self-presentation},
}

@article{moghaddam_probabilistic_1997,
title = {Probabilistic visual learning for object representation},
volume = {19},
issn = {0162-8828},
doi = {10.1109/34.598227},
abstract = {We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands},
number = {7},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
author = {Moghaddam, B. and Pentland, A.},
month = jul,
year = {1997},
keywords = {Face detection, Gaussian distribution, Humans, Maximum likelihood detection, Probability distribution, Target recognition, Training data, density estimation, eigenspace decomposition, high-dimensional spaces, human faces, human hands, image coding, image recognition, maximum likelihood estimation, maximum-likelihood estimation framework, mixture-of-Gaussians model, multivariate Gaussian model, nonrigid objects, object coding, object detection, object recognition, object representation, probabilistic visual learning, probability, probability densities, target detection, unsupervised learning, unsupervised technique, visual search},
pages = {696--710},
}

@inproceedings{liu_multi-objective_2015,
title = {Multi-objective convolutional learning for face labeling},
doi = {10.1109/CVPR.2015.7298967},
abstract = {This paper formulates face labeling as a conditional random field with unary and pairwise classifiers. We develop a novel multi-objective learning method that optimizes a single unified deep convolutional network with two distinct non-structured loss functions: one encoding the unary label likelihoods and the other encoding the pairwise label dependencies. Moreover, we regularize the network by using a nonparametric prior as new input channels in addition to the RGB image, and show that significant performance improvements can be achieved with a much smaller network size. Experiments on both the LFW and Helen datasets demonstrate state-of-the-art results of the proposed algorithm, and accurate labeling results on challenging images can be obtained by the proposed algorithm for real-world applications.},
booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
author = {Liu, Sifei and Yang, J. and Huang, Chang and Yang, M. H.},
month = jun,
year = {2015},
keywords = {Face, Hair, Helen dataset, Image edge detection, LFW dataset, Labeling, RGB image, Semantics, Testing, Training, conditional random field, distinct nonstructured loss function, face labeling, face recognition, image classification, image colour analysis, learning (artificial intelligence), multiobjective convolutional learning, multiobjective learning method, neural nets, nonparametric prior, nonparametric statistics, pairwise classifier, pairwise label dependency encoding, random processes, single unified deep convolutional network optimization, unary classifier, unary label likelihood encoding},
pages = {3451--3459},
}

@article{liu_using_2017,
title = {Using {Real}-{Time} {Social} {Media} {Technologies} to {Monitor} {Levels} of {Perceived} {Stress} and {Emotional} {State} in {College} {Students}: {A} {Web}-{Based} {Questionnaire} {Study}},
volume = {4},
issn = {2368-7959},
shorttitle = {Using {Real}-{Time} {Social} {Media} {Technologies} to {Monitor} {Levels} of {Perceived} {Stress} and {Emotional} {State} in {College} {Students}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5263861/},
doi = {10.2196/mental.5626},
abstract = {Background
College can be stressful for many freshmen as they cope with a variety of stressors. Excess stress can negatively affect both psychological and physical health. Thus, there is a need to find innovative and cost-effective strategies to help identify students experiencing high levels of stress to receive appropriate treatment. Social media use has been rapidly growing, and recent studies have reported that data from these technologies can be used for public health surveillance. Currently, no studies have examined whether Twitter data can be used to monitor stress level and emotional state among college students.

Objective
The primary objective of our study was to investigate whether students’ perceived levels of stress were associated with the sentiment and emotions of their tweets. The secondary objective was to explore whether students’ emotional state was associated with the sentiment and emotions of their tweets.

Methods
We recruited 181 first-year freshman students aged 18-20 years at University of California, Los Angeles. All participants were asked to complete a questionnaire that assessed their demographic characteristics, levels of stress, and emotional state for the last 7 days. All questionnaires were completed within a 48-hour period. All tweets posted by the participants from that week (November 2 to 8, 2015) were mined and manually categorized based on their sentiment (positive, negative, neutral) and emotion (anger, fear, love, happiness) expressed. Ordinal regressions were used to assess whether weekly levels of stress and emotional states were associated with the percentage of positive, neutral, negative, anger, fear, love, or happiness tweets.

Results
A total of 121 participants completed the survey and were included in our analysis. A total of 1879 tweets were analyzed. A higher level of weekly stress was significantly associated with a greater percentage of negative sentiment tweets (beta=1.7, SE 0.7; P=.02) and tweets containing emotions of fear (beta=2.4, SE 0.9; P=.01) and love (beta=3.6, SE 1.4; P=.01). A greater level of anger was negatively associated with the percentage of positive sentiment (beta=–1.6, SE 0.8; P=.05) and tweets related to the emotions of happiness (beta=–2.2, SE 0.9; P=.02). A greater level of fear was positively associated with the percentage of negative sentiment (beta=1.67, SE 0.7; P=.01), particularly a greater proportion of tweets related to the emotion of fear (beta=2.4, SE 0.8; P=.01). Participants who reported a greater level of love showed a smaller percentage of negative sentiment tweets (beta=–1.3, SE 0.7; P=0.05). Emotions of happiness were positively associated with the percentage of tweets related to the emotion of happiness (beta=–1.8, SE 0.8; P=.02) and negatively associated with percentage of negative sentiment tweets (beta=–1.7, SE 0.7; P=.02) and tweets related to the emotion of fear (beta=–2.8, SE 0.8; P=.01).

Conclusions
Sentiment and emotions expressed in the tweets have the potential to provide real-time monitoring of stress level and emotional well-being in college students.},
number = {1},
journal = {JMIR Mental Health},
author = {Liu, Sam and Zhu, Miaoqi and Yu, Dong Jin and Rasin, Alexander and Young, Sean D},
month = jan,
year = {2017},
pmid = {28073737},
pmcid = {PMC5263861},
}

@article{wong_using_2010,
title = {Using {Name} {Lists} to {Infer} {Asian} {Racial}/{Ethnic} {Subgroups} in the {Healthcare} {Setting}},
volume = {48},
issn = {0025-7079},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3249427/},
doi = {10.1097/MLR.0b013e3181d559e9},
abstract = {Background
Many clinical data sources used to assess health disparities lack Asian subgroup information, but do include patient names.

Objective
This project validates Asian surname and given name lists for identifying Asian subgroups (Asian Indian, Chinese, Filipino, Japanese, Korean, Vietnamese) in clinical records.

Subjects
We used 205,000 electronic medical records from the Palo Alto Medical Foundation, a multipayer, outpatient healthcare organization in Northern California, containing patient self-identified race/ethnicity information.

Research Design
Name lists were used to infer racial/ethnic subgroup for patients with self-identified race/ethnicity data. Using self-identification as the “gold standard,” sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) of classification by name were calculated. Clinical outcomes (obesity and hypertension) were compared for name-identified versus self-identified racial/ethnic groups.

Results
With classification using surname and given name, the overall sensitivities ranged from 0.45 to 0.76 for the 6 racial/ethnic groups when no race data are available, and 0.40 to 0.79 when the broad racial classification of “Asian” is known. Specificities ranged from 0.99 to 1.00. PPV and NPV depended on the prevalence of Asians in the population. The lists performed better for men than women and better for persons aged 65 and older. Clinical outcomes were very similar for name-identified and self-identified racial/ethnic groups.

Conclusions
In a clinical setting with a high prevalence of Asian Americans, name-identified and self-identified racial/ethnic groups had similar clinical characteristics. Asian name lists may be a valid substitute for identifying Asian subgroups when self-identification is unavailable.},
number = {6},
journal = {Medical care},
author = {Wong, Eric C. and Palaniappan, Latha P. and Lauderdale, Diane S.},
month = jun,
year = {2010},
pmid = {20421828},
pmcid = {PMC3249427},
pages = {540--546},
}

@techreport{noauthor_pcci_nodate,
title = {{PCCI} asthma project report},
}

@article{menne_overview_2012,
title = {An {Overview} of the {Global} {Historical} {Climatology} {Network}-{Daily} {Database}},
volume = {29},
issn = {0739-0572},
url = {http://journals.ametsoc.org/doi/abs/10.1175/JTECH-D-11-00103.1},
doi = {10.1175/JTECH-D-11-00103.1},
abstract = {A database is described that has been designed to fulfill the need for daily climate data over global land areas. The dataset, known as Global Historical Climatology Network (GHCN)-Daily, was developed for a wide variety of potential applications, including climate analysis and monitoring studies that require data at a daily time resolution (e.g., assessments of the frequency of heavy rainfall, heat wave duration, etc.). The dataset contains records from over 80 000 stations in 180 countries and territories, and its processing system produces the official archive for U.S. daily data. Variables commonly include maximum and minimum temperature, total daily precipitation, snowfall, and snow depth; however, about two-thirds of the stations report precipitation only. Quality assurance checks are routinely applied to the full dataset, but the data are not homogenized to account for artifacts associated with the various eras in reporting practice at any particular station (i.e., for changes in systematic bias).Daily updates are provided for many of the station records in GHCN-Daily. The dataset is also regularly reconstructed, usually once per week, from its 20+ data source components, ensuring that the dataset is broadly synchronized with its growing list of constituent sources. The daily updates and weekly reprocessed versions of GHCN-Daily are assigned a unique version number, and the most recent dataset version is provided on the GHCN-Daily website for free public access. Each version of the dataset is also archived at the NOAA/National Climatic Data Center in perpetuity for future retrieval.},
number = {7},
journal = {Journal of Atmospheric and Oceanic Technology},
author = {Menne, Matthew J. and Durre, Imke and Vose, Russell S. and Gleason, Byron E. and Houston, Tamara G.},
month = mar,
year = {2012},
pages = {897--910},
}

@article{ram_predicting_2015,
title = {Predicting {Asthma}-{Related} {Emergency} {Department} {Visits} {Using} {Big} {Data}},
volume = {19},
issn = {2168-2194},
doi = {10.1109/JBHI.2015.2404829},
abstract = {Asthma is one of the most prevalent and costly chronic conditions in the United States, which cannot be cured. However, accurate and timely surveillance data could allow for timely and targeted interventions at the community or individual level. Current national asthma disease surveillance systems can have data availability lags of up to two weeks. Rapid progress has been made in gathering nontraditional, digital information to perform disease surveillance. We introduce a novel method of using multiple data sources for predicting the number of asthma-related emergency department (ED) visits in a specific area. Twitter data, Google search interests, and environmental sensor data were collected for this purpose. Our preliminary findings show that our model can predict the number of asthma ED visits based on near-real-time environmental and social media data with approximately 70\% precision. The results can be helpful for public health surveillance, ED preparedness, and targeted patient interventions.},
number = {4},
journal = {IEEE Journal of Biomedical and Health Informatics},
author = {Ram, S. and Zhang, W. and Williams, M. and Pengetnze, Y.},
month = jul,
year = {2015},
keywords = {0, Asthma, Big Data, Emergency Department Visits, Environmental Sensors, Google, Google search interests, Market research, Media, Predictive Modeling, Predictive models, Social Media, Surveillance, asthma-related emergency department, chronic conditions, diseases, emergency department (ED) visits, emergency services, environmental sensor data, medical information systems, multiple data sources, national asthma disease surveillance systems, public health surveillance, social media data, social networking (online), surveillance data, targeted patient interventions, twitter},
pages = {1216--1223},
}

@article{gibbs_self-presentation_2006,
title = {Self-{Presentation} in {Online} {Personals}: {The} {Role} of {Anticipated} {Future} {Interaction}, {Self}-{Disclosure}, and {Perceived} {Success} in {Internet} {Dating}},
volume = {33},
issn = {0093-6502},
shorttitle = {Self-{Presentation} in {Online} {Personals}},
url = {http://dx.doi.org/10.1177/0093650205285368},
doi = {10.1177/0093650205285368},
abstract = {This study investigates self-disclosure in the novel context of online dating relationships. Using a national random sample of Match.com members (N = 349), the authors tested a model of relational goals, self-disclosure, and perceived success in online dating. The authors’ findings provide support for social penetration theory and the social information processing and hyperpersonal perspectives as well as highlight the positive effect of anticipated future face-to-face interaction on online self-disclosure. The authors find that perceived online dating success is predicted by four dimensions of self-disclosure (honesty, amount, intent, and valence), although honesty has a negative effect. Furthermore, online dating experience is a strong predictor of perceived success in online dating. Additionally, the authors identify predictors of strategic success versus self-presentation success. This research extends existing theory on computer-mediated communication, self-disclosure, and relational success to the increasingly important arena of mixed-mode relationships, in which participants move from mediated to face-to-face communication.},
language = {en},
number = {2},
journal = {Communication Research},
author = {Gibbs, Jennifer L. and Ellison, Nicole B. and Heino, Rebecca D.},
month = apr,
year = {2006},
pages = {152--177},
}

@article{schau_we_2003,
title = {We {Are} {What} {We} {Post}? {Self}-{Presentation} in {Personal} {Web} {Space}},
volume = {30},
issn = {0093-5301},
shorttitle = {We {Are} {What} {We} {Post}?},
url = {https://academic.oup.com/jcr/article/30/3/385/1790595/We-Are-What-We-Post-Self-Presentation-in-Personal},
doi = {10.1086/378616},
abstract = {This article examines personal Web sites as a conspicuous form of consumer self-presentation. Using theories of self-presentation, possessions, and computer-mediated environments (CMEs), we investigate the ways in which consumers construct identities by digitally associating themselves with signs, symbols, material objects, and places. Specifically, the issues of interest include why consumers create personal Web sites, what consumers want to communicate, what strategies they devise to achieve their goal of self-presentation, and how those Web space strategies compare to the self-presentation strategies of real life (RL). The data reveal insights into the strategies behind constructing a digital self, projecting a digital likeness, digitally associating as a new form of possession, and reorganizing linear narrative structures.},
number = {3},
urldate = {2017-07-15},
journal = {Journal of Consumer Research},
author = {Schau, Hope and Gilly, Mary C.},
month = dec,
year = {2003},
pages = {385--404},
}

@incollection{dindia_self-disclosure_2001,
title = {Self-disclosure research: {Knowledge} through meta-analysis},
isbn = {1-135-67300-4},
url = {https://books.google.com/books?hl=en&lr=&id=lLaRAgAAQBAJ&oi=fnd&pg=PA169&dq=Self-disclosure+research:+Knowledge+through+meta-analysis&ots=khbsHmO51z&sig=CcYHyZIDcSOz0QSpyx2tIkEhBGM#v=onepage&q=Self-disclosure%20research%3A%20Knowledge%20through%20meta-analysis&f=false},
abstract = {This exceptional collection--a compilation of meta-analyses related to issues in interpersonal communication--provides an expansive review of existing interpersonal communication research. Incorporating a wide variety of topics related to interpersonal communication, including couples and safe sex, parent-child communication, argumentativeness, and self-disclosure, the contributions in this volume also examine such basic issues as reciprocity, constructivism, social support in interpersonal communication, as well as gender, conflict, and marital and organizational issues.},
booktitle = {Interpersonal {Communication} {Research}: {Advances} {Through} {Meta}-analysis},
publisher = {Routledge},
author = {Dindia, Katbryn},
year = {2001},
pages = {169--185},
}

@book{goffman_presentation_1959,
edition = {1},
title = {The {Presentation} of {Self} in {Everyday} {Life}},
isbn = {0-385-09402-7},
url = {https://books.google.com/books?hl=en&lr=&id=TlIAzT5uT-IC&oi=fnd&pg=PA120&ots=ItD8bpIrh9&sig=d52wDCJ9Q3G4rhWc0EXhbzGypzI#v=onepage&q&f=false},
abstract = {A notable contribution to our understanding of ourselves. This book explores the realm of human behavior in social situations and the way that we appear to others.  Dr. Goffman uses the metaphor of theatrical performance as a framework. Each person in everyday social intercourse presents himself and his activity to others, attempts to guide and cotnrol the impressions they form of him, and employs certain techniques in order to sustain his performance, just as an actor presents a character to an audience.  The discussions of these social techniques offered here are based upon detailed research and observation of social customs in many regions.},
language = {English},
publisher = {Anchor},
author = {Goffman, Erving},
month = may,
year = {1959},
}

@article{boyd_social_2007,
title = {Social {Network} {Sites}: {Definition}, {History}, and {Scholarship}},
volume = {13},
issn = {1083-6101},
shorttitle = {Social {Network} {Sites}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1083-6101.2007.00393.x/abstract},
doi = {10.1111/j.1083-6101.2007.00393.x},
abstract = {Social network sites (SNSs) are increasingly attracting the attention of academic and industry researchers intrigued by their affordances and reach. This special theme section of the Journal of Computer-Mediated Communication brings together scholarship on these emergent phenomena. In this introductory article, we describe features of SNSs and propose a comprehensive definition. We then present one perspective on the history of such sites, discussing key changes and developments. After briefly summarizing existing scholarship concerning SNSs, we discuss the articles in this special section and conclude with considerations for future research.},
language = {en},
number = {1},
journal = {Journal of Computer-Mediated Communication},
author = {Boyd, Danah M. and Ellison, Nicole B.},
month = oct,
year = {2007},
pages = {210--230},
}

@inproceedings{pennacchiotti_democrats_2011,
address = {New York, NY, USA},
series = {{KDD} '11},
title = {Democrats, {Republicans} and {Starbucks} {Afficionados}: {User} {Classification} in {Twitter}},
isbn = {978-1-4503-0813-7},
shorttitle = {Democrats, {Republicans} and {Starbucks} {Afficionados}},
url = {http://doi.acm.org/10.1145/2020408.2020477},
doi = {10.1145/2020408.2020477},
abstract = {More and more technologies are taking advantage of the explosion of social media (Web search, content recommendation services, marketing, ad targeting, etc.). This paper focuses on the problem of automatically constructing user profiles, which can significantly benefit such technologies. We describe a general and robust machine learning framework for large-scale classification of social media users according to dimensions of interest. We report encouraging experimental results on 3 tasks with different characteristics: political affiliation detection, ethnicity identification and detecting affinity for a particular business.},
booktitle = {Proceedings of the 17th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
publisher = {ACM},
author = {Pennacchiotti, Marco and Popescu, Ana-Maria},
year = {2011},
keywords = {Social Media, machine learning, microblogging, user profiling},
pages = {430--438},
}

@article{kaplan_users_2010,
title = {Users of the world, unite! {The} challenges and opportunities of {Social} {Media}},
volume = {53},
issn = {0007-6813},
url = {http://www.sciencedirect.com/science/article/pii/S0007681309001232},
doi = {10.1016/j.bushor.2009.09.003},
abstract = {The concept of Social Media is top of the agenda for many business executives today. Decision makers, as well as consultants, try to identify ways in which firms can make profitable use of applications such as Wikipedia, YouTube, Facebook, Second Life, and Twitter. Yet despite this interest, there seems to be very limited understanding of what the term “Social Media” exactly means; this article intends to provide some clarification. We begin by describing the concept of Social Media, and discuss how it differs from related concepts such as Web 2.0 and User Generated Content. Based on this definition, we then provide a classification of Social Media which groups applications currently subsumed under the generalized term into more specific categories by characteristic: collaborative projects, blogs, content communities, social networking sites, virtual game worlds, and virtual social worlds. Finally, we present 10 pieces of advice for companies which decide to utilize Social Media.},
number = {1},
journal = {Business Horizons},
author = {Kaplan, Andreas M. and Haenlein, Michael},
month = jan,
year = {2010},
keywords = {Social Media, Social networking sites, User Generated Content, Virtual worlds, Web 2.0},
pages = {59--68},
}

@article{huang_multi-source_2015,
title = {A multi-source integration framework for user occupation inference in social media systems},
volume = {18},
issn = {1386-145X, 1573-1413},
url = {https://link.springer.com/article/10.1007/s11280-014-0300-6},
doi = {10.1007/s11280-014-0300-6},
abstract = {With the rapid development of social media applications, lots of users are connected with friends online, and their daily life and opinions are recorded. Social media provides us an unprecedented way to collect and analyze billions of users’ information. Proper user attribute identification or profile inference becomes increasingly attractive and feasible. However, the flourishing social records also pose great challenge in effective feature selection and integration for user profile inference, which is mainly caused by the text diversity and complex community structures. In this paper, we propose a comprehensive framework to infer the user occupation from his/her social activities recorded in the micro-blog system, which is a multi-source integration framework that combines both content and network information. We first identify some beneficial content features, and propose a machine learning classification model, named content model. We proceed to exploit the social network information, which tailors a community discovery based latent dimension solution to extract community-based feature, and utilizes the neighbor predictions for inference updating. Extensive empirical studies are conducted on a large real-life micro-blog dataset. The experimental results demonstrate the superiority of our integrated model for the occupation inference task, verify the effect of homophily in user interaction records, and reveal different effects of heterogeneous interactive networks.},
language = {en},
number = {5},
urldate = {2017-07-14},
journal = {World Wide Web},
author = {Huang, Yanxiang and Yu, Lele and Wang, Xiang and Cui, Bin},
month = sep,
year = {2015},
pages = {1247--1267},
}

@article{fang_relational_2015,
title = {Relational {User} {Attribute} {Inference} in {Social} {Media}},
volume = {17},
issn = {1520-9210},
doi = {10.1109/TMM.2015.2430819},
abstract = {Nowadays, more and more people are engaged in social media to generate multimedia information, i.e, creating text and photo profiles and posting multimedia messages. Such multimodal social networking activities reveal multiple user attributes such as age, gender, and personal interest. Inferring user attributes is important for user profiling, retrieval, and personalization. Existing work is devoted to inferring user attributes independently and ignores the dependency relations between attributes. In this work, we investigate the problem of relational user attribute inference by exploring the relations between user attributes and extracting both lexical and visual features from online user-generated content. We systematically study six types of user attributes: gender, age, relationship, occupation, interest, and emotional orientation. In view of methodology, we propose a relational latent SVM (LSVM) model to combine a rich set of user features, attribute inference, and attribute relations in a unified framework. In the model, one attribute is selected as the target attribute and others are selected as the auxiliary attributes to assist the target attribute inference. The model infers user attributes and attribute relations simultaneously. Extensive experiments conducted on a collected dataset from Google+ with full attribute annotations demonstrate the effectiveness of the proposed approach in user attribute inference and attribute-based user retrieval.},
number = {7},
journal = {IEEE Transactions on Multimedia},
author = {Fang, Q. and Sang, J. and Xu, C. and Hossain, M. S.},
month = jul,
year = {2015},
keywords = {Attribute relation, Correlation, Feature extraction, Google+, LSVM, Media, Multimedia communication, Social Media, Social network services, Visualization, attribute-based user retrieval, auxiliary attributes, emotional orientation, information retrieval, latent SVM (LSVM), lexical feature extraction, multimedia information, multimedia messages, multimedia systems, multimodal social networking activities, online user-generated content, personalization, relational latent SVM, relational user attribute inference, social networking (online), support vector machines, target attribute, target attribute inference, text analysis, user age, user attribute inference, user features, user gender, user interest, user occupation, user profiling, user relationship, visual feature extraction},
pages = {1031--1044},
}

@inproceedings{chen_comparative_2015,
title = {A {Comparative} {Study} of {Demographic} {Attribute} {Inference} in {Twitter}},
copyright = {Authors who publish a paper in this conference agree to the following terms:    1. Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.    2. The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.    3. The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys’ fees incurred therein.    4. Author(s) retain all proprietary rights other than copyright (such as patent rights).    5. Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.    6. Author(s) may reproduce, or have reproduced, their article/paper for the author’s personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author’s employer, and then only on the author’s or the employer’s own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author’s or the employer’s creation (including tables of contents with links to other papers) without AAAI’s written permission.    7. Author(s) may make limited distribution of all or portions of their article/paper prior to publication.    8. In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.    9. In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
url = {https://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/view/10541},
abstract = {Social media platforms have become a major gateway to receive and analyze public opinions. Understandingusers can provide invaluable context information of their social media posts and significantly improve traditional opinion analysis models. Demographic attributes,such as ethnicity, gender, age, among others,have been extensively applied to characterize social mediausers. While studies have shown that user groups formed by demographic attributes can have coherent opinions towards political issues, these attributes are often not explicitly coded by users through their profiles.Previous work has demonstrated the effectiveness of different user signals such as users’ posts and names in determining demographic attributes. Yet, these efforts mostly evaluate linguistic signals from users’ postsand train models from artificially balanced datasets. In this paper, we propose a comprehensive list of user signals:self-descriptions and posts aggregated from users’ friends and followers, users’ profile images, and users’ names.We provide a comparative study of these signalsside-by-side in the tasks on inferring three major demographic attributes, namely ethnicity, gender, and age.We utilize a realistic unbalanced datasets that share similar demographic makeups in Twitter for training modelsand evaluation experiments. Our experiments indicate that self-descriptions provide the strongest signal for ethnicity and age inference and clearly improve the overall performance when combined with tweets. Profile images for gender inference have the highest precision score with overall score close to the best result in our setting. This suggests that signals in self descriptions and profile images have potentials to facilitate demographic attribute inferences in Twitter, and are promising for future investigation.},
language = {en},
urldate = {2017-07-14},
booktitle = {Ninth {International} {AAAI} {Conference} on {Web} and {Social} {Media}},
author = {Chen, Xin and Wang, Yu and Agichtein, Eugene and Wang, Fusheng},
month = apr,
year = {2015},
}

@inproceedings{xiang_demographic_2017,
series = {Lecture {Notes} in {Computer} {Science}},
title = {Demographic {Attribute} {Inference} from {Social} {Multimedia} {Behaviors}: {A} {Cross}-{OSN} {Approach}},
isbn = {978-3-319-51810-7 978-3-319-51811-4},
shorttitle = {Demographic {Attribute} {Inference} from {Social} {Multimedia} {Behaviors}},
url = {https://link.springer.com/chapter/10.1007/978-3-319-51811-4_42},
doi = {10.1007/978-3-319-51811-4_42},
abstract = {This study focuses on exploiting the dynamic social multimedia behaviors to infer the stable demographic attributes. Existing demographic attribute inference studies are devoted to developing advanced features/models or exploiting external information and knowledge. The conflicts between dynamicity of behaviors and the steadiness of demographic attributes are largely ignored. To address this issue, we introduce a cross-OSN approach to discover the shared stable patterns from users’ social multimedia behaviors on multiple Online Social Networks (OSNs). The basic assumption for the proposed approach is that, the same user’s cross-OSN behaviors are the reflection of his/her demographic attributes in different scenarios. Based on this, a coupled projection matrix extraction method is proposed for solution, where the cross-OSN behaviors are collectively projected onto the same space for demographic attribute inference. Experimental evaluation is conducted on a self-collected Google+ and Twitter dataset consisting of four types of demographic attributes as gender, age, relationship and occupation. The experimental results demonstrate the effectiveness of cross-OSN based demographic attribute inference.},
language = {en},
urldate = {2017-07-14},
booktitle = {{MultiMedia} {Modeling}},
publisher = {Springer, Cham},
author = {Xiang, Liancheng and Sang, Jitao and Xu, Changsheng},
month = jan,
year = {2017},
pages = {515--526},
}

@book{kadushin_understanding_2012,
title = {Understanding {Social} {Networks}: {Theories}, {Concepts}, and {Findings}},
isbn = {978-0-19-537947-1},
shorttitle = {Understanding {Social} {Networks}},
abstract = {Despite the spread and adoption of social network concepts outside of the academy and the rising use of social network analysis across a number of disciplines, there is no general book designed for serious readers that introduces them to the basic ideas and concepts of social networks. Understanding Social Networks fills that gap by explaining the big ideas that underlie the social network phenomenon. Written for the reader who has never studied social networks, it covers fundamental concepts, then discusses networks and their core themes in increasing order of complexity. Kadushin demystifies the concepts, theories, and findings developed by network experts. He selects material that serves as basic building blocks and examples of best practices that will allow the reader to understand and evaluate new developments as they emerge. Understanding Social Networks will be useful to social scientists who encounter social network research in their reading, students new to the network field, as well as managers, marketers, and others who constantly encounter social networks in their work.},
language = {en},
publisher = {Oxford University Press, USA},
author = {Kadushin, Charles},
month = jan,
year = {2012},
note = {Google-Books-ID: ALOhpMgkW\_cC},
keywords = {Business \& Economics / Organizational Behavior, FAMILY \& RELATIONSHIPS, Social Science / Popular Culture, Social Science / Sociology / General},
}

@article{kane_whats_2014,
title = {What's {Different} {About} {Social} {Media} {Networks}? {A} {Framework} and {Research} {Agenda}},
volume = {38},
issn = {0276-7783},
shorttitle = {What's {Different} {About} {Social} {Media} {Networks}?},
url = {http://dl.acm.org/citation.cfm?id=2600518.2600532},
abstract = {In recent years, we have witnessed the rapid proliferation and widespread adoption of a new class of information technologies, commonly known as social media. Researchers often rely on social network analysis (SNA) when attempting to understand these technologies, often without considering how the novel capabilities of social media platforms might affect the underlying theories of SNA, which were developed primarily through studies of offline social networks. This article outlines several key differences between traditional offline social networks and online social media networks by juxtaposing an established typology of social network research with a well-regarded definition of social media platforms that articulates four key features. The results show that at four major points of intersection, social media has considerable theoretical implications for SNA. In exploring these points of intersection, this study outlines a series of theoretically distinct research questions for SNA in social media contexts. These points of intersection offer considerable opportunities for researchers to investigate the theoretical implications introduced by social media and lay the groundwork for a robust social media agenda potentially spanning multiple disciplines.},
number = {1},
journal = {MIS Q.},
author = {Kane, Gerald C. and Alavi, Maryam and Labianca, Giuseppe and Borgatti, Stephen P.},
month = mar,
year = {2014},
keywords = {Social Media, blog, framework, knowledge management, networks, research agenda, social network analysis, theory, wiki},
pages = {275--304},
}

@book{leskovec_mining_2014,
title = {Mining of {Massive} {Datasets}},
isbn = {978-1-107-07723-2},
abstract = {Written by leading authorities in database and Web technologies, this book is essential reading for students and practitioners alike. The popularity of the Web and Internet commerce provides many extremely large datasets from which information can be gleaned by data mining. This book focuses on practical algorithms that have been used to solve key problems in data mining and can be applied successfully to even the largest datasets. It begins with a discussion of the map-reduce framework, an important tool for parallelizing algorithms automatically. The authors explain the tricks of locality-sensitive hashing and stream processing algorithms for mining data that arrives too fast for exhaustive processing. Other chapters cover the PageRank idea and related tricks for organizing the Web, the problems of finding frequent itemsets and clustering. This second edition includes new and extended coverage on social networks, machine learning and dimensionality reduction.},
language = {en},
publisher = {Cambridge University Press},
author = {Leskovec, Jure and Rajaraman, Anand and Ullman, Jeffrey David},
month = nov,
year = {2014},
note = {Google-Books-ID: 16YaBQAAQBAJ},
keywords = {Computers / Databases / Data Mining, Computers / Databases / General, Computers / Desktop Applications / Databases, Computers / General, Computers / Web / General},
}

@article{chen_big_2014,
title = {Big {Data}: {A} {Survey}},
volume = {19},
issn = {1383-469X, 1572-8153},
shorttitle = {Big {Data}},
url = {https://link.springer.com/article/10.1007/s11036-013-0489-0},
doi = {10.1007/s11036-013-0489-0},
abstract = {In this paper, we review the background and state-of-the-art of big data. We first introduce the general background of big data and review related technologies, such as could computing, Internet of Things, data centers, and Hadoop. We then focus on the four phases of the value chain of big data, i.e., data generation, data acquisition, data storage, and data analysis. For each phase, we introduce the general background, discuss the technical challenges, and review the latest advances. We finally examine the several representative applications of big data, including enterprise management, Internet of Things, online social networks, medial applications, collective intelligence, and smart grid. These discussions aim to provide a comprehensive overview and big-picture to readers of this exciting area. This survey is concluded with a discussion of open problems and future directions.},
language = {en},
number = {2},
urldate = {2017-04-17},
journal = {Mobile Networks and Applications},
author = {Chen, Min and Mao, Shiwen and Liu, Yunhao},
month = apr,
year = {2014},
pages = {171--209},
}

@article{manyika_big_2011,
title = {Big data: {The} next frontier for innovation, competition, and productivity},
shorttitle = {Big data},
url = {http://www.mckinsey.com/Insights/MGI/Research/Technology_and_Innovation/Big_data_The_next_frontier_for_innovation},
author = {Manyika, James and Chui, Michael and Brown, Brad and Bughin, Jacques and Dobbs, Richard and Roxburgh, Charles and Byers, Angela},
month = may,
year = {2011},
keywords = {big\_data, big\_data\_text\_sum, data\_mining},
}

@article{walker_big_2014,
title = {Big {Data}: {A} {Revolution} {That} {Will} {Transform} {How} {We} {Live}, {Work}, and {Think}},
volume = {33},
issn = {0265-0487},
shorttitle = {Big {Data}},
url = {http://dx.doi.org/10.2501/IJA-33-1-181-183},
doi = {10.2501/IJA-33-1-181-183},
number = {1},
journal = {International Journal of Advertising},
author = {Walker, Saint John},
month = jan,
year = {2014},
pages = {181--183},
}

@article{wu_data_2014,
title = {Data mining with big data},
volume = {26},
issn = {1041-4347},
doi = {10.1109/TKDE.2013.109},
abstract = {Big Data concern large-volume, complex, growing data sets with multiple, autonomous sources. With the fast development of networking, data storage, and the data collection capacity, Big Data are now rapidly expanding in all science and engineering domains, including physical, biological and biomedical sciences. This paper presents a HACE theorem that characterizes the features of the Big Data revolution, and proposes a Big Data processing model, from the data mining perspective. This data-driven model involves demand-driven aggregation of information sources, mining and analysis, user interest modeling, and security and privacy considerations. We analyze the challenging issues in the data-driven model and also in the Big Data revolution.},
number = {1},
journal = {IEEE Transactions on Knowledge and Data Engineering},
author = {Wu, X. and Zhu, X. and Wu, G. Q. and Ding, W.},
month = jan,
year = {2014},
keywords = {Big Data, Big Data processing model, Big Data revolution, Data Mining, Data models, Data storage systems, Distributed databases, HACE theorem, autonomous sources, complex and evolving associations, data collection capacity, data driven model, data handling, data privacy, data storage, demand driven aggregation, growing data sets, heterogeneity, information management, information sources, networking, user interest modeling, user modelling},
pages = {97--107},
}

@article{selander_digital_2016,
title = {Digital {Action} {Repertories} and {Transforming} a {Social} {Movement} {Organization}},
volume = {40},
url = {http://aisel.aisnet.org/misq/vol40/iss2/6},
number = {2},
journal = {Management Information Systems Quarterly},
author = {Selander, Lisen and Jarvenpaa, Sirkka},
month = jun,
year = {2016},
pages = {331--352},
}

@article{nunamaker_systems_1990,
title = {Systems {Development} in {Information} {Systems} {Research}},
volume = {7},
issn = {0742-1222},
url = {http://dx.doi.org/10.1080/07421222.1990.11517898},
doi = {10.1080/07421222.1990.11517898},
abstract = {In this paper, the use of systems development as a methodology in information systems (is) research is described and defended. A framework to explain the nature of systems development as a research methodology in is research is proposed. Use of this methodology in the engineering field in general is compared with its use specifically in computer science and computer engineering. An integrated program for conducting is research that incorporates theory building, systems development, experimentation, and observation is proposed. Progress in several application domains is reviewed to provide a basis upon which to argue that systems development is a valid research methodology. A systems development research process is presented from a methodological perspective. Software engineering, which is the basic method of applying the systems development research methodology, is then discussed. It is the authors’ belief that systems development and other research methodologies are complementary and that an integrated multi-dimensional and multimethodological approach will generate fruitful is research results. The premise is that research contributions can result from systems development, experimentation, observation, and performance testing of the systems under development and that all of these research approaches are needed to investigate different aspects of the research question.},
number = {3},
journal = {Journal of Management Information Systems},
author = {Nunamaker, Jay F. and Chen, Minder and Purdin, Titus D. M.},
month = dec,
year = {1990},
keywords = {Research methodology, software engineering, systems development},
pages = {89--106},
}

@book{simon_sciences_1996,
title = {The {Sciences} of the {Artificial}},
isbn = {978-0-262-26449-5},
abstract = {Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and tools -- chaos, adaptive systems, genetic algorithms -- for analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter "Economic Reality" has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.},
language = {en},
publisher = {MIT Press},
author = {Simon, Herbert A.},
month = sep,
year = {1996},
note = {Google-Books-ID: k5Sr0nFw7psC},
keywords = {Computers / Intelligence (AI) \& Semantics},
}

@article{march_design_1995,
title = {Design and natural science research on information technology},
volume = {15},
issn = {0167-9236},
url = {http://www.sciencedirect.com/science/article/pii/0167923694000412},
doi = {10.1016/0167-9236(94)00041-2},
abstract = {Research in IT must address the design tasks faced by practitioners. Real problems must be properly conceptualized and represented, appropriate techniques for their solution must be constructed, and solutions must be implemented and evaluated using appropriate criteria. If significant progress is to be made, IT research must also develop an understanding of how and why IT systems work or do not work. Such an understanding must tie together natural laws governing IT systems with natural laws governing the environments in which they operate. This paper presents a two dimensional framework for research in information technology. The first dimension is based on broad types of design and natural science research activities: build, evaluate, theorize, and justify. The second dimension is based on broad types of outputs produced by design research: representational constructs, models, methods, and instantiations. We argue that both design science and natural science activities are needed to insure that IT research is both relevant and effective.},
number = {4},
journal = {Decision Support Systems},
author = {March, Salvatore T. and Smith, Gerald F.},
month = dec,
year = {1995},
keywords = {Information Technology, Information system research, Natural science, design science},
pages = {251--266},
}

@article{markus_design_2002,
title = {A {Design} {Theory} for {Systems} {That} {Support} {Emergent} {Knowledge} {Processes}},
volume = {26},
issn = {0276-7783},
url = {http://www.jstor.org/stable/4132330},
abstract = {This paper addresses the design problem of providing IT support for emerging knowledge processes (EKPs). EKPs are organizational activity patterns that exhibit three characteristics in combination: an emergent process of deliberations with no best structure or sequence; requirements for knowledge that are complex (both general and situational), distributed across people, and evolving dynamically; and an actor set that is unpredictable in terms of job roles or prior knowledge. Examples of EKPs include basic research, new product development, strategic business planning, and organization design. EKPs differ qualitatively from semi-structured decision making processes; therefore, they have unique requirements that are not all thoroughly supported by familiar classes of systems, such as executive information systems, expert systems, electronic communication systems, organizational memory systems, or repositories. Further, the development literature on familiar classes of systems does not provide adequate guidance on how to build systems that support EKPs. Consequently, EKPs require a new IS design theory, as explicated by Walls et al. (1992). We created such a theory while designing and deploying a system for the EKP of organization design. The system was demonstrated through subsequent empirical analysis to be successful in supporting the process. Abstracting from the experience of building this system, we developed an IS design theory for EKP support systems. This new IS design theory is an important theoretical contribution, because it both provides guidance to developers and sets an agenda for academic research. EKP design theory makes the development process more tractable for developers by restricting the range of effective features (or rules for selecting features) and the range of effective development practices to a more manageable set EKP design theory also sets an agenda for academic research by articulating theory-based principles that are subject to empirical, as well as practical, validation.},
number = {3},
journal = {MIS Quarterly},
author = {Markus, M. Lynne and Majchrzak, Ann and Gasser, Les},
year = {2002},
pages = {179--212},
}

@article{mettler_use_2014,
title = {On the {Use} of {Experiments} in {Design} {Science} {Research}: {A} {Proposition} of an {Evaluation} {Framework}},
volume = {34},
issn = {1529-3181},
shorttitle = {On the {Use} of {Experiments} in {Design} {Science} {Research}},
url = {http://aisel.aisnet.org/cais/vol34/iss1/10},
number = {1},
journal = {Communications of the Association for Information Systems},
author = {Mettler, Tobias and Eurich, Markus and Winter, Robert},
month = jan,
year = {2014},
}

@article{abbasi_detecting_2010,
title = {Detecting {Fake} {Websites}: {The} {Contribution} of {Statistical} {Learning} {Theory}},
volume = {34},
issn = {0276-7783},
shorttitle = {Detecting {Fake} {Websites}},
url = {http://www.jstor.org/stable/25750686},
abstract = {Fake websites have become increasingly pervasive, generating billions of dollars in fraudulent revenue at the expense of unsuspecting Internet users. The design and appearance of these websites makes it difficult for users to manually identify them as fake. Automated detection systems have emerged as a mechanism for combating fake websites, however most are fairly simplistic in terms of their fraud cues and detection methods employed. Consequently, existing systems are susceptible to the myriad of obfuscation tactics used by fraudsters, resulting in highly ineffective fake website detection performance. In light of these deficiencies, we propose the development of a new class of fake website detection systems that are based on statistical learning theory (SLT). Using a design science approach, a prototype system was developed to demonstrate the potential utility of this class of systems. We conducted a series of experiments, comparing the proposed system against several existing fake website detection systems on a test bed encompassing 900 websites. The results indicate that systems grounded in SLT can more accurately detect various categories of fake websites by utilizing richer sets of fraud cues in combination with problem-specific knowledge. Given the hefty cost exacted by fake websites, the results have important implications for e-commerce and online security.},
number = {3},
journal = {MIS Quarterly},
author = {Abbasi, Ahmed and Zhang, Zhu and Zimbra, David and Chen, Hsinchun and Nunamaker, Jay F.},
year = {2010},
pages = {435--461},
}

@article{abbasi_cybergate:_2008,
title = {{CyberGate}: {A} {Design} {Framework} and {System} for {Text} {Analysis} of {Computer}-{Mediated} {Communication}},
volume = {32},
issn = {0276-7783},
shorttitle = {{CyberGate}},
url = {http://www.jstor.org/stable/25148873},
abstract = {Content analysis of computer-mediated communication (CMC) is important for evaluating the effectiveness of electronic communication in various organizational settings. CMC text analysis relies on systems capable of providing suitable navigation and knowledge discovery functionalities. However, existing CMC systems focus on structural features, with little support for features derived from message text. This deficiency is attributable to the informational richness and representational complexities associated with CMC text. In order to address this shortcoming, we propose a design framework for CMC text analysis systems. Grounded in systemic functional linguistic theory, the proposed framework advocates the development of systems capable of representing the rich array of information types inherent in CMC text. It also provides guidelines regarding the choice of features, feature selection, and visualization techniques that CMC text analysis systems should employ. The CyberGate system was developed as an instantiation of the design framework. CyberGate incorporates a rich feature set and complementary feature selection and visualization methods, including the writeprints and ink blots techniques. An application example was used to illustrate the system's ability to discern important patterns in CMC text. Furthermore, results from numerous experiments conducted in comparison with benchmark methods confirmed the viability of CyberGate's features and techniques. The results revealed that the CyberGate system and its underlying design framework can dramatically improve CMC text analysis capabilities over those provided by existing systems.},
number = {4},
journal = {MIS Quarterly},
author = {Abbasi, Ahmed and Chen, Hsinchun},
year = {2008},
pages = {811--837},
}

@inproceedings{liu_deep_2015,
title = {Deep {Learning} {Face} {Attributes} in the {Wild}},
url = {http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Liu_Deep_Learning_Face_ICCV_2015_paper.html},
urldate = {2017-07-11},
author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
year = {2015},
pages = {3730--3738},
}

@inproceedings{levi_age_2015,
title = {Age and {Gender} {Classification} {Using} {Convolutional} {Neural} {Networks}},
url = {http://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W08/html/Levi_Age_and_Gender_2015_CVPR_paper.html},
urldate = {2017-07-11},
author = {Levi, Gil and Hassner, Tal},
year = {2015},
pages = {34--42},
}

@article{lawrence_face_1997,
title = {Face recognition: a convolutional neural-network approach},
volume = {8},
issn = {1045-9227},
shorttitle = {Face recognition},
doi = {10.1109/72.554195},
abstract = {We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer},
number = {1},
journal = {IEEE Transactions on Neural Networks},
author = {Lawrence, S. and Giles, C. L. and Tsoi, Ah Chung and Back, A. D.},
month = jan,
year = {1997},
keywords = {Dimensionality reduction, Feature extraction, Humans, Image databases, Image sampling, Karhunen-Loeve transforms, Multilayer perceptrons, Neural networks, Spatial databases, computational complexity, convolution, convolutional neural-network, face recognition, image matching, invariance, local image sampling, quantisation (signal), quantization, self-organising feature maps, self-organizing map, template matching, topological space, topology},
pages = {98--113},
}

@article{lecun_gradient-based_1998,
title = {Gradient-based learning applied to document recognition},
volume = {86},
issn = {0018-9219},
doi = {10.1109/5.726791},
abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
number = {11},
journal = {Proceedings of the IEEE},
author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
month = nov,
year = {1998},
keywords = {2D shape variability, Character recognition, Feature extraction, GTN, Hidden Markov models, Multi-layer neural network, Multilayer perceptrons, Neural networks, Optical character recognition software, Optical computing, back-propagation, backpropagation, cheque reading, complex decision surface synthesis, convolution, convolutional neural network character recognizers, document recognition, document recognition systems, field extraction, gradient based learning technique, gradient-based learning, graph transformer networks, handwritten character recognition, handwritten digit recognition task, high-dimensional patterns, language modeling, machine learning, multilayer neural networks, multimodule systems, optical character recognition, pattern recognition, performance measure minimization, principal component analysis, segmentation recognition},
pages = {2278--2324},
}

@article{strobl_bias_2007,
title = {Bias in random forest variable importance measures: {Illustrations}, sources and a solution},
volume = {8},
issn = {1471-2105},
shorttitle = {Bias in random forest variable importance measures},
url = {https://link.springer.com/article/10.1186/1471-2105-8-25},
doi = {10.1186/1471-2105-8-25},
abstract = {BackgroundVariable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories.ResultsSimulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand.ConclusionWe propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research.},
language = {en},
number = {1},
urldate = {2017-07-11},
journal = {BMC Bioinformatics},
author = {Strobl, Carolin and Boulesteix, Anne-Laure and Zeileis, Achim and Hothorn, Torsten},
month = dec,
year = {2007},
pages = {25},
}

@article{ho_random_1998,
title = {The random subspace method for constructing decision forests},
volume = {20},
issn = {0162-8828},
doi = {10.1109/34.709601},
abstract = {Much of previous attention on decision trees focuses on the splitting criteria and optimization of tree sizes. The dilemma between overfitting and achieving maximum accuracy is seldom resolved. A method to construct a decision tree based classifier is proposed that maintains highest accuracy on training data and improves on generalization accuracy as it grows in complexity. The classifier consists of multiple trees constructed systematically by pseudorandomly selecting subsets of components of the feature vector, that is, trees constructed in randomly chosen subspaces. The subspace method is compared to single-tree classifiers and other forest construction methods by experiments on publicly available datasets, where the method's superiority is demonstrated. We also discuss independence between trees in a forest and relate that to the combined classification accuracy},
number = {8},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
author = {Ho, Tin Kam},
month = aug,
year = {1998},
keywords = {Binary trees, Classification tree analysis, Clustering algorithms, Decision Trees, Stochastic systems, Support vector machine classification, Tin, Training data, classification accuracy, decision forests, decision theory, decision tree based classifier, feature vector, generalization accuracy, learning (artificial intelligence), maximum accuracy, overfitting, pattern classification, random processes, random subspace method, support vector machines, trees (mathematics)},
pages = {832--844},
}

@inproceedings{ho_random_1995,
title = {Random decision forests},
volume = {1},
doi = {10.1109/ICDAR.1995.598994},
abstract = {Decision trees are attractive classifiers due to their high execution speed. But trees derived with traditional methods often cannot be grown to arbitrary complexity for possible loss of generalization accuracy on unseen data. The limitation on complexity usually means suboptimal accuracy on training data. Following the principles of stochastic modeling, we propose a method to construct tree-based classifiers whose capacity can be arbitrarily expanded for increases in accuracy for both training and unseen data. The essence of the method is to build multiple trees in randomly selected subspaces of the feature space. Trees in, different subspaces generalize their classification in complementary ways, and their combined classification can be monotonically improved. The validity of the method is demonstrated through experiments on the recognition of handwritten digits},
booktitle = {Proceedings of 3rd {International} {Conference} on {Document} {Analysis} and {Recognition}},
author = {Ho, Tin Kam},
month = aug,
year = {1995},
keywords = {Classification tree analysis, Decision Trees, Hidden Markov models, Multilayer perceptrons, Optimization methods, Stochastic processes, Testing, Tin, Training data, complexity, decision theory, generalization accuracy, handwriting recognition, handwritten digits, optical character recognition, random decision forests, stochastic modeling, suboptimal accuracy, tree-based classifiers},
pages = {278--282 vol.1},
}

@article{breiman_random_2001,
title = {Random {Forests}},
volume = {45},
issn = {0885-6125, 1573-0565},
url = {https://link.springer.com/article/10.1023/A:1010933404324},
doi = {10.1023/A:1010933404324},
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
language = {en},
number = {1},
urldate = {2017-07-11},
journal = {Machine Learning},
author = {Breiman, Leo},
month = oct,
year = {2001},
pages = {5--32},
}

@inproceedings{pei_prefixspan:_2001,
title = {{PrefixSpan}: {Mining} {Sequential} {Patterns} {Efficiently} by {Prefix}-{Projected} {Pattern} {Growth}},
shorttitle = {{PrefixSpan}},
abstract = {Sequential pattern mining is an important data mining problem with broad applications. It is challenging since one may need to examine a combinatorially explosive number of possible subsequence patterns. Most of the previously developed sequential pattern mining methods follow the methodology of    which may substantially reduce the number of combinations to be examined. However,   still encounters problems when a sequence database is large and/or when sequential patterns to be mined are numerous and/or long.},
author = {Pei, Jian and Han, Jiawei and Mortazavi-asl, Behzad and Pinto, Helen and Chen, Qiming and Dayal, Umeshwar and Hsu, Mei-chun},
year = {2001},
pages = {215--224},
}

@article{han_frequent_2007,
title = {Frequent pattern mining: current status and future directions},
volume = {15},
issn = {1384-5810, 1573-756X},
shorttitle = {Frequent pattern mining},
url = {https://link.springer.com/article/10.1007/s10618-006-0059-1},
doi = {10.1007/s10618-006-0059-1},
abstract = {Frequent pattern mining has been a focused theme in data mining research for over a decade. Abundant literature has been dedicated to this research and tremendous progress has been made, ranging from efficient and scalable algorithms for frequent itemset mining in transaction databases to numerous research frontiers, such as sequential pattern mining, structured pattern mining, correlation mining, associative classification, and frequent pattern-based clustering, as well as their broad applications. In this article, we provide a brief overview of the current status of frequent pattern mining and discuss a few promising research directions. We believe that frequent pattern mining research has substantially broadened the scope of data analysis and will have deep impact on data mining methodologies and applications in the long run. However, there are still some challenging research issues that need to be solved before frequent pattern mining can claim a cornerstone approach in data mining applications.},
language = {en},
number = {1},
urldate = {2017-07-10},
journal = {Data Mining and Knowledge Discovery},
author = {Han, Jiawei and Cheng, Hong and Xin, Dong and Yan, Xifeng},
month = aug,
year = {2007},
pages = {55--86},
}

@article{shimrat_algorithm_1962,
title = {Algorithm 112: {Position} of {Point} {Relative} to {Polygon}},
volume = {5},
issn = {0001-0782},
shorttitle = {Algorithm 112},
url = {http://doi.acm.org/10.1145/368637.368653},
doi = {10.1145/368637.368653},
number = {8},
journal = {Commun. ACM},
author = {Shimrat, M.},
month = aug,
year = {1962},
pages = {434--},
}

@book{laurini_fundamentals_1992,
title = {Fundamentals of {Spatial} {Information} {Systems}},
isbn = {978-0-12-438380-7},
abstract = {The study and application of spatial information systems have been developed primarily from the use of computers in the geosciences. These systems have the principle functions of capturing, storing, representing, manipulating, and displaying data in 2-D and 3-D worlds. This book approaches its subject from the perspectives of informatics and geography, presenting methods of conceptual modeling developed in computer science that provide valuable aids for resolving spatial problems. This book is an essential textbook for both students and practitioners. It is indispensable for academic geographers, computer scientists, and the GIS professional.   Serves as the first comprehensive textbook on the field of Spatial Information Systems (also known as Geographic Information Systems) Contains extensive illustrations Presents numerous detailed examples},
language = {en},
publisher = {Academic Press},
author = {Laurini, Robert and Thompson, Derek},
year = {1992},
keywords = {Computers / Certification Guides / General, Computers / Computer Graphics, Computers / System Administration / Storage \& Retrieval, Science / Earth Sciences / General},
}

@inproceedings{tang_geospatial_2015,
title = {Geospatial interpolation analytics for data streams in eventshop},
doi = {10.1109/ICME.2015.7177513},
abstract = {EventShop is an open-source software which provides a generic infrastructure for the analysis of heterogeneous spatio-temporal data streams. Efficient interpolation of data from spatially sparse sources is critical but currently missing in EventShop. To address this challenge, we implement a Spatial Gaussian Process based statistical operator into the EventShop framework. Spectral analysis is employed to generate features at higher spatial resolution and to improve interpolation accuracy at unsampled locations. Further, we test this operator by interpolating air pollution levels in California. The evaluations of multiple metrics demonstrate that our operators outperform earlier EventShop operators, chemical transportation models, and state-of-the-art methods.},
booktitle = {2015 {IEEE} {International} {Conference} on {Multimedia} and {Expo} ({ICME})},
author = {Tang, Mengfan and Agrawal, P. and Pongpaichet, S. and Jain, R.},
month = jun,
year = {2015},
keywords = {Air pollution, Atmospheric modeling, Data models, EventShop framework, EventShop operators, Gaussian processes, MODIS, Predictive models, Spatial resolution, air pollution level, asthma risk, data analysis, data stream, environmental science computing, geospatial interpolation, geospatial interpolation analytics, interpolation, mathematical operators, open-source software, pm2.5 interpolation, public domain software, spatial Gaussian process, spectral analysis, statistical operator},
pages = {1--6},
}

@misc{united_nations_regional_seminar_on_census_data_dissemination_and_spatial_analysis_spatial_2010,
title = {Spatial {Analysis} \& {Dissemination} of {Census} {Data}},
author = {United Nations Regional Seminar on Census Data Dissemination {and} Spatial Analysis},
year = {2010},
}

@article{mabroukeh_taxonomy_2010,
title = {A {Taxonomy} of {Sequential} {Pattern} {Mining} {Algorithms}},
volume = {43},
issn = {0360-0300},
url = {http://doi.acm.org/10.1145/1824795.1824798},
doi = {10.1145/1824795.1824798},
abstract = {Owing to important applications such as mining web page traversal sequences, many algorithms have been introduced in the area of sequential pattern mining over the last decade, most of which have also been modified to support concise representations like closed, maximal, incremental or hierarchical sequences. This article presents a taxonomy of sequential pattern-mining techniques in the literature with web usage mining as an application. This article investigates these algorithms by introducing a taxonomy for classifying sequential pattern-mining algorithms based on important key features supported by the techniques. This classification aims at enhancing understanding of sequential pattern-mining problems, current status of provided solutions, and direction of research in this area. This article also attempts to provide a comparative performance analysis of many of the key techniques and discusses theoretical aspects of the categories in the taxonomy.},
number = {1},
journal = {ACM Comput. Surv.},
author = {Mabroukeh, Nizar R. and Ezeife, C. I.},
month = dec,
year = {2010},
keywords = {Data Mining, Web usage mining, apriori property, association rules, early pruning, frequent patterns, lattice theory, lexicographic order, pattern growth, prediction, recommender systems, sequence mining, sequential patterns, tree projection, web log},
pages = {3:1--3:41},
}

@article{ferguson_concurrent_2014,
title = {Concurrent and {Prospective} {Analyses} of {Peer}, {Television} and {Social} {Media} {Influences} on {Body} {Dissatisfaction}, {Eating} {Disorder} {Symptoms} and {Life} {Satisfaction} in {Adolescent} {Girls}},
volume = {43},
copyright = {Springer Science+Business Media New York 2014},
issn = {00472891},
url = {http://search.proquest.com/docview/1473698064/abstract/6D030DA5B394AAFPQ/1},
doi = {http://dx.doi.org/10.1007/s10964-012-9898-9},
abstract = {The degree to which media contributes to body dissatisfaction, life satisfaction and eating disorder symptoms in teenage girls continues to be debated. The current study examines television, social media and peer competition influences on body dissatisfaction, eating disorder symptoms and life satisfaction in a sample of 237 mostly Hispanic girls. 101 of these girls were reassessed in a later 6-month follow-up. Neither television exposure to thin ideal media nor social media predicted negative outcomes either concurrently nor prospectively with the exception of a small concurrent correlation between social media use and life satisfaction. Social media use was found to contribute to later peer competition in prospective analysis, however, suggesting potential indirect but not direct effects on body related outcomes. Peer competition proved to be a moderate strong predictor of negative outcomes both concurrently and prospectively. It is concluded that the negative influences of social comparison are focused on peers rather than television or social media exposure.[PUBLICATION ABSTRACT]},
language = {English},
number = {1},
journal = {Journal of Youth and Adolescence; New York},
author = {Ferguson, Christopher J. and Muñoz, Mónica E. and Garza, Adolfo and Galindo, Mariza},
month = jan,
year = {2014},
keywords = {Children And Youth - About, Eating disorders, Girls, Mass media, Psychology, Self image, Social networks, Teenagers, Television},
pages = {1--14},
}

@article{nesi_using_2015,
title = {Using {Social} {Media} for {Social} {Comparison} and {Feedback}-{Seeking}: {Gender} and {Popularity} {Moderate} {Associations} with {Depressive} {Symptoms}},
volume = {43},
copyright = {Springer Science+Business Media New York 2015},
issn = {00910627},
shorttitle = {Using {Social} {Media} for {Social} {Comparison} and {Feedback}-{Seeking}},
url = {http://search.proquest.com/docview/1722361078/abstract/820AA5675CCF45A1PQ/1},
doi = {http://dx.doi.org/10.1007/s10802-015-0020-0},
abstract = {This study examined specific technology-based behaviors (social comparison and interpersonal feedback-seeking) that may interact with offline individual characteristics to predict concurrent depressive symptoms among adolescents. A total of 619 students (57 \% female; mean age 14.6) completed self-report questionnaires at 2 time points. Adolescents reported on levels of depressive symptoms at baseline, and 1 year later on depressive symptoms, frequency of technology use (cell phones, Facebook, and Instagram), excessive reassurance-seeking, and technology-based social comparison and feedback-seeking. Adolescents also completed sociometric nominations of popularity. Consistent with hypotheses, technology-based social comparison and feedback-seeking were associated with depressive symptoms. Popularity and gender served as moderators of this effect, such that the association was particularly strong among females and adolescents low in popularity. Associations were found above and beyond the effects of overall frequency of technology use, offline excessive reassurance-seeking, and prior depressive symptoms. Findings highlight the utility of examining the psychological implications of adolescents' technology use within the framework of existing interpersonal models of adolescent depression and suggest the importance of more nuanced approaches to the study of adolescents' media use.},
language = {English},
number = {8},
journal = {Journal of Abnormal Child Psychology; New York},
author = {Nesi, Jacqueline and Prinstein, Mitchell J.},
month = nov,
year = {2015},
keywords = {Depressive symptoms, Interpersonal feedback-seeking, Social Media, Social comparison, Technology, adolescents},
pages = {1427--1438},
}

@inproceedings{blitzer_biographies_2007,
title = {Biographies, bollywood, boomboxes and blenders: {Domain} adaptation for sentiment classification},
shorttitle = {Biographies, bollywood, boomboxes and blenders},
abstract = {Automatic sentiment classification has been extensively studied and applied in recent years. However, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is impractical. We investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. First, we extend to sentiment classification the recently-proposed structural correspondence learning (SCL) algorithm, reducing the relative error due to adaptation between domains by an average of 30 \% over the original SCL algorithm and 46 \% over a supervised baseline. Second, we identify a measure of domain similarity that correlates well with the potential for adaptation of a classifier from one domain to another. This measure could for instance be used to select a small set of domains to annotate whose trained classifiers would transfer well to many other domains. 1},
booktitle = {In {ACL}},
author = {Blitzer, John and Dredze, Mark and Pereira, Fernando},
year = {2007},
keywords = {Domain adaptation, NLP, paper vesion, project: signal extraction},
pages = {187--205},
}

@article{bruzzone_domain_2010,
title = {Domain {Adaptation} {Problems}: {A} {DASVM} {Classification} {Technique} and a {Circular} {Validation} {Strategy}},
volume = {32},
issn = {0162-8828},
shorttitle = {Domain {Adaptation} {Problems}},
doi = {10.1109/TPAMI.2009.57},
abstract = {This paper addresses pattern classification in the framework of domain adaptation by considering methods that solve problems in which training data are assumed to be available only for a source domain different (even if related) from the target domain of (unlabeled) test data. Two main novel contributions are proposed: 1) a domain adaptation support vector machine (DASVM) technique which extends the formulation of support vector machines (SVMs) to the domain adaptation framework and 2) a circular indirect accuracy assessment strategy for validating the learning of domain adaptation classifiers when no true labels for the target–domain instances are available. Experimental results, obtained on a series of two-dimensional toy problems and on two real data sets related to brain computer interface and remote sensing applications, confirmed the effectiveness and the reliability of both the DASVM technique and the proposed circular validation strategy.},
number = {5},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
author = {Bruzzone, L. and Marconcini, M.},
month = may,
year = {2010},
keywords = {Algorithms, Artificial Intelligence, Computer Simulation, DASVM classification technique, Domain adaptation, Domain adaptation, Models, Theoretical, NLP, Pattern Recognition, Automated, accuracy assessment, brain computer interface, circular indirect accuracy assessment strategy, circular validation strategy, domain adaptation classifiers, domain adaptation problems, domain adaptation support vector machine technique, learning (artificial intelligence), paper vesion, pattern classification, project: signal extraction, remote sensing, semi-supervised learning, support vector machines, transfer learning, validation strategy, validation strategy.},
pages = {770--787},
}

@inproceedings{blitzer_domain_2006,
address = {Stroudsburg, PA, USA},
series = {{EMNLP} '06},
title = {Domain {Adaptation} with {Structural} {Correspondence} {Learning}},
isbn = {978-1-932432-73-2},
url = {http://dl.acm.org/citation.cfm?id=1610075.1610094},
abstract = {Discriminative learning methods are widely used in natural language processing. These methods work best when their training and test data are drawn from the same distribution. For many NLP tasks, however, we are confronted with new domains in which labeled data is scarce or non-existent. In such cases, we seek to adapt existing models from a resource-rich source domain to a resource-poor target domain. We introduce structural correspondence learning to automatically induce correspondences among features from different domains. We test our technique on part of speech tagging and show performance gains for varying amounts of source and target training data, as well as improvements in target domain parsing accuracy using our improved tagger.},
urldate = {2016-08-31},
booktitle = {Proceedings of the 2006 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
publisher = {Association for Computational Linguistics},
author = {Blitzer, John and McDonald, Ryan and Pereira, Fernando},
year = {2006},
keywords = {paper vesion, project: signal extraction},
pages = {120--128},
}

@article{daume_iii_frustratingly_2009,
title = {Frustratingly {Easy} {Domain} {Adaptation}},
url = {http://arxiv.org/abs/0907.1815},
abstract = {We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough ``target'' data to do slightly better than just using only ``source'' data. Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl!) and outperforms state-of-the-art approaches on a range of datasets. Moreover, it is trivially extended to a multi-domain adaptation problem, where one has data from a variety of different domains.},
urldate = {2016-08-31},
journal = {arXiv:0907.1815 [cs]},
author = {Daumé III, Hal},
month = jul,
year = {2009},
note = {arXiv: 0907.1815},
keywords = {CSC665, Computer Science - Computation and Language, Computer Science - Learning, Domain adaptation, NLP, paper vesion, project: signal extraction},
}

@article{broniatowski_national_2013,
title = {National and {Local} {Influenza} {Surveillance} through {Twitter}: {An} {Analysis} of the 2012-2013 {Influenza} {Epidemic}},
volume = {8},
issn = {1932-6203},
shorttitle = {National and {Local} {Influenza} {Surveillance} through {Twitter}},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0083672},
doi = {10.1371/journal.pone.0083672},
abstract = {Social media have been proposed as a data source for influenza surveillance because they have the potential to offer real-time access to millions of short, geographically localized messages containing information regarding personal well-being. However, accuracy of social media surveillance systems declines with media attention because media attention increases “chatter” – messages that are about influenza but that do not pertain to an actual infection – masking signs of true influenza prevalence. This paper summarizes our recently developed influenza infection detection algorithm that automatically distinguishes relevant tweets from other chatter, and we describe our current influenza surveillance system which was actively deployed during the full 2012-2013 influenza season. Our objective was to analyze the performance of this system during the most recent 2012–2013 influenza season and to analyze the performance at multiple levels of geographic granularity, unlike past studies that focused on national or regional surveillance. Our system’s influenza prevalence estimates were strongly correlated with surveillance data from the Centers for Disease Control and Prevention for the United States (r = 0.93, p {\textless} 0.001) as well as surveillance data from the Department of Health and Mental Hygiene of New York City (r = 0.88, p {\textless} 0.001). Our system detected the weekly change in direction (increasing or decreasing) of influenza prevalence with 85\% accuracy, a nearly twofold increase over a simpler model, demonstrating the utility of explicitly distinguishing infection tweets from other chatter.},
number = {12},
urldate = {2017-04-19},
journal = {PLOS ONE},
author = {Broniatowski, David A. and Paul, Michael J. and Dredze, Mark},
month = dec,
year = {2013},
keywords = {Infectious disease control, Infectious disease surveillance, Influenza, New York, S, Social Media, T, United States, Y, a, c, d, disease surveillance, e, f, i, k, l, m, n, o, r, twitter, u, v, w, z},
pages = {e83672},
}

@article{myslin_using_2013,
title = {Using {Twitter} to {Examine} {Smoking} {Behavior} and {Perceptions} of {Emerging} {Tobacco} {Products}},
volume = {15},
issn = {1439-4456},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3758063/},
doi = {10.2196/jmir.2534},
abstract = {Background
Social media platforms such as Twitter are rapidly becoming key resources for public health surveillance applications, yet little is known about Twitter users’ levels of informedness and sentiment toward tobacco, especially with regard to the emerging tobacco control challenges posed by hookah and electronic cigarettes.

Objective
To develop a content and sentiment analysis of tobacco-related Twitter posts and build machine learning classifiers to detect tobacco-relevant posts and sentiment towards tobacco, with a particular focus on new and emerging products like hookah and electronic cigarettes.

Methods
We collected 7362 tobacco-related Twitter posts at 15-day intervals from December 2011 to July 2012. Each tweet was manually classified using a triaxial scheme, capturing genre, theme, and sentiment. Using the collected data, machine-learning classifiers were trained to detect tobacco-related vs irrelevant tweets as well as positive vs negative sentiment, using Naïve Bayes, k-nearest neighbors, and Support Vector Machine (SVM) algorithms. Finally, phi contingency coefficients were computed between each of the categories to discover emergent patterns.

Results
The most prevalent genres were first- and second-hand experience and opinion, and the most frequent themes were hookah, cessation, and pleasure. Sentiment toward tobacco was overall more positive (1939/4215, 46\% of tweets) than negative (1349/4215, 32\%) or neutral among tweets mentioning it, even excluding the 9\% of tweets categorized as marketing. Three separate metrics converged to support an emergent distinction between, on one hand, hookah and electronic cigarettes corresponding to positive sentiment, and on the other hand, traditional tobacco products and more general references corresponding to negative sentiment. These metrics included correlations between categories in the annotation scheme (phihookah-positive=0.39; phie-cigs-positive=0.19); correlations between search keywords and sentiment (χ2
4=414.50, P{\textless}.001, Cramer’s V=0.36), and the most discriminating unigram features for positive and negative sentiment ranked by log odds ratio in the machine learning component of the study. In the automated classification tasks, SVMs using a relatively small number of unigram features (500) achieved best performance in discriminating tobacco-related from unrelated tweets (F score=0.85).

Conclusions
Novel insights available through Twitter for tobacco surveillance are attested through the high prevalence of positive sentiment. This positive sentiment is correlated in complex ways with social image, personal experience, and recently popular products such as hookah and electronic cigarettes. Several apparent perceptual disconnects between these products and their health effects suggest opportunities for tobacco control education. Finally, machine classification of tobacco-related posts shows a promising edge over strictly keyword-based approaches, yielding an improved signal-to-noise ratio in Twitter data and paving the way for automated tobacco surveillance applications.},
number = {8},
journal = {Journal of Medical Internet Research},
author = {Myslín, Mark and Zhu, Shu-Hong and Chapman, Wendy and Conway, Mike},
month = aug,
year = {2013},
pmid = {23989137},
pmcid = {PMC3758063},
}

@inproceedings{abbar_you_2015,
address = {New York, NY, USA},
series = {{CHI} '15},
title = {You {Tweet} {What} {You} {Eat}: {Studying} {Food} {Consumption} {Through} {Twitter}},
isbn = {978-1-4503-3145-6},
shorttitle = {You {Tweet} {What} {You} {Eat}},
url = {http://doi.acm.org/10.1145/2702123.2702153},
doi = {10.1145/2702123.2702153},
abstract = {Food is an integral part of our lives, cultures, and well-being, and is of major interest to public health. The collection of daily nutritional data involves keeping detailed diaries or periodic surveys and is limited in scope and reach. Alternatively, social media is infamous for allowing its users to update the world on the minutiae of their daily lives, including their eating habits. In this work we examine the potential of Twitter to provide insight into US-wide dietary choices by linking the tweeted dining experiences of 210K users to their interests, demographics, and social networks. We validate our approach by relating the caloric values of the foods mentioned in the tweets to the state-wide obesity rates, achieving a Pearson correlation of 0.77 across the 50 US states and the District of Columbia. We then build a model to predict county-wide obesity and diabetes statistics based on a combination of demographic variables and food names mentioned on Twitter. Our results show significant improvement over previous CHI research (Culotta 2014). We further link this data to societal and economic factors, such as education and income, illustrating that areas with higher education levels tweet about food that is significantly less caloric. Finally, we address the somewhat controversial issue of the social nature of obesity (Christakis \& Fowler 2007) by inducing two social networks using mentions and reciprocal following relationships.},
booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
publisher = {ACM},
author = {Abbar, Sofiane and Mejova, Yelena and Weber, Ingmar},
year = {2015},
keywords = {Obesity, Social networks, dietary health, food, twitter},
pages = {3197--3206},
}

@inproceedings{jamison-powell_i_2012,
address = {New York, NY, USA},
series = {{CHI} '12},
title = {"{I} {Can}'{T} {Get} {No} {Sleep}": {Discussing} \#{Insomnia} on {Twitter}},
isbn = {978-1-4503-1015-4},
shorttitle = {"{I} {Can}'{T} {Get} {No} {Sleep}"},
url = {http://doi.acm.org/10.1145/2207676.2208612},
doi = {10.1145/2207676.2208612},
abstract = {Emerging research has shown that social media services are being used as tools to disclose a range of personal health information. To explore the role of social media in the discussion of mental health issues, and with particular reference to insomnia and sleep disorders, a corpus of 18,901 messages - or Tweets - posted to the microblogging social media service Twitter were analysed using a mixed methods approach. We present a content analysis which revealed that Tweets that contained the word "insomnia" contained significantly more negative health information than a random sample, strongly suggesting that individuals were making disclosures about their sleep disorder. A subsequent thematic analysis then revealed two themes: coping with insomnia, and describing the experience of insomnia. We discuss these themes as well as the implications of our research for those in the interaction design community interested in integrating online social media systems in health interventions.},
booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
publisher = {ACM},
author = {Jamison-Powell, Sue and Linehan, Conor and Daley, Laura and Garbett, Andrew and Lawson, Shaun},
year = {2012},
keywords = {Mental health, health, insomnia, microblogging, self-disclosure, twitter},
pages = {1501--1510},
}

@inproceedings{jalali_complex_2015,
title = {Complex asthma risk factor recognition from heterogeneous data streams},
doi = {10.1109/ICMEW.2015.7169780},
abstract = {There are many studies regarding the relationships between environmental factors, particularly air pollution, and asthma exacerbation. Most of these studies ignore the potential confounding effects of a sequence of these factors with a specific time lag between them and asthma outbreaks. In this paper we present a new method for identifying consequential relations in the form of complex patterns between environmental factors and asthma attacks. Temporal structure and order relation between these data and their effect on asthma exacerbation comprise complex patterns called asthma risk factors. By extracting such patterns we create a risk prediction model that is important both for an asthmatic patient and public health. For experimental evaluations, we have collected pollution and meteorological data in Tokyo city and found 32 complex risk factor patterns that might result in asthma outbreaks. The experimental results show that extracted model has 71.15\% precision.},
booktitle = {2015 {IEEE} {International} {Conference} on {Multimedia} {Expo} {Workshops} ({ICMEW})},
author = {Jalali, L. and Dao, Minh-Son and Jain, R. and Zettsu, K.},
month = jun,
year = {2015},
keywords = {Air pollution, Automata, Correlation, Japan, Market research, Meteorology, Tokyo City, asthma attacks, asthma exacerbation, asthma outbreak, asthmatic patient, complex asthma risk factor recognition, complex risk factor pattern, data handling, data order relation, data temporal structure, diseases, environmental factors, environmental science computing, health care, heterogeneous data stream, lung, meteorological data, pattern recognition, pollution data, public health, risk analysis, risk prediction model},
pages = {1--6},
}

@article{szczeklik_natural_2000,
title = {Natural history of aspirin-induced asthma},
volume = {16},
issn = {1399-3003},
url = {http://onlinelibrary.wiley.com/doi/10.1034/j.1399-3003.2000.016003432.x/abstract},
doi = {10.1034/j.1399-3003.2000.016003432.x},
abstract = {There is a subset of patients with bronchial asthma who are susceptible to disease exacerbation upon receiving aspirin and other nonsteroidal anti-inflammatory drugs. This is a clinical syndrome, called aspirin-induced asthma (AIA), associated with alterations in arachidonate metabolism and cysteinyl-leukotriene overproduction. The natural history and clinical characteristics of this type of asthma were studied. Sixteen clinical centres in 10 European countries provided standardized information to the specially developed patient-oriented database regarding: medical history, physical examination, diagnosis, and treatment. Diagnosis of AIA was based on a typical history, confirmed by positive aspirin provocation tests, carried out in 91\% of the patients. A total of 500 patients were enrolled in the study. AIA developed according to a pattern, characterized by a sequence of symptoms. First, persistent rhinitis, appearing at a mean age of 29.7±12.5 yrs, then asthma, aspirin intolerance and nasal polyposis appear. The clinical presentation in different European countries was remarkably similar. In females, who outnumbered males by 2.3:1, the onset of symptoms occurred significantly earlier and the disease was more progressive and severe than in males. Atopy, present in approximately a third of patients, led to earlier manifestation of rhinitis and asthma, but not of aspirin intolerance or nasal polyposis. A family history of aspirin intolerance, recorded in 6\% of patients, had a less evident effect on the course of the disease than sex or atopy. Fifty one per cent of patients, in addition to inhaled steroids, required chronic systemic corticosteroid therapy at a mean dose of 8 mg prednisone·day-1. Surprisingly, 15\% of patients were unaware of intolerance to aspirin and learnt about it only after having provocation tests performed. All over Europe, aspirin-induced asthma develops in a similar characteristic way. Its course is influenced by sex and the presence of atopy. In half of the patients, asthma is severe, and steroid-dependent. The uniform natural history of aspirin-induced asthma might suggest a common underlying principle.},
language = {en},
number = {3},
journal = {European Respiratory Journal},
author = {Szczeklik, A. and Niżankowska, E. and Duplaga, M. and The Aiane Investigators, On Behalf Of},
month = sep,
year = {2000},
keywords = {Aspirin, aspirin-induced asthma, bronchial asthma, eicosanoids, eosinophil, leukotrienes},
pages = {432--436},
}

@article{almqvist_impact_2008,
title = {Impact of gender on asthma in childhood and adolescence: a {GA2LEN} review},
volume = {63},
issn = {1398-9995},
shorttitle = {Impact of gender on asthma in childhood and adolescence},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1398-9995.2007.01524.x/abstract},
doi = {10.1111/j.1398-9995.2007.01524.x},
abstract = {A number of studies have shown gender differences in the prevalence of wheeze and asthma. The aim of this review was to examine published results on gender differences in childhood and adolescent asthma incidence and prevalence, define current concepts and to identify new research needs. A Medline search was performed with the search words (gender OR sex) AND (child OR childhood OR adolescence) AND (asthma). Articles that reported on abscence or prescence of gender differences in asthma were included and reviewed, and cross-references were checked. Boys are consistently reported to have more prevalent wheeze and asthma than girls. In adolescence, the pattern changes and onset of wheeze is more prevalent in females than males. Asthma, after childhood, is more severe in females than in males, and is underdiagnosed and undertreated in female adolescents. Possible explanations for this switch around puberty in the gender susceptibility to develop asthma include hormonal changes and gender-specific differences in environmental exposures. This aspect needs consideration of the doctors and allergists who diagnose and treat asthmatic individuals. In conclusion, sex hormones are likely to play an important role in the development and outcome of the allergic immune response and asthma in particular. By obtaining functional data from appropriate models, the exact underlying mechanisms can be unravelled. To examine the effect of gender-specific differences in environmental exposures and changes of asthma prevalence and severity in puberty, larger populations may need to be investigated.},
language = {en},
number = {1},
journal = {Allergy},
author = {Almqvist, C. and Worm, M. and Leynaert, B. and {for the working group of GA2LEN WP 2.5 ‘Gender’}},
month = jan,
year = {2008},
keywords = {Asthma, Child, GA2LEN, adolescence, gender},
pages = {47--57},
}

@article{chen_stress_2007,
title = {Stress and inflammation in exacerbations of asthma},
volume = {21},
issn = {0889-1591},
url = {http://www.sciencedirect.com/science/article/pii/S0889159107000761},
doi = {10.1016/j.bbi.2007.03.009},
abstract = {In this mini-review, we outline a model depicting the immunologic mechanisms by which psychological stress can exacerbate clinical symptoms in patients with asthma. This model highlights the importance of both social and physical exposures in the exacerbation of asthma symptoms. The basic premise of the model is that psychological stress operates by altering the magnitude of the airway inflammatory response that irritants, allergens, and infections bring about in persons with asthma. The biological pathways for how stress amplifies the immune response to asthma triggers include the hypothalamic-pituitary-adrenal (HPA) axis, the sympathetic-adrenal-medullary (SAM) axis, and the sympathetic (SNS) and parasympathetic (PNS) arms of the autonomic nervous system. Empirical evidence for this model is reviewed, and conclusions and future research directions are discussed.},
number = {8},
journal = {Brain, Behavior, and Immunity},
author = {Chen, Edith and Miller, Gregory E.},
month = nov,
year = {2007},
keywords = {Asthma, Autonomic nervous system, Cytokines, Glucocorticoids, Stress},
pages = {993--999},
}

@article{wright_review_1998,
title = {Review of psychosocial stress and asthma: an integrated biopsychosocial approach},
volume = {53},
copyright = {British Thoracic Society},
issn = {0040-6376, 1468-3296},
shorttitle = {Review of psychosocial stress and asthma},
url = {http://thorax.bmj.com/content/53/12/1066},
doi = {10.1136/thx.53.12.1066},
abstract = {Although consensus has emerged from the clinical, social science, psychological, and biological literature that psychosocial factors affect asthma morbidity in children, their role in the genesis, incidence, and symptomatology of asthma remains controversial since mechanisms are not well understood. Three recent trends in medical research have led both clinicians and investigators to reconsider the role of psychosocial stress in asthma. Firstly, efforts to define the aetiological risk factors for the development and expression of disease have intensified in the face of rising trends in the prevalence and severity of asthma observed worldwide.1 Thus far, focus on traditional environmental risk factors has not fully explained these trends. Secondly, evidence evolved over the last two decades of important interactions among behavioural, neural, endocrine, and immune processes provides fresh insight into means by which psychosocial stressors may influence the development and expression of inflammatory diseases.2 3 This insight emerged in parallel with our increased understanding of the complex cellular and molecular basis of asthma as a chronic inflammatory disorder.4 Finally, hypotheses about the substantial role of the social environment and social integration in health and disease in general have gained significant emphasis over the last decade.5 6 In particular, prospective epidemiological studies have demonstrated associations between life stress, social position or status, and quality of social relationships—that is, social networks, an individual’s ties to friends, family, work, and community through social and religious groups—and health.6 7 All have led to a paradigm shift that reconsiders the overlap between biological determinates and psychosocial factors in understanding the rising asthma burden.8 

This review highlights significant insights into this field from a multidisciplinary (psychoanalytical, behavioural, psychosocial, epidemiological, and immunological) perspective rather than being an exhaustive overview of the subject. We examine behavioural, neural, and immunological pathways, underscoring reciprocal relations that …},
language = {en},
number = {12},
urldate = {2017-07-06},
journal = {Thorax},
author = {Wright, Rosalind J. and Rodriguez, Mario and Cohen, Sheldon},
month = dec,
year = {1998},
pmid = {10195081},
pages = {1066--1074},
}

@article{zacharasiewicz_maternal_2016,
title = {Maternal smoking in pregnancy and its influence on childhood asthma},
volume = {2},
issn = {2312-0541},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5034599/},
doi = {10.1183/23120541.00042-2016},
abstract = {Maternal smoking in pregnancy (MSP) is a large modifiable risk factor for pregnancy related mortality and morbidity and also the most important known modifiable risk factor for asthma., This review summarises the effects of MSP throughout infancy, childhood and adolescence with regards to asthma (development and severity). Firstly, the direct damage caused by nicotine on fetal lung development, fetal growth and neuronal differentiation is discussed, as well as the indirect effects of nicotine on placental functioning. Secondly, the effects of MSP on later immune functioning resulting in increased infection rate are summarised and details are given on the effects of MSP modulating airway hyperreactivity, reducing lung function and therefore increasing asthma morbidity., Furthermore, epigenetic effects are increasingly being recognised. These can also result in transgenerational detrimental effects induced by cigarette smoke., In summary, the causal relationship between MSP and asthma development is well documented and presents a major health problem for generations to come. The high prevalence of MSP is alarming and epigenetic effects of nicotine on immune functioning potentiate this danger. A considerable part of the increase in asthma prevalence worldwide is due to MSP., Smoking in pregnancy increases asthma by interference of lung and placental function and through epigenetic changes
http://ow.ly/WkbB301cyaS},
number = {3},
journal = {ERJ Open Research},
author = {Zacharasiewicz, Angela},
month = jul,
year = {2016},
pmid = {27730206},
pmcid = {PMC5034599},
}

@article{chaudhuri_cigarette_2003,
title = {Cigarette {Smoking} {Impairs} the {Therapeutic} {Response} to {Oral} {Corticosteroids} in {Chronic} {Asthma}},
volume = {168},
issn = {1073-449X},
url = {http://www.atsjournals.org/doi/abs/10.1164/rccm.200304-503OC},
doi = {10.1164/rccm.200304-503OC},
abstract = {The study was designed to assess the effect of cigarette smoking on the therapeutic response to oral corticosteroids in chronic stable asthma. We performed a randomized, placebo-controlled, crossover study with prednisolone (40 mg daily) or placebo for 2 weeks in smokers with asthma, ex-smokers with asthma, and never-smokers with asthma. All subjects had reversibility in FEV1 after nebulized albuterol of 15\% or more and a mean postbronchodilator FEV1\% predicted of more than 80\%. Efficacy was assessed using FEV1, daily PEF, and an asthma control score. There was a significant improvement after oral prednisolone compared with placebo in FEV1, ml (mean difference, 237; 95\% confidence intervals, 43, 231; p = 0.019), morning PEF L/m (mean difference, 36.8; 95\% confidence intervals (CI), 11, 62; p = 0.006), and asthma control score (mean difference, −0.72; 95\% CI, −1.2, −0.3; p = 0.004) in never-smokers with asthma but no change in smokers with asthma (mean differences of 47, 6.5, and −0.05 with p values of 0.605, 0.47, and 0.865, respectively). Ex-smokers with asthma had a significant improvement in morning and night PEF (mean difference, 29.1; CI, 2.3, 56; p = 0.04 and 52.4; CI, 26, 79; p = 0.003, respectively), but not in FEV1 or asthma control score. We conclude that active smoking impairs the efficacy of short-term oral corticosteroid treatment in chronic asthma.},
number = {11},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Chaudhuri, Rekha and Livingston, Eric and McMahon, Alex D. and Thomson, Lorna and Borland, William and Thomson, Neil C.},
month = dec,
year = {2003},
pages = {1308--1311},
}

@article{obyrne_asthma_1982,
title = {Asthma {Induced} by {Cold} {Air} and {Its} {Relation} to {Nonspecific} {Bronchial} {Responsiveness} to {Methacholine}},
volume = {125},
issn = {0003-0805},
url = {http://www.atsjournals.org/doi/abs/10.1164/arrd.1982.125.3.281},
doi = {10.1164/arrd.1982.125.3.281},
abstract = {We compared bronchial responsiveness to isocapnic hyperventilation of cold dry air at −18° C and 0\% humidity with bronchial responsiveness to inhaled methacholine in 24 subjects with current or previous asthma and 2 nonasthmatics. Two inhalation tests with each agent were carried out in random order on 4 consecutive days. The response to cold air was expressed as the respiratory heat exchange required to reduce the FEV1 by 10\% (PD10 RHE) and the response to methacholine as the provocation concentration required to reduce the FEV1 by 20\% (PC20 methacholine). There was a close positive linear correlation between PD10 RHE and PC20 (r = 0.86, p {\textless} 0.001). The responsiveness to each agent was highly reproducible. The PD10 RHE could be measured in all 21 subjects with current symptoms of asthma and it could be obtained by extrapolation in 2 normal subjects, but it could not be measured in 3 subjects with a past history of asthma. The PC20 in the current asthmatics was 6.3 mg/ml or less, in the 2 nonasthmatic subjects, it was 14 and 16 mg/ml, and in the previous asthmatics it was between 26 and 54 mg/ml. The results indicate that nonspecific bronchial responsiveness is an important factor influencing the bronchial response to cold air, that either cold air or methacholine are suitable stimuli to measure nonspecific bronchial responsiveness, and that the differences in bronchial responsiveness observed between asthmatics and nonasthmatic subjects are in keeping with a quantitative rather than a qualitative difference in responsiveness.},
number = {3},
journal = {American Review of Respiratory Disease},
author = {O'Byrne, Paul M. and Ryan, Gerard and Morris, Marilyn and McCormack, Don and Jones, Norman L. and Morse, John L.C. and Hargreave, Frederick E.},
month = mar,
year = {1982},
pages = {281--285},
}

@article{salam_recent_2008,
title = {Recent evidence for adverse effects of residential proximity to traffic sources on asthma},
volume = {14},
issn = {1070-5287},
doi = {10.1097/MCP.0b013e3282f1987a},
abstract = {PURPOSE OF REVIEW: A growing body of evidence indicates that residential proximity to traffic sources increases the risk for asthma and asthma exacerbations. In this review we have considered publications from 2006-2007 that examined the impact of residential traffic-related exposures on asthma occurrence and severity.
RECENT FINDINGS: In these studies, exposures were estimated using traffic metrics based on residential distances from major roads and freeways, traffic densities around homes, and models of traffic exposure. Overall, residential proximity to traffic sources was associated with increased asthma occurrence and exacerbations in both children and adults. Land-use regression models were superior to individual traffic metrics in explaining the variability of traffic-related pollutants. Susceptibility may also play a role in variation in the effects of traffic on asthma.
SUMMARY: There is consistent evidence that living near traffic sources is associated with asthma occurrence and exacerbations. Future studies have the opportunity to improve exposure estimates by measuring traffic-related pollutants near homes and schools and including time/activity patterns in prediction models. Further research is also warranted to investigate the differential impact of traffic by genetic and other susceptibility factors and to identify specific pollutants that underlie the adverse effect of traffic on asthma.},
language = {eng},
number = {1},
journal = {Current Opinion in Pulmonary Medicine},
author = {Salam, Muhammad T. and Islam, Talat and Gilliland, Frank D.},
month = jan,
year = {2008},
pmid = {18043269},
keywords = {Adolescent, Adult, Air Pollutants, Asthma, Child, Child, Preschool, Environmental Exposure, Epidemiologic Studies, Genetic Predisposition to Disease, Humans, Infant, Middle Aged, Risk Factors, Vehicle Emissions},
pages = {3--8},
}

@article{lu_mast_2006,
title = {Mast cells are essential intermediaries in regulatory {T}-cell tolerance},
volume = {442},
copyright = {© 2006 Nature Publishing Group},
issn = {0028-0836},
url = {https://www.nature.com/nature/journal/v442/n7106/abs/nature05010.html},
doi = {10.1038/nature05010},
abstract = {Contrary to the proinflammatory role of mast cells in allergic disorders, the results obtained in this study establish that mast cells are essential in CD4+CD25+Foxp3+ regulatory T (TReg)-cell-dependent peripheral tolerance. Here we confirm that tolerant allografts, which are sustained owing to the immunosuppressive effects of TReg cells, acquire a unique genetic signature dominated by the expression of mast-cell-gene products. We also show that mast cells are crucial for allograft tolerance, through the inability to induce tolerance in mast-cell-deficient mice. High levels of interleukin (IL)-9—a mast cell growth and activation factor—are produced by activated TReg cells, and IL-9 production seems important in mast cell recruitment to, and activation in, tolerant tissue. Our data indicate that IL-9 represents the functional link through which activated TReg cells recruit and activate mast cells to mediate regional immune suppression, because neutralization of IL-9 greatly accelerates allograft rejection in tolerant mice. Finally, immunohistochemical analysis clearly demonstrates the existence of this novel TReg–IL-9–mast cell relationship within tolerant allografts.},
language = {en},
number = {7106},
urldate = {2017-07-06},
journal = {Nature},
author = {Lu, Li-Fan and Lind, Evan F. and Gondek, David C. and Bennett, Kathy A. and Gleeson, Michael W. and Pino-Lagos, Karina and Scott, Zachary A. and Coyle, Anthony J. and Reed, Jennifer L. and Van Snick, Jacques and Strom, Terry B. and Zheng, Xin Xiao and Noelle, Randolph J.},
month = aug,
year = {2006},
keywords = {immune cells},
pages = {997--1002},
}

@article{barnes_cytokine_2008,
title = {The cytokine network in asthma and chronic obstructive pulmonary disease},
volume = {118},
issn = {0021-9738},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2575722/},
doi = {10.1172/JCI36130},
abstract = {Asthma and chronic obstructive pulmonary disease (COPD) are very common inflammatory diseases of the airways. They both cause airway narrowing and are increasing in incidence throughout the world, imposing enormous burdens on health care. Cytokines play a key role in orchestrating the chronic inflammation and structural changes of the respiratory tract in both asthma and COPD and have become important targets for the development of new therapeutic strategies in these diseases.},
number = {11},
journal = {The Journal of Clinical Investigation},
author = {Barnes, Peter J.},
month = nov,
year = {2008},
pmid = {18982161},
pmcid = {PMC2575722},
keywords = {immune cells},
pages = {3546--3556},
}

@misc{who_who_2017,
title = {{WHO} {\textbar} {Asthma}},
url = {http://www.who.int/topics/asthma/en/},
abstract = {Asthma: WHO health topic page on asthma provides links to descriptions of activities, reports, publications, statistics, news, multimedia and events, as well as contacts and cooperating partners in the various WHO programmes and offices working on this topic.},
urldate = {2017-07-05},
journal = {WHO},
author = {WHO},
year = {2017},
}

@article{barnett_costs_2011,
title = {Costs of asthma in the {United} {States}: 2002-2007},
volume = {127},
issn = {0091-6749},
shorttitle = {Costs of asthma in the {United} {States}},
url = {http://www.sciencedirect.com/science/article/pii/S0091674910016349},
doi = {10.1016/j.jaci.2010.10.020},
abstract = {The economic burden of asthma is an important measure of the effect of asthma on society. Although asthma is a costly illness, the total cost of asthma to society has not been estimated in more than a decade. The purpose of this study is to provide the public with current estimates of the incremental direct medical costs and productivity losses due to morbidity and mortality from asthma at both the individual and national levels for the years 2002-2007. Data came from the Medical Expenditure Panel Survey. Two-part models were used to estimate the incremental direct costs of asthma. The incremental number of days lost from work and school was estimated by negative binomial regressions and valued following the human capital approach. Published data were used to value lives lost with an underlying cause of asthma. Over the years 2002-2007, the incremental direct cost of asthma was \$3,259 (2009 dollars) per person per year. The value of additional days lost attributable to asthma per year was approximately \$301 for each worker and \$93 for each student. For the most recent year available, 2007, the total incremental cost of asthma to society was \$56 billion, with productivity losses due to morbidity accounting for \$3.8 billion and productivity losses due to mortality accounting for \$2.1 billion. The current study finds that the estimated costs of asthma are substantial, which stresses the necessity for research and policy to work toward reducing the economic burden of asthma.},
number = {1},
journal = {Journal of Allergy and Clinical Immunology},
author = {Barnett, Sarah Beth L. and Nurmagambetov, Tursynbek A.},
month = jan,
year = {2011},
keywords = {Asthma, Two-part model, direct cost, expenditures, mortality losses, productivity losses},
pages = {145--152},
}

@article{han_lexical_2013,
title = {Lexical {Normalization} for {Social} {Media} {Text}},
volume = {4},
issn = {2157-6904},
url = {http://doi.acm.org/10.1145/2414425.2414430},
doi = {10.1145/2414425.2414430},
abstract = {Twitter provides access to large volumes of data in real time, but is notoriously noisy, hampering its utility for NLP. In this article, we target out-of-vocabulary words in short text messages and propose a method for identifying and normalizing lexical variants. Our method uses a classifier to detect lexical variants, and generates correction candidates based on morphophonemic similarity. Both word similarity and context are then exploited to select the most probable correction candidate for the word. The proposed method doesn't require any annotations, and achieves state-of-the-art performance over an SMS corpus and a novel dataset based on Twitter.},
number = {1},
journal = {ACM Trans. Intell. Syst. Technol.},
author = {Han, Bo and Cook, Paul and Baldwin, Timothy},
month = feb,
year = {2013},
keywords = {lexical normalization, microblog, short text message, text analysis, text preprocessing},
pages = {5:1--5:27},
}

@inproceedings{samangooei_trendminer:_2012,
title = {Trendminer: {An} architecture for real time analysis of social media text},
shorttitle = {Trendminer},
url = {http://citeseerx.ist.psu.edu/viewdoc/citations;jsessionid=97D6DE844AD8D039D67CB1869599D5E8?doi=10.1.1.709.9551},
abstract = {CiteSeerX - Document Details (Isaac Councill, Lee Giles, Pradeep Teregowda): The emergence of online social networks (OSNs) and the accompanying availability of large amounts of data, pose a number of new natural language processing (NLP) and com-putational challenges. Data from OSNs is different to data from traditional sources (e.g. newswire). The texts are short, noisy and conversational. Another important issue is that data occurs in a real-time streams, needing immediate analysis that is grounded in time and context. In this paper we describe a new open-source framework for efficient text processing of streaming OSN data (available at www.trendminer-project.eu). Whilst researchers have made progress in adapting or creating text analysis tools for OSN data, a system to unify these tasks has yet to be built. Our sys-tem is focused on a real world scenario where fast processing and accuracy is paramount. We use the MapReduce frame-work for distributed computing and present running times for our system in order to show that scaling to online scenarios is feasible. We describe the components of the system and eval-uate their accuracy. Our system supports easy integration of future modules in order to extend its functionality. 1},
urldate = {2017-06-08},
author = {Samangooei, Sina and Cohn, Trevor and Gibbins, Nicholas and Niranjan, Mahesan},
year = {2012},
}

@article{surdeanu_learning_2011,
title = {Learning to {Rank} {Answers} to {Non}-{Factoid} {Questions} from {Web} {Collections}},
volume = {37},
issn = {0891-2017},
url = {http://dx.doi.org/10.1162/COLI_a_00051},
doi = {10.1162/COLI_a_00051},
number = {2},
journal = {Computational Linguistics},
author = {Surdeanu, Mihai and Ciaramita, Massimiliano and Zaragoza, Hugo},
month = apr,
year = {2011},
pages = {351--383},
}

@inproceedings{rai_domain_2010,
address = {Stroudsburg, PA, USA},
series = {{ALNLP} '10},
title = {Domain {Adaptation} {Meets} {Active} {Learning}},
url = {http://dl.acm.org/citation.cfm?id=1860625.1860629},
abstract = {In this work, we show how active learning in some (target) domain can leverage information from a different but related (source) domain. We present an algorithm that harnesses the source domain data to learn the best possible initializer hypothesis for doing active learning in the target domain, resulting in improved label complexity. We also present a variant of this algorithm which additionally uses the domain divergence information to selectively query the most informative points in the target domain, leading to further reductions in label complexity. Experimental results on a variety of datasets establish the efficacy of the proposed methods.},
booktitle = {Proceedings of the {NAACL} {HLT} 2010 {Workshop} on {Active} {Learning} for {Natural} {Language} {Processing}},
publisher = {Association for Computational Linguistics},
author = {Rai, Piyush and Saha, Avishek and Daumé, III, Hal and Venkatasubramanian, Suresh},
year = {2010},
pages = {27--32},
}

@inproceedings{zhang_solving_2004,
address = {New York, NY, USA},
series = {{ICML} '04},
title = {Solving {Large} {Scale} {Linear} {Prediction} {Problems} {Using} {Stochastic} {Gradient} {Descent} {Algorithms}},
isbn = {978-1-58113-838-2},
url = {http://doi.acm.org/10.1145/1015330.1015332},
doi = {10.1145/1015330.1015332},
abstract = {Linear prediction methods, such as least squares for regression, logistic regression and support vector machines for classification, have been extensively used in statistics and machine learning. In this paper, we study stochastic gradient descent (SGD) algorithms on regularized forms of linear prediction methods. This class of methods, related to online algorithms such as perceptron, are both efficient and very simple to implement. We obtain numerical rate of convergence for such algorithms, and discuss its implications. Experiments on text data will be provided to demonstrate numerical and statistical consequences of our theoretical findings.},
booktitle = {Proceedings of the {Twenty}-first {International} {Conference} on {Machine} {Learning}},
publisher = {ACM},
author = {Zhang, Tong},
year = {2004},
pages = {116--},
}

@inproceedings{ben-david_analysis_2006,
address = {Cambridge, MA, USA},
series = {{NIPS}'06},
title = {Analysis of {Representations} for {Domain} {Adaptation}},
url = {http://dl.acm.org/citation.cfm?id=2976456.2976474},
abstract = {Discriminative learning methods for classification perform well when training and test data are drawn from the same distribution. In many situations, though, we have labeled training data for a source domain, and we wish to learn a classifier which performs well on a target domain with a different distribution. Under what conditions can we adapt a classifier trained on the source domain for use in the target domain? Intuitively, a good feature representation is a crucial factor in the success of domain adaptation. We formalize this intuition theoretically with a generalization bound for domain adaption. Our theory illustrates the tradeoffs inherent in designing a representation for domain adaptation and gives a new justification for a recently proposed model. It also points toward a promising new model for domain adaptation: one which explicitly minimizes the difference between the source and target domains, while at the same time maximizing the margin of the training set.},
booktitle = {Proceedings of the 19th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
publisher = {MIT Press},
author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando},
year = {2006},
pages = {137--144},
}

@inproceedings{yao_boosting_2010,
title = {Boosting for transfer learning with multiple sources},
doi = {10.1109/CVPR.2010.5539857},
abstract = {Transfer learning allows leveraging the knowledge of source domains, available a priori, to help training a classifier for a target domain, where the available data is scarce. The effectiveness of the transfer is affected by the relationship between source and target. Rather than improving the learning, brute force leveraging of a source poorly related to the target may decrease the classifier performance. One strategy to reduce this negative transfer is to import knowledge from multiple sources to increase the chance of finding one source closely related to the target. This work extends the boosting framework for transferring knowledge from multiple sources. Two new algorithms, MultiSource-TrAdaBoost, and TaskTrAdaBoost, are introduced, analyzed, and applied for object category recognition and specific object detection. The experiments demonstrate their improved performance by greatly reducing the negative transfer as the number of sources increases. TaskTrAdaBoost is a fast algorithm enabling rapid retraining over new targets.},
booktitle = {2010 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
author = {Yao, Y. and Doretto, G.},
month = jun,
year = {2010},
keywords = {Algorithm design and analysis, Boosting, Computer vision, Data visualization, Machine learning algorithms, Probability distribution, TaskTrAdaBoost, Testing, Training data, boosting framework, brute force leveraging, learning (artificial intelligence), machine learning, multisource TrAdaBoost, object category recognition, object detection, object recognition, transfer learning},
pages = {1855--1862},
}

@inproceedings{lim_transfer_2011,
address = {USA},
series = {{NIPS}'11},
title = {Transfer {Learning} by {Borrowing} {Examples} for {Multiclass} {Object} {Detection}},
isbn = {978-1-61839-599-3},
url = {http://dl.acm.org/citation.cfm?id=2986459.2986473},
abstract = {Despite the recent trend of increasingly large datasets for object detection, there still exist many classes with few training examples. To overcome this lack of training data for certain classes, we propose a novel way of augmenting the training data for each class by borrowing and transforming examples from other classes. Our model learns which training instances from other classes to borrow and how to transform the borrowed examples so that they become more similar to instances from the target class. Our experimental results demonstrate that our new object detector, with borrowed and transformed examples, improves upon the current state-of-the-art detector on the challenging SUN09 object detection dataset.},
booktitle = {Proceedings of the 24th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
publisher = {Curran Associates Inc.},
author = {Lim, Joseph J. and Salakhutdinov, Ruslan and Torralba, Antonio},
year = {2011},
pages = {118--126},
}

@inproceedings{aytar_tabula_2011,
title = {Tabula rasa: {Model} transfer for object category detection},
shorttitle = {Tabula rasa},
doi = {10.1109/ICCV.2011.6126504},
abstract = {Our objective is transfer training of a discriminatively trained object category detector, in order to reduce the number of training images required. To this end we propose three transfer learning formulations where a template learnt previously for other categories is used to regularize the training of a new category. All the formulations result in convex optimization problems. Experiments (on PASCAL VOC) demonstrate significant performance gains by transfer learning from one class to another (e.g. motorbike to bicycle), including one-shot learning, specialization from class to a subordinate class (e.g. from quadruped to horse) and transfer using multiple components. In the case of multiple training samples it is shown that a detection performance approaching that of the state of the art can be achieved with substantially fewer training samples.},
booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
author = {Aytar, Y. and Zisserman, A.},
month = nov,
year = {2011},
keywords = {Adaptation models, Bicycles, Detectors, Motorcycles, Tabula Rasa, Training, Vectors, convex optimization problems, convex programming, learning (artificial intelligence), model transfer, object category detection, object detection, one-shot learning, support vector machines, training images, transfer learning formulations},
pages = {2252--2259},
}

@inproceedings{oquab_learning_2014,
title = {Learning and {Transferring} {Mid}-{Level} {Image} {Representations} using {Convolutional} {Neural} {Networks}},
url = {http://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Oquab_Learning_and_Transferring_2014_CVPR_paper.html},
urldate = {2017-06-04},
author = {Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},
year = {2014},
pages = {1717--1724},
}

@inproceedings{donahue_decaf:_2014,
title = {{DeCAF}: {A} {Deep} {Convolutional} {Activation} {Feature} for {Generic} {Visual} {Recognition}},
shorttitle = {{DeCAF}},
url = {http://machinelearning.wustl.edu/mlpapers/papers/icml2014c1_donahue14},
urldate = {2017-06-04},
author = {Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
year = {2014},
pages = {647--655},
}

@inproceedings{tommasi_frustratingly_2013,
title = {Frustratingly {Easy} {NBNN} {Domain} {Adaptation}},
url = {http://www.cv-foundation.org/openaccess/content_iccv_2013/html/Tommasi_Frustratingly_Easy_NBNN_2013_ICCV_paper.html},
urldate = {2017-06-04},
author = {Tommasi, Tatiana and Caputo, Barbara},
year = {2013},
pages = {897--904},
}

@inproceedings{ni_subspace_2013,
title = {Subspace {Interpolation} via {Dictionary} {Learning} for {Unsupervised} {Domain} {Adaptation}},
url = {http://www.cv-foundation.org/openaccess/content_cvpr_2013/html/Ni_Subspace_Interpolation_via_2013_CVPR_paper.html},
urldate = {2017-06-04},
author = {Ni, Jie and Qiu, Qiang and Chellappa, Rama},
year = {2013},
pages = {692--699},
}

@inproceedings{shekhar_generalized_2013,
title = {Generalized {Domain}-{Adaptive} {Dictionaries}},
url = {http://www.cv-foundation.org/openaccess/content_cvpr_2013/html/Shekhar_Generalized_Domain-Adaptive_Dictionaries_2013_CVPR_paper.html},
urldate = {2017-06-04},
author = {Shekhar, Sumit and Patel, Vishal M. and Nguyen, Hien V. and Chellappa, Rama},
year = {2013},
pages = {361--368},
}

@inproceedings{long_transfer_2013,
title = {Transfer {Feature} {Learning} with {Joint} {Distribution} {Adaptation}},
url = {http://www.cv-foundation.org/openaccess/content_iccv_2013/html/Long_Transfer_Feature_Learning_2013_ICCV_paper.html},
urldate = {2017-06-04},
author = {Long, Mingsheng and Wang, Jianmin and Ding, Guiguang and Sun, Jiaguang and Yu, Philip S.},
year = {2013},
pages = {2200--2207},
}

@article{hoffman_efficient_2013,
title = {Efficient {Learning} of {Domain}-invariant {Image} {Representations}},
url = {http://arxiv.org/abs/1301.3224},
abstract = {We present an algorithm that learns representations which explicitly compensate for domain mismatch and which can be efficiently realized as linear classifiers. Specifically, we form a linear transformation that maps features from the target (test) domain to the source (training) domain as part of training the classifier. We optimize both the transformation and classifier parameters jointly, and introduce an efficient cost function based on misclassification loss. Our method combines several features previously unavailable in a single algorithm: multi-class adaptation through representation learning, ability to map across heterogeneous feature spaces, and scalability to large datasets. We present experiments on several image datasets that demonstrate improved accuracy and computational advantages compared to previous approaches.},
journal = {arXiv:1301.3224 [cs]},
author = {Hoffman, Judy and Rodner, Erik and Donahue, Jeff and Darrell, Trevor and Saenko, Kate},
month = jan,
year = {2013},
note = {arXiv: 1301.3224},
keywords = {Computer Science - Learning},
}

@inproceedings{tommasi_safety_2010,
title = {Safety in numbers: {Learning} categories from few examples with multi model knowledge transfer},
shorttitle = {Safety in numbers},
doi = {10.1109/CVPR.2010.5540064},
abstract = {Learning object categories from small samples is a challenging problem, where machine learning tools can in general provide very few guarantees. Exploiting prior knowledge may be useful to reproduce the human capability of recognizing objects even from only one single view. This paper presents an SVM-based model adaptation algorithm able to select and weight appropriately prior knowledge coming from different categories. The method relies on the solution of a convex optimization problem which ensures to have the minimal leave-one-out error on the training set. Experiments on a subset of the Caltech-256 database show that the proposed method produces better results than both choosing one single prior model, and transferring from all previous experience in a flat uninformative way.},
booktitle = {2010 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
author = {Tommasi, T. and Orabona, F. and Caputo, B.},
month = jun,
year = {2010},
keywords = {Adaptation model, Databases, Humans, Kernel, Machine learning algorithms, Optimization methods, SVM-based model adaptation algorithm, Safety, convex optimization problem, convex programming, knowledge transfer, learning (artificial intelligence), learning object categories, machine learning, machine learning tools, minimal leave-one-out error, multimodel knowledge transfer, object recognition, support vector machines},
pages = {3081--3088},
}

@article{duan_domain_2012,
title = {Domain {Adaptation} {From} {Multiple} {Sources}: {A} {Domain}-{Dependent} {Regularization} {Approach}},
volume = {23},
issn = {2162-237X},
shorttitle = {Domain {Adaptation} {From} {Multiple} {Sources}},
doi = {10.1109/TNNLS.2011.2178556},
abstract = {In this paper, we propose a new framework called domain adaptation machine (DAM) for the multiple source domain adaption problem. Under this framework, we learn a robust decision function (referred to as target classifier) for label prediction of instances from the target domain by leveraging a set of base classifiers which are prelearned by using labeled instances either from the source domains or from the source domains and the target domain. With the base classifiers, we propose a new domain-dependent regularizer based on smoothness assumption, which enforces that the target classifier shares similar decision values with the relevant base classifiers on the unlabeled instances from the target domain. This newly proposed regularizer can be readily incorporated into many kernel methods (e.g., support vector machines (SVM), support vector regression, and least-squares SVM (LS-SVM)). For domain adaptation, we also develop two new domain adaptation methods referred to as FastDAM and UniverDAM. In FastDAM, we introduce our proposed domain-dependent regularizer into LS-SVM as well as employ a sparsity regularizer to learn a sparse target classifier with the support vectors only from the target domain, which thus makes the label prediction on any test instance very fast. In UniverDAM, we additionally make use of the instances from the source domains as Universum to further enhance the generalization ability of the target classifier. We evaluate our two methods on the challenging TRECIVD 2005 dataset for the large-scale video concept detection task as well as on the 20 newsgroups and email spam datasets for document retrieval. Comprehensive experiments demonstrate that FastDAM and UniverDAM outperform the existing multiple source domain adaptation methods for the two applications.},
number = {3},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
author = {Duan, L. and Xu, D. and Tsang, I. W. H.},
month = mar,
year = {2012},
keywords = {FastDAM method, Kernel, Kernel methods, LS-SVM, Learning systems, Training, Training data, UniverDAM method, Vectors, base classifiers, document retrieval, domain adaptation machine, domain-dependent regularization approach, domain-dependent regularizer, email spam datasets, instances label prediction, large-scale video concept detection task, learning (artificial intelligence), least squares approximations, least-squares support vector machines, multiple source domain adaptation, multiple source domain adaption problem, pattern classification, robust decision function, robustness, smoothness assumption, support vector machines},
pages = {504--518},
}

@inproceedings{duan_domain_2009,
address = {New York, NY, USA},
series = {{ICML} '09},
title = {Domain {Adaptation} from {Multiple} {Sources} via {Auxiliary} {Classifiers}},
isbn = {978-1-60558-516-1},
url = {http://doi.acm.org/10.1145/1553374.1553411},
doi = {10.1145/1553374.1553411},
abstract = {We propose a multiple source domain adaptation method, referred to as Domain Adaptation Machine (DAM), to learn a robust decision function (referred to as target classifier) for label prediction of patterns from the target domain by leveraging a set of pre-computed classifiers (referred to as auxiliary/source classifiers) independently learned with the labeled patterns from multiple source domains. We introduce a new data-dependent regularizer based on smoothness assumption into Least-Squares SVM (LS-SVM), which enforces that the target classifier shares similar decision values with the auxiliary classifiers from relevant source domains on the unlabeled patterns of the target domain. In addition, we employ a sparsity regularizer to learn a sparse target classifier. Comprehensive experiments on the challenging TRECVID 2005 corpus demonstrate that DAM outperforms the existing multiple source domain adaptation methods for video concept detection in terms of effectiveness and efficiency.},
booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning}},
publisher = {ACM},
author = {Duan, Lixin and Tsang, Ivor W. and Xu, Dong and Chua, Tat-Seng},
year = {2009},
pages = {289--296},
}

@inproceedings{bickel_discriminative_2007,
address = {New York, NY, USA},
series = {{ICML} '07},
title = {Discriminative {Learning} for {Differing} {Training} and {Test} {Distributions}},
isbn = {978-1-59593-793-3},
url = {http://doi.acm.org/10.1145/1273496.1273507},
doi = {10.1145/1273496.1273507},
abstract = {We address classification problems for which the training instances are governed by a distribution that is allowed to differ arbitrarily from the test distribution---problems also referred to as classification under covariate shift. We derive a solution that is purely discriminative: neither training nor test distribution are modeled explicitly. We formulate the general problem of learning under covariate shift as an integrated optimization problem. We derive a kernel logistic regression classifier for differing training and test distributions.},
booktitle = {Proceedings of the 24th {International} {Conference} on {Machine} {Learning}},
publisher = {ACM},
author = {Bickel, Steffen and Brückner, Michael and Scheffer, Tobias},
year = {2007},
pages = {81--88},
}

@inproceedings{sugiyama_direct_2007,
address = {USA},
series = {{NIPS}'07},
title = {Direct {Importance} {Estimation} with {Model} {Selection} and {Its} {Application} to {Covariate} {Shift} {Adaptation}},
isbn = {978-1-60560-352-0},
url = {http://dl.acm.org/citation.cfm?id=2981562.2981742},
abstract = {A situation where training and test samples follow different input distributions is called covariate shift. Under covariate shift, standard learning methods such as maximum likelihood estimation are no longer consistent—weighted variants according to the ratio of test and training input densities are consistent. Therefore, accurately estimating the density ratio, called the importance, is one of the key issues in covariate shift adaptation. A naive approach to this task is to first estimate training and test input densities separately and then estimate the importance by taking the ratio of the estimated densities. However, this naive approach tends to perform poorly since density estimation is a hard task particularly in high dimensional cases. In this paper, we propose a direct importance estimation method that does not involve density estimation. Our method is equipped with a natural cross validation procedure and hence tuning parameters such as the kernel width can be objectively optimized. Simulations illustrate the usefulness of our approach.},
booktitle = {Proceedings of the 20th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
publisher = {Curran Associates Inc.},
author = {Sugiyama, Masashi and Nakajima, Shinichi and Kashima, Hisashi and Bünau, Paul von and Kawanabe, Motoaki},
year = {2007},
pages = {1433--1440},
}

@inproceedings{huang_correcting_2006,
address = {Cambridge, MA, USA},
series = {{NIPS}'06},
title = {Correcting {Sample} {Selection} {Bias} by {Unlabeled} {Data}},
url = {http://dl.acm.org/citation.cfm?id=2976456.2976532},
abstract = {We consider the scenario where training and test data are drawn from different distributions, commonly referred to as sample selection bias. Most algorithms for this setting try to first recover sampling distributions and then make appropriate corrections based on the distribution estimate. We present a nonparametric method which directly produces resampling weights without distribution estimation. Our method works by matching distributions between training and testing sets in feature space. Experimental results demonstrate that our method works well in practice.},
booktitle = {Proceedings of the 19th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
publisher = {MIT Press},
author = {Huang, Jiayuan and Smola, Alexander J. and Gretton, Arthur and Borgwardt, Karsten M. and Scholkopf, Bernhard},
year = {2006},
pages = {601--608},
}

@article{pan_survey_2010,
title = {A {Survey} on {Transfer} {Learning}},
volume = {22},
issn = {1041-4347},
doi = {10.1109/TKDE.2009.191},
abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
number = {10},
journal = {IEEE Transactions on Knowledge and Data Engineering},
author = {Pan, S. J. and Yang, Q.},
month = oct,
year = {2010},
keywords = {Data Mining, Labeling, Learning systems, Machine learning algorithms, Space technology, Testing, Training data, data mining., inductive transfer learning, knowledge engineering, knowledge transfer, learning by example, machine learning, optimisation, survey, transductive transfer learning, transfer learning, unsupervised learning, unsupervised transfer learning},
pages = {1345--1359},
}

@inproceedings{ben-david_impossibility_2010,
title = {Impossibility {Theorems} for {Domain} {Adaptation}},
url = {http://proceedings.mlr.press/v9/david10a.html},
abstract = {The domain adaptation problem in machine learning occurs when the test data generating distribution differs from the one that generates the training data. It is clear that the success of learning u...},
language = {en},
urldate = {2017-06-03},
booktitle = {{PMLR}},
author = {Ben-David, Shai and Tyler, Lu and Teresa, Luu and David, Pal},
month = mar,
year = {2010},
pages = {129--136},
}

@article{ben-david_domain_2014,
title = {Domain adaptation–can quantity compensate for quality?},
volume = {70},
issn = {1012-2443, 1573-7470},
url = {https://link.springer.com/article/10.1007/s10472-013-9371-9},
doi = {10.1007/s10472-013-9371-9},
abstract = {The Domain Adaptation problem in machine learning occurs when the distribution generating the test data differs from the one that generates the training data. A common approach to this issue is to train a standard learner for the learning task with the available training sample (generated by a distribution that is different from the test distribution). One can view such learning as learning from a not-perfectly-representative training sample. The question we focus on is under which circumstances large sizes of such training samples can guarantee that the learned classifier preforms just as well as one learned from target generated samples. In other words, are there circumstances in which quantity can compensate for quality (of the training data)? We give a positive answer, showing that this is possible when using a Nearest Neighbor algorithm. We show this under some assumptions about the relationship between the training and the target data distributions (the assumptions of covariate shift as well as a bound on the ratio of certain probability weights between the source (training) and target (test) distribution). We further show that in a slightly different learning model, when one imposes restrictions on the nature of the learned classifier, these assumptions are not always sufficient to allow such a replacement of the training sample: For proper learning, where the output classifier has to come from a predefined class, we prove that any learner needs access to data generated from the target distribution.},
language = {en},
number = {3},
urldate = {2017-06-03},
journal = {Annals of Mathematics and Artificial Intelligence},
author = {Ben-David, Shai and Urner, Ruth},
month = mar,
year = {2014},
pages = {185--202},
}

@article{ben-david_theory_2010,
title = {A theory of learning from different domains},
volume = {79},
issn = {0885-6125, 1573-0565},
url = {https://link.springer.com/article/10.1007/s10994-009-5152-4},
doi = {10.1007/s10994-009-5152-4},
abstract = {Discriminative learning methods for classification perform well when training and test data are drawn from the same distribution. Often, however, we have plentiful labeled training data from a source domain but wish to learn a classifier which performs well on a target domain with a different distribution and little or no labeled training data. In this work we investigate two questions. First, under what conditions can a classifier trained from source data be expected to perform well on target data? Second, given a small amount of labeled target data, how should we combine it during training with the large amount of labeled source data to achieve the lowest target error at test time?We address the first question by bounding a classifier’s target error in terms of its source error and the divergence between the two domains. We give a classifier-induced divergence measure that can be estimated from finite, unlabeled samples from the domains. Under the assumption that there exists some hypothesis that performs well in both domains, we show that this quantity together with the empirical source error characterize the target error of a source-trained classifier.We answer the second question by bounding the target error of a model which minimizes a convex combination of the empirical source and target errors. Previous theoretical work has considered minimizing just the source error, just the target error, or weighting instances from the two domains equally. We show how to choose the optimal combination of source and target error as a function of the divergence, the sample sizes of both domains, and the complexity of the hypothesis class. The resulting bound generalizes the previously studied cases and is always at least as tight as a bound which considers minimizing only the target error or an equal weighting of source and target errors.},
language = {en},
number = {1-2},
urldate = {2017-06-03},
journal = {Machine Learning},
author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
month = may,
year = {2010},
pages = {151--175},
}

@techreport{noauthor_theory:_nodate,
title = {Theory: {Domain} {Adaptation}},
}

@article{signorini_use_2011,
title = {The {Use} of {Twitter} to {Track} {Levels} of {Disease} {Activity} and {Public} {Concern} in the {U}.{S}. during the {Influenza} {A} {H1N1} {Pandemic}},
volume = {6},
issn = {1932-6203},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0019467},
doi = {10.1371/journal.pone.0019467},
abstract = {Twitter is a free social networking and micro-blogging service that enables its millions of users to send and read each other's “tweets,” or short, 140-character messages. The service has more than 190 million registered users and processes about 55 million tweets per day. Useful information about news and geopolitical events lies embedded in the Twitter stream, which embodies, in the aggregate, Twitter users' perspectives and reactions to current events. By virtue of sheer volume, content embedded in the Twitter stream may be useful for tracking or even forecasting behavior if it can be extracted in an efficient manner. In this study, we examine the use of information embedded in the Twitter stream to (1) track rapidly-evolving public sentiment with respect to H1N1 or swine flu, and (2) track and measure actual disease activity. We also show that Twitter can be used as a measure of public interest or concern about health-related events. Our results show that estimates of influenza-like illness derived from Twitter chatter accurately track reported disease levels.},
number = {5},
urldate = {2017-06-01},
journal = {PLOS ONE},
author = {Signorini, Alessio and Segre, Alberto Maria and Polgreen, Philip M.},
month = may,
year = {2011},
keywords = {1, H, P, S, T, a, b, c, d, e, f, i, k, l, n, o, r, u, v, w, z},
pages = {e19467},
}

@inproceedings{barbosa_robust_2010,
address = {Stroudsburg, PA, USA},
series = {{COLING} '10},
title = {Robust {Sentiment} {Detection} on {Twitter} from {Biased} and {Noisy} {Data}},
url = {http://dl.acm.org/citation.cfm?id=1944566.1944571},
abstract = {In this paper, we propose an approach to automatically detect sentiments on Twitter messages (tweets) that explores some characteristics of how tweets are written and meta-information of the words that compose these messages. Moreover, we leverage sources of noisy labels as our training data. These noisy labels were provided by a few sentiment detection websites over twitter data. In our experiments, we show that since our features are able to capture a more abstract representation of tweets, our solution is more effective than previous ones and also more robust regarding biased and noisy data, which is the kind of data provided by these sources.},
booktitle = {Proceedings of the 23rd {International} {Conference} on {Computational} {Linguistics}: {Posters}},
publisher = {Association for Computational Linguistics},
author = {Barbosa, Luciano and Feng, Junlan},
year = {2010},
pages = {36--44},
}

@inproceedings{castillo_information_2011,
address = {New York, NY, USA},
series = {{WWW} '11},
title = {Information {Credibility} on {Twitter}},
isbn = {978-1-4503-0632-4},
url = {http://doi.acm.org/10.1145/1963405.1963500},
doi = {10.1145/1963405.1963500},
abstract = {We analyze the information credibility of news propagated through Twitter, a popular microblogging service. Previous research has shown that most of the messages posted on Twitter are truthful, but the service is also used to spread misinformation and false rumors, often unintentionally. On this paper we focus on automatic methods for assessing the credibility of a given set of tweets. Specifically, we analyze microblog postings related to "trending" topics, and classify them as credible or not credible, based on features extracted from them. We use features from users' posting and re-posting ("re-tweeting") behavior, from the text of the posts, and from citations to external sources. We evaluate our methods using a significant number of human assessments about the credibility of items on a recent sample of Twitter postings. Our results shows that there are measurable differences in the way messages propagate, that can be used to classify them automatically as credible or not credible, with precision and recall in the range of 70\% to 80\%.},
booktitle = {Proceedings of the 20th {International} {Conference} on {World} {Wide} {Web}},
publisher = {ACM},
author = {Castillo, Carlos and Mendoza, Marcelo and Poblete, Barbara},
year = {2011},
keywords = {social media analytics, social media credibility, twitter},
pages = {675--684},
}

@article{junco_effect_2011,
title = {The effect of {Twitter} on college student engagement and grades},
volume = {27},
issn = {1365-2729},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1365-2729.2010.00387.x/abstract},
doi = {10.1111/j.1365-2729.2010.00387.x},
abstract = {Despite the widespread use of social media by students and its increased use by instructors, very little empirical evidence is available concerning the impact of social media use on student learning and engagement. This paper describes our semester-long experimental study to determine if using Twitter – the microblogging and social networking platform most amenable to ongoing, public dialogue – for educationally relevant purposes can impact college student engagement and grades. A total of 125 students taking a first year seminar course for pre-health professional majors participated in this study (70 in the experimental group and 55 in the control group). With the experimental group, Twitter was used for various types of academic and co-curricular discussions. Engagement was quantified by using a 19-item scale based on the National Survey of Student Engagement. To assess differences in engagement and grades, we used mixed effects analysis of variance (ANOVA) models, with class sections nested within treatment groups. We also conducted content analyses of samples of Twitter exchanges. The ANOVA results showed that the experimental group had a significantly greater increase in engagement than the control group, as well as higher semester grade point averages. Analyses of Twitter communications showed that students and faculty were both highly engaged in the learning process in ways that transcended traditional classroom activities. This study provides experimental evidence that Twitter can be used as an educational tool to help engage students and to mobilize faculty into a more active and participatory role.},
language = {en},
number = {2},
journal = {Journal of Computer Assisted Learning},
author = {Junco, R. and Heiberger, G. and Loken, E.},
month = apr,
year = {2011},
keywords = {Social Media, cooperative/collaborative learning, learning communities, media in education, post-secondary education, teaching/learning strategies},
pages = {119--132},
}

@inproceedings{sriram_short_2010,
address = {New York, NY, USA},
series = {{SIGIR} '10},
title = {Short {Text} {Classification} in {Twitter} to {Improve} {Information} {Filtering}},
isbn = {978-1-4503-0153-4},
url = {http://doi.acm.org/10.1145/1835449.1835643},
doi = {10.1145/1835449.1835643},
abstract = {In microblogging services such as Twitter, the users may become overwhelmed by the raw data. One solution to this problem is the classification of short text messages. As short texts do not provide sufficient word occurrences, traditional classification methods such as "Bag-Of-Words" have limitations. To address this problem, we propose to use a small set of domain-specific features extracted from the author's profile and text. The proposed approach effectively classifies the text to a predefined set of generic classes such as News, Events, Opinions, Deals, and Private Messages.},
booktitle = {Proceedings of the 33rd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
publisher = {ACM},
author = {Sriram, Bharath and Fuhry, Dave and Demir, Engin and Ferhatosmanoglu, Hakan and Demirbas, Murat},
year = {2010},
keywords = {classification, feature selection, short text, twitter},
pages = {841--842},
}

@article{jansen_twitter_2009,
title = {Twitter power: {Tweets} as electronic word of mouth},
volume = {60},
issn = {1532-2890},
shorttitle = {Twitter power},
url = {http://onlinelibrary.wiley.com/doi/10.1002/asi.21149/abstract},
doi = {10.1002/asi.21149},
abstract = {In this paper we report research results investigating microblogging as a form of electronic word-of-mouth for sharing consumer opinions concerning brands. We analyzed more than 150,000 microblog postings containing branding comments, sentiments, and opinions. We investigated the overall structure of these microblog postings, the types of expressions, and the movement in positive or negative sentiment. We compared automated methods of classifying sentiment in these microblogs with manual coding. Using a case study approach, we analyzed the range, frequency, timing, and content of tweets in a corporate account. Our research findings show that 19\% of microblogs contain mention of a brand. Of the branding microblogs, nearly 20\% contained some expression of brand sentiments. Of these, more than 50\% were positive and 33\% were critical of the company or product. Our comparison of automated and manual coding showed no significant differences between the two approaches. In analyzing microblogs for structure and composition, the linguistic structure of tweets approximate the linguistic patterns of natural language expressions. We find that microblogging is an online tool for customer word of mouth communications and discuss the implications for corporations using microblogging as part of their overall marketing strategy.},
language = {en},
number = {11},
journal = {Journal of the American Society for Information Science and Technology},
author = {Jansen, Bernard J. and Zhang, Mimi and Sobel, Kate and Chowdury, Abdur},
month = nov,
year = {2009},
keywords = {classification, marketing, sentiment analysis, social networking, twitter},
pages = {2169--2188},
}

@inproceedings{sakaki_earthquake_2010,
address = {New York, NY, USA},
series = {{WWW} '10},
title = {Earthquake {Shakes} {Twitter} {Users}: {Real}-time {Event} {Detection} by {Social} {Sensors}},
isbn = {978-1-60558-799-8},
shorttitle = {Earthquake {Shakes} {Twitter} {Users}},
url = {http://doi.acm.org/10.1145/1772690.1772777},
doi = {10.1145/1772690.1772777},
abstract = {Twitter, a popular microblogging service, has received much attention recently. An important characteristic of Twitter is its real-time nature. For example, when an earthquake occurs, people make many Twitter posts (tweets) related to the earthquake, which enables detection of earthquake occurrence promptly, simply by observing the tweets. As described in this paper, we investigate the real-time interaction of events such as earthquakes in Twitter and propose an algorithm to monitor tweets and to detect a target event. To detect a target event, we devise a classifier of tweets based on features such as the keywords in a tweet, the number of words, and their context. Subsequently, we produce a probabilistic spatiotemporal model for the target event that can find the center and the trajectory of the event location. We consider each Twitter user as a sensor and apply Kalman filtering and particle filtering, which are widely used for location estimation in ubiquitous/pervasive computing. The particle filter works better than other comparable methods for estimating the centers of earthquakes and the trajectories of typhoons. As an application, we construct an earthquake reporting system in Japan. Because of the numerous earthquakes and the large number of Twitter users throughout the country, we can detect an earthquake with high probability (96\% of earthquakes of Japan Meteorological Agency (JMA) seismic intensity scale 3 or more are detected) merely by monitoring tweets. Our system detects earthquakes promptly and sends e-mails to registered users. Notification is delivered much faster than the announcements that are broadcast by the JMA.},
booktitle = {Proceedings of the 19th {International} {Conference} on {World} {Wide} {Web}},
publisher = {ACM},
author = {Sakaki, Takeshi and Okazaki, Makoto and Matsuo, Yutaka},
year = {2010},
keywords = {earthquake, event detection, location estimation, social sensor, twitter},
pages = {851--860},
}

@techreport{noauthor_doctoal_nodate,
title = {Doctoal consortium proposal},
}

@article{sporik_association_1995,
title = {Association of asthma with serum {IgE} and skin test reactivity to allergens among children living at high altitude. {Tickling} the dragon's breath},
volume = {151},
issn = {1073-449X},
doi = {10.1164/ajrccm.151.5.7735590},
abstract = {Asthma in children and young adults is strongly associated with immediate hypersensitivity to indoor allergens, notably those derived from the house dust mite. In addition, outdoor air pollution is considered to aggravate existing asthma. We investigated the prevalence of asthma and the pattern of allergen sensitization in a mite-free environment with low levels of outdoor air pollution. A total of 567 children aged between 12 and 14 attending Los Alamos Middle School, NM (altitude 7,200 feet) were screened using a respiratory questionnaire; 120 children (53 control children) underwent allergen skin testing and serum IgE measurement, and their bronchial reactivity to histamine was measured. Dust was collected from 111 homes and the level of indoor mite and cat allergen measured. The prevalence of respiratory symptoms was high (13\%), and from the detailed testing it was estimated that 6.3\% of the children had asthma (defined as symptomatic bronchial reactivity). Children with asthma had elevated IgE, 367 (179 to 755) versus 38 (23 to 61), and predominant sensitization to cat, 68 versus 20\% (p {\textless} 0.001). A high number of households (77\%) had a pet cat or dog. The concentration of mite allergen was very low (mean 0.18 micrograms Der p milligrams sieved house dust), whereas that of cat allergen was high in homes with a cat (80.8 micrograms Fel d milligrams) but also in homes with no cat (3.2 micrograms Fel d milligrams). The results show that in a mite-free environment with low levels of outdoor air pollution, asthma was still a major cause of morbidity among schoolchildren.(ABSTRACT TRUNCATED AT 250 WORDS)},
language = {eng},
number = {5},
journal = {American Journal of Respiratory and Critical Care Medicine},
author = {Sporik, R. and Ingram, J. M. and Price, W. and Sussman, J. H. and Honsinger, R. W. and Platts-Mills, T. A.},
month = may,
year = {1995},
pmid = {7735590},
keywords = {Adolescent, Allergens, Altitude, Animals, Asthma, Cats, Child, Dogs, Humans, Immunoglobulin E, Mites, New Mexico, Respiratory Hypersensitivity, Skin Tests},
pages = {1388--1392},
}

@article{zhou_th2_2001,
title = {Th2 cytokines and asthma — {Interleukin}-9 as a therapeutic target for asthma},
volume = {2},
issn = {1465-9921},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC59572/},
doi = {10.1186/rr42},
abstract = {Asthma is a complex heritable inflammatory disorder of the airways in which the development of clinical disease depends on environmental exposure. It has been well established that T helper type 2 (TH2) lymphocytes and their cytokines have an important role in allergic asthma. Interleukin (IL)-9, a member of the TH2 cytokine family, has recently been implicated as an essential factor in determining mucosal immunity and susceptibility to atopic asthma. In this review we examine the critical experiments and observations that support this hypothesis. We also discuss these results in comparison with the experiments supporting the involvement of other TH2 cytokines such as IL-4, IL-5 and IL-13.},
number = {2},
urldate = {2017-04-28},
journal = {Respiratory Research},
author = {Zhou, Yuhong and McLane, Michael and Levitt, Roy C},
year = {2001},
pmid = {11686869},
pmcid = {PMC59572},
pages = {80--84},
}

@inproceedings{noauthor_examining_nodate,
title = {Examining {Patterns} of {Inﬂuenza} {Vaccination} in {Social} {Media}},
}

@inproceedings{tang_learning_2014,
address = {Baltimore, Maryland, USA},
title = {Learning {Sentiment}-{Speciﬁc} {Word} {Embedding} for {Twitter} {Sentiment} {Classiﬁcation}},
booktitle = {the 52nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
publisher = {Association for Computational Linguistics},
author = {Tang, Duyu and Wei, Furu and Yang, Nan and Zhou, Ming and Liu, Ting and Qin, Bing},
month = jun,
year = {2014},
pages = {1555--1565},
}

@article{tang_sentiment_2016,
title = {Sentiment {Embeddings} with {Applications} to {Sentiment} {Analysis}},
volume = {28},
issn = {1041-4347},
doi = {10.1109/TKDE.2015.2489653},
abstract = {We propose learning sentiment-specific word embeddings dubbed sentiment embeddings in this paper. Existing word embedding learning algorithms typically only use the contexts of words but ignore the sentiment of texts. It is problematic for sentiment analysis because the words with similar contexts but opposite sentiment polarity, such as good and bad, are mapped to neighboring word vectors. We address this issue by encoding sentiment information of texts (e.g., sentences and words) together with contexts of words in sentiment embeddings. By combining context and sentiment level evidences, the nearest neighbors in sentiment embedding space are semantically similar and it favors words with the same sentiment polarity. In order to learn sentiment embeddings effectively, we develop a number of neural networks with tailoring loss functions, and collect massive texts automatically with sentiment signals like emoticons as the training data. Sentiment embeddings can be naturally used as word features for a variety of sentiment analysis tasks without feature engineering. We apply sentiment embeddings to word-level sentiment analysis, sentence level sentiment classification, and building sentiment lexicons. Experimental results show that sentiment embeddings consistently outperform context-based embeddings on several benchmark datasets of these tasks. This work provides insights on the design of neural networks for learning task-specific word embeddings in other natural language processing tasks.},
number = {2},
journal = {IEEE Transactions on Knowledge and Data Engineering},
author = {Tang, D. and Wei, F. and Qin, B. and Yang, N. and Liu, T. and Zhou, M.},
month = feb,
year = {2016},
keywords = {Context, Context modeling, Mathematical model, Neural networks, Predictive models, Vocabulary, natural language processing, sentiment analysis, word embeddings},
pages = {496--509},
}

@inproceedings{moghaddam_gender_2000,
title = {Gender classification with support vector machines},
doi = {10.1109/AFGR.2000.840651},
abstract = {Support vector machines (SVM) are investigated for visual gender classification with low-resolution “thumbnail” faces (21-by-12 pixels) processed from 1755 images from the FERET face database. The performance of SVM (3.4\% error) is shown to be superior to traditional pattern classifiers (linear, quadratic, Fisher linear discriminant, nearest-neighbor) as well as more modern techniques such as radial basis function (RBF) classifiers and large ensemble-RBF networks. SVM also out-performed human test subjects at the same task: in a perception study with 30 human test subjects, ranging in age from mid-20s to mid-40s, the average error rate was found to be 32\% for the “thumbnails” and 6.7\% with higher resolution images. The difference in performance between low- and high-resolution tests with SVM was only 1\%, demonstrating robustness and relative scale invariance for visual classification},
booktitle = {Proceedings {Fourth} {IEEE} {International} {Conference} on {Automatic} {Face} and {Gesture} {Recognition} ({Cat}. {No}. {PR00580})},
author = {Moghaddam, B. and Yang, Ming-Hsuan},
year = {2000},
keywords = {Error analysis, FERET face database, Humans, Image databases, Pixel, Support vector machine classification, Testing, Visual databases, face recognition, image classification, image resolution, learning (artificial intelligence), performance, robustness, scale invariance, support vector machines, thumbnail faces, visual gender classification},
pages = {306--311},
}

@article{shan_learning_2012,
series = {Intelligent {Multimedia} {Interactivity}},
title = {Learning local binary patterns for gender classification on real-world face images},
volume = {33},
issn = {0167-8655},
url = {http://www.sciencedirect.com/science/article/pii/S0167865511001607},
doi = {10.1016/j.patrec.2011.05.016},
abstract = {Gender recognition is one of fundamental face analysis tasks. Most of the existing studies have focused on face images acquired under controlled conditions. However, real-world applications require gender classification on real-life faces, which is much more challenging due to significant appearance variations in unconstrained scenarios. In this paper, we investigate gender recognition on real-life faces using the recently built database, the Labeled Faces in the Wild (LFW). Local Binary Patterns (LBP) is employed to describe faces, and Adaboost is used to select the discriminative LBP features. We obtain the performance of 94.81\% by applying Support Vector Machine (SVM) with the boosted LBP features. The public database used in this study makes future benchmark and evaluation possible.},
number = {4},
urldate = {2017-04-27},
journal = {Pattern Recognition Letters},
author = {Shan, Caifeng},
month = mar,
year = {2012},
keywords = {Face image analysis, Gender classification, Local binary patterns},
pages = {431--437},
}

@inproceedings{zhang_key_2016,
address = {Nashville, USA},
title = {Key {Conversation} {Trends} and {Patterns} about {Electronic} {Cigarettes} on {Social} {Media}},
booktitle = {Text {Mining} in {Health} and {Security} {Analytics}},
author = {Zhang, Wenli and Ram, Sudha},
month = nov,
year = {2016},
}

@article{mohammad_nrc-canada:_2013,
title = {{NRC}-{Canada}: {Building} the {State}-of-the-{Art} in {Sentiment} {Analysis} of {Tweets}},
shorttitle = {{NRC}-{Canada}},
url = {http://arxiv.org/abs/1308.6242},
abstract = {In this paper, we describe how we created two state-of-the-art SVM classifiers, one to detect the sentiment of messages such as tweets and SMS (message-level task) and one to detect the sentiment of a term within a submissions stood first in both tasks on tweets, obtaining an F-score of 69.02 in the message-level task and 88.93 in the term-level task. We implemented a variety of surface-form, semantic, and sentiment features. with sentiment-word hashtags, and one from tweets with emoticons. In the message-level task, the lexicon-based features provided a gain of 5 F-score points over all others. Both of our systems can be replicated us available resources.},
urldate = {2017-04-26},
journal = {arXiv:1308.6242 [cs]},
author = {Mohammad, Saif M. and Kiritchenko, Svetlana and Zhu, Xiaodan},
month = aug,
year = {2013},
note = {arXiv: 1308.6242},
keywords = {Computer Science - Computation and Language},
}

@article{fosso_wamba_how_2015,
title = {How ‘big data’ can make big impact: {Findings} from a systematic review and a longitudinal case study},
volume = {165},
issn = {0925-5273},
shorttitle = {How ‘big data’ can make big impact},
url = {http://www.sciencedirect.com/science/article/pii/S0925527314004253},
doi = {10.1016/j.ijpe.2014.12.031},
abstract = {Big data has the potential to revolutionize the art of management. Despite the high operational and strategic impacts, there is a paucity of empirical research to assess the business value of big data. Drawing on a systematic review and case study findings, this paper presents an interpretive framework that analyzes the definitional perspectives and the applications of big data. The paper also provides a general taxonomy that helps broaden the understanding of big data and its role in capturing business value. The synthesis of the diverse concepts within the literature on big data provides deeper insights into achieving value through big data strategy and implementation.},
urldate = {2017-04-26},
journal = {International Journal of Production Economics},
author = {Fosso Wamba, Samuel and Akter, Shahriar and Edwards, Andrew and Chopin, Geoffrey and Gnanzou, Denis},
month = jul,
year = {2015},
keywords = {Analytics, Business value, Case study, Issues, Literature review, emergency services, ‘Big data’},
pages = {234--246},
}

@misc{cdc_cdc_2017,
title = {{CDC} - {Asthma}},
url = {https://www.cdc.gov/asthma/},
urldate = {2017-04-20},
author = {CDC},
year = {2017},
}

@inproceedings{peng_movies_2011,
address = {Tianjin, China},
title = {Movies {Recommenders} {Systems}: {Fuzzy} {Multiple} {Criteria} {Decision} {Making} {Approach}},
author = {Peng, Yi and Zhang, Wenli and Kou, Gang and Shi, Yong},
month = jul,
year = {2011},
}

@inproceedings{zhang_asthma_2015,
address = {Washington DC, US},
title = {Asthma {Surveillance} {Using} {Social} {Media} {Data}},
booktitle = {Social {Media} in {Healthcare} {Panel}},
author = {Zhang, Wenli and Ram, Sudha and Burkart, Mark and Williams, Max and Pengetnze, Yolande},
month = oct,
year = {2015},
}

@inproceedings{peng_fuzzy_2011,
address = {Chengdu, China},
title = {A {Fuzzy} {MCDM} {Based} {Approach} for {Hybrid} {Recommender} {Systems}},
author = {Peng, Yi and Zhang, Wenli and Kou, Gang},
month = sep,
year = {2011},
}

@inproceedings{peng_hybrid_2011,
address = {Shanghai, China},
title = {A {Hybrid} {Movie} {Recommender} {System}},
author = {Peng, Yi and Zhang, Wenli and Kou, Gang},
month = dec,
year = {2011},
}

@inproceedings{zhang_comprehensive_2015,
address = {Dallas, Texas, USA},
title = {A {Comprehensive} {Methodology} for {Extracting} {Signal} from {Social} {Media} {Text} {Using} {Natural} {Language} {Processing} and {Machine} {Learning}},
author = {Zhang, Wenli and Ram, Sudha},
month = dec,
year = {2015},
}

@inproceedings{zhang_extracting_2016,
address = {Montreal, Quebec, Canada},
series = {{DH} '16},
title = {Extracting {Signals} from {Social} {Media} for {Chronic} {Disease} {Surveillance}},
isbn = {978-1-4503-4224-7},
url = {http://doi.acm.org/10.1145/2896338.2897728},
doi = {10.1145/2896338.2897728},
abstract = {Asthma is a chronic disease that affects people of all ages, and is a serious health and economic concern worldwide. However, accurate and timely surveillance and predicting hospital visits could allow for targeted interventions and reduce the societal burden of asthma. Current national asthma disease surveillance systems can have data availability lags of up to months and years. Rapid progress has been made in gathering social media data to perform disease surveillance and prediction. We introduce novel methods for extracting signals from social media data to assist in accurate and timely asthma surveillance. Our empirical analyses show that our methods are very effective for surveillance of asthma prevalence at both state and municipal levels. They are also useful for predicting the number of hospital visits based on near-real-time social media data for specific geographic areas. Our results can be used for public health surveillance, ED preparedness, and targeted patient interventions.},
urldate = {2017-04-24},
booktitle = {Proceedings of the 6th {International} {Conference} on {Digital} {Health} {Conference}},
publisher = {ACM},
author = {Zhang, Wenli and Ram, Sudha and Burkart, Mark and Pengetnze, Yolande},
year = {2016},
keywords = {Asthma, Big Data, Emergency Department Visits, Environmental Sensors, Predictive Modeling, Social Media},
pages = {79--83},
}

@techreport{fda_e-cigarette_2014,
title = {E-cigarette {Adverse} {Events}},
url = {https://www.fda.gov/tobaccoproducts/aboutctp/ucm221165.htm},
abstract = {You can read the adverse event reports for ENDS that were voluntarily reported to FDA at the FOIA Electronic Reading Room.},
author = {FDA},
year = {2014},
}

@article{huang_cross-sectional_2014,
title = {A cross-sectional examination of marketing of electronic cigarettes on {Twitter}},
volume = {23},
copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions.  This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 3.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/3.0/},
issn = {0964-4563, 1468-3318},
url = {http://tobaccocontrol.bmj.com/content/23/suppl_3/iii26},
doi = {10.1136/tobaccocontrol-2014-051551},
abstract = {Background Rapid increases in marketing of e-cigarettes coincide with growth in e-cigarette use in recent years; however, little is known about how e-cigarettes are marketed on social media platforms.
Methods Keywords were used to collect tweets related to e-cigarettes from the Twitter Firehose between 1 May 2012 and 30 June 2012. Tweets were coded for smoking cessation mentions, as well as health and safety mentions, and were classified as commercial or non-commercial (‘organic’) tweets using a combination of Naïve Bayes machine learning methods, keyword algorithms and human coding. Metadata associated with each tweet were used to examine the characteristics of accounts tweeting about e-cigarettes.
Results 73 672 tweets related to e-cigarettes were captured in the study period, 90\% of which were classified as commercial tweets. Accounts tweeting commercial e-cigarette content were associated with lower Klout scores, a measure of influence. Commercial tweeting was largely driven by a small group of highly active accounts, and 94\% of commercial tweets included links to websites, many of which sell or promote e-cigarettes. Approximately 10\% of commercial and organic tweets mentioned smoking cessation, and 34\% of commercial tweets included mentions of prices or discounts for e-cigarettes.
Conclusions Twitter appears to be an important marketing platform for e-cigarettes. Tweets related to e-cigarettes were overwhelmingly commercial, and a substantial proportion mentioned smoking cessation. E-cigarette marketing on Twitter may have public health implications. Continued surveillance of e-cigarette marketing on social media platforms is needed.},
language = {en},
number = {suppl 3},
urldate = {2017-04-23},
journal = {Tobacco Control},
author = {Huang, Jidong and Kornfield, Rachel and Szczypka, Glen and Emery, Sherry L.},
month = jul,
year = {2014},
pmid = {24935894},
keywords = {Media, Social marketing, electronic nicotine delivery devices},
pages = {iii26--iii30},
}

@inproceedings{han_method_2011,
title = {The {Method} of {Medical} {Named} {Entity} {Recognition} {Based} on {Semantic} {Model} and {Improved} {SVM}-{KNN} {Algorithm}},
doi = {10.1109/SKG.2011.24},
abstract = {In the medical field, a lot of unstructured information which is expressed by natural language exists in medical literature, technical documentation and medical records. IE (Information Extraction) as one of the most important research directions in natural language process aims to help humans extract concerned information automatically. NER (Named Entity Recognition) is one of the subsystems of IE and has direct influence on the quality of IE. Nowadays NER of medical field has not reached ideal precision largely due to the knowledge complexity in medical field. It is hard to describe the medical entity definitely in feature selection and current selected features are not rich and lack of semantic information. Besides that, different medical entities which have the similar characters more easily cause classification algorithm making wrong judgment. Combination multi classification algorithms such as SVM-KNN can overcome its own disadvantages and get higher performance. But current SVM-KNN classification algorithm may provide wrong categories results due to setting inappropriate K value and unbalanced examples distribution. In this paper, we introduce two-level modelling tool to help specialists to build semantic models and select features from them. We design and implement medical named entity recognition analysis engine based on UIMA framework and adopt improved SVM-KNN algorithm called EK-SVM-KNN (Extending K SVM-KNN) in classification. We collect experiment data from SLE(Systemic Lupus Erythematosus) clinical information system in Renji Hospital. We adopt 50 Pathology reports as training data and provide 1000 Pathology as test data. Experiment shows medical NER based on semantic model and improved SVM-KNN algorithm can enhance the quality of NER and we get the precision, recall rate and F value up to 86\%.},
booktitle = {2011 {Seventh} {International} {Conference} on {Semantics}, {Knowledge} and {Grids}},
author = {Han, X. and Ruonan, R.},
month = oct,
year = {2011},
keywords = {Algorithm design and analysis, Classification algorithms, Data Mining, Data models, EK-SVM-KNN, Engines, Feature extraction, NER, Renji hospital, SLE clinical information system, SVM-KNN, Semantics, UIMA, UIMA framework, computational complexity, feature selection, improved SVM-KNN algorithm, information extraction, information management, knowledge complexity, medical field, medical information systems, medical named entity recognition, medical record, multiclassification algorithm, natural language process, natural language processing, pathology report, pattern classification, semantic information, semantic model, support vector machines, systemic lupus erythematosus, technical documentation, unstructured information},
pages = {21--27},
}

@article{sussan_exposure_2015,
title = {Exposure to {Electronic} {Cigarettes} {Impairs} {Pulmonary} {Anti}-{Bacterial} and {Anti}-{Viral} {Defenses} in a {Mouse} {Model}},
volume = {10},
issn = {1932-6203},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0116861},
doi = {10.1371/journal.pone.0116861},
abstract = {Electronic cigarettes (E-cigs) have experienced sharp increases in popularity over the past five years due to many factors, including aggressive marketing, increased restrictions on conventional cigarettes, and a perception that E-cigs are healthy alternatives to cigarettes. Despite this perception, studies on health effects in humans are extremely limited and in vivo animal models have not been generated. Presently, we determined that E-cig vapor contains 7x1011 free radicals per puff. To determine whether E-cig exposure impacts pulmonary responses in mice, we developed an inhalation chamber for E-cig exposure. Mice that were exposed to E-cig vapor contained serum cotinine concentrations that are comparable to human E-cig users. E-cig exposure for 2 weeks produced a significant increase in oxidative stress and moderate macrophage-mediated inflammation. Since, COPD patients are susceptible to bacterial and viral infections, we tested effects of E-cigs on immune response. Mice that were exposed to E-cig vapor showed significantly impaired pulmonary bacterial clearance, compared to air-exposed mice, following an intranasal infection with Streptococcus pneumonia. This defective bacterial clearance was partially due to reduced phagocytosis by alveolar macrophages from E-cig exposed mice. In response to Influenza A virus infection, E-cig exposed mice displayed increased lung viral titers and enhanced virus-induced illness and mortality. In summary, this study reports a murine model of E-cig exposure and demonstrates that E-cig exposure elicits impaired pulmonary anti-microbial defenses. Hence, E-cig exposure as an alternative to cigarette smoking must be rigorously tested in users for their effects on immune response and susceptibility to bacterial and viral infections.},
number = {2},
urldate = {2017-04-23},
journal = {PLOS ONE},
author = {Sussan, Thomas E. and Gajghate, Sachin and Thimmulappa, Rajesh K. and Ma, Jinfang and Kim, Jung-Hyun and Sudini, Kuladeep and Consolini, Nicola and Cormier, Stephania A. and Lomnicki, Slawo and Hasan, Farhana and Pekosz, Andrew and Biswal, Shyam},
month = feb,
year = {2015},
keywords = {Alveolar macrophages, Cytokines, Electronic cigarettes, Free radicals, Inflammation, Mouse models, Smoking habits, Vapors},
pages = {e0116861},
}

@article{wu_electronic_2014,
title = {Electronic {Cigarette} {Liquid} {Increases} {Inflammation} and {Virus} {Infection} in {Primary} {Human} {Airway} {Epithelial} {Cells}},
volume = {9},
issn = {1932-6203},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0108342},
doi = {10.1371/journal.pone.0108342},
abstract = {Background/Objective The use of electronic cigarettes (e-cigarettes) is rapidly increasing in the United States, especially among young people since e-cigarettes have been perceived as a safer alternative to conventional tobacco cigarettes. However, the scientific evidence regarding the human health effects of e-cigarettes on the lung is extremely limited. The major goal of our current study is to determine if e-cigarette use alters human young subject airway epithelial functions such as inflammatory response and innate immune defense against respiratory viral (i.e., human rhinovirus, HRV) infection.  Methodology/Main Results We examined the effects of e-cigarette liquid (e-liquid) on pro-inflammatory cytokine (e.g., IL-6) production, HRV infection and host defense molecules (e.g., short palate, lung, and nasal epithelium clone 1, SPLUNC1) in primary human airway epithelial cells from young healthy non-smokers. Additionally, we examined the role of SPLUNC1 in lung defense against HRV infection using a SPLUNC1 knockout mouse model. We found that nicotine-free e-liquid promoted IL-6 production and HRV infection. Addition of nicotine into e-liquid further amplified the effects of nicotine-free e-liquid. Moreover, SPLUNC1 deficiency in mice significantly increased lung HRV loads. E-liquid inhibited SPLUNC1 expression in primary human airway epithelial cells. These findings strongly suggest the deleterious health effects of e-cigarettes in the airways of young people. Our data will guide future studies to evaluate the impact of e-cigarettes on lung health in human populations, and help inform the public about potential health risks of e-cigarettes.},
number = {9},
urldate = {2017-04-23},
journal = {PLOS ONE},
author = {Wu, Qun and Jiang, Di and Minor, Maisha and Chu, Hong Wei},
month = sep,
year = {2014},
keywords = {Cell cultures, Electronic cigarettes, Epithelial cells, Nicotine, Respiratory infections, Respiratory physiology, Rhinovirus infection, Smoking related disorders},
pages = {e108342},
}

@article{hughes_shape_2004,
title = {Shape of the relapse curve and long-term abstinence among untreated smokers},
volume = {99},
issn = {0965-2140},
abstract = {OBJECTIVE: To describe the relapse curve and rate of long-term prolonged abstinence among smokers who try to quit without treatment.
METHOD: Systematic literature review.
DATA SOURCES: Cochrane Reviews, Dissertation Abstracts, Excerpt Medica, Medline, Psych Abstracts and US Center for Disease Control databases plus bibliographies of articles and requests of scientists.
STUDY SELECTION: Prospective studies of self-quitters or studies that included a no-treatment control group.
DATA EXTRACTION: Two reviewers independently extracted data in a non-blind manner.
DATA SYNTHESIS: The number of studies was too small and the data too heterogeneous for meta-analysis or other statistical techniques.
RESULTS: There is a paucity of studies reporting relapse curves of self-quitters. The existing eight relapse curves from two studies of self-quitters and five no-treatment control groups indicate most relapse occurs in the first 8 days. These relapse curves were heterogeneous even when the final outcome was made similar. In terms of prolonged abstinence rates, a prior summary of 10 self-quitting studies, two other studies of self-quitters and three no-treatment control groups indicate 3-5\% of self-quitters achieve prolonged abstinence for 6-12 month after a given quit attempt.
CONCLUSIONS: More reports of relapse curves of self-quitters are needed. Smoking cessation interventions should focus on the first week of abstinence. Interventions that produce abstinence rates of 5-10\% may be effective. Cessation studies should report relapse curves.},
language = {eng},
number = {1},
journal = {Addiction (Abingdon, England)},
author = {Hughes, John R. and Keely, Josue and Naud, Shelly},
month = jan,
year = {2004},
pmid = {14678060},
keywords = {Humans, Prospective Studies, Recurrence, Self Care, Smoking, Smoking Cessation, Time Factors, survival analysis},
pages = {29--38},
}

@article{hajek_electronic_2014,
title = {Electronic cigarettes: review of use, content, safety, effects on smokers and potential for harm and benefit},
volume = {109},
issn = {1360-0443},
shorttitle = {Electronic cigarettes},
url = {http://onlinelibrary.wiley.com/doi/10.1111/add.12659/abstract},
doi = {10.1111/add.12659},
abstract = {Aims

We reviewed available research on the use, content and safety of electronic cigarettes (EC), and on their effects on users, to assess their potential for harm or benefit and to extract evidence that can guide future policy.


Methods

Studies were identified by systematic database searches and screening references to February 2014.


Results

EC aerosol can contain some of the toxicants present in tobacco smoke, but at levels which are much lower. Long-term health effects of EC use are unknown but compared with cigarettes, EC are likely to be much less, if at all, harmful to users or bystanders. EC are increasingly popular among smokers, but to date there is no evidence of regular use by never-smokers or by non-smoking children. EC enable some users to reduce or quit smoking.


Conclusions

Allowing EC to compete with cigarettes in the market-place might decrease smoking-related morbidity and mortality. Regulating EC as strictly as cigarettes, or even more strictly as some regulators propose, is not warranted on current evidence. Health professionals may consider advising smokers unable or unwilling to quit through other routes to switch to EC as a safer alternative to smoking and a possible pathway to complete cessation of nicotine use.},
language = {en},
number = {11},
urldate = {2017-04-23},
journal = {Addiction},
author = {Hajek, Peter and Etter, Jean-François and Benowitz, Neal and Eissenberg, Thomas and McRobbie, Hayden},
month = nov,
year = {2014},
keywords = {Electronic cigarettes, Prevalence, Smoking Cessation, harm reduction, product safety, regulation},
pages = {1801--1810},
}

@article{pisinger_systematic_2014,
title = {A systematic review of health effects of electronic cigarettes},
volume = {69},
issn = {0091-7435},
url = {http://www.sciencedirect.com/science/article/pii/S0091743514003739},
doi = {10.1016/j.ypmed.2014.10.009},
abstract = {Objective
To provide a systematic review of the existing literature on health consequences of vaporing of electronic cigarettes (ECs).
Methods
Search in: PubMed, EMBASE and CINAHL. Inclusion criteria: Original publications describing a health-related topic, published before 14 August 2014. PRISMA recommendations were followed. We identified 1101 studies; 271 relevant after screening; 94 eligible.
Results
We included 76 studies investigating content of fluid/vapor of ECs, reports on adverse events and human and animal experimental studies. Serious methodological problems were identified. In 34\% of the articles the authors had a conflict of interest. Studies found fine/ultrafine particles, harmful metals, carcinogenic tobacco-specific nitrosamines, volatile organic compounds, carcinogenic carbonyls (some in high but most in low/trace concentrations), cytotoxicity and changed gene expression. Of special concern are compounds not found in conventional cigarettes, e.g. propylene glycol. Experimental studies found increased airway resistance after short-term exposure. Reports on short-term adverse events were often flawed by selection bias.
Conclusions
Due to many methodological problems, severe conflicts of interest, the relatively few and often small studies, the inconsistencies and contradictions in results, and the lack of long-term follow-up no firm conclusions can be drawn on the safety of ECs. However, they can hardly be considered harmless.},
urldate = {2017-04-23},
journal = {Preventive Medicine},
author = {Pisinger, Charlotta and Døssing, Martin},
month = dec,
year = {2014},
keywords = {E-cigarette, ENDS, Electronic nicotine delivery device, Electronic nicotine delivery system, electronic cigarette},
pages = {248--260},
}

@inproceedings{liu_identifying_2015,
address = {Philadelphia},
title = {Identifying {Adverse} {Drug} {Events} from {Health} {Social} {Media} {Using} {Distant} {Supervision}},
abstract = {Adverse drug events (ADEs) have been recognized as a significant healthcare problem
worldwide. Prior studies have shown that health social media can be used to generate medical
hypotheses and identify adverse drug events. Most studies adopted supervised learning approach
for ADE detection in health social media, which requires human annotated data and is not
scalable to large datasets. In this study, we develop an information extraction framework to
identify novel adverse drug events using distant supervised learning, which leverages existing
knowledge of adverse drug events and requires no labeled text. Our proposed framework
achieves competent performance in identifying adverse drug events without expensive human
annotation.},
booktitle = {Applications of {Text} {Analysis}},
author = {Liu, Xiao and Chen, Hsinchun},
month = oct,
year = {2015},
}

@article{allem_importance_2016,
title = {The {Importance} of {Debiasing} {Social} {Media} {Data} to {Better} {Understand} {E}-{Cigarette}-{Related} {Attitudes} and {Behaviors}},
volume = {18},
copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work (},
url = {http://www.jmir.org/2016/8/e219/},
doi = {10.2196/jmir.6185},
abstract = {- [J Med Internet Res 2016;18(8):e219]},
language = {en},
number = {8},
urldate = {2017-04-22},
journal = {Journal of Medical Internet Research},
author = {Allem, Jon-Patrick and Ferrara, Emilio},
year = {2016},
pages = {e219},
}

@article{perret_smoking_2016,
title = {Smoking cessation strategies for patients with asthma: improving patient outcomes},
volume = {9},
issn = {1178-6965},
shorttitle = {Smoking cessation strategies for patients with asthma},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4928655/},
doi = {10.2147/JAA.S85615},
abstract = {Smoking is common in adults with asthma, yet a paucity of literature exists on smoking cessation strategies specifically targeting this subgroup. Adverse respiratory effects from personal smoking include worse asthma control and a predisposition to lower lung function and chronic obstructive pulmonary disease. Some data suggest that individuals with asthma are more likely than their non-asthmatic peers to smoke regularly at an earlier age. While quit attempts can be more frequent in smokers with asthma, they are also of shorter duration than in non-asthmatics. Considering these asthma-specific characteristics is important in order to individualize smoking cessation strategies. In particular, asthma-specific information such as “lung age” should be provided and longer-term follow-up is advised. Promising emerging strategies include reminders by cellular phone and web-based interventions using consumer health informatics. For adolescents, training older peers to deliver asthma education is another promising strategy. For smokers who are hospitalized for asthma, inpatient nicotine replacement therapy and counseling are a priority. Overall, improving smoking cessation rates in smokers with asthma may rely on a more personalized approach, with the potential for substantial health benefits to individuals and the population at large.},
urldate = {2017-04-22},
journal = {Journal of Asthma and Allergy},
author = {Perret, Jennifer L and Bonevski, Billie and McDonald, Christine F and Abramson, Michael J},
month = jun,
year = {2016},
pmid = {27445499},
pmcid = {PMC4928655},
pages = {117--128},
}

@article{chatkin_management_2016,
title = {The management of asthmatic smokers},
volume = {2},
issn = {2054-7064},
url = {http://dx.doi.org/10.1186/s40733-016-0025-7},
doi = {10.1186/s40733-016-0025-7},
abstract = {Asthma is still a major public health problem in most countries; new strategies to better control this disease are necessary. Such strategies must include predisposing factors. One of these factors is smoking and a significant fraction of asthmatics are smokers. However, clinical trials studying new drugs or newer therapeutic regimens for asthma generally exclude smokers. Therefore, there is a lack of specific information about the treatment of asthma in smokers. The asthmatic smoker is a special phenotype with important therapeutic and prognostic clinical implications. Any form of tobacco use, especially cigarette smoking, plays an important role in this disease. Asthmatic smokers are prone to several negative outcomes. Smoking cessation results in an improvement of symptoms and pulmonary functioning. Counselling and first-line medications for smoking cessation (nicotine replacement therapy, bupropion and varenicline) significantly increase quitting rates. The role of electronic cigarettes in this group of patients has only begun to be studied. The treatment of asthmatics that smoke has characteristics that need must be well understood by clinicians, especially the poor response to corticosteroids. This condition is not universal and physicians should always consider its inclusion in the treatment of these patients. The association of inhaled corticosteroids (ICS) plus a long-acting beta2 adrenegic (LABA) by smoking asthmatics results in more pronounced improvement in several asthma outcomes compared with the use of corticosteroid alone. Inhaled corticosteroids in extra-fine particles associated with LABA may be a new perspective of treatment. Also the use of leukotriene antagonists may become another therapeutic alternative. The purpose of this narrative review is to discuss the challenges faced by clinicians to control asthma in smokers and to present methods of coping with smoking treatment and avoiding relapses.},
urldate = {2017-04-22},
journal = {Asthma Research and Practice},
author = {Chatkin, José Miguel and Dullius, Cynthia Rocha},
year = {2016},
keywords = {Anti asthmatic agents, Asthma, Smoking, Smoking Cessation},
pages = {10},
}

@article{sands_smoking_2014,
title = {Smoking and asthma: never the twain should meet},
volume = {113},
issn = {1081-1206, 1534-4436},
shorttitle = {Smoking and asthma},
url = {http://www.annallergy.org/article/S1081-1206(14)00592-4/abstract},
doi = {10.1016/j.anai.2014.08.011},
language = {English},
number = {5},
urldate = {2017-04-22},
journal = {Annals of Allergy, Asthma \& Immunology},
author = {Sands, Mark F.},
month = nov,
year = {2014},
pmid = {25240333},
pages = {502--505},
}

@article{miler_changes_2016,
title = {Changes in the {Frequency} of {Airway} {Infections} in {Smokers} {Who} {Switched} {To} {Vaping}: {Results} of an {Online} {Survey}},
volume = {7},
issn = {2155-6105},
shorttitle = {Changes in the {Frequency} of {Airway} {Infections} in {Smokers} {Who} {Switched} {To} {Vaping}},
url = {https://www.omicsonline.org/open-access/changes-in-the-frequency-of-airway-infections-in-smokers-who-switched-to-vaping-results-of-an-online-survey-2155-6105-1000290.php?aid=77944},
doi = {10.4172/2155-6105.1000290},
abstract = {Background and aim: Cell and animal studies suggested that use of e-cigarettes may increase vulnerability to respiratory infection, though the available studies have serious limitations. Limited data are available on respiratory health of vapers. Methods: An on-line survey assessed subjective changes in respiratory symptoms in smokers who switched to vaping for at least two months. Results: Among 941 responders, 29\% reported no change in respiratory symptoms, 5\% reported worsening, and 66\% reported an improvement. Among qualitative comments, 232 elaborated on positive and 15 on negative experiences. Conclusion: The switch from smoking to vaping was associated with a reduced incidence of self-reported respiratory infections. Further studies using objective measures in samples that are not self-selected are needed.},
number = {4},
urldate = {2017-04-22},
journal = {Journal of Addiction Research \& Therapy},
author = {Miler, Joanna Astrid and Mayer, Bernhard and Hajek, Peter},
month = aug,
year = {2016},
}

@article{polosa_evidence_2016,
title = {Evidence for harm reduction in {COPD} smokers who switch to electronic cigarettes},
volume = {17},
issn = {1465-993X},
url = {http://dx.doi.org/10.1186/s12931-016-0481-x},
doi = {10.1186/s12931-016-0481-x},
abstract = {Electronic cigarettes (ECs) are battery-operated devices designed to vaporise nicotine, which may help smokers quitting or reducing their tobacco consumption. There is a lack of data on the health effects of EC use among smokers with COPD and whether regular use results in improvement in subjective and objective COPD outcomes.},
urldate = {2017-04-22},
journal = {Respiratory Research},
author = {Polosa, Riccardo and Morjaria, Jaymin Bhagwanji and Caponnetto, Pasquale and Prosperini, Umberto and Russo, Cristina and Pennisi, Alfio and Bruno, Cosimo Marcello},
year = {2016},
keywords = {COPD, Smoking Cessation, Tobacco harm reduction, electronic cigarette},
pages = {166},
}

@article{kruse_use_nodate,
title = {Use of {Electronic} {Cigarettes} {Among} {U}.{S}. {Adults} {With} {Medical} {Comorbidities}},
issn = {0749-3797},
url = {http://www.sciencedirect.com/science/article/pii/S0749379716306663},
doi = {10.1016/j.amepre.2016.12.004},
abstract = {Introduction
Electronic cigarette (e-cigarette) use is rising in the U.S. Smokers with comorbidities may increasingly use e-cigarettes if they believe e-cigarettes reduce smoking-related harm. This study examined e-cigarette use among adults with medical comorbidities.
Methods
In 2016, this study analyzed 68,136 U.S. adults in the 2014 and 2015 National Health Interview Survey. Prevalent e-cigarette use by medical comorbidities and adjusted odds of e-cigarette use were calculated.
Results
Among current cigarette smokers, ever use of e-cigarettes was more often reported by adults with one or more medical comorbidity versus those without comorbidity (18–24 years: 73.5\% vs 61.4\%; 25–44 years: 60.6\% vs 54.3\%; 45–64 years: 46.5\% vs 40.3\%; ≥65 years: 35.2\% vs 19.4\%; all p\&lt;0.05). Current smokers aged 25–64 years with one or more comorbidity reported current e-cigarette use more often than those without comorbidity (25–44 years, 17.8\% vs 14.3\%, p=0.03; 45–64 years, 15.9\% vs 11.5\%, p=0.02). Current smokers with chronic obstructive pulmonary disease, asthma, and cardiovascular disease had higher odds of ever e-cigarette use versus those without comorbidity. Current smokers with asthma and cardiovascular disease had higher odds of current e-cigarette use. Former smokers with chronic obstructive pulmonary disease had higher odds of ever and current e-cigarette use and former smokers with cancer had lower odds of current e-cigarette use.
Conclusions
E-cigarette use by current and former smokers with medical comorbidities is substantial, especially among individuals with chronic lung or cardiovascular disease. Clinicians should routinely ask these patients about e-cigarette use, actively consider all pathways to help their patients quit combustible cigarettes, and recommend evidence-based treatments.},
urldate = {2017-04-22},
journal = {American Journal of Preventive Medicine},
author = {Kruse, Gina R. and Kalkhoran, Sara and Rigotti, Nancy A.},
}

@article{polosa_effect_2014,
title = {Effect of {Smoking} {Abstinence} and {Reduction} in {Asthmatic} {Smokers} {Switching} to {Electronic} {Cigarettes}: {Evidence} for {Harm} {Reversal}},
volume = {11},
copyright = {http://creativecommons.org/licenses/by/3.0/},
shorttitle = {Effect of {Smoking} {Abstinence} and {Reduction} in {Asthmatic} {Smokers} {Switching} to {Electronic} {Cigarettes}},
url = {http://www.mdpi.com/1660-4601/11/5/4965},
doi = {10.3390/ijerph110504965},
abstract = {Electronic cigarettes (e-cigs) are marketed as safer alternatives to tobacco cigarettes and have shown to reduce their consumption. Here we report for the first time the effects of  e-cigs on subjective and objective asthma parameters as well as tolerability in asthmatic smokers who quit or reduced their tobacco consumption by switching to these products.  We retrospectively reviewed changes in spirometry data, airway hyper-responsiveness (AHR), asthma exacerbations and subjective asthma control in smoking asthmatics who switched to regular e-cig use. Measurements were taken prior to switching (baseline) and at two consecutive visits (Follow-up/1 at 6 (±1) and Follow-up/2 at 12 (±2) months).  Eighteen smoking asthmatics (10 single users, eight dual users) were identified.  Overall there were significant improvements in spirometry data, asthma control and AHR. These positive outcomes were noted in single and dual users. Reduction in exacerbation rates was reported, but was not significant. No severe adverse events were noted.  This small retrospective study indicates that regular use of e-cigs to substitute smoking is associated with objective and subjective improvements in asthma outcomes.  Considering that e-cig use is reportedly less harmful than conventional smoking and can lead to reduced cigarette consumption with subsequent improvements in asthma outcomes, this study shows that e-cigs can be a valid option for asthmatic patients who cannot quit smoking by other methods.},
language = {en},
number = {5},
urldate = {2017-04-22},
journal = {International Journal of Environmental Research and Public Health},
author = {Polosa, Riccardo and Morjaria, Jaymin and Caponnetto, Pasquale and Caruso, Massimo and Strano, Simona and Battaglia, Eliana and Russo, Cristina},
month = may,
year = {2014},
keywords = {Asthma, Smoking Cessation, electronic cigarette, harm reduction, lung function, methacholine challenge},
pages = {4965--4977},
}

@inproceedings{stoyneva_poster:_nodate,
title = {{POSTER}: {Exploring} {Twitter} data for key conversations, trends, and patterns {reLated} to e-cigarettes},
abstract = {The analysis revealed an increase in e-cigarette-related tweets from May 2013 through April 2014, with a spike in December 2013. Over the course of the analysis period, tweets about e-cigarettes were mostly positive, and were often posted by everyday people and individuals from the e-cigarette community movement. These two user groups were responsible for tweets that captured information, news, marketing messages, and policy and government themes, as well as first-person experiences and opinions. This reveals that everyday people and the e-cigarette community are dominating forces across several genres and themes, warranting continued monitoring to understand trends and their implications regarding public opinion, e-cigarette use, and smoking cessation. Analyzing social media trends is a meaningful way to inform public health practitioners of current sentiments regarding e-cigarettes. This study contributes a replicable methodology, as well as insights on how it can be automated using computational methods, such as supervised machine learning.},
author = {Stoyneva, Iva},
}

@article{ayers_why_2017,
title = {Why do people use electronic nicotine delivery systems (electronic cigarettes)? {A} content analysis of {Twitter}, 2012-2015},
volume = {12},
issn = {1932-6203},
shorttitle = {Why do people use electronic nicotine delivery systems (electronic cigarettes)?},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0170702},
doi = {10.1371/journal.pone.0170702},
abstract = {The reasons for using electronic nicotine delivery systems (ENDS) are poorly understood and are primarily documented by expensive cross-sectional surveys that use preconceived close-ended response options rather than allowing respondents to use their own words. We passively identify the reasons for using ENDS longitudinally from a content analysis of public postings on Twitter. All English language public tweets including several ENDS terms (e.g., “e-cigarette” or “vape”) were captured from the Twitter data stream during 2012 and 2015. After excluding spam, advertisements, and retweets, posts indicating a rationale for vaping were retained. The specific reasons for vaping were then inferred based on a supervised content analysis using annotators from Amazon’s Mechanical Turk. During 2012 quitting combustibles was the most cited reason for using ENDS with 43\% (95\%CI 39–48) of all reason-related tweets cited quitting combustibles, e.g., “I couldn’t quit till I tried ecigs,” eclipsing the second most cited reason by more than double. Other frequently cited reasons in 2012 included ENDS’s social image (21\%; 95\%CI 18–25), use indoors (14\%; 95\%CI 11–17), flavors (14\%; 95\%CI 11–17), safety relative to combustibles (9\%; 95\%CI 7–11), cost (3\%; 95\%CI 2–5) and favorable odor (2\%; 95\%CI 1–3). By 2015 the reasons for using ENDS cited on Twitter had shifted. Both quitting combustibles and use indoors significantly declined in mentions to 29\% (95\%CI 24–33) and 12\% (95\%CI 9–16), respectively. At the same time, social image increased to 37\% (95\%CI 32–43) and lack of odor increased to 5\% (95\%CI 2–5), the former leading all cited reasons in 2015. Our data suggest the reasons people vape are shifting away from cessation and toward social image. The data also show how the ENDS market is responsive to a changing policy landscape. For instance, smoking indoors was less frequently cited in 2015 as indoor smoking restrictions became more common. Because the data and analytic approach are scalable, adoption of our strategies in the field can inform follow-up survey-based surveillance (so the right questions are asked), interventions, and policies for ENDS.},
number = {3},
urldate = {2017-04-22},
journal = {PLOS ONE},
author = {Ayers, John W. and Leas, Eric C. and Allem, Jon-Patrick and Benton, Adrian and Dredze, Mark and Althouse, Benjamin M. and Cruz, Tess B. and Unger, Jennifer B.},
month = mar,
year = {2017},
keywords = {Electronic cigarettes, Human intelligence, Public and occupational health, Smoking habits, Surveys, Tobacco control, disease surveillance, twitter},
pages = {e0170702},
}

@article{lazard_e-cigarette_2016,
title = {E-{Cigarette} {Social} {Media} {Messages}: {A} {Text} {Mining} {Analysis} of {Marketing} and {Consumer} {Conversations} on {Twitter}},
volume = {2},
issn = {2369-2960},
shorttitle = {E-{Cigarette} {Social} {Media} {Messages}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5187450/},
doi = {10.2196/publichealth.6551},
abstract = {Background
As the use of electronic cigarettes (e-cigarettes) rises, social media likely influences public awareness and perception of this emerging tobacco product.

Objective
This study examined the public conversation on Twitter to determine overarching themes and insights for trending topics from commercial and consumer users.

Methods
Text mining uncovered key patterns and important topics for e-cigarettes on Twitter. SAS Text Miner 12.1 software (SAS Institute Inc) was used for descriptive text mining to reveal the primary topics from tweets collected from March 24, 2015, to July 3, 2015, using a Python script in conjunction with Twitter’s streaming application programming interface. A total of 18 keywords related to e-cigarettes were used and resulted in a total of 872,544 tweets that were sorted into overarching themes through a text topic node for tweets (126,127) and retweets (114,451) that represented more than 1\% of the conversation.

Results
While some of the final themes were marketing-focused, many topics represented diverse proponent and user conversations that included discussion of policies, personal experiences, and the differentiation of e-cigarettes from traditional tobacco, often by pointing to the lack of evidence for the harm or risks of e-cigarettes or taking the position that e-cigarettes should be promoted as smoking cessation devices.

Conclusions
These findings reveal that unique, large-scale public conversations are occurring on Twitter alongside e-cigarette advertising and promotion. Proponents and users are turning to social media to share knowledge, experience, and questions about e-cigarette use. Future research should focus on these unique conversations to understand how they influence attitudes towards and use of e-cigarettes.},
number = {2},
urldate = {2017-04-22},
journal = {JMIR Public Health and Surveillance},
author = {Lazard, Allison J and Saffer, Adam J and Wilcox, Gary B and Chung, Arnold DongWoo and Mackert, Michael S and Bernhardt, Jay M},
month = dec,
year = {2016},
pmid = {27956376},
pmcid = {PMC5187450},
}

@article{cole-lewis_social_2015,
title = {Social {Listening}: {A} {Content} {Analysis} of {E}-{Cigarette} {Discussions} on {Twitter}},
volume = {17},
issn = {1439-4456},
shorttitle = {Social {Listening}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4642379/},
doi = {10.2196/jmir.4969},
abstract = {Background
Electronic cigarette (e-cigarette) use has increased in the United States, leading to active debate in the public health sphere regarding e-cigarette use and regulation. To better understand trends in e-cigarette attitudes and behaviors, public health and communication professionals can turn to the dialogue taking place on popular social media platforms such as Twitter.

Objective
The objective of this study was to conduct a content analysis to identify key conversation trends and patterns over time using historical Twitter data.

Methods
A 5-category content analysis was conducted on a random sample of tweets chosen from all publicly available tweets sent between May 1, 2013, and April 30, 2014, that matched strategic keywords related to e-cigarettes. Relevant tweets were isolated from the random sample of approximately 10,000 tweets and classified according to sentiment, user description, genre, and theme. Descriptive analyses including univariate and bivariate associations, as well as correlation analyses were performed on all categories in order to identify patterns and trends.

Results
The analysis revealed an increase in e-cigarette–related tweets from May 2013 through April 2014, with tweets generally being positive; 71\% of the sample tweets were classified as having a positive sentiment. The top two user categories were everyday people (65\%) and individuals who are part of the e-cigarette community movement (16\%). These two user groups were responsible for a majority of informational (79\%) and news tweets (75\%), compared to reputable news sources and foundations or organizations, which combined provided 5\% of informational tweets and 12\% of news tweets. Personal opinion (28\%), marketing (21\%), and first person e-cigarette use or intent (20\%) were the three most common genres of tweets, which tended to have a positive sentiment. Marketing was the most common theme (26\%), and policy and government was the second most common theme (20\%), with 86\% of these tweets coming from everyday people and the e-cigarette community movement combined, compared to 5\% of policy and government tweets coming from government, reputable news sources, and foundations or organizations combined.

Conclusions
Everyday people and the e-cigarette community are dominant forces across several genres and themes, warranting continued monitoring to understand trends and their implications regarding public opinion, e-cigarette use, and smoking cessation. Analyzing social media trends is a meaningful way to inform public health practitioners of current sentiments regarding e-cigarettes, and this study contributes a replicable methodology.},
number = {10},
urldate = {2017-04-22},
journal = {Journal of Medical Internet Research},
author = {Cole-Lewis, Heather and Pugatch, Jillian and Sanders, Amy and Varghese, Arun and Posada, Susana and Yun, Christopher and Schwarz, Mary and Augustson, Erik},
month = oct,
year = {2015},
pmid = {26508089},
pmcid = {PMC4642379},
}

@article{cameron_variable_2013,
title = {Variable and potentially fatal amounts of nicotine in e-cigarette nicotine solutions},
copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions},
issn = {0964-4563, 1468-3318},
url = {http://tobaccocontrol.bmj.com/content/early/2013/02/12/tobaccocontrol-2012-050604},
doi = {10.1136/tobaccocontrol-2012-050604},
abstract = {Experimental research on electronic cigarettes (e-cigarettes) is sparse. Regulated as tobacco products by the US Food and Drug Administration, e-cigarette safety has not been determined. This enables the sale of e-cigarettes and tobacco-derived nicotine solution to consumers without rigorous safety regulations that would be required if the products were regulated as drug delivery devices .1 As such, despite the recent popularity of e-cigarettes as an alternative to cigarette smoking, consumers currently do not have industry-regulated information on the concentration of e-cigarette solutions or their safety.1 The present study reports the nicotine concentration of several of these solutions.

A convenience sample of seven e-cigarette nicotine solutions was analysed. Samples ranged from prepackaged and sealed with concentration levels printed on the labels to blank bottles with hand-written labels with no concentration level, warning …},
language = {en},
urldate = {2017-04-22},
journal = {Tobacco Control},
author = {Cameron, Jennifer M. and Howell, Donelle N. and White, John R. and Andrenyak, David M. and Layton, Matthew E. and Roll, John M.},
month = feb,
year = {2013},
pmid = {23407110},
keywords = {Nicotine, Toxicology, electronic nicotine delivery devices},
pages = {tobaccocontrol--2012--050604},
}

@article{goniewicz_patterns_2013,
title = {Patterns of electronic cigarette use and user beliefs about their safety and benefits: an internet survey},
volume = {32},
issn = {1465-3362},
shorttitle = {Patterns of electronic cigarette use and user beliefs about their safety and benefits},
doi = {10.1111/j.1465-3362.2012.00512.x},
abstract = {INTRODUCTION AND AIMS: As the popularity of electronic cigarettes (e-cigarettes) increases, it is becoming important to find out more about the characteristics of e-cigarette users, why and how they use the product and whether e-cigarettes are used exclusively or in combination with conventional cigarettes. The objective of this study was to investigate patterns and effects of e-cigarette use and user beliefs about e-cigarette safety and benefits.
DESIGN AND METHODS: E-cigarette users in Poland were recruited online and asked to participate in a web-based survey. The participants provided information on their smoking history, patterns of e-cigarette use, beliefs and attitudes regarding the product and information on concurrent use of conventional cigarettes.
RESULTS: The survey was completed by 179 e-cigarette users. Almost all participants used e-cigarettes daily. E-cigarettes were primarily used to quit smoking or to reduce the harm associated with smoking (both 41\%), and were successful in helping the surveyed users to achieve these goals with 66\% not smoking conventional cigarettes at all and 25\% smoking under five cigarettes a day. Most participants (82\%) did not think that e-cigarettes were completely safe, but thought that they were less dangerous than conventional cigarettes. Sixty percent believed that e-cigarettes were addictive, but less so than conventional cigarettes.
DISCUSSION AND CONCLUSIONS: The participants primarily used e-cigarettes as a stop-smoking aid or as an alternative to conventional cigarettes, and the majority reported that they successfully stopped smoking. More data on e-cigarette safety and its efficacy in harm-reduction and smoking cessation are needed.},
language = {eng},
number = {2},
journal = {Drug and Alcohol Review},
author = {Goniewicz, Maciej L. and Lingas, Elena O. and Hajek, Peter},
month = mar,
year = {2013},
pmid = {22994631},
pmcid = {PMC3530631},
keywords = {Adolescent, Adult, Culture, Data Collection, Female, Health Knowledge, Attitudes, Practice, Humans, Internet, Male, Middle Aged, Poland, Smoking, Smoking Cessation, Tobacco Products, Young Adult},
pages = {133--140},
}

@article{regan_electronic_2011,
title = {Electronic nicotine delivery systems: adult use and awareness of the ‘e-cigarette’ in the {USA}},
copyright = {© 2011, Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions.},
issn = {0964-4563, 1468-3318},
shorttitle = {Electronic nicotine delivery systems},
url = {http://tobaccocontrol.bmj.com/content/early/2011/10/27/tobaccocontrol-2011-050044},
doi = {10.1136/tobaccocontrol-2011-050044},
abstract = {Background Electronic nicotine delivery systems (ENDS), also referred to as electronic cigarettes or e-cigarettes, were introduced into the US market in 2007. Despite concerns regarding the long-term health impact of this product, there is little known about awareness and use of ENDS among adults in the USA.
Methods A consumer-based mail-in survey (ConsumerStyles) was completed by 10 587 adults (≥18 years) in 2009 and 10 328 adults in 2010. Data from these surveys were used to monitor awareness, ever use and past month use of ENDS from 2009 to 2010 and to assess demographic characteristics and tobacco use of ENDS users.
Results In this US sample, awareness of ENDS doubled from 16.4\% in 2009 to 32.2\% in 2010 and ever use more than quadrupled from 2009 (0.6\%) to 2010 (2.7\%). Ever use of ENDS was most common among women and those with lower education, although these were not the groups who had heard of ENDS most often. Current smokers and tobacco users were most likely to try ENDS. However, current smokers who had tried ENDS did not say they planned to quit smoking more often than smokers who had never tried them.
Conclusions Given the large increase in awareness and ever use of ENDS during this 1-year period and the unknown impact of ENDS use on cigarette smoking behaviours and long-term health, continued monitoring of these products is needed.},
language = {en},
urldate = {2017-04-22},
journal = {Tobacco Control},
author = {Regan, Annette K. and Promoff, Gabbi and Dube, Shanta R. and Arrazola, Rene},
month = jan,
year = {2011},
pmid = {22034071},
keywords = {Mental health, adolescents, cessation, electronic nicotine delivery devices, industry documents, industry public relations/media, marginalised populations, qualitative study, smokeless tobacco products, smoking topography, surveillance and monitoring, tobacco, tobacco industry, tobacco use, young adults, youth tobacco use},
pages = {tobaccocontrol--2011--050044},
}

@article{polosa_effect_2011,
title = {Effect of an electronic nicotine delivery device (e-{Cigarette}) on smoking reduction and cessation: a prospective 6-month pilot study},
volume = {11},
issn = {1471-2458},
shorttitle = {Effect of an electronic nicotine delivery device (e-{Cigarette}) on smoking reduction and cessation},
url = {http://dx.doi.org/10.1186/1471-2458-11-786},
doi = {10.1186/1471-2458-11-786},
abstract = {Cigarette smoking is a tough addiction to break. Therefore, improved approaches to smoking cessation are necessary. The electronic-cigarette (e-Cigarette), a battery-powered electronic nicotine delivery device (ENDD) resembling a cigarette, may help smokers to remain abstinent during their quit attempt or to reduce cigarette consumption. Efficacy and safety of these devices in long-term smoking cessation and/or smoking reduction studies have never been investigated.},
urldate = {2017-04-22},
journal = {BMC Public Health},
author = {Polosa, Riccardo and Caponnetto, Pasquale and Morjaria, Jaymin B. and Papale, Gabriella and Campagna, Davide and Russo, Cristina},
year = {2011},
pages = {786},
}

@article{pearson_e-cigarette_2012,
title = {e-{Cigarette} awareness, use, and harm perceptions in {US} adults},
volume = {102},
issn = {1541-0048},
doi = {10.2105/AJPH.2011.300526},
abstract = {OBJECTIVES: We estimated e-cigarette (electronic nicotine delivery system) awareness, use, and harm perceptions among US adults.
METHODS: We drew data from 2 surveys conducted in 2010: a national online study (n = 2649) and the Legacy Longitudinal Smoker Cohort (n = 3658). We used multivariable models to examine e-cigarette awareness, use, and harm perceptions.
RESULTS: In the online survey, 40.2\% (95\% confidence interval [CI] = 37.3, 43.1) had heard of e-cigarettes, with awareness highest among current smokers. Utilization was higher among current smokers (11.4\%; 95\% CI = 9.3, 14.0) than in the total population (3.4\%; 95\% CI = 2.6, 4.2), with 2.0\% (95\% CI = 1.0, 3.8) of former smokers and 0.8\% (95\% CI = 0.35, 1.7) of never-smokers ever using e-cigarettes. In both surveys, non-Hispanic Whites, current smokers, young adults, and those with at least a high-school diploma were most likely to perceive e-cigarettes as less harmful than regular cigarettes.
CONCLUSIONS: Awareness of e-cigarettes is high, and use among current and former smokers is evident. We recommend product regulation and careful surveillance to monitor public health impact and emerging utilization patterns, and to ascertain why, how, and under what conditions e-cigarettes are being used.},
language = {eng},
number = {9},
journal = {American Journal of Public Health},
author = {Pearson, Jennifer L. and Richardson, Amanda and Niaura, Raymond S. and Vallone, Donna M. and Abrams, David B.},
month = sep,
year = {2012},
pmid = {22813087},
pmcid = {PMC3474361},
keywords = {Adolescent, Adult, Cohort Studies, Cross-Sectional Studies, Educational Status, European Continental Ancestry Group, Female, Health Knowledge, Attitudes, Practice, Health Surveys, Humans, Longitudinal Studies, Male, Middle Aged, Nicotine, Smoking, United States, Young Adult},
pages = {1758--1766},
}

@techreport{noauthor_big_nodate,
title = {{BIG} {DATA}},
url = {http://www.aapor.org/Education-Resources/Reports/Big-Data.aspx},
}

@book{hazewinke_linear_2001,
title = {"{Linear} interpolation", {Encyclopaedia} of {Mathematics}},
isbn = {978-1-55608-010-4},
url = {http://www.springer.com/gp/book/9781556080104},
abstract = {The Encyclopaedia of Mathematics is the most up-to-date,  authoritative and comprehensive English-language work of reference in  mathematics which exists...},
urldate = {2017-04-21},
publisher = {Springer Netherlands},
author = {Hazewinke, Michiel},
year = {2001},
}

@article{sadat_fuzzy_2015,
title = {Fuzzy spatial association rule mining to analyze the effect of environmental variables on the risk of allergic asthma prevalence},
volume = {41},
issn = {2029-6991},
url = {http://dx.doi.org/10.3846/20296991.2015.1051339},
doi = {10.3846/20296991.2015.1051339},
abstract = {The prevalence of allergic diseases has greatly increased in recent decades, likely due to contamination of the environment with allergy irritants. One common treatment is identifying that allergy irritant, and then avoiding exposure to it. This article studies the relation between the prevalence of allergic asthma and certain allergy irritants that are related to environmental variables. To that end, we use spatial association rule mining to determine the association between the spatial distribution of allergic asthma prevalence and air pollutants such as CO, SO2, NO2, PM10, PM2.5, and O3 (from data compiled by air pollution monitoring stations), as well as other factors, such as the distance of residence from parks and roads. In order to clear up the uncertainties inherent in the attributes linked to the spatial data, the dimensions in question have been defined as fuzzy sets. Results for the case study (i.e. Tehran metropolitan area) indicate that distance to parks and roads, as well as CO, NO2, PM10, and PM2.5 levels are related to allergic asthma prevalence, while SO2 and O3 are not. Finally, we use the extracted association rules in fuzzy inference system to produce the spatial risk map of allergic asthma prevalence, which shows how much is the risk of allergic asthma prevalence at each point of the city.},
number = {2},
urldate = {2017-04-21},
journal = {Geodesy and Cartography},
author = {Sadat, Yousef Kanani and Nikaein, Tina and Karimipour, Farid},
month = apr,
year = {2015},
keywords = {Air pollution, GIS, allergic asthma, fuzzy spatial association rule mining, risk analysis, spatial data mining},
pages = {101--112},
}

@article{moghaddam_learning_2002,
title = {Learning gender with support faces},
volume = {24},
issn = {0162-8828},
doi = {10.1109/34.1000244},
abstract = {Nonlinear support vector machines (SVMs) are investigated for appearance-based gender classification with low-resolution "thumbnail" faces processed from 1,755 images from the FERET (FacE REcognition Technology) face database. The performance of SVMs (3.4\% error) is shown to be superior to traditional pattern classifiers (linear, quadratic, Fisher linear discriminant, nearest-neighbor) as well as more modern techniques, such as radial basis function (RBF) classifiers and large ensemble-RBF networks. Furthermore, the difference in classification performance with low-resolution "thumbnails" (21×12 pixels) and the corresponding higher-resolution images (84×48 pixels) was found to be only 1\%, thus demonstrating robustness and stability with respect to scale and the degree of facial detail},
number = {5},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
author = {Moghaddam, B. and Yang, Ming-Hsuan},
month = may,
year = {2002},
keywords = {FERET face database, Fisher linear discriminant classifiers, Image databases, Pixel, Robust stability, Support vector machine classification, appearance-based gender classification, classification performance, ensemble-RBF networks, face recognition, face recognition technology, facial detail, gender issues, high-resolution images, image classification, image resolution, learning, learning (artificial intelligence), learning automata, linear classifiers, low-resolution thumbnail images, nearest-neighbor classifiers, nonlinear support vector machines, pattern classifiers, quadratic classifiers, radial basis function networks, robustness, scale, stability, support vector machines},
pages = {707--711},
}

@article{haughney_features_2007,
title = {Features of asthma management: quantifying the patient perspective},
volume = {7},
issn = {1471-2466},
shorttitle = {Features of asthma management},
url = {http://dx.doi.org/10.1186/1471-2466-7-16},
doi = {10.1186/1471-2466-7-16},
abstract = {In the management of asthma, features of care important to patients may not be fully appreciated. This study quantifies the importance of different features of asthma management from the patient perspective. This may assist in the development of personalised management strategies.},
urldate = {2017-04-20},
journal = {BMC Pulmonary Medicine},
author = {Haughney, John and Fletcher, Monica and Wolfe, Stephanie and Ratcliffe, Julie and Brice, Roger and Partridge, Martyn R.},
year = {2007},
pages = {16},
}

@article{koinis-mitchell_identifying_2012,
title = {Identifying {Individual}, {Cultural} and {Asthma}-{Related} {Risk} and {Protective} {Factors} {Associated} {With} {Resilient} {Asthma} {Outcomes} in {Urban} {Children} and {Families}},
volume = {37},
issn = {0146-8693},
url = {https://academic.oup.com/jpepsy/article/37/4/424/895602/Identifying-Individual-Cultural-and-Asthma-Related},
doi = {10.1093/jpepsy/jss002},
number = {4},
urldate = {2017-04-20},
journal = {Journal of Pediatric Psychology},
author = {Koinis-Mitchell, Daphne and McQuaid, Elizabeth L. and Jandasek, Barbara and Kopel, Sheryl J. and Seifer, Ronald and Klein, Robert B. and Potter, Christina and Fritz, Gregory K.},
month = may,
year = {2012},
pages = {424--437},
}

@article{herman_conceptual_2011,
title = {Conceptual {Framework} of the {Controlling} {Asthma} in {American} {Cities} {Project}},
volume = {88},
issn = {1099-3460},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3042064/},
doi = {10.1007/s11524-010-9473-1},
abstract = {The Controlling Asthma in American Cities Project (CAACP) was designed to improve the control of asthma in inner-city populations of children with a disparate burden of symptoms and adverse outcomes. As with many chronic diseases, asthma is the manifestation of multiple biologic, environmental, and social determinants. In addition to appropriate medical management, individuals with asthma must have logistical, financial, and cultural access to environments that allow avoidance of asthma triggers and encourage good asthma management practices. In recognition of this complexity, the CAACP required the seven project sites to coordinate and synchronize multiple interventions (education, healthcare access, medical management, trigger reduction) at multiple levels (individual, home, school, community, and policy) through the collaboration of relevant groups, institutions, and individuals. This paper describes the “program theory” of the CAACP project—the assumptions about how the project worked, how the components were linked, and what outcomes were anticipated. It relates the subsequent papers in the supplement to the program theory and describes how the papers can inform and guide other community-based interventions, and advance the translation of scientific knowledge to effective interventions in communities of need.},
number = {Suppl 1},
urldate = {2017-04-20},
journal = {Journal of Urban Health : Bulletin of the New York Academy of Medicine},
author = {Herman, Elizabeth Jane},
month = feb,
year = {2011},
pmid = {21337048},
pmcid = {PMC3042064},
pages = {7--15},
}

@article{baltrus_individual_2017,
title = {Individual and county level predictors of asthma related emergency department visits among children on {Medicaid}: {A} multilevel approach},
volume = {54},
issn = {0277-0903},
shorttitle = {Individual and county level predictors of asthma related emergency department visits among children on {Medicaid}},
url = {http://dx.doi.org/10.1080/02770903.2016.1196367},
doi = {10.1080/02770903.2016.1196367},
abstract = {Objective: Disparities in asthma outcomes are well documented in the United States. Interventions to promote equity in asthma outcomes could target factors at the individual and community levels. The objective of this analysis was to understand the effect of individual (race, gender, age, and preventive inhaler use) and county-level factors (demographic, socioeconomic, health care, air-quality) on asthma emergency department (ED) visits among Medicaid-enrolled children. This was a retrospective cohort study of Medicaid-enrolled children with asthma in 29 states in 2009. Multilevel regression models of asthma ED visits were constructed utilizing individual-level variables (race, gender, age, and preventive inhaler use) from the Medicaid enrollment file and county-level variables reflecting population and health system characteristics from the Area Resource File (ARF). County-level measures of air quality were obtained from Environmental Protection Agency (EPA) data. Results: The primary modifiable risk factor at the individual level was found to be the ratio of long-term controller medications to total asthma medications. County-level factors accounted for roughly 6\% of the variance in the asthma ED visit risk. Increasing county-level racial segregation (OR=1.04, 95\% CI=1.01-1.08) was associated with increasing risk of asthma ED visits. Greater supply of pulmonary physicians at the county level (OR=0.81, 95\% CI=0.68-0.97) was associated with a reduction in risk of asthma ED visits. Conclusions: At the patient care level, proper use of controller medications is the factor most amenable to intervention. There is also a societal imperative to address negative social determinants, such as residential segregation.},
number = {1},
urldate = {2017-04-19},
journal = {Journal of Asthma},
author = {Baltrus, Peter and Xu, Junjun and Immergluck, Lilly and Gaglioti, Anne and Adesokan, Adeola and Rust, George},
month = jan,
year = {2017},
pmid = {27285734},
keywords = {Asthma, Emergency Department Visits, Medicaid, Poverty, children, counties, health care system, long-term controller medication, multilevel, race, segregation},
pages = {53--61},
}

@article{lee_novel_2011,
title = {A novel data mining mechanism considering bio-signal and environmental data with applications on asthma monitoring},
volume = {101},
issn = {1872-7565},
doi = {10.1016/j.cmpb.2010.04.016},
abstract = {Chronic asthmatic sufferers need to be constantly observed to prevent sudden attacks. In order to improve the efficiency and effectiveness of patient monitoring, we proposed in this paper a novel data mining mechanism for predicting attacks of chronic diseases by considering of both bio-signals of patients and environmental factors. We proposed two data mining methods, namely Pattern Based Decision Tree (PBDT) and Pattern Based Class-Association Rule (PBCAR). Both methods integrate the concepts of sequential pattern mining to extract features of asthma attacks, and then build classifiers with the concepts of decision tree mining and rule-based method respectively. Besides the general clinical data of patients, we considered environmental factors, which are related to many chronic diseases. For experimental evaluations, we adopted the children asthma allergic dataset collated from a hospital in Taiwan as well as the environmental factors like weather and air pollutant data. The experimental results show that PBCAR delivers 86.89\% of accuracy and 84.12\% of recall, and PBDT shows 87.52\% accuracy and 85.59 of recall. These results also indicate that our methods can perform high accuracy and recall on predictions of chronic disease attacks. The readable rules of both classifiers can provide patients and healthcare workers with insights on essential illness related information. At the same time, additional environmental factors of input data are also proven to be valuable in predicting attacks.},
language = {eng},
number = {1},
journal = {Computer Methods and Programs in Biomedicine},
author = {Lee, Chao-Hui and Chen, Jessie Chia-Yu and Tseng, Vincent S.},
month = jan,
year = {2011},
pmid = {20554074},
keywords = {Air Pollutants, Asthma, Child, Data Mining, Databases, Factual, Decision Trees, Environment, Humans, Risk Factors, Taiwan},
pages = {44--61},
}

@article{hong_lifestyle_1994,
title = {Lifestyle and behavioural risk factors associated with asthma morbidity in adults},
volume = {87},
issn = {1460-2725},
url = {https://academic.oup.com/qjmed/article-abstract/87/10/639/1592388/Lifestyle-and-behavioural-risk-factors-associated},
doi = {10.1093/oxfordjournals.qjmed.a068877},
number = {10},
urldate = {2017-04-19},
journal = {QJM: An International Journal of Medicine},
author = {Hong, C. Y. and Ng, T. P. and Wong, M. L. and Koh, K. T. C. and Goh, L. G. and Ling, S. L.},
month = oct,
year = {1994},
pages = {639--645},
}

@article{ho_air_2007,
title = {Air pollution, weather, and associated risk factors related to asthma prevalence and attack rate},
volume = {104},
issn = {0013-9351},
url = {http://www.sciencedirect.com/science/article/pii/S0013935107000205},
doi = {10.1016/j.envres.2007.01.007},
abstract = {Asthma is an important public health challenge. The objective of this research was to investigate the relationship of air pollution and weather to adolescent asthma prevalence and attack rate. A 6-month mass screening asthma study was conducted from October 1995 to March 1996 in Taiwan. The study population included junior high school students from throughout the country (1,139,452 students). Eighty-nine percent of students completed questionnaires (International Study of Asthma and Allergies in Childhood—ISAAC and New England Core Questionnaires) and passed a logical screening error program. Lung function data was collected to assist in the diagnosis of asthma status. From the students screened during this mass survey, a stratified random sample of 64,660 students was analyzed for asthma prevalence and attack rate. Using a regression model to compare the USEPA National Ambient Air Quality Standards 2000 (NAAQS, 2000) to asthma prevalence, this investigation found that the standards may not provide enough protection for adolescents after controlling for age, rhinitis, eczema, urban birth location, parental education level, exercise, cigarette smoking, environmental tobacco smoking, alcohol beverage consumption and weather factors. The general estimating equations (GEE) model, a repeated measurement regression model, was used to examine the relationship between the monthly asthma attack rate among asthma patients and air pollution (nitrogen oxides; nitrogen dioxide; nitric oxide; Ozone; PM10) while controlling for household smoking. The GEE model demonstrated that air pollution is related to asthma attack rate. Air pollution factors also interacted with weather parameters when related to asthma attack rate.},
number = {3},
urldate = {2017-04-19},
journal = {Environmental Research},
author = {Ho, Wen-Chao and Hartley, William R. and Myers, Leann and Lin, Meng-Hung and Lin, Yu-Sheng and Lien, Chih-Hui and Lin, Ruey-Shiung},
month = jul,
year = {2007},
keywords = {Air pollution, Asthma, Attack rate, Prevalence, Weather},
pages = {402--409},
}

@article{galant_predictive_2004,
title = {Predictive value of a cross-cultural asthma case-detection tool in an elementary school population},
volume = {114},
issn = {1098-4275},
doi = {10.1542/peds.2003-0575-F},
abstract = {OBJECTIVE: Bronchial asthma, which affects approximately 5 million US children, is vastly underdiagnosed and treated, particularly among minorities and those of low socioeconomic status. Because current methods of detecting those at greatest risk of asthma in a multicultural setting appear inadequate, we assessed the validity and reliability of a new asthma questionnaire across 3 dominant cultures in Orange County, California (white, Hispanic, and Vietnamese).
METHODS: Children in grades 1, 3, and 5 and their families, in 3 different schools representative of these major ethnic groups, were randomly selected to participate in the validation process. Two schools with low socioeconomic status and dominant Hispanic or Vietnamese minorities were designated inner-city schools, whereas the third school was a suburban school with predominately white students. Participants completed a 7-question, 11-element questionnaire in their primary language, followed by an asthma evaluation (history, physical examination, and spirometry) by an asthma specialist (who was blinded with respect to the results of the questionnaire), at their respective schools. The physician then made a determination regarding the presence and severity (according to National Institutes of Health guidelines) of asthma. Several weeks later, the entire student body was asked to complete the questionnaire at home and return it to school for analysis. Validation of each item was evaluated for sensitivity, specificity, and positive and negative predictive values, and application of univariate analyses provided an estimated probability of an asthma diagnosis by the asthma specialist. A "best-fit" algorithm was determined with all 11 elements, if possible, and an abbreviated algorithm that selected the fewest-question combination that yielded the best asthma predictability was established. Reliability was established with the percent agreement between the 2 questionnaires and the kappa statistic.
RESULTS: Of the 401 children/families who participated in the validation analysis, 45\% were Hispanic, 22\% white, 19\% Vietnamese, and 15\% other. The overall prevalence of asthma specialist-diagnosed asthma was 28\%, with 65\% of cases being graded as intermittent and 35\% as persistent. Sixty-two percent of the children had not been previously diagnosed with asthma. There were no significant differences among cultures in sensitivity or specificity for any of the individual questions or the complete or abbreviated algorithms. The abbreviated algorithm with 3 questions, ie, question 1 (asthma in the past 2 years), question 4 (cough, chest tightness, trouble breathing, or wheezing with exercise), and question 6 (same symptoms in the morning or day in the past 4 weeks) yielded comparable sensitivity and specificity for the complete algorithm in all groups. The abbreviated algorithm had {\textgreater}86\% predictability in detecting children with persistent asthma and 56\% predictability in detecting children with intermittent asthma. Reliability was also excellent, with percent agreement usually {\textgreater} 80\% and kappa values of {\textgreater}.70.
CONCLUSIONS: This asthma detection tool has been shown to be suitable for detecting persistent asthma in a multicultural inner-city population, as well as in a suburban setting. An abbreviated algorithm with 3 questions and {\textgreater}80\% predictability in detecting persistent asthma seems ideal for evaluating large numbers of school-aged children. The school setting is an excellent site for identifying children with asthma. Although there is concern that subjects detected in the school setting might not have access to ongoing medical care, case detection is an important first step that could lead to earlier diagnosis and treatment. Reducing the barriers to good care in inner-city environments is the next step.},
language = {eng},
number = {3},
journal = {Pediatrics},
author = {Galant, Stanley P. and Crawford, Linda J. R. and Morphew, Tricia and Jones, Craig A. and Bassin, Stanley},
month = sep,
year = {2004},
pmid = {15342891},
keywords = {Algorithms, Asthma, California, Child, Child, Preschool, Cultural Diversity, European Continental Ancestry Group, Female, Hispanic Americans, Humans, Male, Poverty Areas, Predictive Value of Tests, Reproducibility of Results, Sensitivity and Specificity, Suburban Population, Surveys and Questionnaires, Urban Population, Vietnam},
pages = {e307--316},
}

@article{arif_occupational_2009,
title = {Occupational exposures and asthma among nursing professionals},
volume = {66},
copyright = {2009 BMJ Publishing Group},
issn = {1351-0711, 1470-7926},
url = {http://oem.bmj.com/content/66/4/274},
doi = {10.1136/oem.2008.042382},
abstract = {Objectives: To identify occupational exposure risk factors associated with the development of new-onset asthma in nurses.
Methods: A cross-sectional survey was administered to a sample of licensed Texas nurses (response rate 70\%) and compared to three other healthcare professional groups. Nursing professionals were defined based on self-reported longest held job. Outcome variables were physician-diagnosed new-onset asthma after entry into the healthcare profession and symptoms associated with bronchial hyper-responsiveness (BHR). Occupational exposures were ascertained through a job-exposure matrix, grouped into four categories: cleaning-related tasks, use of powdered latex gloves, administration of aerosolised medications, and tasks involving adhesive compounds, glues and/or solvents.
Results: After adjustment for age, sex, ethnicity, atopy, smoking, body mass index and seniority, reported asthma was significantly greater among nursing professionals involved in medical instrument cleaning (OR = 1.67, 95\% CI 1.06 to 2.62) and exposure to general cleaning products and disinfectants (OR = 1.72, 95\% CI 1.00 to 2.94). Use of powdered latex gloves during 1992–2000 was associated with 1.6 times (95\% CI 1.01 to 2.50) the odds of reported asthma. In univariate analysis, exposure to adhesives, glues and/or solvents was associated with a twofold increase in the odds of reported asthma, but not after adjustment for covariates. Similarly, the odds of BHR-related symptoms were significantly greater among nursing professionals exposed to general cleaning products and disinfectants (OR = 1.57, 95\% CI 1.11 to 2.21) and adhesives, glues and/or solvents used in patient care (OR = 1.51, 95\% CI 1.08 to 2.12).
Conclusion: Among nursing professionals, workplace exposures to cleaning products and disinfectants increase the risk of new-onset asthma.},
language = {en},
number = {4},
urldate = {2017-04-19},
journal = {Occupational and Environmental Medicine},
author = {Arif, A. A. and Delclos, G. L. and Serra, C.},
month = apr,
year = {2009},
pmid = {19164328},
pages = {274--278},
}

@article{sloan_who_2015,
title = {Who {Tweets}? {Deriving} the {Demographic} {Characteristics} of {Age}, {Occupation} and {Social} {Class} from {Twitter} {User} {Meta}-{Data}},
volume = {10},
issn = {1932-6203},
shorttitle = {Who {Tweets}?},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115545},
doi = {10.1371/journal.pone.0115545},
abstract = {This paper specifies, designs and critically evaluates two tools for the automated identification of demographic data (age, occupation and social class) from the profile descriptions of Twitter users in the United Kingdom (UK). Meta-data data routinely collected through the Collaborative Social Media Observatory (COSMOS: http://www.cosmosproject.net/) relating to UK Twitter users is matched with the occupational lookup tables between job and social class provided by the Office for National Statistics (ONS) using SOC2010. Using expert human validation, the validity and reliability of the automated matching process is critically assessed and a prospective class distribution of UK Twitter users is offered with 2011 Census baseline comparisons. The pattern matching rules for identifying age are explained and enacted following a discussion on how to minimise false positives. The age distribution of Twitter users, as identified using the tool, is presented alongside the age distribution of the UK population from the 2011 Census. The automated occupation detection tool reliably identifies certain occupational groups, such as professionals, for which job titles cannot be confused with hobbies or are used in common parlance within alternative contexts. An alternative explanation on the prevalence of hobbies is that the creative sector is overrepresented on Twitter compared to 2011 Census data. The age detection tool illustrates the youthfulness of Twitter users compared to the general UK population as of the 2011 Census according to proportions, but projections demonstrate that there is still potentially a large number of older platform users. It is possible to detect “signatures” of both occupation and age from Twitter meta-data with varying degrees of accuracy (particularly dependent on occupational groups) but further confirmatory work is needed.},
number = {3},
urldate = {2017-04-19},
journal = {PLOS ONE},
author = {Sloan, Luke and Morgan, Jeffrey and Burnap, Pete and Williams, Matthew},
month = mar,
year = {2015},
keywords = {Age distribution, Census, Demography, Facebook, Professions, Social Media, Social sciences, twitter},
pages = {e0115545},
}

@inproceedings{rao_classifying_2010,
address = {New York, NY, USA},
series = {{SMUC} '10},
title = {Classifying {Latent} {User} {Attributes} in {Twitter}},
isbn = {978-1-4503-0386-6},
url = {http://doi.acm.org/10.1145/1871985.1871993},
doi = {10.1145/1871985.1871993},
abstract = {Social media outlets such as Twitter have become an important forum for peer interaction. Thus the ability to classify latent user attributes, including gender, age, regional origin, and political orientation solely from Twitter user language or similar highly informal content has important applications in advertising, personalization, and recommendation. This paper includes a novel investigation of stacked-SVM-based classification algorithms over a rich set of original features, applied to classifying these four user attributes. It also includes extensive analysis of features and approaches that are effective and not effective in classifying user attributes in Twitter-style informal written genres as distinct from the other primarily spoken genres previously studied in the user-property classification literature. Our models, singly and in ensemble, significantly outperform baseline models in all cases. A detailed analysis of model components and features provides an often entertaining insight into distinctive language-usage variation across gender, age, regional origin and political orientation in modern informal communication.},
urldate = {2017-04-19},
booktitle = {Proceedings of the {2Nd} {International} {Workshop} on {Search} and {Mining} {User}-generated {Contents}},
publisher = {ACM},
author = {Rao, Delip and Yarowsky, David and Shreevats, Abhishek and Gupta, Manaswi},
year = {2010},
keywords = {Social Media, attribute learning, latent attribute classification},
pages = {37--44},
}

@inproceedings{burger_discriminating_2011,
address = {Stroudsburg, PA, USA},
series = {{EMNLP} '11},
title = {Discriminating {Gender} on {Twitter}},
isbn = {978-1-937284-11-4},
url = {http://dl.acm.org/citation.cfm?id=2145432.2145568},
abstract = {Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.},
urldate = {2017-04-19},
booktitle = {Proceedings of the {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
publisher = {Association for Computational Linguistics},
author = {Burger, John D. and Henderson, John and Kim, George and Zarrella, Guido},
year = {2011},
pages = {1301--1309},
}

@article{bates_big_2014,
title = {Big {Data} {In} {Health} {Care}: {Using} {Analytics} {To} {Identify} {And} {Manage} {High}-{Risk} {And} {High}-{Cost} {Patients}},
volume = {33},
issn = {0278-2715, 1544-5208},
shorttitle = {Big {Data} {In} {Health} {Care}},
url = {http://content.healthaffairs.org/content/33/7/1123},
doi = {10.1377/hlthaff.2014.0041},
abstract = {The US health care system is rapidly adopting electronic health records, which will dramatically increase the quantity of clinical data that are available electronically. Simultaneously, rapid progress has been made in clinical analytics—techniques for analyzing large quantities of data and gleaning new insights from that analysis—which is part of what is known as big data. As a result, there are unprecedented opportunities to use big data to reduce the costs of health care in the United States. We present six use cases—that is, key examples—where some of the clearest opportunities exist to reduce costs through the use of big data: high-cost patients, readmissions, triage, decompensation (when a patient’s condition worsens), adverse events, and treatment optimization for diseases affecting multiple organ systems. We discuss the types of insights that are likely to emerge from clinical analytics, the types of data needed to obtain such insights, and the infrastructure—analytics, algorithms, registries, assessment scores, monitoring devices, and so forth—that organizations will need to perform the necessary analyses and to implement changes that will improve care while reducing costs. Our findings have policy implications for regulatory oversight, ways to address privacy concerns, and the support of research on analytics.},
language = {en},
number = {7},
urldate = {2017-04-17},
journal = {Health Affairs},
author = {Bates, David W. and Saria, Suchi and Ohno-Machado, Lucila and Shah, Anand and Escobar, Gabriel},
month = jul,
year = {2014},
pmid = {25006137},
keywords = {Cost of Health Care, Information Technology, Quality Of Care},
pages = {1123--1131},
}

@article{ben-shlomo_life_2002,
title = {A life course approach to chronic disease epidemiology: conceptual models, empirical challenges and interdisciplinary perspectives},
volume = {31},
issn = {0300-5771},
shorttitle = {A life course approach to chronic disease epidemiology},
url = {https://academic.oup.com/ije/article/31/2/285/617688/A-life-course-approach-to-chronic-disease},
doi = {10.1093/ije/31.2.285},
number = {2},
urldate = {2017-04-18},
journal = {International Journal of Epidemiology},
author = {Ben-Shlomo, Yoav and Kuh, Diana},
month = apr,
year = {2002},
pages = {285--293},
}

@inproceedings{tang_habits_2015,
address = {New York, NY, USA},
series = {{WebSci} '15},
title = {Habits vs {Environment}: {What} {Really} {Causes} {Asthma}?},
isbn = {978-1-4503-3672-7},
shorttitle = {Habits vs {Environment}},
url = {http://doi.acm.org/10.1145/2786451.2786481},
doi = {10.1145/2786451.2786481},
abstract = {Despite considerable number of studies on risk factors for asthma onset, very little is known about their relative importance. To have a full picture of these factors, both categories, personal and environmental data, have to be taken into account simultaneously, which is missing in previous studies. We propose a framework to rank the risk factors from heterogeneous data sources of the two categories. Established on top of EventShop and Personal EventShop, this framework extracts about 400 features, and analyzes them by employing a gradient boosting tree. The features come from sources including personal profile and life-event data, and environmental data on air pollution, weather and PM2.5 emission sources. The top ranked risk factors derived from our framework agree well with the general medical consensus. Thus, our framework is a reliable approach, and the discovered rankings of relative importance of risk factors can provide insights for the prevention of asthma.},
urldate = {2017-04-19},
booktitle = {Proceedings of the {ACM} {Web} {Science} {Conference}},
publisher = {ACM},
author = {Tang, Mengfan and Agrawal, Pranav and Jain, Ramesh},
year = {2015},
keywords = {Asthma, Asthma risk analysis, Feature extraction, Gradient Boosting Tree, asthma\_project},
pages = {30:1--30:5},
}

@misc{cdc_cdc_2017-1,
title = {{CDC} - {Asthma} - {Most} {Recent} {Asthma} {State} {Data}},
url = {https://www.cdc.gov/asthma/most_recent_data_states.htm},
urldate = {2017-04-19},
author = {CDC},
month = feb,
year = {2017},
}

@article{cdc_vital_2011,
title = {Vital signs: asthma prevalence, disease characteristics, and self-management education: {United} {States}, 2001--2009},
volume = {60},
issn = {1545-861X},
shorttitle = {Vital signs},
abstract = {BACKGROUND: Most persons with asthma can be symptom-free if they receive appropriate medical care, use inhaled corticosteroids when prescribed, and modify their environment to reduce or eliminate exposure to allergens and irritants. This report reviews recent progress in managing asthma and reducing its prevalence in the United States.
METHODS: CDC analyzed asthma data from the 2001--2009 National Health Interview Survey concerning children and adults, and from the 2001, 2005, and 2009 state-based Behavioral Risk Factor Surveillance System concerning adults.
RESULTS: Among persons of all ages, the prevalence of asthma increased from 7.3\% (20.3 million persons) in 2001 to 8.2\% (24.6 million persons) in 2009, a 12.3\% increase. Prevalence among children (persons aged {\textless}18 years) was 9.6\%, and was highest among poor children (13.5\%) and among non-Hispanic black children (17.0\%). Prevalence among adults was 7.7\%, and was greatest in women (9.7\%) and in adults who were poor (10.6\%). More uninsured persons with asthma than insured could not afford to buy prescription medications (40.3\% versus 11.5\%), and fewer uninsured persons reported seeing or talking with a primary-care physician (58.8\% versus 85.6\%) or specialist (19.5\% versus 36.9\%). Among persons with asthma, 34.2\% reported being given a written asthma action plan, and 68.1\% had been taught the appropriate response to symptoms of an asthma attack. Only about one third of children or adults were using long-term control medicine such as inhaled corticosteroids at the time of the survey. CONCLUSIONS AND COMMENT: Persons with asthma need to have access to health care and appropriate medications and use them. They also need to learn self-management skills and practice evidence-based interventions that reduce environmental risk factors.},
language = {eng},
number = {17},
journal = {MMWR. Morbidity and mortality weekly report},
author = {{CDC}},
month = may,
year = {2011},
pmid = {21544044},
keywords = {Administration, Inhalation, Adolescent, Adrenal Cortex Hormones, Adult, Allergens, Asthma, Behavioral Risk Factor Surveillance System, Child, Environment, Environmental Exposure, Female, Health Services Accessibility, Health Services Needs and Demand, Humans, Income, Insurance, Health, Irritants, Male, Medically Uninsured, Patient Education as Topic, Prevalence, Self Care, Severity of Illness Index, United States},
pages = {547--552},
}

@article{akinbami_asthma_2011,
title = {Asthma prevalence, health care use, and mortality: {United} {States}, 2005-2009},
issn = {2164-8344},
shorttitle = {Asthma prevalence, health care use, and mortality},
abstract = {OBJECTIVES: This report presents recent data on asthma prevalence and health care use. Additional data on school and work absences and asthma management practices are also presented. Where possible, differences are examined by age, sex, race or ethnicity, geographic region, poverty status, and urbanicity.
METHODS: Data from the National Health Interview Survey, the National Ambulatory Medical Care Survey, the National Hospital Ambulatory Medical Care Survey, the National Hospital Discharge Survey, and the National Vital Statistics System were used to calculate national estimates. The most recent data available from each system are presented, and 3-year annual averages are used to increase the reliability of estimates for subgroups where necessary.
RESULTS: In 2009, current asthma prevalence was 8.2\% of the U.S. population (24.6 million people); within population subgroups it was higher among females, children, persons of non-Hispanic black and Puerto Rican race or ethnicity, persons with family income below the poverty level, and those residing in the Northeast and Midwest regions. In 2008, persons with asthma missed 10.5 million school days and 14.2 million work days due to their asthma. In 2007, there were 1.75 million asthma-related emergency department visits and 456,000 asthma hospitalizations. Asthma emergency visit and hospitalization rates were higher among females than males, among children than adults, and among black than white persons. Despite the high burden from adverse impacts, use of some asthma management strategies based on clinical guidelines for the treatment of asthma remained below the targets set by the Healthy People 2010 initiative.},
language = {eng},
number = {32},
journal = {National Health Statistics Reports},
author = {Akinbami, Lara J. and Moorman, Jeanne E. and Liu, Xiang},
month = jan,
year = {2011},
pmid = {21355352},
keywords = {Absenteeism, Adolescent, Adult, Aged, Aged, 80 and over, Asthma, Child, Child, Preschool, Emergency Service, Hospital, Female, Health Surveys, Humans, Infant, Infant, Newborn, Male, Middle Aged, Prevalence, United States, Young Adult},
pages = {1--14},
}

@article{yin_using_2012,
title = {Using {Social} {Media} to {Enhance} {Emergency} {Situation} {Awareness}},
volume = {27},
issn = {1541-1672},
doi = {10.1109/MIS.2012.6},
abstract = {The described system uses natural language processing and data mining techniques to extract situation awareness information from Twitter messages generated during various disasters and crises.},
number = {6},
journal = {IEEE Intelligent Systems},
author = {Yin, J. and Lampert, A. and Cameron, M. and Robinson, B. and Power, R.},
month = nov,
year = {2012},
keywords = {Clustering algorithms, Data Mining, Feature extraction, Medical information processing, Medical services, Social Media, Social network services, Twitter message, burst detection, crises, data mining technique, disaster, disasters, emergency response, emergency services, emergency situation awareness, information retrieval, natural language processing, online clustering, situation awareness, situation awareness information extraction, social networking (online), text classification, twitter},
pages = {52--59},
}

@inproceedings{eisenstein_what_2013,
title = {What to do about bad language on the internet},
abstract = {The rise of social media has brought computational linguistics in ever-closer contact with bad language: text that defies our expectations about vocabulary, spelling, and syntax. This paper surveys the landscape of bad language, and offers a critical review of the NLP community’s response, which has largely followed two paths: normalization and domain adaptation. Each approach is evaluated in the context of theoretical and empirical work on computer-mediated communication. In addition, the paper presents a quantitative analysis of the lexical diversity of social media text, and its relationship to other corpora. 1},
booktitle = {{HLT}-{NAACL}},
author = {Eisenstein, Jacob},
year = {2013},
pages = {359--369},
}

@article{ruths_social_2014,
title = {Social media for large studies of behavior},
volume = {346},
copyright = {Copyright © 2014, American Association for the Advancement of Science},
issn = {0036-8075, 1095-9203},
url = {http://science.sciencemag.org/content/346/6213/1063},
doi = {10.1126/science.346.6213.1063},
abstract = {On 3 November 1948, the day after Harry Truman won the United States presidential elections, the Chicago Tribune published one of the most famous erroneous headlines in newspaper history: “Dewey Defeats Truman” (1, 2). The headline was informed by telephone surveys, which had inadvertently undersampled Truman supporters (1). Rather than permanently discrediting the practice of polling, this event led to the development of more sophisticated techniques and higher standards that produce the more accurate and statistically rigorous polls conducted today (3).
Large-scale studies of human behavior in social media need to be held to higher methodological standards
Large-scale studies of human behavior in social media need to be held to higher methodological standards},
language = {en},
number = {6213},
urldate = {2017-04-19},
journal = {Science},
author = {Ruths, Derek and Pfeffer, Jürgen},
month = nov,
year = {2014},
pmid = {25430759},
pages = {1063--1064},
}

@article{ramachandran_effectiveness_2013,
title = {Effectiveness of mobile phone messaging in prevention of type 2 diabetes by lifestyle modification in men in {India}: a prospective, parallel-group, randomised controlled trial},
volume = {1},
issn = {2213-8587, 2213-8595},
shorttitle = {Effectiveness of mobile phone messaging in prevention of type 2 diabetes by lifestyle modification in men in {India}},
url = {http://thelancet.com/journals/landia/article/PIIS2213-8587(13)70067-6/abstract},
doi = {10.1016/S2213-8587(13)70067-6},
abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}h3{\textgreater}Background{\textless}/h3{\textgreater}{\textless}p{\textgreater}Type 2 diabetes can often be prevented by lifestyle modification; however, successful lifestyle intervention programmes are labour intensive. Mobile phone messaging is an inexpensive alternative way to deliver educational and motivational advice about lifestyle modification. We aimed to assess whether mobile phone messaging that encouraged lifestyle change could reduce incident type 2 diabetes in Indian Asian men with impaired glucose tolerance.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Methods{\textless}/h3{\textgreater}{\textless}p{\textgreater}We did a prospective, parallel-group, randomised controlled trial between Aug 10, 2009, and Nov 30, 2012, at ten sites in southeast India. Working Indian men (aged 35–55 years) with impaired glucose tolerance were randomly assigned (1:1) with a computer-generated randomisation sequence to a mobile phone messaging intervention or standard care (control group). Participants in the intervention group received frequent mobile phone messages compared with controls who received standard lifestyle modification advice at baseline only. Field staff and participants were, by necessity, not masked to study group assignment, but allocation was concealed from laboratory personnel as well as principal and co-investigators. The primary outcome was incidence of type 2 diabetes, analysed by intention to treat. This trial is registered with ClinicalTrials.gov, number NCT00819455.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}We assessed 8741 participants for eligibility. 537 patients were randomly assigned to either the mobile phone messaging intervention (n=271) or standard care (n=266). The cumulative incidence of type 2 diabetes was lower in those who received mobile phone messages than in controls: 50 (18\%) participants in the intervention group developed type 2 diabetes compared with 73 (27\%) in the control group (hazard ratio 0·64, 95\% CI 0·45–0·92; p=0·015). The number needed to treat to prevent one case of type 2 diabetes was 11 (95\% CI 6–55). One patient in the control group died suddenly at the end of the first year. We recorded no other serious adverse events.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Interpretation{\textless}/h3{\textgreater}{\textless}p{\textgreater}Mobile phone messaging is an effective and acceptable method to deliver advice and support towards lifestyle modification to prevent type 2 diabetes in men at high risk.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Funding{\textless}/h3{\textgreater}{\textless}p{\textgreater}The UK India Education and Research Initiative, the World Diabetes Foundation.{\textless}/p{\textgreater}},
language = {English},
number = {3},
urldate = {2017-04-18},
journal = {The Lancet Diabetes \& Endocrinology},
author = {Ramachandran, Ambady and Snehalatha, Chamukuttan and Ram, Jagannathan and Selvam, Sundaram and Simon, Mary and Nanditha, Arun and Shetty, Ananth Samith and Godsland, Ian F. and Chaturvedi, Nish and Majeed, Azeem and Oliver, Nick and Toumazou, Christofer and Alberti, K. George and Johnston, Desmond G.},
month = nov,
year = {2013},
pages = {191--198},
}

@article{eichstaedt_psychological_2015,
title = {Psychological {Language} on {Twitter} {Predicts} {County}-{Level} {Heart} {Disease} {Mortality}},
volume = {26},
issn = {0956-7976},
url = {http://dx.doi.org/10.1177/0956797614557867},
doi = {10.1177/0956797614557867},
abstract = {Hostility and chronic stress are known risk factors for heart disease, but they are costly to assess on a large scale. We used language expressed on Twitter to characterize community-level psychological correlates of age-adjusted mortality from atherosclerotic heart disease (AHD). Language patterns reflecting negative social relationships, disengagement, and negative emotions—especially anger—emerged as risk factors; positive emotions and psychological engagement emerged as protective factors. Most correlations remained significant after controlling for income and education. A cross-sectional regression model based only on Twitter language predicted AHD mortality significantly better than did a model that combined 10 common demographic, socioeconomic, and health risk factors, including smoking, diabetes, hypertension, and obesity. Capturing community psychological characteristics through social media is feasible, and these characteristics are strong markers of cardiovascular mortality at the community level.},
language = {en},
number = {2},
urldate = {2017-04-18},
journal = {Psychological Science},
author = {Eichstaedt, Johannes C. and Schwartz, Hansen Andrew and Kern, Margaret L. and Park, Gregory and Labarthe, Darwin R. and Merchant, Raina M. and Jha, Sneha and Agrawal, Megha and Dziurzynski, Lukasz A. and Sap, Maarten and Weeg, Christopher and Larson, Emily E. and Ungar, Lyle H. and Seligman, Martin E. P.},
month = feb,
year = {2015},
pages = {159--169},
}

@article{eurowinter_group_cold_1997,
title = {Cold exposure and winter mortality from ischaemic heart disease, cerebrovascular disease, respiratory disease, and all causes in warm and cold regions of {Europe}},
volume = {349},
issn = {0140-6736},
url = {http://www.sciencedirect.com/science/article/pii/S0140673696123382},
doi = {10.1016/S0140-6736(96)12338-2},
abstract = {SummaryBackground
Differences in baseline mortality, age structure, and influenza epidemics confound comparisons of cold-related increases in mortality between regions with different climates. The Eurowinter study aimed to assess whether increases in mortality per 1°C fall in temperature differ in various European regions and to relate any differences to usual winter climate and measures to protect against cold.
Methods
Percentage increases in deaths per day per 1°C fall in temperature below 18°C (indices of cold-related mortality) were estimated by generalised linear modelling. We assessed protective factors by surveys and adjusted by regression to 7°C outdoor temperature. Cause-specific data gathered from 1988 to 1992 were analysed by multiple regression for men and women aged 50–59 and 65–74 in north Finland, south Finland, Baden-Württemburg, the Netherlands, London, and north Italy (24 groups). We used a similar method to analyse 1992 data in Athens and Palermo.
Findings
The percentage increases in all-cause mortality per 1°C fall in temperature below 18°C were greater in warmer regions than in colder regions (eg, Athens 2·15\% [95\% CI 1·20–3·10] vs south Finland 0·27\% [0·15–0·40]). At an outdoor temperature of 7°C, the mean living-room temperature was 19·2°C in Athens and 21·7°C in south Finland; 13\% and 72\% of people in these regions, respectively, wore hats when outdoors at 7°C. Multiple regression analyses (with allowance for sex and age, in the six regions with full data) showed that high indices of cold-related mortality were associated with high mean winter temperatures, low living-room temperatures, limited bedroom heating, low proportions of people wearing hats, gloves, and anoraks, and inactivity and shivering when outdoors at 7°C (p\&lt;0·01 for all-cause mortality and respiratory mortality; p\&gt;0·05 for mortality from ischaemic heart disease and cerebrovascular disease).
Interpretation
Mortality increased to a greater extent with given fall of temperature in regions with warm winters, in populations with cooler homes, and among people who wore fewer clothes and were less active outdoors.},
number = {9062},
urldate = {2017-04-18},
journal = {The Lancet},
author = {Eurowinter Group},
month = may,
year = {1997},
pages = {1341--1346},
}

@article{kovats_heat_2008,
title = {Heat {Stress} and {Public} {Health}: {A} {Critical} {Review}},
volume = {29},
shorttitle = {Heat {Stress} and {Public} {Health}},
url = {http://dx.doi.org/10.1146/annurev.publhealth.29.020907.090843},
doi = {10.1146/annurev.publhealth.29.020907.090843},
abstract = {Heat is an environmental and occupational hazard. The prevention of deaths in the community caused by extreme high temperatures (heat waves) is now an issue of public health concern. The risk of heat-related mortality increases with natural aging, but persons with particular social and/or physical vulnerability are also at risk. Important differences in vulnerability exist between populations, depending on climate, culture, infrastructure (housing), and other factors. Public health measures include health promotion and heat wave warning systems, but the effectiveness of acute measures in response to heat waves has not yet been formally evaluated. Climate change will increase the frequency and the intensity of heat waves, and a range of measures, including improvements to housing, management of chronic diseases, and institutional care of the elderly and the vulnerable, will need to be developed to reduce health impacts.},
number = {1},
urldate = {2017-04-18},
journal = {Annual Review of Public Health},
author = {Kovats, R. Sari and Hajat, Shakoor},
year = {2008},
pmid = {18031221},
pages = {41--55},
}

@article{andreu-perez_wearable_2015,
title = {From {Wearable} {Sensors} to {Smart} {Implants}--{Toward} {Pervasive} and {Personalized} {Healthcare}},
volume = {62},
issn = {1558-2531},
doi = {10.1109/TBME.2015.2422751},
abstract = {OBJECTIVE: This paper discusses the evolution of pervasive healthcare from its inception for activity recognition using wearable sensors to the future of sensing implant deployment and data processing.
METHODS: We provide an overview of some of the past milestones and recent developments, categorized into different generations of pervasive sensing applications for health monitoring. This is followed by a review on recent technological advances that have allowed unobtrusive continuous sensing combined with diverse technologies to reshape the clinical workflow for both acute and chronic disease management. We discuss the opportunities of pervasive health monitoring through data linkages with other health informatics systems including the mining of health records, clinical trial databases, multiomics data integration, and social media.
CONCLUSION: Technical advances have supported the evolution of the pervasive health paradigm toward preventative, predictive, personalized, and participatory medicine.
SIGNIFICANCE: The sensing technologies discussed in this paper and their future evolution will play a key role in realizing the goal of sustainable healthcare systems.},
language = {eng},
number = {12},
journal = {IEEE transactions on bio-medical engineering},
author = {Andreu-Perez, Javier and Leff, Daniel R. and Ip, H. M. D. and Yang, Guang-Zhong},
month = dec,
year = {2015},
pmid = {25879838},
keywords = {Humans, Monitoring, Ambulatory, Prostheses and Implants, medical informatics, precision medicine},
pages = {2750--2762},
}

@article{andreu-perez_big_2015,
title = {Big {Data} for {Health}},
volume = {19},
issn = {2168-2194},
doi = {10.1109/JBHI.2015.2450362},
abstract = {This paper provides an overview of recent developments in big data in the context of biomedical and health informatics. It outlines the key characteristics of big data and how medical and health informatics, translational bioinformatics, sensor informatics, and imaging informatics will benefit from an integrated approach of piecing together different aspects of personalized information from a diverse range of data sources, both structured and unstructured, covering genomics, proteomics, metabolomics, as well as imaging, clinical diagnosis, and long-term continuous physiological sensing of an individual. It is expected that recent advances in big data will expand our knowledge for testing new hypotheses about disease management from diagnosis to prevention to personalized treatment. The rise of big data, however, also raises challenges in terms of privacy, security, data ownership, data stewardship, and governance. This paper discusses some of the existing activities and future opportunities related to big data for health, outlining some of the key underlying issues that need to be tackled.},
number = {4},
journal = {IEEE Journal of Biomedical and Health Informatics},
author = {Andreu-Perez, J. and Poon, C. C. Y. and Merrifield, R. D. and Wong, S. T. C. and Yang, G. Z.},
month = jul,
year = {2015},
keywords = {1, Big Data, Bioinformatics, Disease Management, Drugs, Informatics, biomedical imaging, biomedical informatics, clinical diagnosis, data ownership, data privacy, data stewardship, diseases, genomics, governance, health informatics, imaging informatics, long-term continuous physiological sensing, medical imaging, medical informatics, medical information systems, metabolomics, patient treatment, personalized information, personalized treatment, precision medicine, privacy, proteomics, security, security of data, sensor informatics, social health, translational bioinformatics},
pages = {1193--1208},
}

@article{marcos_interoperability_2013,
title = {Interoperability of clinical decision-support systems and electronic health records using archetypes: a case study in clinical trial eligibility},
volume = {46},
issn = {1532-0480},
shorttitle = {Interoperability of clinical decision-support systems and electronic health records using archetypes},
doi = {10.1016/j.jbi.2013.05.004},
abstract = {Clinical decision-support systems (CDSSs) comprise systems as diverse as sophisticated platforms to store and manage clinical data, tools to alert clinicians of problematic situations, or decision-making tools to assist clinicians. Irrespective of the kind of decision-support task CDSSs should be smoothly integrated within the clinical information system, interacting with other components, in particular with the electronic health record (EHR). However, despite decades of developments, most CDSSs lack interoperability features. We deal with the interoperability problem of CDSSs and EHRs by exploiting the dual-model methodology. This methodology distinguishes a reference model and archetypes. A reference model is represented by a stable and small object-oriented model that describes the generic properties of health record information. For their part, archetypes are reusable and domain-specific definitions of clinical concepts in the form of structured and constrained combinations of the entities of the reference model. We rely on archetypes to make the CDSS compatible with EHRs from different institutions. Concretely, we use archetypes for modelling the clinical concepts that the CDSS requires, in conjunction with a series of knowledge-intensive mappings relating the archetypes to the data sources (EHR and/or other archetypes) they depend on. We introduce a comprehensive approach, including a set of tools as well as methodological guidelines, to deal with the interoperability of CDSSs and EHRs based on archetypes. Archetypes are used to build a conceptual layer of the kind of a virtual health record (VHR) over the EHR whose contents need to be integrated and used in the CDSS, associating them with structural and terminology-based semantics. Subsequently, the archetypes are mapped to the EHR by means of an expressive mapping language and specific-purpose tools. We also describe a case study where the tools and methodology have been employed in a CDSS to support patient recruitment in the framework of a clinical trial for colorectal cancer screening. The utilisation of archetypes not only has proved satisfactory to achieve interoperability between CDSSs and EHRs but also offers various advantages, in particular from a data model perspective. First, the VHR/data models we work with are of a high level of abstraction and can incorporate semantic descriptions. Second, archetypes can potentially deal with different EHR architectures, due to their deliberate independence of the reference model. Third, the archetype instances we obtain are valid instances of the underlying reference model, which would enable e.g. feeding back the EHR with data derived by abstraction mechanisms. Lastly, the medical and technical validity of archetype models would be assured, since in principle clinicians should be the main actors in their development.},
language = {eng},
number = {4},
journal = {Journal of Biomedical Informatics},
author = {Marcos, Mar and Maldonado, Jose A. and Martínez-Salvador, Begoña and Boscá, Diego and Robles, Montserrat},
month = aug,
year = {2013},
pmid = {23707417},
keywords = {Clinical Trials as Topic, Clinical decision support systems, Clinical trials, Colorectal Neoplasms, Decision Support Systems, Clinical, Electronic Health Records, Humans, Medical Record Linkage, SNOMED CT, Systems integration, Terminology},
pages = {676--689},
}

@article{hagar_survival_2014,
title = {Survival analysis with electronic health record data: {Experiments} with chronic kidney disease},
volume = {7},
issn = {1932-1872},
shorttitle = {Survival analysis with electronic health record data},
url = {http://onlinelibrary.wiley.com/doi/10.1002/sam.11236/abstract},
doi = {10.1002/sam.11236},
abstract = {This article presents a detailed survival analysis for chronic kidney disease (CKD). The analysis is based on the electronic health record (EHR) data comprising almost two decades of clinical observations collected at New York-Presbyterian, a large hospital in New York City with one of the oldest electronic health records in the United States. Our survival analysis approach centers around Bayesian multiresolution hazard modeling, with an objective to capture the changing hazard of CKD over time, adjusted for patient clinical covariates and kidney-related laboratory tests. Special attention is paid to statistical issues common to all EHR data, such as cohort definition, missing data and censoring, variable selection, and potential for joint survival and longitudinal modeling, all of which are discussed alone and within the EHR CKD context.},
language = {en},
number = {5},
urldate = {2017-04-17},
journal = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
author = {Hagar, Yolanda and Albers, David and Pivovarov, Rimma and Chase, Herbert and Dukic, Vanja and Elhadad, Noémie},
month = oct,
year = {2014},
keywords = {EHR, chronic kidney disease, multiresolution hazard, survival analysis},
pages = {385--403},
}

@article{boland_discovering_2013,
title = {Discovering medical conditions associated with periodontitis using linked electronic health records},
volume = {40},
issn = {1600-051X},
doi = {10.1111/jcpe.12086},
abstract = {AIM: To use linked electronic medical and dental records to discover associations between periodontitis and medical conditions independent of a priori hypotheses.
MATERIALS AND METHODS: This case-control study included 2475 patients who underwent dental treatment at the College of Dental Medicine at Columbia University and medical treatment at NewYork-Presbyterian Hospital. Our cases are patients who received periodontal treatment and our controls are patients who received dental maintenance but no periodontal treatment. Chi-square analysis was performed for medical treatment codes and logistic regression was used to adjust for confounders.
RESULTS: Our method replicated several important periodontitis associations in a largely Hispanic population, including diabetes mellitus type I (OR = 1.6, 95\% CI 1.30-1.99, p {\textless} 0.001) and type II (OR = 1.4, 95\% CI 1.22-1.67, p {\textless} 0.001), hypertension (OR = 1.2, 95\% CI 1.10-1.37, p {\textless} 0.001), hypercholesterolaemia (OR = 1.2, 95\% CI 1.07-1.38, p = 0.004), hyperlipidaemia (OR = 1.2, 95\% CI 1.06-1.43, p = 0.008) and conditions pertaining to pregnancy and childbirth (OR = 2.9, 95\% CI: 1.32-7.21, p = 0.014). We also found a previously unreported association with benign prostatic hyperplasia (OR = 1.5, 95\% CI 1.05-2.10, p = 0.026) after adjusting for age, gender, ethnicity, hypertension, diabetes, obesity, lipid and circulatory system conditions, alcohol and tobacco abuse.
CONCLUSIONS: This study contributes a high-throughput method for associating periodontitis with systemic diseases using linked electronic records.},
language = {eng},
number = {5},
journal = {Journal of Clinical Periodontology},
author = {Boland, Mary Regina and Hripcsak, George and Albers, David J. and Wei, Ying and Wilcox, Adam B. and Wei, Jin and Li, Jianhua and Lin, Steven and Breene, Michael and Myers, Ronnie and Zimmerman, John and Papapanou, Panos N. and Weng, Chunhua},
month = may,
year = {2013},
pmid = {23495669},
pmcid = {PMC3690348},
keywords = {Adult, Aged, Alcoholism, Case-Control Studies, Clinical Coding, Confounding Factors (Epidemiology), Data Collection, Data Mining, Dental Records, Diabetes Mellitus, Type 1, Diabetes Mellitus, Type 2, Electronic Health Records, Epidemiology, Female, Hispanic Americans, Humans, Hypercholesterolemia, Hyperlipidemias, Hypertension, Male, Middle Aged, New York, Obesity, Parturition, Periodontitis, Pregnancy, Prostatic Hyperplasia, Tobacco Use Disorder},
pages = {474--482},
}

@article{sun_predicting_2014,
title = {Predicting changes in hypertension control using electronic health records from a chronic disease management program},
volume = {21},
issn = {1067-5027},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3932462/},
doi = {10.1136/amiajnl-2013-002033},
abstract = {Objective
Common chronic diseases such as hypertension are costly and difficult to manage. Our ultimate goal is to use data from electronic health records to predict the risk and timing of deterioration in hypertension control. Towards this goal, this work predicts the transition points at which hypertension is brought into, as well as pushed out of, control.

Method
In a cohort of 1294 patients with hypertension enrolled in a chronic disease management program at the Vanderbilt University Medical Center, patients are modeled as an array of features derived from the clinical domain over time, which are distilled into a core set using an information gain criteria regarding their predictive performance. A model for transition point prediction was then computed using a random forest classifier.

Results
The most predictive features for transitions in hypertension control status included hypertension assessment patterns, comorbid diagnoses, procedures and medication history. The final random forest model achieved a c-statistic of 0.836 (95\% CI 0.830 to 0.842) and an accuracy of 0.773 (95\% CI 0.766 to 0.780).

Conclusions
This study achieved accurate prediction of transition points of hypertension control status, an important first step in the long-term goal of developing personalized hypertension management plans.},
number = {2},
urldate = {2017-04-17},
journal = {Journal of the American Medical Informatics Association : JAMIA},
author = {Sun, Jimeng and McNaughton, Candace D and Zhang, Ping and Perer, Adam and Gkoulalas-Divanis, Aris and Denny, Joshua C and Kirby, Jacqueline and Lasko, Thomas and Saip, Alexander and Malin, Bradley A},
month = mar,
year = {2014},
pmid = {24045907},
pmcid = {PMC3932462},
pages = {337--344},
}

@article{lim_comparative_2012,
title = {A comparative risk assessment of burden of disease and injury attributable to 67 risk factors and risk factor clusters in 21 regions, 1990-2010: a systematic analysis for the {Global} {Burden} of {Disease} {Study} 2010},
volume = {380},
issn = {1474-547X},
shorttitle = {A comparative risk assessment of burden of disease and injury attributable to 67 risk factors and risk factor clusters in 21 regions, 1990-2010},
doi = {10.1016/S0140-6736(12)61766-8},
abstract = {BACKGROUND: Quantification of the disease burden caused by different risks informs prevention by providing an account of health loss different to that provided by a disease-by-disease analysis. No complete revision of global disease burden caused by risk factors has been done since a comparative risk assessment in 2000, and no previous analysis has assessed changes in burden attributable to risk factors over time.
METHODS: We estimated deaths and disability-adjusted life years (DALYs; sum of years lived with disability [YLD] and years of life lost [YLL]) attributable to the independent effects of 67 risk factors and clusters of risk factors for 21 regions in 1990 and 2010. We estimated exposure distributions for each year, region, sex, and age group, and relative risks per unit of exposure by systematically reviewing and synthesising published and unpublished data. We used these estimates, together with estimates of cause-specific deaths and DALYs from the Global Burden of Disease Study 2010, to calculate the burden attributable to each risk factor exposure compared with the theoretical-minimum-risk exposure. We incorporated uncertainty in disease burden, relative risks, and exposures into our estimates of attributable burden.
FINDINGS: In 2010, the three leading risk factors for global disease burden were high blood pressure (7·0\% [95\% uncertainty interval 6·2-7·7] of global DALYs), tobacco smoking including second-hand smoke (6·3\% [5·5-7·0]), and alcohol use (5·5\% [5·0-5·9]). In 1990, the leading risks were childhood underweight (7·9\% [6·8-9·4]), household air pollution from solid fuels (HAP; 7·0\% [5·6-8·3]), and tobacco smoking including second-hand smoke (6·1\% [5·4-6·8]). Dietary risk factors and physical inactivity collectively accounted for 10·0\% (95\% UI 9·2-10·8) of global DALYs in 2010, with the most prominent dietary risks being diets low in fruits and those high in sodium. Several risks that primarily affect childhood communicable diseases, including unimproved water and sanitation and childhood micronutrient deficiencies, fell in rank between 1990 and 2010, with unimproved water and sanitation accounting for 0·9\% (0·4-1·6) of global DALYs in 2010. However, in most of sub-Saharan Africa childhood underweight, HAP, and non-exclusive and discontinued breastfeeding were the leading risks in 2010, while HAP was the leading risk in south Asia. The leading risk factor in Eastern Europe, most of Latin America, and southern sub-Saharan Africa in 2010 was alcohol use; in most of Asia, North Africa and Middle East, and central Europe it was high blood pressure. Despite declines, tobacco smoking including second-hand smoke remained the leading risk in high-income north America and western Europe. High body-mass index has increased globally and it is the leading risk in Australasia and southern Latin America, and also ranks high in other high-income regions, North Africa and Middle East, and Oceania.
INTERPRETATION: Worldwide, the contribution of different risk factors to disease burden has changed substantially, with a shift away from risks for communicable diseases in children towards those for non-communicable diseases in adults. These changes are related to the ageing population, decreased mortality among children younger than 5 years, changes in cause-of-death composition, and changes in risk factor exposures. New evidence has led to changes in the magnitude of key risks including unimproved water and sanitation, vitamin A and zinc deficiencies, and ambient particulate matter pollution. The extent to which the epidemiological shift has occurred and what the leading risks currently are varies greatly across regions. In much of sub-Saharan Africa, the leading risks are still those associated with poverty and those that affect children.
FUNDING: Bill \& Melinda Gates Foundation.},
language = {eng},
number = {9859},
journal = {Lancet (London, England)},
author = {Lim, Stephen S. and Vos, Theo and Flaxman, Abraham D. and Danaei, Goodarz and Shibuya, Kenji and Adair-Rohani, Heather and Amann, Markus and Anderson, H. Ross and Andrews, Kathryn G. and Aryee, Martin and Atkinson, Charles and Bacchus, Loraine J. and Bahalim, Adil N. and Balakrishnan, Kalpana and Balmes, John and Barker-Collo, Suzanne and Baxter, Amanda and Bell, Michelle L. and Blore, Jed D. and Blyth, Fiona and Bonner, Carissa and Borges, Guilherme and Bourne, Rupert and Boussinesq, Michel and Brauer, Michael and Brooks, Peter and Bruce, Nigel G. and Brunekreef, Bert and Bryan-Hancock, Claire and Bucello, Chiara and Buchbinder, Rachelle and Bull, Fiona and Burnett, Richard T. and Byers, Tim E. and Calabria, Bianca and Carapetis, Jonathan and Carnahan, Emily and Chafe, Zoe and Charlson, Fiona and Chen, Honglei and Chen, Jian Shen and Cheng, Andrew Tai-Ann and Child, Jennifer Christine and Cohen, Aaron and Colson, K. Ellicott and Cowie, Benjamin C. and Darby, Sarah and Darling, Susan and Davis, Adrian and Degenhardt, Louisa and Dentener, Frank and Des Jarlais, Don C. and Devries, Karen and Dherani, Mukesh and Ding, Eric L. and Dorsey, E. Ray and Driscoll, Tim and Edmond, Karen and Ali, Suad Eltahir and Engell, Rebecca E. and Erwin, Patricia J. and Fahimi, Saman and Falder, Gail and Farzadfar, Farshad and Ferrari, Alize and Finucane, Mariel M. and Flaxman, Seth and Fowkes, Francis Gerry R. and Freedman, Greg and Freeman, Michael K. and Gakidou, Emmanuela and Ghosh, Santu and Giovannucci, Edward and Gmel, Gerhard and Graham, Kathryn and Grainger, Rebecca and Grant, Bridget and Gunnell, David and Gutierrez, Hialy R. and Hall, Wayne and Hoek, Hans W. and Hogan, Anthony and Hosgood, H. Dean and Hoy, Damian and Hu, Howard and Hubbell, Bryan J. and Hutchings, Sally J. and Ibeanusi, Sydney E. and Jacklyn, Gemma L. and Jasrasaria, Rashmi and Jonas, Jost B. and Kan, Haidong and Kanis, John A. and Kassebaum, Nicholas and Kawakami, Norito and Khang, Young-Ho and Khatibzadeh, Shahab and Khoo, Jon-Paul and Kok, Cindy and Laden, Francine and Lalloo, Ratilal and Lan, Qing and Lathlean, Tim and Leasher, Janet L. and Leigh, James and Li, Yang and Lin, John Kent and Lipshultz, Steven E. and London, Stephanie and Lozano, Rafael and Lu, Yuan and Mak, Joelle and Malekzadeh, Reza and Mallinger, Leslie and Marcenes, Wagner and March, Lyn and Marks, Robin and Martin, Randall and McGale, Paul and McGrath, John and Mehta, Sumi and Mensah, George A. and Merriman, Tony R. and Micha, Renata and Michaud, Catherine and Mishra, Vinod and Mohd Hanafiah, Khayriyyah and Mokdad, Ali A. and Morawska, Lidia and Mozaffarian, Dariush and Murphy, Tasha and Naghavi, Mohsen and Neal, Bruce and Nelson, Paul K. and Nolla, Joan Miquel and Norman, Rosana and Olives, Casey and Omer, Saad B. and Orchard, Jessica and Osborne, Richard and Ostro, Bart and Page, Andrew and Pandey, Kiran D. and Parry, Charles D. H. and Passmore, Erin and Patra, Jayadeep and Pearce, Neil and Pelizzari, Pamela M. and Petzold, Max and Phillips, Michael R. and Pope, Dan and Pope, C. Arden and Powles, John and Rao, Mayuree and Razavi, Homie and Rehfuess, Eva A. and Rehm, Jürgen T. and Ritz, Beate and Rivara, Frederick P. and Roberts, Thomas and Robinson, Carolyn and Rodriguez-Portales, Jose A. and Romieu, Isabelle and Room, Robin and Rosenfeld, Lisa C. and Roy, Ananya and Rushton, Lesley and Salomon, Joshua A. and Sampson, Uchechukwu and Sanchez-Riera, Lidia and Sanman, Ella and Sapkota, Amir and Seedat, Soraya and Shi, Peilin and Shield, Kevin and Shivakoti, Rupak and Singh, Gitanjali M. and Sleet, David A. and Smith, Emma and Smith, Kirk R. and Stapelberg, Nicolas J. C. and Steenland, Kyle and Stöckl, Heidi and Stovner, Lars Jacob and Straif, Kurt and Straney, Lahn and Thurston, George D. and Tran, Jimmy H. and Van Dingenen, Rita and van Donkelaar, Aaron and Veerman, J. Lennert and Vijayakumar, Lakshmi and Weintraub, Robert and Weissman, Myrna M. and White, Richard A. and Whiteford, Harvey and Wiersma, Steven T. and Wilkinson, James D. and Williams, Hywel C. and Williams, Warwick and Wilson, Nicholas and Woolf, Anthony D. and Yip, Paul and Zielinski, Jan M. and Lopez, Alan D. and Murray, Christopher J. L. and Ezzati, Majid and AlMazroa, Mohammad A. and Memish, Ziad A.},
month = dec,
year = {2012},
pmid = {23245609},
pmcid = {PMC4156511},
keywords = {Adolescent, Adult, Age Factors, Aged, Aged, 80 and over, Child, Child, Preschool, Female, Global Health, Humans, Infant, Infant, Newborn, Male, Middle Aged, Quality-Adjusted Life Years, Risk Assessment, Risk Factors, Sex Factors, Young Adult, mortality},
pages = {2224--2260},
}

@article{raghupathi_big_2014,
title = {Big data analytics in healthcare: promise and potential},
volume = {2},
issn = {2047-2501},
shorttitle = {Big data analytics in healthcare},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4341817/},
doi = {10.1186/2047-2501-2-3},
abstract = {Objective
To describe the promise and potential of big data analytics in healthcare.

Methods
The paper describes the nascent field of big data analytics in healthcare, discusses the benefits, outlines an architectural framework and methodology, describes examples reported in the literature, briefly discusses the challenges, and offers conclusions.

Results
The paper provides a broad overview of big data analytics for healthcare researchers and practitioners.

Conclusions
Big data analytics in healthcare is evolving into a promising field for providing insight from very large data sets and improving outcomes while reducing costs. Its potential is great; however there remain challenges to overcome.},
urldate = {2017-04-17},
journal = {Health Information Science and Systems},
author = {Raghupathi, Wullianallur and Raghupathi, Viju},
month = feb,
year = {2014},
pmid = {25825667},
pmcid = {PMC4341817},
}

@article{bodenheimer_patient_2002,
title = {Patient self-management of chronic disease in primary care},
volume = {288},
issn = {0098-7484},
abstract = {Patients with chronic conditions make day-to-day decisions about--self-manage--their illnesses. This reality introduces a new chronic disease paradigm: the patient-professional partnership, involving collaborative care and self-management education. Self-management education complements traditional patient education in supporting patients to live the best possible quality of life with their chronic condition. Whereas traditional patient education offers information and technical skills, self-management education teaches problem-solving skills. A central concept in self-management is self-efficacy--confidence to carry out a behavior necessary to reach a desired goal. Self-efficacy is enhanced when patients succeed in solving patient-identified problems. Evidence from controlled clinical trials suggests that (1) programs teaching self-management skills are more effective than information-only patient education in improving clinical outcomes; (2) in some circumstances, self-management education improves outcomes and can reduce costs for arthritis and probably for adult asthma patients; and (3) in initial studies, a self-management education program bringing together patients with a variety of chronic conditions may improve outcomes and reduce costs. Self-management education for chronic illness may soon become an integral part of high-quality primary care.},
language = {eng},
number = {19},
journal = {JAMA},
author = {Bodenheimer, Thomas and Lorig, Kate and Holman, Halsted and Grumbach, Kevin},
month = nov,
year = {2002},
pmid = {12435261},
keywords = {Chronic Disease, Cooperative Behavior, Humans, Patient Care Planning, Patient Education as Topic, Patient Participation, Physician-Patient Relations, Primary Health Care, Self Care, Self Efficacy, Treatment Outcome},
pages = {2469--2475},
}

@article{mattke_results_2015,
title = {Results from a national survey on chronic care management by health plans},
volume = {21},
issn = {1936-2692},
abstract = {OBJECTIVES: The growing burden of chronic disease necessitates innovative approaches to help patients and to ensure the sustainability of our healthcare system. Health plans have introduced chronic care management models, but systematic data on the type and prevalence of different approaches are lacking. Our goal was to conduct a systematic examination of chronic care management programs offered by health plans in the commercial market (ie, in products sold to employers and individuals.
STUDY DESIGN AND METHODS: We undertook a national survey of a representative sample of health plans (70 plans, 36\% response rate) and 6 case studies on health plans' programs to improve chronic care in the commercial market. The data underwent descriptive and bivariate analyses.
RESULTS: All plans, regardless of size, location, and ownership, offer chronic care management programs, which identify eligible members from claims data and match them to interventions based on overall risk and specific care gaps. Plans then report information on care gaps to providers and offer self-management support to their members. While internal evaluations suggest that the interventions improve care and reduce cost, plans report difficulties in engaging members and providers. To overcome those obstacles, plans are integrating their programs into provider work flow, collaborating with providers on care redesign and leveraging patient support technologies.
CONCLUSIONS: Our study shows that chronic care management programs have become a standard component of the overall approach used by health plans to manage the health of their members.},
language = {eng},
number = {5},
journal = {The American Journal of Managed Care},
author = {Mattke, Soeren and Higgins, Aparna and Brook, Robert},
month = may,
year = {2015},
pmid = {26167703},
keywords = {Chronic Disease, Disease Management, Equipment and Supplies, Humans, Insurance Claim Review, Insurance, Health, Motivation, Remote Sensing Technology, Self Care, Social Work, Surveys and Questionnaires},
pages = {370--376},
}

@article{s_results_2015,
title = {Results from a national survey on chronic care management by health plans.},
volume = {21},
issn = {1088-0224},
url = {http://europepmc.org/abstract/med/26167703},
abstract = {Abstract: The growing burden of chronic disease necessitates innovative approaches to help patients and to ensure the sustainability of our healthcare...},
language = {eng},
number = {5},
urldate = {2017-04-17},
journal = {The American journal of managed care},
author = {S, Mattke and A, Higgins and R, Brook},
month = may,
year = {2015},
pmid = {26167703},
pages = {370--376},
}

@article{strong_preventing_2005,
title = {Preventing chronic diseases: how many lives can we save?},
volume = {366},
issn = {1474-547X},
shorttitle = {Preventing chronic diseases},
doi = {10.1016/S0140-6736(05)67341-2},
abstract = {35 million people will die in 2005 from heart disease, stroke, cancer, and other chronic diseases. Only 20\% of these deaths will be in high-income countries--while 80\% will occur in low-income and middle-income countries. The death rates from these potentially preventable diseases are higher in low-income and middle-income countries than in high-income countries, especially among adults aged 30-69 years. The impact on men and women is similar. We propose a new goal for reducing deaths from chronic disease to focus prevention and control efforts among those concerned about international health. This goal-to reduce chronic disease death rates by an additional 2\% annually--would avert 36 million deaths by 2015. An additional benefit will be a gain of about 500 million years of life over the 10 years from 2006 to 2015. Most of these averted deaths and life-years gained will be in low-income and middle-income countries, and just under half will be in people younger than 70 years. We base the global goal on worldwide projections of deaths by cause for 2005 and 2015. The data are presented for the world, selected countries, and World Bank income groups.},
language = {eng},
number = {9496},
journal = {Lancet (London, England)},
author = {Strong, Kathleen and Mathers, Colin and Leeder, Stephen and Beaglehole, Robert},
month = nov,
year = {2005},
pmid = {16257345},
keywords = {Adult, Aged, Chronic Disease, Female, Global Health, Goals, Humans, Male, Middle Aged, Poverty, Primary Prevention},
pages = {1578--1582},
}

@article{cutler_value_2006,
title = {The {Value} of {Medical} {Spending} in the {United} {States}, 1960–2000},
volume = {355},
issn = {0028-4793},
url = {http://dx.doi.org/10.1056/NEJMsa054744},
doi = {10.1056/NEJMsa054744},
abstract = {Advances in medical care have led to sustained increases in medical spending over time. Adjusted for inflation, annual medical spending per person has increased from approximately \$700 in 1960 to more than \$6,000 today, tripling as a share of the gross domestic product (GDP).1 At least half this increase is a result of more care, not higher prices for existing care.2 An evaluation of whether increased medical spending is useful requires the valuation of the increase in care. The enormous growth in spending has led many to argue that the increasing costs are excessive.3 Others, however, suggest that spending more . . .},
number = {9},
urldate = {2017-04-17},
journal = {New England Journal of Medicine},
author = {Cutler, David M. and Rosen, Allison B. and Vijan, Sandeep},
month = aug,
year = {2006},
pmid = {16943404},
pages = {920--927},
}

@misc{cdc_national_2016,
title = {National {Center} for {Chronic} {Disease} {Prevention} and {Health} {Promotion}},
url = {https://www.cdc.gov/chronicdisease/},
urldate = {2017-04-17},
author = {CDC},
year = {2016},
}

@article{larsen_we_2015,
title = {We {Feel}: {Mapping} {Emotion} on {Twitter}},
volume = {19},
issn = {2168-2194},
shorttitle = {We {Feel}},
doi = {10.1109/JBHI.2015.2403839},
abstract = {Research data on predisposition to mental health problems, and the fluctuations and regulation of emotions, thoughts, and behaviors are traditionally collected through surveys, which cannot provide a real-time insight into the emotional state of individuals or communities. Large datasets such as World Health Organization (WHO) statistics are collected less than once per year, whereas social network platforms, such as Twitter, offer the opportunity for real-time analysis of expressed mood. Such patterns are valuable to the mental health research community, to help understand the periods and locations of greatest demand and unmet need. We describe the “We Feel” system for analyzing global and regional variations in emotional expression, and report the results of validation against known patterns of variation in mood. $^{\textrm{9\$}}$ emotional tweets were collected over a 12-week period, and automatically annotated for emotion, geographic location, and gender. Principal component analysis (PCA) of the data illustrated a dominant in-phase pattern across all emotions, modulated by antiphase patterns for “positive” and “negative” emotions. The first three principal components accounted for over 90\% of the variation in the data. PCA was also used to remove the dominant diurnal and weekly variations allowing identification of significant events within the data, with z-scores showing expression of emotions over 80 standard deviations from the mean. We also correlate emotional expression with WHO data at a national level and although no correlations were observed for the burden of depression, the burden of anxiety and suicide rates appeared to correlate with expression of particular emotions.},
number = {4},
journal = {IEEE Journal of Biomedical and Health Informatics},
author = {Larsen, M. E. and Boonstra, T. W. and Batterham, P. J. and O’Dea, B. and Paris, C. and Christensen, H.},
month = jul,
year = {2015},
keywords = {1, Australia, Communities, Correlation, Fluctuations, Internet, Mental health, PCA, Standards, WHO statistics, antiphase patterns, behavioural sciences computing, emotional state, emotional tweets, mapping emotion, mental health problems, mental health research community, negative emotions, positive emotions, principal component analysis, real-time analysis, real-time systems, sentiment analysis, social network platforms, social networking (online), twitter, world health organization},
pages = {1246--1252},
}

@article{scanfeld_dissemination_2010,
title = {Dissemination of health information through social networks: {Twitter} and antibiotics},
volume = {38},
issn = {0196-6553},
shorttitle = {Dissemination of health information through social networks},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3601456/},
doi = {10.1016/j.ajic.2009.11.004},
abstract = {Background
This study reviewed Twitter status updates mentioning “antibiotic(s)” to determine overarching categories and explore evidence of misunderstanding or misuse of antibiotics.

Methods
One thousand Twitter status updates mentioning antibiotic(s) were randomly selected for content analysis and categorization. To explore cases of potential misunderstanding or misuse, these status updates were mined for co-occurrence of the following terms: “cold + antibiotic(s),” “extra antibiotic(s),” “flu + antibiotic(s),” “leftover antibiotic(s),” and “share antibiotic(s)” and reviewed to confirm evidence of misuse or misunderstanding.

Results
Of the 1,000 status updates, 971 were categorized into 11 groups: General Use (n=289), Advice/Information (n=157), Side Effects/Negative Reactions (n=113), Diagnosis (n=102), Resistance (n=92), Misunderstanding and/or Misuse (n=55), Positive Reactions (n=48), Animals (n=46), Other (n=42), Wanting/Needing (n=19), and Cost (n=8). Cases of misunderstanding or abuse were identified for the following combinations: “flu + antibiotic(s)” (n=345), “cold + antibiotic(s)” (n=302), “leftover antibiotic(s)” (n=23), “share antibiotic(s)” (n=10), and “extra antibiotic(s)” (n=7).

Conclusions
Social media sites offer means of health information sharing. Further study is warranted to explore how such networks may provide a venue to identify misuse or misunderstanding of antibiotics, promote positive behavior change, disseminate valid information, and explore how such tools can be used to gather real-time health data.},
number = {3},
urldate = {2017-04-17},
journal = {American journal of infection control},
author = {Scanfeld, Daniel and Scanfeld, Vanessa and Larson, Elaine L.},
month = apr,
year = {2010},
pmid = {20347636},
pmcid = {PMC3601456},
pages = {182--188},
}

@article{christakis_collective_2008,
title = {The {Collective} {Dynamics} of {Smoking} in a {Large} {Social} {Network}},
volume = {358},
issn = {0028-4793},
url = {http://dx.doi.org/10.1056/NEJMsa0706154},
doi = {10.1056/NEJMsa0706154},
abstract = {Roughly 44.5 million adults were smokers in the United States in 2004,1 and smoking remains the leading preventable cause of death,2 with 440,000 deaths annually.3 Nevertheless, the prevalence of smoking has declined from 45\% to 21\% over the past four decades.4 Past studies have documented the impact of dyadic social ties on the initiation and cessation of smoking, primarily in young people.5,6 However, the extent to which smoking depends on how people are embedded in a social network and the extent to which smoking behavior transcends direct dyadic ties are not known. Since diverse phenomena can spread within social . . .},
number = {21},
urldate = {2017-04-17},
journal = {New England Journal of Medicine},
author = {Christakis, Nicholas A. and Fowler, James H.},
month = may,
year = {2008},
pmid = {18499567},
pages = {2249--2258},
}

@book{rogers_first_2011,
address = {Boca Raton},
edition = {1 edition},
title = {A {First} {Course} in {Machine} {Learning}},
isbn = {978-1-4398-2414-6},
abstract = {A First Course in Machine Learning covers the core mathematical and statistical techniques needed to understand some of the most popular machine learning algorithms. The algorithms presented span the main problem areas within machine learning: classification, clustering and projection. The text gives detailed descriptions and derivations for a small number of algorithms rather than cover many algorithms in less detail.  Referenced throughout the text and available on a supporting website (http://bit.ly/firstcourseml), an extensive collection of MATLAB®/Octave scripts enables students to recreate plots that appear in the book and investigate changing model specifications and parameter values. By experimenting with the various algorithms and concepts, students see how an abstract set of equations can be used to solve real problems.  Requiring minimal mathematical prerequisites, the classroom-tested material in this text offers a concise, accessible introduction to machine learning. It provides students with the knowledge and confidence to explore the machine learning literature and research specific methods in more detail.},
language = {English},
publisher = {Chapman and Hall/CRC},
author = {Rogers, Simon and Girolami, Mark},
month = oct,
year = {2011},
}

@article{altman_introduction_1992,
title = {An {Introduction} to {Kernel} and {Nearest}-{Neighbor} {Nonparametric} {Regression}},
volume = {46},
issn = {0003-1305},
url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1992.10475879},
doi = {10.1080/00031305.1992.10475879},
abstract = {Nonparametric regression is a set of techniques for estimating a regression curve without making strong assumptions about the shape of the true regression function. These techniques are therefore useful for building and checking parametric models, as well as for data description. Kernel and nearest-neighbor regression estimators are local versions of univariate location estimators, and so they can readily be introduced to beginning students and consulting clients who are familiar with such summaries as the sample mean and median.},
number = {3},
urldate = {2016-12-10},
journal = {The American Statistician},
author = {Altman, N. S.},
month = aug,
year = {1992},
keywords = {Confidence intervals, Local linear regression, Model building, Model checking, Smoothing},
pages = {175--185},
}

@book{balakrishnama_linear_1998,
title = {Linear discriminant analysis-a brief tutorial},
volume = {Processing 18},
publisher = {Institute for Signal and information},
author = {Balakrishnama, Suresh and Aravind, Ganapathiraju},
year = {1998},
}

@article{jossinet_variability_1996,
title = {Variability of impedivity in normal and pathological breast tissue},
volume = {34},
issn = {0140-0118, 1741-0444},
url = {http://link.springer.com/article/10.1007/BF02520002},
doi = {10.1007/BF02520002},
abstract = {The impedivity of six groups of breast tissue is measured between 0.488 kHz and 1 MHz using a hand-held probe, ensuring a constant geometry factor, and a microcomputer-controlled impedance spectroscopy system. 120 spectra are collected in excised tissue samples from 64 patients undergoing breast surgery. Each spectrum consists of 12 frequency points. The mean m, the standard deviation s, and the ‘reduced standard error’ (ε=s/(m N)) of the magnitude and the phase angle of the impedivity are calculated at each frequency for all groups of tissues. The variability at low frequency (f{\textless}10 kHz) is attributed to the dispersion in measurement errors. This contributed to the choice of 32 kHz as the lower limit of measurement frequency in the constructed electrical impedance tomograph. The collected data also show that frequencies larger than 1 MHz are needed for the bio-electrical characterisation of breast tissue. In the frequency range used in electrical impedance tomography the reduced standard error of impedivity in breast tissue is about 0.1 or less. The lowest dispersions are observed in the adipose tissue, carcinoma and fibro-adenoma.},
language = {en},
number = {5},
urldate = {2016-12-09},
journal = {Medical and Biological Engineering and Computing},
author = {Jossinet, J.},
month = sep,
year = {1996},
pages = {346--350},
}

@article{silva_classification_2000,
title = {Classification of breast tissue by electrical impedance spectroscopy},
volume = {38},
issn = {0140-0118, 1741-0444},
url = {http://link.springer.com/article/10.1007/BF02344684},
doi = {10.1007/BF02344684},
abstract = {Electrical impedance spectroscopy is a minimally invasive technique that has clear advantages for living tissue characterisation owing to its low cost and ease of use. The present paper describes how this technique can be applied to breast tissue classification and breast cancer detection. Statistical analysis is used to derive a set of rules based on features extracted from the graphical representation of electrical impedance spectra. These rules are used hierarchically to discriminate several classes of breast tissue. Results of statistical classification obtained from a data set of 106 cases representing six classes of excised breast tissue show an overall classification efficiency of ∼92\% with carcinoma discrimination {\textgreater}86\%.},
language = {en},
number = {1},
urldate = {2016-12-09},
journal = {Medical and Biological Engineering and Computing},
author = {Silva, J. Estrela da and Sá, J. P. Marques de and Jossinet, J.},
month = jan,
year = {2000},
pages = {26--30},
}

@article{zou_review_2003,
title = {A review of electrical impedance techniques for breast cancer detection},
volume = {25},
issn = {1350-4533},
abstract = {Some evidence has been found that malignant breast tumors have lower electrical impedance than surrounding normal tissues. Although the separation of malignant tumors from benign lesions based on impedance measurements needs further investigation, electrical impedance could be used as an indicator for breast cancer detection. In this paper, we provide a systematic technical review of the existing electrical impedance techniques proposed for breast cancer detection, with an emphasis on noninvasive impedance imaging techniques. The electrical impedance of human breast tissue is first introduced, with tabulation of previous in vitro impedance measurement results on cancerous and normal breast tissues, and a brief description on the limited in vivo impedance measurements completed with invasive, or noninvasive, non-imaging techniques. A detailed review on noninvasive impedance imaging techniques for breast cancer detection, such as electrical impedance tomography (EIT) and electrical impedance mapping (EIM), is then presented. We suggest that for better breast cancer detection, an invasive impedance technique may be enhanced by combination with other cancer indicators. 3D EIT should be improved through collective efforts. EIM using a pair of electrode arrays is a viable method with great potential. Magnetic induction tomography and other magnetic induction based impedance imaging for breast cancer detection are promising and merit further exploration as well.},
language = {eng},
number = {2},
journal = {Medical Engineering \& Physics},
author = {Zou, Y. and Guo, Z.},
month = mar,
year = {2003},
pmid = {12538062},
keywords = {Breast, Breast Neoplasms, Electric Impedance, Electric Stimulation, Electrodes, Female, Humans, Magnetics, Tomography},
pages = {79--90},
}

@misc{silberman_does_2016,
title = {Does {Having} {Dense} {Breasts} {Increase} {Your} {Risk} for {Cancer}?},
url = {http://www.healthline.com/health/dense-breast-tissue-what-it-and-cancer-risk},
abstract = {Learn what having dense breasts means and how it may increase your risk for breast cancer.},
urldate = {2016-12-08},
journal = {Healthline},
author = {Silberman, Ann},
month = oct,
year = {2016},
}

@article{siegel_cancer_2016,
title = {Cancer statistics, 2016},
volume = {66},
issn = {1542-4863},
url = {http://onlinelibrary.wiley.com/doi/10.3322/caac.21332/abstract},
doi = {10.3322/caac.21332},
abstract = {Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States in the current year and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data were collected by the National Cancer Institute (Surveillance, Epidemiology, and End Results [SEER] Program), the Centers for Disease Control and Prevention (National Program of Cancer Registries), and the North American Association of Central Cancer Registries. Mortality data were collected by the National Center for Health Statistics. In 2016, 1,685,210 new cancer cases and 595,690 cancer deaths are projected to occur in the United States. Overall cancer incidence trends (13 oldest SEER registries) are stable in women, but declining by 3.1\% per year in men (from 2009-2012), much of which is because of recent rapid declines in prostate cancer diagnoses. The cancer death rate has dropped by 23\% since 1991, translating to more than 1.7 million deaths averted through 2012. Despite this progress, death rates are increasing for cancers of the liver, pancreas, and uterine corpus, and cancer is now the leading cause of death in 21 states, primarily due to exceptionally large reductions in death from heart disease. Among children and adolescents (aged birth-19 years), brain cancer has surpassed leukemia as the leading cause of cancer death because of the dramatic therapeutic advances against leukemia. Accelerating progress against cancer requires both increased national investment in cancer research and the application of existing cancer control knowledge across all segments of the population. CA Cancer J Clin 2016;7–30. © 2015 American Cancer Society.},
language = {en},
number = {1},
urldate = {2016-12-07},
journal = {CA: A Cancer Journal for Clinicians},
author = {Siegel, Rebecca L. and Miller, Kimberly D. and Jemal, Ahmedin},
month = jan,
year = {2016},
keywords = {cancer cases, cancer statistics, death rates, incidence, mortality, survival, trends},
pages = {7--30},
}

@article{bordes_question_2014,
title = {Question {Answering} with {Subgraph} {Embeddings}},
url = {http://arxiv.org/abs/1406.3676},
abstract = {This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few hand-crafted features. Our model learns low-dimensional embeddings of words and knowledge base constituents; these representations are used to score natural language questions against candidate answers. Training our system using pairs of questions and structured representations of their answers, and pairs of question paraphrases, yields competitive results on a competitive benchmark of the literature.},
urldate = {2016-08-31},
journal = {arXiv:1406.3676 [cs]},
author = {Bordes, Antoine and Chopra, Sumit and Weston, Jason},
month = jun,
year = {2014},
note = {arXiv: 1406.3676},
keywords = {Computer Science - Computation and Language, paper vesion},
}

@inproceedings{li_learning_2002,
address = {Stroudsburg, PA, USA},
series = {{COLING} '02},
title = {Learning {Question} {Classifiers}},
url = {http://dx.doi.org/10.3115/1072228.1072378},
doi = {10.3115/1072228.1072378},
abstract = {In order to respond correctly to a free form factual question given a large collection of texts, one needs to understand the question to a level that allows determining some of the constraints the question imposes on a possible answer. These constraints may include a semantic classification of the sought after answer and may even suggest using different strategies when looking for and verifying a candidate answer.This paper presents a machine learning approach to question classification. We learn a hierarchical classifier that is guided by a layered semantic hierarchy of answer types, and eventually classifies questions into fine-grained classes. We show accurate results on a large collection of free-form questions used in TREC 10.},
urldate = {2016-08-31},
booktitle = {Proceedings of the 19th {International} {Conference} on {Computational} {Linguistics} - {Volume} 1},
publisher = {Association for Computational Linguistics},
author = {Li, Xin and Roth, Dan},
year = {2002},
keywords = {paper vesion},
pages = {1--7},
}

@inproceedings{levy_dependencybased_2014,
title = {Dependencybased word embeddings},
abstract = {While continuous word embeddings are gaining popularity, current models are based solely on linear contexts. In this work, we generalize the skip-gram model with negative sampling introduced by Mikolov et al. to include arbitrary con-texts. In particular, we perform exper-iments with dependency-based contexts, and show that they produce markedly different embeddings. The dependency-based embeddings are less topical and ex-hibit more functional similarity than the original skip-gram embeddings. 1},
booktitle = {In {ACL}},
author = {Levy, Omer and Goldberg, Yoav},
year = {2014},
keywords = {paper vesion},
}

@book{nielsen_neural_2015,
title = {Neural {Networks} and {Deep} {Learning}},
url = {http://neuralnetworksanddeeplearning.com},
urldate = {2016-08-31},
author = {Nielsen, Michael A.},
year = {2015},
keywords = {CSC665, Neural Networks, deep learning, paper vesion},
}

@article{pan_domain_2011,
title = {Domain {Adaptation} via {Transfer} {Component} {Analysis}},
volume = {22},
issn = {1045-9227},
doi = {10.1109/TNN.2010.2091281},
abstract = {Domain adaptation allows knowledge from a source domain to be transferred to a different but related target domain. Intuitively, discovering a good feature representation across domains is crucial. In this paper, we first propose to find such a representation through a new learning method, transfer component analysis (TCA), for domain adaptation. TCA tries to learn some transfer components across domains in a reproducing kernel Hilbert space using maximum mean miscrepancy. In the subspace spanned by these transfer components, data properties are preserved and data distributions in different domains are close to each other. As a result, with the new representations in this subspace, we can apply standard machine learning methods to train classifiers or regression models in the source domain for use in the target domain. Furthermore, in order to uncover the knowledge hidden in the relations between the data labels from the source and target domains, we extend TCA in a semisupervised learning setting, which encodes label information into transfer components learning. We call this extension semisupervised TCA. The main contribution of our work is that we propose a novel dimensionality reduction framework for reducing the distance between domains in a latent space for domain adaptation. We propose both unsupervised and semisupervised feature extraction approaches, which can dramatically reduce the distance between domain distributions by projecting data onto the learned transfer components. Finally, our approach can handle large datasets and naturally lead to out-of-sample generalization. The effectiveness and efficiency of our approach are verified by experiments on five toy datasets and two real-world applications: cross-domain indoor WiFi localization and cross-domain text classification.},
number = {2},
journal = {IEEE Transactions on Neural Networks},
author = {Pan, S. J. and Tsang, I. W. and Kwok, J. T. and Yang, Q.},
month = feb,
year = {2011},
keywords = {Algorithms, Artificial Intelligence, Automatic Data Processing, Computer Simulation, Dimensionality reduction, Domain adaptation, Feature extraction, Hilbert space, Hilbert space embedding of distributions, Hilbert spaces, Kernel, Learning systems, Manifolds, Neural Networks (Computer), Noise measurement, Optimization, Pattern Recognition, Automated, Transfer (Psychology), classifiers, cross-domain indoor WiFi localization, cross-domain text classification, dimensionality reduction framework, kernel Hilbert space, learning (artificial intelligence), learning method, maximum mean miscrepancy, paper vesion, pattern classification, regression analysis, regression models, semisupervised feature extraction approach, semisupervised learning, standard machine learning methods, text analysis, transfer component analysis, transfer learning, wireless LAN},
pages = {199--210},
}

@inproceedings{glorot_domain_2011,
title = {Domain adaptation for large-scale sentiment classification: {A} deep learning approach},
shorttitle = {Domain adaptation for large-scale sentiment classification},
abstract = {The exponential increase in the availability of online reviews and recommendations makes sentiment classification an interesting topic in academic and industrial research. Reviews can span so many different domains that it is difficult to gather annotated training data for all of them. Hence, this paper studies the problem of domain adaptation for sentiment classifiers, hereby a system is trained on labeled reviews from one source domain but is meant to be deployed on another. We propose a deep learning approach which learns to extract a meaningful representation for each review in an unsupervised fashion. Sentiment classifiers trained with this high-level feature representation clearly outperform state-of-the-art methods on a benchmark composed of reviews of 4 types of Amazon products. Furthermore, this method scales well and allowed us to successfully perform domain adaptation on a larger industrial-strength dataset of 22 domains. 1.},
booktitle = {In {Proceedings} of the {Twenty}-eight {International} {Conference} on {Machine} {Learning}, {ICML}},
author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
year = {2011},
keywords = {Domain adaptation, NLP, deep learning, paper vesion, project: signal extraction},
}

@inproceedings{zou_infectious_2016,
address = {New York, NY, USA},
series = {{DH} '16},
title = {On {Infectious} {Intestinal} {Disease} {Surveillance} {Using} {Social} {Media} {Content}},
isbn = {978-1-4503-4224-7},
url = {http://doi.acm.org/10.1145/2896338.2896372},
doi = {10.1145/2896338.2896372},
abstract = {This paper investigates whether infectious intestinal diseases (IIDs) can be detected and quantified using social media content. Experiments are conducted on user-generated data from the microblogging service, Twitter. Evaluation is based on the comparison with the number of IID cases reported by traditional health surveillance methods. We employ a deep learning approach for creating a topical vocabulary, and then apply a regularised linear (Elastic Net) as well as a nonlinear (Gaussian Process) regression function for inference. We show that like previous text regression tasks, the nonlinear approach performs better. In general, our experimental results, both in terms of predictive performance and semantic interpretation, indicate that Twitter data contain a signal that could be strong enough to complement conventional methods for IID surveillance.},
urldate = {2016-08-31},
booktitle = {Proceedings of the 6th {International} {Conference} on {Digital} {Health} {Conference}},
publisher = {ACM},
author = {Zou, Bin and Lampos, Vasileios and Gorton, Russell and Cox, Ingemar J.},
year = {2016},
keywords = {Social Media, disease surveillance, iid, infectious intestinal disease, project: asthma entire US, project: signal extraction, twitter, user-generated content, word embeddings},
pages = {157--161},
}

@inproceedings{rich_towards_2016,
address = {New York, NY, USA},
series = {{DH} '16},
title = {Towards {Bottom}-{Up} {Analysis} of {Social} {Food}},
isbn = {978-1-4503-4224-7},
url = {http://doi.acm.org/10.1145/2896338.2897734},
doi = {10.1145/2896338.2897734},
abstract = {Social media provide a wealth of information for research into public health by providing a rich mix of personal data, location, hashtags, and social network information. Among these, Instagram has been recently the subject of many computational social science studies. However despite Instagram's focus on image sharing, most studies have exclusively focused on the hashtag and social network structure. In this paper we perform the first large scale content analysis of Instagram posts, addressing both the image and the associated hashtags, aiming to understand the content of partially-labelled images taken in-the-wild and the relationship with hashtags that individuals use as noisy labels. In particular, we explore the possibility of learning to recognise food image content in a data driven way, discovering both the categories of food, and how to recognise them, purely from social network data. Notably, we demonstrate that our approach to food recognition can often achieve accuracies greater than 70\% in recognising popular food-related image categories, despite using no manual annotation. We highlight the current capabilities and future challenges and opportunities for such data-driven analysis of image content and the relation to hashtags.},
urldate = {2016-08-31},
booktitle = {Proceedings of the 6th {International} {Conference} on {Digital} {Health} {Conference}},
publisher = {ACM},
author = {Rich, Jaclyn and Haddadi, Hamed and Hospedales, Timothy M.},
year = {2016},
keywords = {Social Media, image recognition, instagram, machine learning, paper vesion, project: vector borne},
pages = {111--120},
}

@article{mciver_wikipedia_2014,
title = {Wikipedia {Usage} {Estimates} {Prevalence} of {Influenza}-{Like} {Illness} in the {United} {States} in {Near} {Real}-{Time}},
volume = {10},
url = {http://dx.doi.org/10.1371/journal.pcbi.1003581},
doi = {10.1371/journal.pcbi.1003581},
abstract = {Author Summary Although influenza is largely avoidable through vaccination, between 3,000–50,000 deaths occur in the United States each year that are attributed to this disease. The Centers for Disease Control and Prevention continuously monitor the amount of influenza that is present in the American population and compiles this information in weekly reports. However, because it can take a long time to collect and analyze all of this information, the data that is being reported each week is typically between 1–2 weeks old at the time of publishing. For this reason, we are interested in developing new techniques to determine the amount of influenza in the population that are accurate, can return results in real-time, and can be used to supplement traditional monitoring. We have created a method of estimating the amount of influenza-like illness in the American population, at any time of year, by analyzing the amount of Internet traffic seen on certain influenza-related Wikipedia articles. This method is able to accurately estimate the percentage of Americans with influenza-like illness, in real-time, and is robust to influenza seasons that are more severe than normal and to events that promote much media attention, such as the H1N1 pandemic in 2009.},
number = {4},
urldate = {2014-04-21},
journal = {PLoS Comput Biol},
author = {McIver, David J. and Brownstein, John S.},
month = apr,
year = {2014},
keywords = {PCCI, Prediction, Public Health, Social Media, Wikipedia},
pages = {e1003581},
}

@article{preis_quantifying_2013,
title = {Quantifying {Trading} {Behavior} in {Financial} {Markets} {Using} {Google} {Trends}},
volume = {3},
copyright = {© 2013 Macmillan Publishers Limited. All rights reserved},
url = {http://www.nature.com/srep/2013/130425/srep01684/full/srep01684.html},
doi = {10.1038/srep01684},
abstract = {Crises in financial markets affect humans worldwide. Detailed market data on trading decisions reflect some of the complex human behavior that has led to these crises. We suggest that massive new data sources resulting from human interaction with the Internet may offer a new perspective on the behavior of market participants in periods of large market movements. By analyzing changes in Google query volumes for search terms related to finance, we find patterns that may be interpreted as “early warning signs” of stock market moves. Our results illustrate the potential that combining extensive behavioral data sets offers for a better understanding of collective human behavior.},
language = {en},
urldate = {2014-04-01},
journal = {Scientific Reports},
author = {Preis, Tobias and Moat, Helen Susannah and Stanley, H. Eugene},
month = apr,
year = {2013},
keywords = {Google, Social Media, Stock Market},
}

@article{noauthor_recent_nodate,
title = {Recent {Big}-{Data} {Struggles} {Are} ‘{Birthing} {Pains},’ {Researchers} {Say}},
url = {http://m.chronicle.com/article/Recent-Big-Data-Struggles-Are/145625/?cid=pm&utm_source=pm&utm_medium=en},
keywords = {Big Data, Google, Social Media},
}

@unpublished{noauthor_comparing_nodate,
title = {Comparing {Peer} {Influences} in {Large} {Social} {Networks}: {Cohesion} or {Structural} {Equivalence}  in {Caller} {Ring} back {Tone} {Networks}?},
keywords = {MIS Speaker Serials, Social Network},
}

@inproceedings{elif_performance_2013,
title = {Performance evaluation of a mongodb and hadoop platform for scientific data analysis},
abstract = {Scientiﬁc facilities such as the Advanced Light Source (ALS)
and Joint Genome Institute and projects such as the Ma-
terials Project have an increasing need to capture, store,
and analyze dynamic semi-structured data and metadata.
A similar growth of semi-structured data within large In-
ternet service providers has led to the creation of NoSQL
data stores for scalable indexing and MapReduce for scal-
able parallel analysis. MapReduce and NoSQL stores have
been applied to scientiﬁc data. Hadoop, the most popular
open source implementation of MapReduce, has been eval-
uated, utilized and modiﬁed for addressing the needs of dif-
ferent scientiﬁc analysis problems. ALS and the Materials
Project are using MongoDB, a document oriented NoSQL
store. However, there is a limited understanding of the per-
formance trade-oﬀs of using these two technologies together.
In this paper we evaluate the performance, scalability and
fault-tolerance of using MongoDB with Hadoop, towards the
goal of identifying the right software environment for scien-
tiﬁc data analysis.},
booktitle = {Proceedings of the 4th {ACM} workshop on {Scientific} cloud computing},
author = {Elif, Dede and Govindaraju, Madhusudhan and Gunter, Daniel},
year = {2013},
keywords = {Hadoop, MongoDB},
}

@article{pescatore_simple_nodate,
title = {A simple asthma prediction tool for preschool children with wheeze or cough},
issn = {0091-6749},
url = {http://www.sciencedirect.com/science/article/pii/S0091674913009111},
doi = {10.1016/j.jaci.2013.06.002},
abstract = {Background
Many preschool children have wheeze or cough, but only some have asthma later. Existing prediction tools are difficult to apply in clinical practice or exhibit methodological weaknesses.
Objective
We sought to develop a simple and robust tool for predicting asthma at school age in preschool children with wheeze or cough.
Methods
From a population-based cohort in Leicestershire, United Kingdom, we included 1- to 3-year-old subjects seeing a doctor for wheeze or cough and assessed the prevalence of asthma 5 years later. We considered only noninvasive predictors that are easy to assess in primary care: demographic and perinatal data, eczema, upper and lower respiratory tract symptoms, and family history of atopy. We developed a model using logistic regression, avoided overfitting with the least absolute shrinkage and selection operator penalty, and then simplified it to a practical tool. We performed internal validation and assessed its predictive performance using the scaled Brier score and the area under the receiver operating characteristic curve.
Results
Of 1226 symptomatic children with follow-up information, 345 (28\%) had asthma 5 years later. The tool consists of 10 predictors yielding a total score between 0 and 15: sex, age, wheeze without colds, wheeze frequency, activity disturbance, shortness of breath, exercise-related and aeroallergen-related wheeze/cough, eczema, and parental history of asthma/bronchitis. The scaled Brier scores for the internally validated model and tool were 0.20 and 0.16, and the areas under the receiver operating characteristic curves were 0.76 and 0.74, respectively.
Conclusion
This tool represents a simple, low-cost, and noninvasive method to predict the risk of later asthma in symptomatic preschool children, which is ready to be tested in other populations.},
urldate = {2013-09-16},
journal = {Journal of Allergy and Clinical Immunology},
author = {Pescatore, Anina M. and Dogaru, Cristian M. and Duembgen, Lutz and Silverman, Michael and Gaillard, Erol A. and Spycher, Ben D. and Kuehni, Claudia E.},
keywords = {Asthma, PCCI, Prediction},
}

@article{spycher_genome-wide_2012,
title = {Genome-wide prediction of childhood asthma and related phenotypes in a longitudinal birth cohort},
volume = {130},
issn = {0091-6749},
url = {http://www.sciencedirect.com/science/article/pii/S0091674912009475},
doi = {10.1016/j.jaci.2012.06.002},
abstract = {Background
Childhood wheezing and asthma vary greatly in clinical presentation and time course. The extent to which phenotypic variation reflects heterogeneity in disease pathways is unclear.
Objective
We sought to assess the extent to which single nucleotide polymorphisms (SNPs) associated with childhood asthma in a genome-wide association study are predictive of asthma-related phenotypes.
Methods
In 8365 children from a population-based birth cohort, the Avon Longitudinal Study of Parents and Children, allelic scores were derived based on between 10 and 215,443 SNPs ranked according to the inverse of the P value for their association with physician-diagnosed asthma in an independent genome-wide association study (6176 cases and 7111 control subjects). We assessed the predictive value of allelic scores for asthma-related outcomes at age 7 to 9 years (physician’s diagnosis, longitudinal wheezing phenotypes, and measurements of pulmonary function, bronchial responsiveness, and atopy).
Results
Scores based on the 46 highest-ranked SNPs were associated with the symptom-based phenotypes early onset persistent wheeze (P \&lt; 10−11; area under the receiver operating characteristic curve [AUC], 0.59) and intermediate-onset wheeze (P \&lt; 10−3; AUC, 0.58). Among lower-ranked SNPs (ranks, 21,545-46,416), there was evidence for associations with diagnosed asthma (P \&lt; 10−4; AUC, 0.54) and atopy (P \&lt; 10−5; AUC, 0.55). We found little evidence of associations with transient early wheezing, reduced pulmonary function, or nonasthma phenotypes.
Conclusion
The genetic origins of asthma are diverse, and some pathways are specific to wheezing syndromes, whereas others are shared with atopy and bronchial hyperresponsiveness. Our study also provides evidence of etiologic differences among wheezing syndromes.},
number = {2},
urldate = {2013-09-16},
journal = {Journal of Allergy and Clinical Immunology},
author = {Spycher, Ben D. and Henderson, John and Granell, Raquel and Evans, David M. and Smith, George Davey and Timpson, Nicholas J. and Sterne, Jonathan A.C.},
month = aug,
year = {2012},
keywords = {Asthma, PCCI},
pages = {503--509.e7},
}

@article{savenije_predicting_2012,
title = {Predicting who will have asthma at school age among preschool children},
volume = {130},
issn = {0091-6749},
url = {http://www.sciencedirect.com/science/article/pii/S0091674912007804},
doi = {10.1016/j.jaci.2012.05.007},
abstract = {It is difficult to distinguish at preschool age whether a wheezing child will or will not have asthma at school age. A prediction rule for asthma in preschool children might help to determine a prognosis and to study improvements in treatment and prevention. This review discusses (1) the development and use of clinical prediction rules, (2) the European Respiratory Society Task Force classification of wheeze at preschool age, (3) published prediction rules developed to identify preschool children who will have asthma at school age, and (4) recommendations to improve asthma prediction. Prediction rules are currently created more frequently, yet their clinical use remains low. The classification of episodic wheeze and multiple-trigger wheeze in preschool children shows conflicting results as to whether episodic wheeze and multiple-trigger wheeze differ in clinical features and has limited value in predicting asthma at school age. Clearly, more studies are needed to confirm this. Currently available prediction rules aiming to identify preschool children having asthma at school age are of modest clinical value. Prediction can be improved by more precise definitions and measures and, ultimately, by more knowledge of pathophysiologic mechanisms. In the future, biomarkers and genomic risk profiles to develop personalized medicine might further improve asthma prediction, treatment, and prevention.},
number = {2},
urldate = {2013-09-16},
journal = {Journal of Allergy and Clinical Immunology},
author = {Savenije, Olga E.M. and Kerkhof, Marjan and Koppelman, Gerard H. and Postma, Dirkje S.},
month = aug,
year = {2012},
keywords = {Asthma, PCCI, Prediction},
pages = {325--331},
}

@article{holt_toward_2010,
title = {Toward improved prediction of risk for atopy and asthma among preschoolers: {A} prospective cohort study},
volume = {125},
issn = {0091-6749},
shorttitle = {Toward improved prediction of risk for atopy and asthma among preschoolers},
url = {http://www.sciencedirect.com/science/article/pii/S0091674909018156},
doi = {10.1016/j.jaci.2009.12.018},
abstract = {Background
Atopy and asthma are commonly initiated during early life, and there is increasing interest in the development of preventive treatments for at-risk children. However, effective methods for assessing the level of risk in individual children are lacking.
Objective
We sought to identify clinical and laboratory biomarkers in 2-year-olds that are predictive of the risk for persistent atopy and wheeze at age 5 years.
Methods
We prospectively studied 198 atopic family history–positive children to age 5 years. Clinical and laboratory assessments related to asthma history and atopy status were undertaken annually; episodes of acute respiratory illness were assessed and classified throughout and graded by severity.
Results
Aeroallergen-specific IgE titers cycled continuously within the low range in nonatopic subjects. Atopic subjects displayed similar cycling in infancy but eventually locked into a stable pattern of upwardly trending antibody production and TH2-polarized cellular immunity. The latter was associated with stable expression of IL-4 receptor in allergen-specific TH2 memory responses, which was absent from responses during infancy. Risk for persistent wheeze was strongly linked to early sensitization and in turn to early infection. Integration of these data by means of logistic regression revealed that attaining mite-specific IgE titers of greater than 0.20 kU/L by age 2 years was associated with a 12.7\% risk of persistent wheeze, increasing progressively to an 87.2\% risk with increasing numbers of severe lower respiratory tract illnesses experienced.
Conclusion
The risk for development of persistent wheeze in children can be quantified by means of integration of measures related to early sensitization and early infections. Follow-up studies along similar lines in larger unselected populations to refine this approach are warranted.},
number = {3},
urldate = {2013-09-16},
journal = {Journal of Allergy and Clinical Immunology},
author = {Holt, Patrick G. and Rowe, Julie and Kusel, Merci and Parsons, Faith and Hollams, Elysia M. and Bosco, Anthony and McKenna, Kathy and Subrata, Lily and de Klerk, Nicholas and Serralha, Michael and Holt, Barbara J. and Zhang, Guicheng and Loh, Richard and Ahlstedt, Staffan and Sly, Peter D.},
month = mar,
year = {2010},
keywords = {Asthma, PCCI, Prediction},
pages = {653--659.e7},
}

@article{leonardi_validation_2011,
title = {Validation of the {Asthma} {Predictive} {Index} and comparison with simpler clinical prediction rules},
volume = {127},
issn = {0091-6749},
url = {http://www.sciencedirect.com/science/article/pii/S009167491100368X},
doi = {10.1016/j.jaci.2011.03.001},
abstract = {Background
The loose and stringent Asthma Predictive Indices (API), developed in Tucson, are popular rules to predict asthma in preschool children. To be clinically useful, they require validation in different settings.
Objective
To assess the predictive performance of the API in an independent population and compare it with simpler rules based only on preschool wheeze.
Methods
We studied 1954 children of the population-based Leicester Respiratory Cohort, followed up from age 1 to 10 years. The API and frequency of wheeze were assessed at age 3 years, and we determined their association with asthma at ages 7 and 10 years by using logistic regression. We computed test characteristics and measures of predictive performance to validate the API and compare it with simpler rules.
Results
The ability of the API to predict asthma in Leicester was comparable to Tucson: for the loose API, odds ratios for asthma at age 7 years were 5.2 in Leicester (5.5 in Tucson), and positive predictive values were 26\% (26\%). For the stringent API, these values were 8.2 (9.8) and 40\% (48\%). For the simpler rule early wheeze, corresponding values were 5.4 and 21\%; for early frequent wheeze, 6.7 and 36\%. The discriminative ability of all prediction rules was moderate (c statistic ≤ 0.7) and overall predictive performance low (scaled Brier score \&lt; 20\%).
Conclusion
Predictive performance of the API in Leicester, although comparable to the original study, was modest and similar to prediction based only on preschool wheeze. This highlights the need for better prediction rules.},
number = {6},
urldate = {2013-09-16},
journal = {Journal of Allergy and Clinical Immunology},
author = {Leonardi, Nora A. and Spycher, Ben D. and Strippoli, Marie-Pierre F. and Frey, Urs and Silverman, Michael and Kuehni, Claudia E.},
month = jun,
year = {2011},
keywords = {Asthma, PCCI, Prediction},
pages = {1466--1472.e6},
}

@article{marenholz_interaction_2009,
title = {An interaction between filaggrin mutations and early food sensitization improves the prediction of childhood asthma},
volume = {123},
issn = {0091-6749},
url = {http://www.jacionline.org/article/S0091-6749(09)00171-7/abstract},
doi = {10.1016/j.jaci.2009.01.051},
abstract = {Background
Asthma prediction in early infancy is essential for the development of new preventive strategies. Loss-of-function mutations in the filaggrin gene (FLG) were identified as risk factors for eczema and associated asthma.
Objective
We evaluated the utility of the FLG mutations for the prediction of asthma.
Methods
Eight hundred seventy-one individuals of the prospective German Multicenter Allergy Study cohort were genotyped for 3 FLG mutations. Information on asthma, eczema, and food sensitization was available from birth to 13 years of age. Pulmonary function was measured from 7 to 13 years of age. The predictive value of the FLG mutations and of atopic phenotypes in infancy was assessed for asthma.
Results
In infants with eczema and sensitization to food allergens, the FLG mutations predicted childhood asthma with a positive predictive value of 100\% (95\% CI, 65.5\% to 100\%). This subgroup was characterized by a significant decrease in pulmonary function until puberty and represented 8.1\% of all asthmatic children and 19.1\% of patients with asthma after infantile eczema. We found a strong synergistic interaction between the FLG-null alleles and early food sensitization in the disease transition from eczema to asthma (relative excess risk due to interaction, 2.64; 95\% CI, 1.70-3.98; P = .00040).
Conclusion
FLG mutations and food sensitization represent 2 distinct mechanisms interacting in the pathogenesis of asthma. In infants with eczema and food sensitization, genotyping of the FLG mutations allows the prediction of asthma before the onset of symptoms. Our findings might facilitate the development of early subgroup-specific interventions to prevent the progression from eczema to asthma.},
number = {4},
urldate = {2013-09-16},
journal = {Journal of Allergy and Clinical Immunology},
author = {Marenholz, Ingo and Kerscher, Tamara and Bauerfeind, Anja and Esparza-Gordillo, Jorge and Nickel, Renate and Keil, Thomas and Lau, Susanne and Rohde, Klaus and Wahn, Ulrich and Lee, Young-Ae},
month = apr,
year = {2009},
keywords = {Asthma, PCCI, Prediction},
pages = {911--916},
}

@article{guilbert_long-term_2006,
title = {Long-{Term} {Inhaled} {Corticosteroids} in {Preschool} {Children} at {High} {Risk} for {Asthma}},
volume = {354},
issn = {0028-4793},
url = {http://www.nejm.org/doi/full/10.1056/NEJMoa051378},
doi = {10.1056/NEJMoa051378},
abstract = {Studies of the natural history of asthma have shown that the initial symptoms commonly occur during the first years of life.1,2 Children with frequent wheezing (at least four episodes in the prior year) and either one major risk factor (a parental history of asthma or a personal history of atopic dermatitis) or two of three minor risk factors (allergic rhinitis, eosinophilia, and wheezing without colds) are thought to be at high risk.3 Although daily therapy with inhaled corticosteroids appears to be effective in reducing symptoms in high-risk young children with frequent wheezing,4–9 the long-term preventive effect of inhaled . . .},
number = {19},
urldate = {2013-09-16},
journal = {New England Journal of Medicine},
author = {Guilbert, Theresa W. and Morgan, Wayne J. and Zeiger, Robert S. and Mauger, David T. and Boehmer, Susan J. and Szefler, Stanley J. and Bacharier, Leonard B. and Lemanske, Robert F. and Strunk, Robert C. and Allen, David B. and Bloomberg, Gordon R. and Heldt, Gregory and Krawiec, Marzena and Larsen, Gary and Liu, Andrew H. and Chinchilli, Vernon M. and Sorkness, Christine A. and Taussig, Lynn M. and Martinez, Fernando D.},
year = {2006},
pmid = {16687711},
keywords = {Asthma, PCCI},
pages = {1985--1997},
}

@article{lodrup_carlsen_asthma_2010,
title = {Asthma prediction in school children; the value of combined {IgE}-antibodies and obstructive airways disease severity score*},
volume = {65},
copyright = {© 2010 John Wiley \& Sons A/S},
issn = {1398-9995},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1398-9995.2010.02344.x/abstract},
doi = {10.1111/j.1398-9995.2010.02344.x},
abstract = {To cite this article: Lødrup Carlsen KC, Söderström L, Mowinckel P, Håland G, Pettersen M, Munthe Kaas MC, Devulapalli CS, Buchmann M, Ahlstedt S, Carlsen K-H. Asthma prediction in school children; the value of combined IgE-antibodies and obstructive airways disease severity score. Allergy 2010; 65: 1134–1140.AbstractBackground: Allergic sensitisation increases the risk for asthma development. In this prospective birth cohort (Environment and Childhood Asthma) study, we hypothesized that combining quantitative measures of IgE antibodies (Σ-IgE) and Severity score of obstructive airways disease (OAD) at 2 years of age (Severity score) is superior to predict current asthma (CA) at 10 years than either measure alone. Secondarily, we assessed if gender modified the prediction of CA.Methods: A follow-up study at 10 years of age was performed in 371 2-year-old children with recurrent (n = 219) or no (n = 152) bronchial obstruction with available serum analysed for Σ-IgE to common food and inhalant allergens through a panel test, Phadiatop Infant® (Phadia, Uppsala, Sweden). Clinical variables included allergic sensitisation and exercise testing to characterise children with CA vs not CA at 10 years and the Severity score (0–12, 0 indicating no OAD) was used to assess risk modification.Results: Severity score alone explained 24\% (Nagelkerke R2 = 0.24) of the variation in CA, whereas Σ-IgE explained only 6\% (R2 = 0.06). Combining the two increased the explanatory capacity to R2 = 0.30. Gender interacted significantly with Σ-IgE; whereas Severity score predicted CA in both genders, the predictive capacity of Σ-IgE for CA at 10 years was significant in boys only.Conclusion: Combining Σ-IgE to inhalant allergens and Severity score at 2 years was superior to predict asthma at 10 years than either alone. Severity score predicted CA in both genders, whereas Σ-IgE significantly predicted CA in boys only.},
language = {en},
number = {9},
urldate = {2013-09-16},
journal = {Allergy},
author = {Lødrup Carlsen, K. C. and Söderström, L. and Mowinckel, P. and Håland, G. and Pettersen, M. and Munthe Kaas, M. C. and Devulapalli, C. S. and Buchmann, M. and Ahlstedt, S. and Carlsen, K.-H.},
year = {2010},
keywords = {Asthma, PCCI, Prediction},
pages = {1134--1140},
}

@article{paul_model_2012,
title = {A model for mining public health topics from {Twitter}},
volume = {11},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?rep=rep1&type=pdf&doi=10.1.1.226.4323},
urldate = {2013-09-06},
journal = {HEALTH},
author = {Paul, Michael J. and Dredze, Mark},
year = {2012},
keywords = {PCCI, Social Media, Twitter},
pages = {16--6},
}

@article{miller_active_2013,
title = {Active {Social} {Media} {Management}: {The} {Case} of {Health} {Care}},
volume = {24},
shorttitle = {Active {Social} {Media} {Management}},
url = {http://isr.journal.informs.org/content/24/1/52.short},
number = {1},
urldate = {2013-09-06},
journal = {Information Systems Research},
author = {Miller, Amalia R. and Tucker, Catherine},
year = {2013},
keywords = {PCCI, Social Media},
pages = {52--70},
}

@article{hawn_take_2009,
title = {Take {Two} {Aspirin} {And} {Tweet} {Me} {In} {The} {Morning}: {How} {Twitter}, {Facebook}, {And} {Other} {Social} {Media} {Are} {Reshaping} {Health} {Care}},
volume = {28},
issn = {0278-2715, 1544-5208},
shorttitle = {Take {Two} {Aspirin} {And} {Tweet} {Me} {In} {The} {Morning}},
url = {http://content.healthaffairs.org/content/28/2/361},
doi = {10.1377/hlthaff.28.2.361},
abstract = {If you want a glimpse of what health care could look like a few years from now, consider “Hello Health,” the Brooklyn-based primary care practice that is fast becoming an emblem of modern medicine. A paperless, concierge practice that eschews the limitations of insurance-based medicine, Hello Health is popular and successful, largely because of the powerful and cost-effective communication tools it employs: Web-based social media. Indeed, across the health care industry, from large hospital networks to patient support groups, new media tools like weblogs, instant messaging platforms, video chat, and social networks are reengineering the way doctors and patients interact.},
language = {en},
number = {2},
urldate = {2013-09-06},
journal = {Health Affairs},
author = {Hawn, Carleen},
month = mar,
year = {2009},
pmid = {19275991},
keywords = {Facebook, PCCI, Public Health, Social Media, Twitter},
pages = {361--368},
}

@article{hamm_social_2013,
title = {Social media use among patients and caregivers: a scoping review},
volume = {3},
issn = {2044-6055,},
shorttitle = {Social media use among patients and caregivers},
url = {http://bmjopen.bmj.com/content/3/5/e002819},
doi = {10.1136/bmjopen-2013-002819},
abstract = {Objective To map the state of the existing literature evaluating the use of social media in patient and caregiver populations.
Design Scoping review.
Data sources Medline, CENTRAL, ERIC, PubMed, CINAHL Plus Full Text, Academic Search Complete, Alt Health Watch, Health Source, Communication and Mass Media Complete, Web of Knowledge and ProQuest (2000–2012).
Study selection Studies reporting primary research on the use of social media (collaborative projects, blogs/microblogs, content communities, social networking sites, virtual worlds) by patients or caregivers.
Data extraction Two reviewers screened studies for eligibility; one reviewer extracted data from relevant studies and a second performed verification for accuracy and completeness on a 10\% sample. Data were analysed to describe which social media tools are being used, by whom, for what purpose and how they are being evaluated.
Results Two hundred eighty-four studies were included. Discussion forums were highly prevalent and constitute 66.6\% of the sample. Social networking sites (14.8\%) and blogs/microblogs (14.1\%) were the next most commonly used tools. The intended purpose of the tool was to facilitate self-care in 77.1\% of studies. While there were clusters of studies that focused on similar conditions (eg, lifestyle/weight loss (12.7\%), cancer (11.3\%)), there were no patterns in the objectives or tools used. A large proportion of the studies were descriptive (42.3\%); however, there were also 48 (16.9\%) randomised controlled trials (RCTs). Among the RCTs, 35.4\% reported statistically significant results favouring the social media intervention being evaluated; however, 72.9\% presented positive conclusions regarding the use of social media.
Conclusions There is an extensive body of literature examining the use of social media in patient and caregiver populations. Much of this work is descriptive; however, with such widespread use, evaluations of effectiveness are required. In studies that have examined effectiveness, positive conclusions are often reported, despite non-significant findings.},
language = {en},
number = {5},
urldate = {2013-09-06},
journal = {BMJ Open},
author = {Hamm, Michele P. and Chisholm, Annabritt and Shulhan, Jocelyn and Milne, Andrea and Scott, Shannon D. and Given, Lisa M. and Hartling, Lisa},
month = jan,
year = {2013},
pmid = {23667163},
keywords = {PCCI, Public Health, Social Media},
pages = {e002819},
}

@article{centola_social_2013,
title = {Social {Media} and the {Science} of {Health} {Behavior}},
volume = {127},
issn = {0009-7322, 1524-4539},
url = {http://circ.ahajournals.org/content/127/21/2135},
doi = {10.1161/CIRCULATIONAHA.112.101816},
language = {en},
number = {21},
urldate = {2013-09-06},
journal = {Circulation},
author = {Centola, Damon},
month = may,
year = {2013},
pmid = {23716382},
keywords = {PCCI, Public Health, Social Media},
pages = {2135--2144},
}

@article{chretien_social_2013,
title = {Social {Media} and {Clinical} {Care} {Ethical}, {Professional}, and {Social} {Implications}},
volume = {127},
issn = {0009-7322, 1524-4539},
url = {http://circ.ahajournals.org/content/127/13/1413},
doi = {10.1161/CIRCULATIONAHA.112.128017},
language = {en},
number = {13},
urldate = {2013-09-06},
journal = {Circulation},
author = {Chretien, Katherine C. and Kind, Terry},
month = apr,
year = {2013},
pmid = {23547180},
keywords = {PCCI, Social Media},
pages = {1413--1421},
}

@article{centola_social_2013-1,
title = {Social {Media} as a {Tool} in {Medicine}},
volume = {127},
url = {http://dcentola.net/Centola%202013%20Social%20Media%20and%20Health.pdf},
urldate = {2013-09-06},
journal = {Circulation},
author = {Centola, Damon},
year = {2013},
keywords = {PCCI, Public Health, Social Media},
pages = {2135--2144},
}

@article{huang_connecting_2013,
title = {Connecting to patients via social media: {A} hype or a reality?},
volume = {13},
issn = {1745-7904, 1745-7912},
shorttitle = {Connecting to patients via social media},
url = {http://mmj.sagepub.com/content/13/1/14},
doi = {10.1177/1745790413477647},
abstract = {Although healthcare professionals have done much to take advantage of social media for healthcare purposes, few empirical studies have investigated such practices. It is not known whether hospitals are using social media mainly as a marketing tool or as a way to friend, listen to, and interact with their visitors. Through a content analysis of 23,300 posts/tweets on 172 US hospitals’ Facebook and Twitter pages in a systematic probability sample, this study found that the flow of information on hospital Facebook pages, and especially Twitter pages, is dominantly one-way; nevertheless, hospitals, especially larger hospitals, have made great effort to interact with their Facebook visitors while marketing themselves, though such interaction is minimal. The study also found that it is very important for hospitals to encourage a large visitor base on Facebook because the more visitors a hospital attracts to its Facebook page, the more ‘Likes’ and posts the hospital will attract, the more people will comment on the hospital posts, and the more the hospital will get recommended. The comparison between the traffic on Facebook and on Twitter demonstrates that using social media as a two-way communication channel seems to be much more effective for hospitals to connect to their visitors than using them as a one-way marketing tool.},
language = {en},
number = {1},
urldate = {2013-09-06},
journal = {Journal of Medical Marketing: Device, Diagnostic and Pharmaceutical Marketing},
author = {Huang, Edgar and Dunbar, Christina L.},
month = feb,
year = {2013},
keywords = {PCCI, Social Media},
pages = {14--23},
}